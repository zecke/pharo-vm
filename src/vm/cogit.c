/* Automatically generated by
	CCodeGenerator VMMaker.oscog-jeanbaptistearnaud.782 uuid: 4529b9a2-dbec-4078-83aa-46de2ee4ed38
   from
	NBCogit NativeBoost-CogPlugin-HolgerHansPeterFreyther.21 uuid: e0df6e2d-5694-40e2-8035-dc217200b424
 */
static char __buildInfo[] = "NBCogit NativeBoost-CogPlugin-HolgerHansPeterFreyther.21 uuid: e0df6e2d-5694-40e2-8035-dc217200b424 " __DATE__ ;
char *__cogitBuildInfo = __buildInfo;



#include <stddef.h>
#include <setjmp.h>
#include "sq.h"
#include "sqCogStackAlignment.h"
#include "cogmethod.h"
#if COGMTVM
#include "cointerpmt.h"
#else
#include "cointerp.h"
#endif
#include "cogit.h"
#include "dispdbg.h"

typedef struct _AbstractInstruction {
	char	opcode;
	char	machineCodeSize;
	char	maxSize;
	unsigned long		operands [3];
	unsigned long	address;
	struct _AbstractInstruction *dependent;
	unsigned char		machineCode [10];
 } AbstractInstruction;

#define CogIA32Compiler AbstractInstruction


typedef struct {
	AbstractInstruction *fakeHeader;
	AbstractInstruction *fillInstruction;
	sqInt	numArgs;
	sqInt	numCopied;
	sqInt	numInitialNils;
	sqInt	startpc;
	AbstractInstruction *entryLabel;
	AbstractInstruction *stackCheckLabel;
	sqInt	span;
 } BlockStart;

#define CogBlockStart BlockStart


typedef struct _BytecodeDescriptor {
	sqInt (*generator )(void);
	sqInt (*spanFunction )(struct _BytecodeDescriptor *,sqInt,sqInt,sqInt);
	sqInt (*needsFrameFunction )(sqInt);
	signed char	stackDelta;
	unsigned char	opcode;
	unsigned char	numBytes;
	unsigned		isBranchTrue : 1;
	unsigned		isBranchFalse : 1;
	unsigned		isReturn : 1;
	unsigned		isBlockCreation : 1;
	unsigned		isMapped : 1;
	unsigned		isMappedInBlock : 1;
	unsigned		isExtension : 1;
 } BytecodeDescriptor;

#define CogBytecodeDescriptor BytecodeDescriptor


typedef struct {
	sqInt	annotation;
	AbstractInstruction *instruction;
 } InstructionAnnotation;

#define CogInstructionAnnotation InstructionAnnotation


typedef struct {
	sqInt (*primitiveGenerator )(void);
	sqInt	primNumArgs;
	sqInt (*enabled )(sqInt);
 } PrimitiveDescriptor;

#define CogPrimitiveDescriptor PrimitiveDescriptor


typedef struct {
	AbstractInstruction *targetInstruction;
	sqInt	instructionIndex;
	sqInt	simStackPtr;
 } BytecodeFixup;

#define CogSSBytecodeFixup BytecodeFixup


typedef struct {
	char	type;
	char	spilled;
	char	annotateUse;
	sqInt	registerr;
	sqInt	offset;
	sqInt	constant;
	sqInt	bcptr;
 } CogSimStackEntry;


typedef struct {
	sqInt	isReceiverResultRegLive;
	CogSimStackEntry *ssEntry;
 } CogSSOptStatus;



/*** Constants ***/
#define AddCqR 90
#define AddCwR 97
#define AddRdRd 104
#define AddRR 83
#define AlignmentNops 2
#define AllButTypeMask 0xFFFFFFFCUL
#define AltBlockCreationBytecodeSize null
#define AltNSSendIsPCAnnotated null
#define AndCqR 92
#define AndCwR 99
#define AndRR 85
#define AnnotationShift 5
#define Arg0Reg -7
#define Arg1Reg -8
#define ArithmeticShiftRightCqR 76
#define ArithmeticShiftRightRR 77
#define BadRegisterSet 1
#define BlockCreationBytecodeSize 4
#define Call 9
#define CDQ 110
#define ClassMethodContextCompactIndex 14
#define ClassReg -5
#define ClosureFirstCopiedValueIndex 3
#define ClosureNumArgsIndex 2
#define ClosureOuterContextIndex 0
#define ClosureStartPCIndex 1
#define CMBlock 3
#define CMClosedPIC 4
#define CMFree 1
#define CMMaxUsageCount 7
#define CMMethod 2
#define CMOpenPIC 5
#define CMPXCHGAwR 118
#define CMPXCHGMwrR 119
#define CmpCqR 89
#define CmpCwR 96
#define CmpRdRd 103
#define CmpRR 82
#define CompactClasses 28
#define ConstZero 1
#define ConvertRRd 109
#define CPUID 113
#define Debug DEBUGVM
#define DisplacementMask 0x1F
#define DisplacementX2N 32
#define DivRdRd 107
#define DPFPReg0 -9
#define DPFPReg1 -10
#define DPFPReg2 -11
#define DPFPReg3 -12
#define DPFPReg4 -13
#define DPFPReg5 -14
#define DPFPReg6 -15
#define DPFPReg7 -16
#define EAX 0
#define EBP 5
#define EBX 3
#define ECX 1
#define EDI 7
#define EDX 2
#define EncounteredUnknownBytecode -6
#define ESI 6
#define ESP 4
#define Fill16 5
#define Fill32 6
#define FillFromWord 7
#define FirstAnnotation 64
#define FirstJump 12
#define FirstShortJump 15
#define FoxCallerSavedIP 4
#define FoxMethod -4
#define FoxMFReceiver -12
#define FoxThisContext -8
#define FPReg -1
#define GCModeBecome 4
#define GCModeFull 1
#define GCModeIncr 2
#define GCModeScavenge 3
#define GPRegMax -3
#define GPRegMin -8
#define HasBytecodePC 5
#define HashBitsOffset 17
#define HashMaskUnshifted 0xFFF
#define HeaderIndex 0
#define HeaderTypeShort 3
#define HeaderTypeSizeAndClass 0
#define IDIVR 111
#define IMULRR 112
#define InstanceSpecificationIndex 2
#define InstructionPointerIndex 1
#define InsufficientCodeSpace -2
#define IsAbsPCReference 4
#define IsDisplacementX2N 1
#define IsNSSendCall null
#define IsObjectReference 3
#define IsRelativeCall 6
#define IsSendCall 7
#define Jump 15
#define JumpAbove 30
#define JumpAboveOrEqual 29
#define JumpBelow 28
#define JumpBelowOrEqual 31
#define JumpCarry 22
#define JumpFPEqual 32
#define JumpFPGreater 36
#define JumpFPGreaterOrEqual 37
#define JumpFPLess 34
#define JumpFPLessOrEqual 35
#define JumpFPNotEqual 33
#define JumpFPOrdered 38
#define JumpFPUnordered 39
#define JumpGreater 26
#define JumpGreaterOrEqual 25
#define JumpLess 24
#define JumpLessOrEqual 27
#define JumpLong 12
#define JumpLongNonZero 14
#define JumpLongZero 13
#define JumpNegative 18
#define JumpNoCarry 23
#define JumpNonNegative 19
#define JumpNonZero 17
#define JumpNoOverflow 21
#define JumpOverflow 20
#define JumpR 11
#define JumpZero 16
#define Label 1
#define LastJump 39
#define LFENCE 114
#define LinkReg -17
#define LOCK 117
#define LoadEffectiveAddressMwrR 73
#define LogicalShiftLeftCqR 80
#define LogicalShiftLeftRR 81
#define LogicalShiftRightCqR 78
#define LogicalShiftRightRR 79
#define LongSizeMask 0xFFFFFFFCUL
#define MapEnd 0
#define MaxCompiledPrimitiveIndex 222
#define MaxMethodSize 65535
#define MaxNegativeErrorCode -7
#define MaxNumArgs 15
#define MaxStackAllocSize 1572864
#define MaxStackCheckOffset 0xFFF
#define MaxUnitDisplacement 31
#define MaxX2NDisplacement 992
#define MethodCacheClass 2
#define MethodCacheMask 0xFFC
#define MethodCacheMethod 3
#define MethodCacheSelector 1
#define MethodIndex 3
#define MethodTooBig -4
#define MFENCE 115
#define MFMethodFlagHasContextFlag 1
#define MFMethodFlagIsBlockFlag 2
#define ModReg 3
#define ModRegInd 0
#define ModRegRegDisp32 2
#define ModRegRegDisp8 1
#define MoveAwR 41
#define MoveCqR 62
#define MoveCwR 63
#define MoveM16rR 50
#define MoveM64rRd 67
#define MoveMbrR 58
#define MoveMwrR 44
#define MoveRAw 42
#define MoveRdM64r 68
#define MoveRdRd 66
#define MoveRMbr 59
#define MoveRMwr 45
#define MoveRR 40
#define MoveRXbrR 61
#define MoveRXwrR 47
#define MoveXbrRR 60
#define MoveXwrRR 46
#define MULTIPLEBYTECODESETS 0
#define MulRdRd 106
#define NegateR 75
#define NewspeakVM 0
#define Nop 8
#define NotFullyInitialized -1
#define NSSendIsPCAnnotated null
#define NumObjRefsInRuntime 2
#define NumSendTrampolines 4
#define NumTrampolines 52
#define OrCqR 93
#define OrCwR 100
#define OrRR 86
#define PopR 69
#define PrefetchAw 72
#define PrimCallCollectsProfileSamples 8
#define PrimCallMayCallBack 4
#define PrimCallNeedsNewMethod 1
#define PrimCallNeedsPrimitiveFunction 2
#define PrimErrWritePastObject 17
#define PushCw 71
#define PushR 70
#define ReceiverIndex 5
#define ReceiverResultReg -3
#define RetN 10
#define RootBit 0x40000000
#define RootBitDigitLength 4
#define SelectorCannotInterpret 34
#define SelectorDoesNotUnderstand 20
#define SenderIndex 0
#define SendNumArgsReg -6
#define SFENCE 116
#define ShiftForWord 2
#define SIB1 0
#define SIB4 2
#define Size4Bit 0
#define SizeMask 0xFC
#define SPReg -2
#define SqrtRd 108
#define SSBaseOffset 1
#define SSConstant 2
#define SSRegister 3
#define SSSpill 4
#define SubCqR 91
#define SubCwR 98
#define SubRdRd 105
#define SubRR 84
#define TempReg -4
#define TypeMask 0x3
#define UnimplementedPrimitive -7
#define ValueIndex 1
#define XCHGAwR 120
#define XCHGMwrR 121
#define XCHGRR 122
#define XMM0L 0
#define XMM1L 2
#define XMM2L 4
#define XMM3L 6
#define XMM4L 8
#define XMM5L 10
#define XMM6L 12
#define XMM7L 14
#define XorCwR 101
#define XorRR 87
#define YoungSelectorInPIC -5


/*** Function Prototypes ***/


#if defined(PRODUCTION) && !PRODUCTION && defined(__GNUC__) && !defined(NoDbgRegParms)
# define NoDbgRegParms __attribute__ ((regparm (0)))
#endif

#if !defined(NoDbgRegParms)
# define NoDbgRegParms /*empty*/
#endif

static AbstractInstruction * gAndCqR(sqInt quickConstant, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gArithmeticShiftRightRR(sqInt reg1, sqInt reg2) NoDbgRegParms;
sqInt abortOffset(void);
static sqInt abstractInstructionfollows(AbstractInstruction *theAbstractInstruction, AbstractInstruction *anAbstractInstruction) NoDbgRegParms;
static sqInt abstractRegisterForConcreteRegister(AbstractInstruction * self_in_abstractRegisterForConcreteRegister, sqInt reg) NoDbgRegParms;
static BlockStart * addBlockStartAtnumArgsnumCopiedspan(sqInt bytecodepc, sqInt numArgs, sqInt numCopied, sqInt span) NoDbgRegParms;
static void addCleanBlockStarts(void);
void addCogMethodsToHeapMap(void);
static AbstractInstruction * addDependent(AbstractInstruction * self_in_addDependent, AbstractInstruction *anInstruction) NoDbgRegParms;
static sqInt addressIsInFixups(AbstractInstruction *address) NoDbgRegParms;
static sqInt addressIsInInstructions(AbstractInstruction *address) NoDbgRegParms;
static sqInt addressOfEndOfCaseinCPIC(sqInt n, CogMethod *cPIC) NoDbgRegParms;
static void addToOpenPICList(CogMethod *anOpenPIC) NoDbgRegParms;
static void addToYoungReferrers(CogMethod *cogMethod) NoDbgRegParms;
static sqInt alignUptoRoutineBoundary(sqInt anAddress) NoDbgRegParms;
static sqInt allMachineCodeObjectReferencesValid(void);
static sqInt allMethodsHaveCorrectHeader(void);
static sqInt allocate(sqInt numBytes) NoDbgRegParms;
static sqInt allYoungObjectsAgeInFullGC(void);
static AbstractInstruction * annotateAbsolutePCRef(AbstractInstruction *abstractInstruction) NoDbgRegParms;
static void annotateBytecodeIfAnnotated(CogSimStackEntry *aSimStackEntry) NoDbgRegParms;
static AbstractInstruction * annotateBytecode(AbstractInstruction *abstractInstruction) NoDbgRegParms;
static AbstractInstruction * annotateobjRef(AbstractInstruction *abstractInstruction, sqInt anOop) NoDbgRegParms;
static AbstractInstruction * annotatewith(AbstractInstruction *abstractInstruction, sqInt annotationFlag) NoDbgRegParms;
static sqInt anyReferencesToRegisterinTopNItems(sqInt reg, sqInt n) NoDbgRegParms;
static void assertSaneJumpTarget(AbstractInstruction *jumpTarget) NoDbgRegParms;
static sqInt blockCreationBytecodeSizeForHeader(sqInt methodHeader) NoDbgRegParms;
static sqInt blockDispatchTargetsForperformarg(CogMethod *cogMethod, usqInt (*binaryFunction)(sqInt mcpc, sqInt arg), sqInt arg) NoDbgRegParms;
sqInt bytecodePCForstartBcpcin(sqInt mcpc, sqInt startbcpc, CogBlockMethod *cogMethod);
static AbstractInstruction * CallRT(sqInt callTarget) NoDbgRegParms;
static AbstractInstruction * CallRTregistersToBeSavedMask(sqInt callTarget, sqInt registersToBeSaved) NoDbgRegParms;
static AbstractInstruction * CallSend(sqInt callTarget) NoDbgRegParms;
static AbstractInstruction * gCall(sqInt callTarget) NoDbgRegParms;
static AbstractInstruction * gCmpCqR(sqInt quickConstant, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gCmpCwR(sqInt wordConstant, sqInt reg) NoDbgRegParms;
static sqInt cacheTagIsMarked(sqInt cacheTag) NoDbgRegParms;
static sqInt callerSavedRegisterMask(AbstractInstruction * self_in_callerSavedRegisterMask) NoDbgRegParms;
static sqInt callInstructionByteSize(AbstractInstruction * self_in_callInstructionByteSize) NoDbgRegParms;
static sqInt callsAreRelative(AbstractInstruction * self_in_callsAreRelative) NoDbgRegParms;
static sqInt callTargetFromReturnAddress(AbstractInstruction * self_in_callTargetFromReturnAddress, sqInt callSiteReturnAddress) NoDbgRegParms;
static sqInt canDivQuoRem(AbstractInstruction * self_in_canDivQuoRem) NoDbgRegParms;
sqInt canLinkToYoungClasses(void);
static sqInt canMulRR(AbstractInstruction * self_in_canMulRR) NoDbgRegParms;
static sqInt ceClosureCopyDescriptor(sqInt descriptor) NoDbgRegParms;
sqInt ceCPICMissreceiver(CogMethod *cPIC, sqInt receiver);
sqInt ceSICMiss(sqInt receiver);
void checkAssertsEnabledInCogit(void);
static sqInt checkIfValidOopRefAndTargetpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod) NoDbgRegParms;
static sqInt checkIfValidOopRefpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod) NoDbgRegParms;
sqInt checkIntegrityOfObjectReferencesInCode(sqInt fullGCFlag);
static sqInt checkMaybeObjRefAt(sqInt mcpc) NoDbgRegParms;
static void checkPrimitiveTableEnablers(void);
static sqInt checkValidInlineCacheTag(sqInt cacheTag) NoDbgRegParms;
static sqInt checkValidObjectReferencesInClosedPIC(CogMethod *cPIC) NoDbgRegParms;
static sqInt checkValidObjectReference(sqInt anOop) NoDbgRegParms;
static sqInt checkValidOopReference(sqInt anOop) NoDbgRegParms;
static void clearCogCompiledCode(void);
static sqInt closedPICRefersToUnmarkedObject(CogMethod *cPIC) NoDbgRegParms;
static CogMethod * cmHomeMethod(CogBlockMethod * self_in_cmHomeMethod) NoDbgRegParms;
char * codeEntryFor(char *address);
char * codeEntryNameFor(char *address);
sqInt cogCodeBase(void);
sqInt cogCodeConstituents(void);
static sqInt cogExtendPICCaseNMethodtagisMNUCase(CogMethod *cPIC, sqInt caseNMethod, sqInt caseNTag, sqInt isMNUCase) NoDbgRegParms;
void cogitPostGCAction(sqInt gcMode);
sqInt cogMethodDoesntLookKosher(CogMethod *cogMethod);
CogMethod * cogMNUPICSelectormethodOperandnumArgs(sqInt selector, sqInt methodOperand, sqInt numArgs);
static CogMethod * cogOpenPICSelectornumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static CogMethod * cogPICSelectornumArgsCase0MethodCase1MethodtagisMNUCase(sqInt selector, sqInt numArgs, CogMethod *case0CogMethod, sqInt case1MethodOrNil, sqInt case1Tag, sqInt isMNUCase) NoDbgRegParms;
CogMethod * cogselector(sqInt aMethodObj, sqInt aSelectorOop);
void compactCogCompiledCode(void);
static void compactCompiledCode(void);
static void compileAbort(void);
static sqInt compileAbstractInstructionsFromthrough(sqInt start, sqInt end) NoDbgRegParms;
static sqInt compileBlockBodies(void);
static sqInt compileBlockDispatch(void);
static sqInt compileBlockDispatchFromto(sqInt lowBlockStartIndex, sqInt highBlockStartIndex) NoDbgRegParms;
static void compileBlockEntry(BlockStart *blockStart) NoDbgRegParms;
static void compileBlockFrameBuild(BlockStart *blockStart) NoDbgRegParms;
static void compileBlockFramelessEntry(BlockStart *blockStart) NoDbgRegParms;
static sqInt compileClosedPICPrototype(void);
static CogMethod * compileCogMethod(sqInt selector) NoDbgRegParms;
static AbstractInstruction * compileCPICEntry(void);
static sqInt compileCPICCase0Case1MethodtagisMNUCasenumArgs(CogMethod *cPIC, CogMethod *case0CogMethod, sqInt case1Method, sqInt case1Tag, sqInt isMNUCase, sqInt numArgs) NoDbgRegParms;
static sqInt compileEntireMethod(void);
static void compileEntry(void);
static sqInt compileFallbackToInterpreterPrimitive(void);
static sqInt compileFrameBuild(void);
static void compileGetErrorCode(void);
static sqInt compileInterpreterPrimitive(void (*primitiveRoutine)(void)) NoDbgRegParms;
static sqInt compileMethodBody(void);
static sqInt compileMNUCPICmethodOperandnumArgs(CogMethod *cPIC, sqInt methodOperand, sqInt numArgs) NoDbgRegParms;
static void compileOpenPICnumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static sqInt compilePICProlog(sqInt numArgs) NoDbgRegParms;
static sqInt compilePrimitive(void);
static void compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNil) NoDbgRegParms;
static void computeEntryOffsets(void);
static sqInt computeJumpTargetOffsetPlus(AbstractInstruction * self_in_computeJumpTargetOffsetPlus, sqInt anPCOffset) NoDbgRegParms;
static sqInt computeMaximumSize(AbstractInstruction * self_in_computeMaximumSize) NoDbgRegParms;
static void computeMaximumSizes(void);
static sqInt computeShiftRRSize(AbstractInstruction * self_in_computeShiftRRSize) NoDbgRegParms;
static sqInt concreteDPFPRegister(AbstractInstruction * self_in_concreteDPFPRegister, sqInt registerIndex) NoDbgRegParms;
static sqInt concreteRegister(AbstractInstruction * self_in_concreteRegister, sqInt registerIndex) NoDbgRegParms;
static sqInt concretizeAddCqR(AbstractInstruction * self_in_concretizeAddCqR) NoDbgRegParms;
static sqInt concretizeAddCwR(AbstractInstruction * self_in_concretizeAddCwR) NoDbgRegParms;
static sqInt concretizeAddRR(AbstractInstruction * self_in_concretizeAddRR) NoDbgRegParms;
static AbstractInstruction * concretizeAlignmentNops(AbstractInstruction * self_in_concretizeAlignmentNops) NoDbgRegParms;
static sqInt concretizeAndCqR(AbstractInstruction * self_in_concretizeAndCqR) NoDbgRegParms;
static sqInt concretizeAndCwR(AbstractInstruction * self_in_concretizeAndCwR) NoDbgRegParms;
static sqInt concretizeAndRR(AbstractInstruction * self_in_concretizeAndRR) NoDbgRegParms;
static sqInt concretizeArithmeticShiftRightCqR(AbstractInstruction * self_in_concretizeArithmeticShiftRightCqR) NoDbgRegParms;
static sqInt concretizeArithmeticShiftRightRR(AbstractInstruction * self_in_concretizeArithmeticShiftRightRR) NoDbgRegParms;
static sqInt concretizeAt(AbstractInstruction * self_in_concretizeAt, sqInt actualAddress) NoDbgRegParms;
static sqInt concretizeCall(AbstractInstruction * self_in_concretizeCall) NoDbgRegParms;
static sqInt concretizeCDQ(AbstractInstruction * self_in_concretizeCDQ) NoDbgRegParms;
static sqInt concretizeCMPXCHGAwR(AbstractInstruction * self_in_concretizeCMPXCHGAwR) NoDbgRegParms;
static sqInt concretizeCMPXCHGMwrR(AbstractInstruction * self_in_concretizeCMPXCHGMwrR) NoDbgRegParms;
static sqInt concretizeCmpCqR(AbstractInstruction * self_in_concretizeCmpCqR) NoDbgRegParms;
static sqInt concretizeCmpCwR(AbstractInstruction * self_in_concretizeCmpCwR) NoDbgRegParms;
static sqInt concretizeCmpRdRd(AbstractInstruction * self_in_concretizeCmpRdRd) NoDbgRegParms;
static sqInt concretizeCmpRR(AbstractInstruction * self_in_concretizeCmpRR) NoDbgRegParms;
static sqInt concretizeConditionalJumpLong(AbstractInstruction * self_in_concretizeConditionalJumpLong, sqInt conditionCode) NoDbgRegParms;
static sqInt concretizeConditionalJump(AbstractInstruction * self_in_concretizeConditionalJump, sqInt conditionCode) NoDbgRegParms;
static sqInt concretizeConvertRRd(AbstractInstruction * self_in_concretizeConvertRRd) NoDbgRegParms;
static sqInt concretizeCPUID(AbstractInstruction * self_in_concretizeCPUID) NoDbgRegParms;
static sqInt concretizeFENCE(AbstractInstruction * self_in_concretizeFENCE, sqInt regOpcode) NoDbgRegParms;
static sqInt concretizeFill16(AbstractInstruction * self_in_concretizeFill16) NoDbgRegParms;
static sqInt concretizeFill32(AbstractInstruction * self_in_concretizeFill32) NoDbgRegParms;
static sqInt concretizeFillFromWord(AbstractInstruction * self_in_concretizeFillFromWord) NoDbgRegParms;
static sqInt concretizeIDIVR(AbstractInstruction * self_in_concretizeIDIVR) NoDbgRegParms;
static sqInt concretizeJump(AbstractInstruction * self_in_concretizeJump) NoDbgRegParms;
static sqInt concretizeJumpLong(AbstractInstruction * self_in_concretizeJumpLong) NoDbgRegParms;
static sqInt concretizeJumpR(AbstractInstruction * self_in_concretizeJumpR) NoDbgRegParms;
static sqInt concretizeLabel(AbstractInstruction * self_in_concretizeLabel) NoDbgRegParms;
static sqInt concretizeLOCK(AbstractInstruction * self_in_concretizeLOCK) NoDbgRegParms;
static sqInt concretizeLoadEffectiveAddressMwrR(AbstractInstruction * self_in_concretizeLoadEffectiveAddressMwrR) NoDbgRegParms;
static sqInt concretizeLogicalShiftLeftCqR(AbstractInstruction * self_in_concretizeLogicalShiftLeftCqR) NoDbgRegParms;
static sqInt concretizeLogicalShiftLeftRR(AbstractInstruction * self_in_concretizeLogicalShiftLeftRR) NoDbgRegParms;
static sqInt concretizeLogicalShiftRightCqR(AbstractInstruction * self_in_concretizeLogicalShiftRightCqR) NoDbgRegParms;
static sqInt concretizeMoveAwR(AbstractInstruction * self_in_concretizeMoveAwR) NoDbgRegParms;
static sqInt concretizeMoveCqR(AbstractInstruction * self_in_concretizeMoveCqR) NoDbgRegParms;
static sqInt concretizeMoveCwR(AbstractInstruction * self_in_concretizeMoveCwR) NoDbgRegParms;
static sqInt concretizeMoveM16rR(AbstractInstruction * self_in_concretizeMoveM16rR) NoDbgRegParms;
static sqInt concretizeMoveM64rRd(AbstractInstruction * self_in_concretizeMoveM64rRd) NoDbgRegParms;
static sqInt concretizeMoveMbrR(AbstractInstruction * self_in_concretizeMoveMbrR) NoDbgRegParms;
static sqInt concretizeMoveMwrR(AbstractInstruction * self_in_concretizeMoveMwrR) NoDbgRegParms;
static sqInt concretizeMoveRAw(AbstractInstruction * self_in_concretizeMoveRAw) NoDbgRegParms;
static sqInt concretizeMoveRdM64r(AbstractInstruction * self_in_concretizeMoveRdM64r) NoDbgRegParms;
static sqInt concretizeMoveRMbr(AbstractInstruction * self_in_concretizeMoveRMbr) NoDbgRegParms;
static sqInt concretizeMoveRMwr(AbstractInstruction * self_in_concretizeMoveRMwr) NoDbgRegParms;
static sqInt concretizeMoveRR(AbstractInstruction * self_in_concretizeMoveRR) NoDbgRegParms;
static sqInt concretizeMoveRXbrR(AbstractInstruction * self_in_concretizeMoveRXbrR) NoDbgRegParms;
static sqInt concretizeMoveRXwrR(AbstractInstruction * self_in_concretizeMoveRXwrR) NoDbgRegParms;
static sqInt concretizeMoveXbrRR(AbstractInstruction * self_in_concretizeMoveXbrRR) NoDbgRegParms;
static sqInt concretizeMoveXwrRR(AbstractInstruction * self_in_concretizeMoveXwrRR) NoDbgRegParms;
static sqInt concretizeMulRR(AbstractInstruction * self_in_concretizeMulRR) NoDbgRegParms;
static sqInt concretizeNegateR(AbstractInstruction * self_in_concretizeNegateR) NoDbgRegParms;
static sqInt concretizeNop(AbstractInstruction * self_in_concretizeNop) NoDbgRegParms;
static sqInt concretizeOrCqR(AbstractInstruction * self_in_concretizeOrCqR) NoDbgRegParms;
static sqInt concretizeOrCwR(AbstractInstruction * self_in_concretizeOrCwR) NoDbgRegParms;
static sqInt concretizeOrRR(AbstractInstruction * self_in_concretizeOrRR) NoDbgRegParms;
static sqInt concretizePopR(AbstractInstruction * self_in_concretizePopR) NoDbgRegParms;
static sqInt concretizePrefetchAw(AbstractInstruction * self_in_concretizePrefetchAw) NoDbgRegParms;
static sqInt concretizePushCw(AbstractInstruction * self_in_concretizePushCw) NoDbgRegParms;
static sqInt concretizePushR(AbstractInstruction * self_in_concretizePushR) NoDbgRegParms;
static sqInt concretizeRetN(AbstractInstruction * self_in_concretizeRetN) NoDbgRegParms;
static sqInt concretizeSEE2OpRdRd(AbstractInstruction * self_in_concretizeSEE2OpRdRd, sqInt opCode) NoDbgRegParms;
static sqInt concretizeSqrtRd(AbstractInstruction * self_in_concretizeSqrtRd) NoDbgRegParms;
static sqInt concretizeSubCqR(AbstractInstruction * self_in_concretizeSubCqR) NoDbgRegParms;
static sqInt concretizeSubCwR(AbstractInstruction * self_in_concretizeSubCwR) NoDbgRegParms;
static sqInt concretizeSubRR(AbstractInstruction * self_in_concretizeSubRR) NoDbgRegParms;
static sqInt concretizeXCHGAwR(AbstractInstruction * self_in_concretizeXCHGAwR) NoDbgRegParms;
static sqInt concretizeXCHGMwrR(AbstractInstruction * self_in_concretizeXCHGMwrR) NoDbgRegParms;
static sqInt concretizeXCHGRR(AbstractInstruction * self_in_concretizeXCHGRR) NoDbgRegParms;
static sqInt concretizeXorCwR(AbstractInstruction * self_in_concretizeXorCwR) NoDbgRegParms;
static sqInt concretizeXorRR(AbstractInstruction * self_in_concretizeXorRR) NoDbgRegParms;
static sqInt couldBeObject(sqInt oop) NoDbgRegParms;
static sqInt counterTargetFromFollowingAddress(AbstractInstruction * self_in_counterTargetFromFollowingAddress, sqInt nextInstructionAddress) NoDbgRegParms;
static sqInt cPICHasFreedTargets(CogMethod *cPIC) NoDbgRegParms;
static sqInt cPICMissTrampolineFor(sqInt numArgs) NoDbgRegParms;
static sqInt cPICHasTarget(CogMethod *cPIC, CogMethod *targetMethod) NoDbgRegParms;
static sqInt cResultRegister(AbstractInstruction * self_in_cResultRegister) NoDbgRegParms;
static sqInt createsClosuresInline(void);
static AbstractInstruction * gDivRRQuoRem(sqInt rDivisor, sqInt rDividend, sqInt rQuotient, sqInt rRemainder) NoDbgRegParms;
static void dispatchConcretize(AbstractInstruction * self_in_dispatchConcretize) NoDbgRegParms;
static sqInt doubleExtendedDoAnythingBytecode(void);
static sqInt duplicateTopBytecode(void);
static sqInt endPCOf(sqInt aMethod) NoDbgRegParms;
static BytecodeFixup * ensureFixupAt(sqInt targetIndex) NoDbgRegParms;
static BytecodeFixup * ensureNonMergeFixupAt(sqInt targetIndex) NoDbgRegParms;
static void ensureReceiverResultRegContainsSelf(void);
static CogSimStackEntry * ensureSpilledAtfrom(CogSimStackEntry * self_in_ensureSpilledAtfrom, sqInt baseOffset, sqInt baseRegister) NoDbgRegParms;
void enterCogCodePopReceiver(void);
void enterCogCodePopReceiverAndClassRegs(void);
void enterCogCodePopReceiverArg0Regs(void);
void enterCogCodePopReceiverArg1Arg0Regs(void);
static void evaluateat(BytecodeDescriptor *descriptor, sqInt pc) NoDbgRegParms;
static sqInt extendedPushBytecode(void);
static sqInt extendedStoreAndPopBytecode(void);
static sqInt extendedStoreBytecode(void);
static sqInt fillInBlockHeadersAt(sqInt startAddress) NoDbgRegParms;
static CogMethod * fillInCPICHeadersizenumArgsnumCaseshasMNUCaseselector(CogMethod *pic, sqInt size, sqInt numArgs, sqInt numCases, sqInt hasMNUCase, sqInt selector) NoDbgRegParms;
static CogMethod * fillInMethodHeadersizeselector(CogMethod *method, sqInt size, sqInt selector) NoDbgRegParms;
static CogMethod * fillInOPICHeadersizenumArgsselector(CogMethod *pic, sqInt size, sqInt numArgs, sqInt selector) NoDbgRegParms;
static usqInt findBlockMethodWithEntrystartBcpc(sqInt blockEntryMcpc, sqInt startBcpc) NoDbgRegParms;
static sqInt findMapLocationForMcpcinMethod(sqInt targetMcpc, CogMethod *cogMethod) NoDbgRegParms;
CogBlockMethod * findMethodForStartBcpcinHomeMethod(sqInt startbcpc, CogMethod *cogMethod);
static sqInt findIsBackwardBranchMcpcBcpcMatchingMcpc(BytecodeDescriptor *descriptor, sqInt isBackwardBranch, char *mcpc, sqInt bcpc, void *targetMcpc) NoDbgRegParms;
static sqInt frameOffsetOfTemporary(sqInt index) NoDbgRegParms;
static void freeMethod(CogMethod *cogMethod) NoDbgRegParms;
static void freeOlderMethodsForCompaction(void);
static void freePICsWithFreedTargets(void);
void freeUnmarkedMachineCode(void);
static sqInt genActiveContextTrampoline(void);
static sqInt genAddSmallIntegerTagsTo(sqInt aRegister) NoDbgRegParms;
static sqInt genAlignCStackSavingRegistersnumArgswordAlignment(AbstractInstruction * self_in_genAlignCStackSavingRegistersnumArgswordAlignment, sqInt saveRegs, sqInt numArgs, sqInt alignment) NoDbgRegParms;
static AbstractInstruction * genAllocFloatValueintoscratchRegscratchReg(sqInt dpreg, sqInt resultReg, sqInt scratch1, sqInt scratch2) NoDbgRegParms;
static sqInt genCheckForInterruptsTrampoline(void);
static sqInt genConvertIntegerToSmallIntegerInReg(sqInt reg) NoDbgRegParms;
static sqInt genConvertIntegerToSmallIntegerInScratchReg(sqInt scratchReg) NoDbgRegParms;
static sqInt genConvertSmallIntegerToIntegerInReg(sqInt reg) NoDbgRegParms;
static sqInt genCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock) NoDbgRegParms;
static AbstractInstruction * genDivRRQuoRem(AbstractInstruction * self_in_genDivRRQuoRem, sqInt abstractRegDivisor, sqInt abstractRegDividend, sqInt abstractRegQuotient, sqInt abstractRegRemainder) NoDbgRegParms;
static sqInt genDoubleArithmeticpreOpCheck(sqInt arithmeticOperator, AbstractInstruction *(*preOpCheckOrNil)(int rcvrReg, int argReg)) NoDbgRegParms;
static sqInt genDoubleComparisoninvert(AbstractInstruction *(*jumpOpcodeGenerator)(void *), sqInt invertComparison) NoDbgRegParms;
static AbstractInstruction * genDoubleFailIfZeroArgRcvrarg(sqInt rcvrReg, sqInt argReg) NoDbgRegParms;
static void (*genEnilopmartForandandcalled(sqInt regArg1, sqInt regArg2, sqInt regArg3, char *trampolineName))(void)  NoDbgRegParms;
static void (*genEnilopmartForandcalled(sqInt regArg1, sqInt regArg2, char *trampolineName))(void)  NoDbgRegParms;
static void (*genEnilopmartForcalled(sqInt regArg, char *trampolineName))(void)  NoDbgRegParms;
static sqInt genEnsureObjInRegNotForwardedscratchReg(sqInt reg, sqInt scratch) NoDbgRegParms;
static sqInt genEnsureOopInRegNotForwardedscratchReg(sqInt reg, sqInt scratch) NoDbgRegParms;
static void (*genEnterPICEnilopmartNumArgs(sqInt numArgs))(void)  NoDbgRegParms;
static sqInt genExtendedSendBytecode(void);
static sqInt genExtendedSuperBytecode(void);
static sqInt genExternalizePointersForPrimitiveCall(void);
static void generateCaptureCStackPointers(sqInt captureFramePointer) NoDbgRegParms;
static AbstractInstruction * generateCheckFeatures(AbstractInstruction * self_in_generateCheckFeatures) NoDbgRegParms;
static void generateClosedPICPrototype(void);
static CogMethod * generateCogMethod(sqInt selector) NoDbgRegParms;
static void generateEnilopmarts(void);
static AbstractInstruction * generateICacheFlush(AbstractInstruction * self_in_generateICacheFlush) NoDbgRegParms;
static sqInt generateInstructionsAt(sqInt eventualAbsoluteAddress) NoDbgRegParms;
static AbstractInstruction * generateLowLevelTryLock(AbstractInstruction * self_in_generateLowLevelTryLock, sqInt vmOwnerLockAddress) NoDbgRegParms;
static AbstractInstruction * generateLowLevelUnlock(AbstractInstruction * self_in_generateLowLevelUnlock, sqInt vmOwnerLockAddress) NoDbgRegParms;
static sqInt generateMapAtstart(sqInt addressOrNull, sqInt startAddress) NoDbgRegParms;
static void generateMissAbortTrampolines(void);
static void generateObjectRepresentationTrampolines(void);
static void generateOpenPICPrototype(void);
static void generateRunTimeTrampolines(void);
static void generateSendTrampolines(void);
static void generateStackPointerCapture(void);
static void generateTracingTrampolines(void);
static void generateTrampolines(void);
static void generateVMOwnerLockFunctions(void);
static sqInt genFastPrimFail(void);
static void genFastPrimTraceUsingand(sqInt r1, sqInt r2) NoDbgRegParms;
static sqInt genFetchIndexRegisterfrominto(sqInt indexReg, sqInt tableObj, sqInt destReg) NoDbgRegParms;
static sqInt genFramelessStorePopReceiverVariable(sqInt popBoolean, sqInt slotIndex) NoDbgRegParms;
static void genGetActiveContextNumArgslargeinBlock(sqInt numArgs, sqInt isLargeContext, sqInt isInBlock) NoDbgRegParms;
static sqInt genGetClassFormatOfNonIntintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg) NoDbgRegParms;
static sqInt genGetClassObjectOfintoscratchReginstRegIsReceiver(sqInt instReg, sqInt destReg, sqInt scratchReg, sqInt instRegIsReceiver) NoDbgRegParms;
static AbstractInstruction * genGetClassTagOfintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg) NoDbgRegParms;
static sqInt genGetCompactClassIndexNonImmOfinto(sqInt instReg, sqInt destReg) NoDbgRegParms;
static sqInt genGetDoubleValueOfinto(sqInt srcReg, sqInt destFPReg) NoDbgRegParms;
static sqInt genGetFixedFieldsOfPointerNonIntintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg) NoDbgRegParms;
static sqInt genGetHashFieldNonImmOfasSmallIntegerInto(sqInt instReg, sqInt destReg) NoDbgRegParms;
static sqInt genGetLeafCallStackPointer(void);
static AbstractInstruction * genGetLeafCallStackPointerFunction(AbstractInstruction * self_in_genGetLeafCallStackPointerFunction) NoDbgRegParms;
static sqInt genInnerPICAbortTrampoline(char *name) NoDbgRegParms;
static sqInt genInnerPrimitiveAsCharacterinReg(sqInt retNOffset, sqInt reg) NoDbgRegParms;
static sqInt genInnerPrimitiveAtPut(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveAt(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveCharacterValue(sqInt retNOffset) NoDbgRegParms;
static sqInt genInnerPrimitiveIdenticalorNotIf(sqInt retNoffset, sqInt orNot) NoDbgRegParms;
static sqInt genInnerPrimitiveIdentityHash(sqInt retNOffset) NoDbgRegParms;
static sqInt genInnerPrimitiveNewMethod(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveNewWithArg(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveNew(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveSize(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveStringAtPut(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveStringAt(sqInt retNOffset) NoDbgRegParms;
static sqInt genJumpBackTo(sqInt targetBytecodePC) NoDbgRegParms;
static AbstractInstruction * genJumpFPEqual(AbstractInstruction * self_in_genJumpFPEqual, void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * genJumpFPGreaterOrEqual(AbstractInstruction * self_in_genJumpFPGreaterOrEqual, void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * genJumpFPGreater(AbstractInstruction * self_in_genJumpFPGreater, void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * genJumpFPLessOrEqual(AbstractInstruction * self_in_genJumpFPLessOrEqual, void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * genJumpFPLess(AbstractInstruction * self_in_genJumpFPLess, void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * genJumpFPNotEqual(AbstractInstruction * self_in_genJumpFPNotEqual, void *jumpTarget) NoDbgRegParms;
static sqInt genJumpIfto(sqInt boolean, sqInt targetBytecodePC) NoDbgRegParms;
static AbstractInstruction * genJumpImmediateInScratchReg(sqInt aRegister) NoDbgRegParms;
static AbstractInstruction * genJumpNotSmallIntegerInScratchReg(sqInt aRegister) NoDbgRegParms;
static AbstractInstruction * genJumpSmallIntegerInScratchReg(sqInt aRegister) NoDbgRegParms;
static sqInt genJumpTo(sqInt targetBytecodePC) NoDbgRegParms;
static sqInt genLoadCStackPointer(AbstractInstruction * self_in_genLoadCStackPointer) NoDbgRegParms;
static sqInt genLoadCStackPointers(AbstractInstruction * self_in_genLoadCStackPointers) NoDbgRegParms;
static sqInt genLoadCStackPointersForPrimCall(void);
static sqInt genLoadSlotsourceRegdestReg(sqInt index, sqInt sourceReg, sqInt destReg) NoDbgRegParms;
static sqInt genLoadStackPointers(AbstractInstruction * self_in_genLoadStackPointers) NoDbgRegParms;
static sqInt genLongJumpIfFalse(void);
static sqInt genLongJumpIfTrue(void);
static sqInt genLongStoreAndPopTemporaryVariableBytecode(void);
static sqInt genLongUnconditionalBackwardJump(void);
static sqInt genLongUnconditionalForwardJump(void);
static sqInt genMarshalledSendSupernumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static sqInt genMarshalledSendnumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static sqInt genMethodAbortTrampolineFor(sqInt numArgs) NoDbgRegParms;
static AbstractInstruction * genMulRR(AbstractInstruction * self_in_genMulRR, sqInt regSource, sqInt regDest) NoDbgRegParms;
static sqInt genMustBeBooleanTrampolineForcalled(sqInt boolean, char *trampolineName) NoDbgRegParms;
static void genNewArrayOfSizeinitialized(sqInt size, sqInt initialized) NoDbgRegParms;
static sqInt genNonLocalReturnTrampoline(void);
static sqInt genPassConstasArgument(AbstractInstruction * self_in_genPassConstasArgument, sqInt constant, sqInt zeroRelativeArgIndex) NoDbgRegParms;
static sqInt genPassRegasArgument(AbstractInstruction * self_in_genPassRegasArgument, sqInt abstractRegister, sqInt zeroRelativeArgIndex) NoDbgRegParms;
static sqInt genPICAbortTrampolineFor(sqInt numArgs) NoDbgRegParms;
static sqInt genPICMissTrampolineFor(sqInt numArgs) NoDbgRegParms;
static sqInt genPopStackBytecode(void);
static sqInt genPrimitiveAdd(void);
static sqInt genPrimitiveAsCharacter(void);
static sqInt genPrimitiveAsFloat(void);
static sqInt genPrimitiveAt(void);
static sqInt genPrimitiveAtPut(void);
static sqInt genPrimitiveBitAnd(void);
static sqInt genPrimitiveBitOr(void);
static sqInt genPrimitiveBitShift(void);
static sqInt genPrimitiveBitXor(void);
static sqInt genPrimitiveCharacterValue(void);
static sqInt genPrimitiveClass(void);
static sqInt genPrimitiveClosureValue(void);
static sqInt genPrimitiveDiv(void);
static sqInt genPrimitiveDivide(void);
static sqInt genPrimitiveEqual(void);
static sqInt genPrimitiveFloatAdd(void);
static sqInt genPrimitiveFloatDivide(void);
static sqInt genPrimitiveFloatEqual(void);
static sqInt genPrimitiveFloatGreaterOrEqual(void);
static sqInt genPrimitiveFloatGreaterThan(void);
static sqInt genPrimitiveFloatLessOrEqual(void);
static sqInt genPrimitiveFloatLessThan(void);
static sqInt genPrimitiveFloatMultiply(void);
static sqInt genPrimitiveFloatNotEqual(void);
static sqInt genPrimitiveFloatSquareRoot(void);
static sqInt genPrimitiveFloatSubtract(void);
static sqInt genPrimitiveGreaterOrEqual(void);
static sqInt genPrimitiveGreaterThan(void);
static sqInt genPrimitiveIdentical(void);
static sqInt genPrimitiveIdentityHash(void);
static sqInt genPrimitiveLessOrEqual(void);
static sqInt genPrimitiveLessThan(void);
static sqInt genPrimitiveMod(void);
static sqInt genPrimitiveMultiply(void);
static sqInt genPrimitiveNew(void);
static sqInt genPrimitiveNewMethod(void);
static sqInt genPrimitiveNewWithArg(void);
static sqInt genPrimitiveNotEqual(void);
static sqInt genPrimitiveNotIdentical(void);
static sqInt genPrimitiveQuo(void);
static sqInt genPrimitiveSize(void);
static sqInt genPrimitiveStringAt(void);
static sqInt genPrimitiveStringAtPut(void);
static sqInt genPrimitiveSubtract(void);
static void genPrimReturnEnterCogCodeEnilopmart(sqInt profiling) NoDbgRegParms;
static sqInt genPushActiveContextBytecode(void);
static sqInt genPushClosureCopyCopiedValuesBytecode(void);
static sqInt genPushConstantFalseBytecode(void);
static sqInt genPushConstantNilBytecode(void);
static sqInt genPushConstantTrueBytecode(void);
static sqInt genPushLiteralConstantBytecode(void);
static sqInt genPushLiteralIndex(sqInt literalIndex) NoDbgRegParms;
static sqInt genPushLiteralVariableBytecode(void);
static sqInt genPushLiteralVariable(sqInt literalIndex) NoDbgRegParms;
static sqInt genPushLiteral(sqInt literal) NoDbgRegParms;
static sqInt genPushMaybeContextReceiverVariable(sqInt slotIndex) NoDbgRegParms;
static sqInt genPushNewArrayBytecode(void);
static sqInt genPushQuickIntegerConstantBytecode(void);
static sqInt genPushReceiverBytecode(void);
static sqInt genPushReceiverVariableBytecode(void);
static sqInt genPushReceiverVariable(sqInt index) NoDbgRegParms;
static void genPushRegisterArgs(void);
static AbstractInstruction * genPushRegisterArgsForAbortMissNumArgs(AbstractInstruction * self_in_genPushRegisterArgsForAbortMissNumArgs, sqInt numArgs) NoDbgRegParms;
static AbstractInstruction * genPushRegisterArgsForNumArgs(AbstractInstruction * self_in_genPushRegisterArgsForNumArgs, sqInt numArgs) NoDbgRegParms;
static sqInt genPushRemoteTempLongBytecode(void);
static sqInt genPushTemporaryVariableBytecode(void);
static sqInt genPushTemporaryVariable(sqInt index) NoDbgRegParms;
sqInt genQuickReturnConst(void);
sqInt genQuickReturnInstVar(void);
sqInt genQuickReturnSelf(void);
static sqInt genRemoveNArgsFromStack(AbstractInstruction * self_in_genRemoveNArgsFromStack, sqInt n) NoDbgRegParms;
static sqInt genRemoveSmallIntegerTagsInScratchReg(sqInt scratchReg) NoDbgRegParms;
static sqInt genRestoreRegs(AbstractInstruction * self_in_genRestoreRegs) NoDbgRegParms;
static sqInt genRestoreRegsExcept(AbstractInstruction * self_in_genRestoreRegsExcept, sqInt abstractReg) NoDbgRegParms;
static sqInt genReturnFalse(void);
static sqInt genReturnNil(void);
static sqInt genReturnReceiver(void);
static sqInt genReturnTopFromBlock(void);
static sqInt genReturnTopFromMethod(void);
static sqInt genReturnTrue(void);
static sqInt genSafeTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0) NoDbgRegParms;
static sqInt genSafeTrampolineForcalledargarg(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1) NoDbgRegParms;
static sqInt genSaveRegisters(AbstractInstruction * self_in_genSaveRegisters) NoDbgRegParms;
static sqInt genSaveStackPointers(AbstractInstruction * self_in_genSaveStackPointers) NoDbgRegParms;
static sqInt genSecondExtendedSendBytecode(void);
static sqInt genSendLiteralSelector0ArgsBytecode(void);
static sqInt genSendLiteralSelector1ArgBytecode(void);
static sqInt genSendLiteralSelector2ArgsBytecode(void);
static sqInt genSendSupernumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static sqInt genSendTrampolineFornumArgscalledargargarg(void *aRoutine, sqInt numArgs, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2) NoDbgRegParms;
static sqInt genSendTrampolineFornumArgscalledargargargarg(void *aRoutine, sqInt numArgs, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3) NoDbgRegParms;
static sqInt genSendnumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static sqInt genSetSmallIntegerTagsIn(sqInt scratchReg) NoDbgRegParms;
static sqInt genShiftAwaySmallIntegerTagsInScratchReg(sqInt scratchReg) NoDbgRegParms;
static sqInt genShortJumpIfFalse(void);
static sqInt genShortUnconditionalJump(void);
static sqInt genSmallIntegerComparisonorDoubleComparison(sqInt jumpOpcode, AbstractInstruction *(*jumpFPOpcodeGenerator)(void *)) NoDbgRegParms;
static sqInt genSmalltalkToCStackSwitch(void);
static sqInt genSpecialSelectorArithmetic(void);
static sqInt genSpecialSelectorClass(void);
static sqInt genSpecialSelectorComparison(void);
static sqInt genSpecialSelectorEqualsEquals(void);
static sqInt genSpecialSelectorSend(void);
static sqInt genStoreAndPopReceiverVariableBytecode(void);
static sqInt genStoreAndPopRemoteTempLongBytecode(void);
static sqInt genStoreAndPopTemporaryVariableBytecode(void);
static sqInt genStoreImmediateInSourceRegslotIndexdestReg(sqInt sourceReg, sqInt index, sqInt destReg) NoDbgRegParms;
static sqInt genStorePopLiteralVariable(sqInt popBoolean, sqInt litVarIndex) NoDbgRegParms;
static sqInt genStorePopMaybeContextReceiverVariable(sqInt popBoolean, sqInt slotIndex) NoDbgRegParms;
static sqInt genStorePopReceiverVariable(sqInt popBoolean, sqInt slotIndex) NoDbgRegParms;
static sqInt genStorePopRemoteTempAt(sqInt popBoolean, sqInt slotIndex, sqInt remoteTempIndex) NoDbgRegParms;
static sqInt genStorePopTemporaryVariable(sqInt popBoolean, sqInt tempIndex) NoDbgRegParms;
static sqInt genStoreRemoteTempLongBytecode(void);
static sqInt genStoreSourceRegslotIndexdestRegscratchReg(sqInt sourceReg, sqInt index, sqInt destReg, sqInt scratchReg) NoDbgRegParms;
static sqInt genStoreSourceRegslotIndexintoNewObjectInDestReg(sqInt sourceReg, sqInt index, sqInt destReg) NoDbgRegParms;
static AbstractInstruction * genSubstituteReturnAddress(AbstractInstruction * self_in_genSubstituteReturnAddress, sqInt retpc) NoDbgRegParms;
static sqInt genTrampolineForcalled(void *aRoutine, char *aString) NoDbgRegParms;
static sqInt genTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0) NoDbgRegParms;
static sqInt genTrampolineForcalledargargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt resultReg) NoDbgRegParms;
static sqInt genTrampolineForcalledargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt resultReg) NoDbgRegParms;
static sqInt genTrampolineForcalledargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt resultReg) NoDbgRegParms;
static sqInt genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(void *aRoutine, char *trampolineName, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNil, sqInt appendBoolean) NoDbgRegParms;
static sqInt genUpArrowReturn(void);
static AbstractInstruction * genWriteCResultIntoReg(AbstractInstruction * self_in_genWriteCResultIntoReg, sqInt abstractRegister) NoDbgRegParms;
static AbstractInstruction * gen(sqInt opcode) NoDbgRegParms;
static AbstractInstruction * genoperand(sqInt opcode, sqInt operand) NoDbgRegParms;
static AbstractInstruction * genoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo) NoDbgRegParms;
static AbstractInstruction * genoperandoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo, sqInt operandThree) NoDbgRegParms;
static sqInt getActiveContextAllocatesInMachineCode(void);
static AbstractInstruction * getInlineCacheClassTagFrominto(sqInt sourceReg, sqInt destReg) NoDbgRegParms;
static AbstractInstruction * getJmpTarget(AbstractInstruction * self_in_getJmpTarget) NoDbgRegParms;
static sqInt getLiteral(sqInt litIndex) NoDbgRegParms;
static sqInt hasDoublePrecisionFloatingPointSupport(AbstractInstruction * self_in_hasDoublePrecisionFloatingPointSupport) NoDbgRegParms;
static sqInt hasLinkRegister(AbstractInstruction * self_in_hasLinkRegister) NoDbgRegParms;
static sqInt hasPCDependentInstructions(AbstractInstruction * self_in_hasPCDependentInstructions) NoDbgRegParms;
static sqInt hasSSE2Instructions(AbstractInstruction * self_in_hasSSE2Instructions) NoDbgRegParms;
static sqInt hasSSEInstructions(AbstractInstruction * self_in_hasSSEInstructions) NoDbgRegParms;
static sqInt incrementUsageOfTargetIfLinkedSendmcpcignored(sqInt annotation, char *mcpc, sqInt superfluity) NoDbgRegParms;
static sqInt initialClosedPICUsageCount(void);
static void initializeBackend(void);
void initializeCodeZoneFromupTo(sqInt startAddress, sqInt endAddress);
static BytecodeFixup * initializeFixupAt(sqInt targetIndex) NoDbgRegParms;
static sqInt initialMethodUsageCount(void);
static sqInt initialOpenPICUsageCount(void);
static void initSimStackForFramefulMethod(sqInt startpc) NoDbgRegParms;
static void initSimStackForFramelessBlock(sqInt startpc) NoDbgRegParms;
static void initSimStackForFramelessMethod(sqInt startpc) NoDbgRegParms;
static sqInt inlineCacheTagAt(AbstractInstruction * self_in_inlineCacheTagAt, sqInt callSiteReturnAddress) NoDbgRegParms;
static sqInt inlineCacheTagForInstance(sqInt oop) NoDbgRegParms;
static sqInt inlineCacheTagIsYoung(sqInt cacheTag) NoDbgRegParms;
static sqInt inlineCacheTagsMayBeObjects(void);
static sqInt instructionSizeAt(AbstractInstruction * self_in_instructionSizeAt, sqInt pc) NoDbgRegParms;
sqInt interpretOffset(void);
static sqInt inverseBranchFor(sqInt opcode) NoDbgRegParms;
static sqInt isAFixup(AbstractInstruction * self_in_isAFixup, void *fixupOrAddress) NoDbgRegParms;
static sqInt isAnInstruction(AbstractInstruction * self_in_isAnInstruction, AbstractInstruction *addressOrInstruction) NoDbgRegParms;
static sqInt isBackwardBranchatextsin(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
static sqInt isBigEndian(AbstractInstruction * self_in_isBigEndian) NoDbgRegParms;
static sqInt isBranch(BytecodeDescriptor * self_in_isBranch) NoDbgRegParms;
static sqInt isCallPreceedingReturnPC(AbstractInstruction * self_in_isCallPreceedingReturnPC, sqInt mcpc) NoDbgRegParms;
static sqInt isJump(AbstractInstruction * self_in_isJump) NoDbgRegParms;
static sqInt isJumpAt(AbstractInstruction * self_in_isJumpAt, sqInt pc) NoDbgRegParms;
static sqInt isLongJump(AbstractInstruction * self_in_isLongJump) NoDbgRegParms;
static sqInt isPCDependent(AbstractInstruction * self_in_isPCDependent) NoDbgRegParms;
static sqInt isPCMappedAnnotationalternateInstructionSet(sqInt annotation, sqInt isAlternateInstSet) NoDbgRegParms;
sqInt isPCWithinMethodZone(char *address);
static sqInt isQuick(AbstractInstruction * self_in_isQuick, unsigned long operand) NoDbgRegParms;
sqInt isSendReturnPC(sqInt retpc);
static sqInt isSmallIntegerTagNonZero(void);
static sqInt isUnconditionalBranch(BytecodeDescriptor * self_in_isUnconditionalBranch) NoDbgRegParms;
static AbstractInstruction * gJumpFPEqual(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPGreaterOrEqual(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPGreater(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPLessOrEqual(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPLess(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPNotEqual(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * JumpRT(sqInt callTarget) NoDbgRegParms;
static AbstractInstruction * jmpTarget(AbstractInstruction * self_in_jmpTarget, AbstractInstruction *anAbstractInstruction) NoDbgRegParms;
static sqInt jumpLongByteSize(AbstractInstruction * self_in_jumpLongByteSize) NoDbgRegParms;
static sqInt jumpLongConditionalByteSize(AbstractInstruction * self_in_jumpLongConditionalByteSize) NoDbgRegParms;
static sqInt jumpLongTargetBeforeFollowingAddress(AbstractInstruction * self_in_jumpLongTargetBeforeFollowingAddress, sqInt mcpc) NoDbgRegParms;
static sqInt jumpShortByteSize(AbstractInstruction * self_in_jumpShortByteSize) NoDbgRegParms;
static AbstractInstruction * jumpTargetAddress(AbstractInstruction * self_in_jumpTargetAddress) NoDbgRegParms;
static sqInt jumpTargetPCAt(AbstractInstruction * self_in_jumpTargetPCAt, sqInt pc) NoDbgRegParms;
static sqInt kosherYoungReferrers(void);
static AbstractInstruction * gLabel(void);
static AbstractInstruction * gLogicalShiftRightCqR(sqInt quickConstant, sqInt reg) NoDbgRegParms;
static sqInt labelOffset(AbstractInstruction * self_in_labelOffset) NoDbgRegParms;
static AbstractInstruction * lastOpcode(void);
static sqInt leafCallStackPointerDelta(AbstractInstruction * self_in_leafCallStackPointerDelta) NoDbgRegParms;
void linkSendAtintooffsetreceiver(sqInt callSiteReturnAddress, CogMethod *sendingMethod, CogMethod *targetMethod, sqInt theEntryOffset, sqInt receiver);
static sqInt literalBeforeFollowingAddress(AbstractInstruction * self_in_literalBeforeFollowingAddress, sqInt followingAddress) NoDbgRegParms;
static sqInt liveRegisters(void);
static sqInt loadLiteralByteSize(AbstractInstruction * self_in_loadLiteralByteSize) NoDbgRegParms;
static void loadSubsequentBytesForDescriptorat(BytecodeDescriptor *descriptor, sqInt pc) NoDbgRegParms;
static AbstractInstruction * longJumpTargetAddress(AbstractInstruction * self_in_longJumpTargetAddress) NoDbgRegParms;
static AbstractInstruction * gMoveAwR(sqInt address, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gMoveCwR(sqInt wordConstant, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gMoveMwrR(sqInt offset, sqInt baseReg, sqInt destReg) NoDbgRegParms;
static AbstractInstruction * gMoveRMwr(sqInt sourceReg, sqInt offset, sqInt baseReg) NoDbgRegParms;
static AbstractInstruction * gMulRR(sqInt reg1, sqInt reg2) NoDbgRegParms;
static sqInt machineCodeBytes(AbstractInstruction * self_in_machineCodeBytes) NoDbgRegParms;
static void manageFromto(sqInt theStartAddress, sqInt theLimitAddress) NoDbgRegParms;
static sqInt mapEndFor(CogMethod *cogMethod) NoDbgRegParms;
static sqInt mapForperformUntilarg(CogMethod *cogMethod, int (*functionSymbol)(sqInt annotation, char *mcpc, sqInt arg), sqInt arg) NoDbgRegParms;
static sqInt mapObjectReferencesInClosedPIC(CogMethod *cPIC) NoDbgRegParms;
static void mapObjectReferencesInGeneratedRuntime(void);
static void mapObjectReferencesInMachineCodeForBecome(void);
static void mapObjectReferencesInMachineCodeForFullGC(void);
static void mapObjectReferencesInMachineCodeForYoungGC(void);
void mapObjectReferencesInMachineCode(sqInt gcMode);
static void markAndTraceLiteralIfYoung(sqInt literal) NoDbgRegParms;
static void markAndTraceLiteral(sqInt literal) NoDbgRegParms;
static void markAndTraceMachineCodeForNewSpaceGC(void);
void markAndTraceMachineCodeOfMarkedMethods(void);
static void markAndTraceObjectReferencesInGeneratedRuntime(void);
void markAndTraceObjectsOrFreeMachineCode(sqInt inFullGC);
static sqInt markAndTraceOrFreeCogMethodfirstVisit(CogMethod *cogMethod, sqInt firstVisit) NoDbgRegParms;
static void markAndTraceOrFreeMachineCodeForFullGC(void);
static sqInt markLiteralsAndUnlinkIfUnmarkedSendpcmethod(sqInt annotation, char *mcpc, sqInt cogMethod) NoDbgRegParms;
static sqInt markLiteralspcmethod(sqInt annotation, char *mcpc, sqInt cogMethod) NoDbgRegParms;
void markMethodAndReferents(CogBlockMethod *aCogMethod);
static sqInt markYoungObjectspcmethod(sqInt annotation, char *mcpc, sqInt cogMethod) NoDbgRegParms;
static void marshallSendArguments(sqInt numArgs) NoDbgRegParms;
usqInt maxCogMethodAddress(void);
static void maybeCompileAllocFillerCheck(void);
static sqInt maybeFreeCogMethodDoesntLookKosher(CogMethod *cogMethod) NoDbgRegParms;
static sqInt maybeGenerateCheckFeatures(void);
static sqInt maybeGenerateICacheFlush(void);
usqInt mcPCForBackwardBranchstartBcpcin(sqInt bcpc, sqInt startbcpc, CogBlockMethod *cogMethod);
static CogSimStackEntry * mergeAtfrom(CogSimStackEntry * self_in_mergeAtfrom, sqInt baseOffset, sqInt baseRegister) NoDbgRegParms;
static void mergeafterContinuation(BytecodeFixup *fixup, sqInt mergeWithContinuation) NoDbgRegParms;
static sqInt methodAbortTrampolineFor(sqInt numArgs) NoDbgRegParms;
CogMethod * methodFor(void *address);
static sqInt methodhasSameCodeAscheckPenultimate(sqInt methodA, sqInt methodB, sqInt comparePenultimateLiteral) NoDbgRegParms;
sqInt minCogMethodAddress(void);
sqInt mnuOffset(void);
static sqInt modRMRO(AbstractInstruction * self_in_modRMRO, sqInt mod, sqInt regMode, sqInt regOpcode) NoDbgRegParms;
static AbstractInstruction * gNegateR(sqInt reg) NoDbgRegParms;
static sqInt needsFrameIfInBlock(sqInt stackDelta) NoDbgRegParms;
static sqInt needsFrameIfMod16GENumArgs(sqInt stackDelta) NoDbgRegParms;
static sqInt needsFrameIfStackGreaterThanOne(sqInt stackDelta) NoDbgRegParms;
static sqInt needsFrameNever(sqInt stackDelta) NoDbgRegParms;
static sqInt noAssertMethodClassAssociationOf(sqInt methodPointer) NoDbgRegParms;
static sqInt noCogMethodsMaximallyMarked(void);
static AbstractInstruction * nopsFromto(AbstractInstruction * self_in_nopsFromto, sqInt startAddr, sqInt endAddr) NoDbgRegParms;
static sqInt noTargetsFreeInClosedPIC(CogMethod *cPIC) NoDbgRegParms;
static sqInt numberOfSpillsInTopNItems(sqInt n) NoDbgRegParms;
static sqInt numCheckFeaturesOpcodes(AbstractInstruction * self_in_numCheckFeaturesOpcodes) NoDbgRegParms;
static sqInt numICacheFlushOpcodes(AbstractInstruction * self_in_numICacheFlushOpcodes) NoDbgRegParms;
static sqInt numLowLevelLockOpcodes(AbstractInstruction * self_in_numLowLevelLockOpcodes) NoDbgRegParms;
static sqInt numMethods(void);
sqInt numMethodsOfType(sqInt cogMethodType);
sqInt numRegArgs(void);
static sqInt numSmallIntegerBits(void);
static sqInt occurrencesInYoungReferrers(CogMethod *cogMethod) NoDbgRegParms;
static sqInt oopisGreaterThanOrEqualTo(sqInt anOop, sqInt otherOop) NoDbgRegParms;
static sqInt oopisGreaterThan(sqInt anOop, sqInt otherOop) NoDbgRegParms;
static sqInt oopisLessThan(sqInt anOop, sqInt otherOop) NoDbgRegParms;
static CogMethod * openPICWithSelector(sqInt aSelector) NoDbgRegParms;
static sqInt outputInstructionsAt(sqInt startAddress) NoDbgRegParms;
static sqInt outputInstructionsForGeneratedRuntimeAt(sqInt startAddress) NoDbgRegParms;
static AbstractInstruction * gPushCw(sqInt wordConstant) NoDbgRegParms;
static AbstractInstruction * padIfPossibleWithNopsFromto(AbstractInstruction * self_in_padIfPossibleWithNopsFromto, sqInt startAddr, sqInt endAddr) NoDbgRegParms;
sqInt patchToOpenPICFornumArgsreceiver(sqInt selector, sqInt numArgs, sqInt receiver);
sqInt pcisWithinMethod(char *address, CogMethod *cogMethod);
static sqInt picAbortTrampolineFor(sqInt numArgs) NoDbgRegParms;
static void planCompaction(void);
static CogSimStackEntry * popToReg(CogSimStackEntry * self_in_popToReg, sqInt reg) NoDbgRegParms;
static sqInt prevInstIsPCAnnotated(void);
static PrimitiveDescriptor * primitiveGeneratorOrNil(void);
void printCogMethodFor(void *address);
void printCogMethods(void);
void printCogMethodsOfType(sqInt cmType);
void printCogMethodsWithMethod(sqInt methodOop);
void printCogMethodsWithPrimitive(sqInt primIdx);
void printCogMethodsWithSelector(sqInt selectorOop);
void printCogYoungReferrers(void);
void printOpenPICList(void);
void printTrampolineTable(void);
static sqInt processorHasDivQuoRem(sqInt ignoredPrimIndex) NoDbgRegParms;
static sqInt processorHasDoublePrecisionFloatingPointSupport(sqInt ignoredPrimIndex) NoDbgRegParms;
static sqInt processorHasMultiply(sqInt ignoredPrimIndex) NoDbgRegParms;
static sqInt pruneYoungReferrers(void);
void recordCallOffsetInof(CogMethod *cogMethod, void *callLabelArg);
static void recordGeneratedRunTimeaddress(char *aString, sqInt address) NoDbgRegParms;
sqInt recordPrimTraceFunc(void);
static void recordRunTimeObjectReferences(void);
static sqInt registerMask(CogSimStackEntry * self_in_registerMask) NoDbgRegParms;
static sqInt registerMaskFor(sqInt reg) NoDbgRegParms;
static sqInt registerMaskForand(sqInt reg1, sqInt reg2) NoDbgRegParms;
static sqInt registerMaskForandand(sqInt reg1, sqInt reg2, sqInt reg3) NoDbgRegParms;
static sqInt registerOrNil(CogSimStackEntry * self_in_registerOrNil) NoDbgRegParms;
static void reinitializeFixupsFromthrough(sqInt start, sqInt end) NoDbgRegParms;
static sqInt relocateAndPruneYoungReferrers(void);
static AbstractInstruction * relocateCallBeforeReturnPCby(AbstractInstruction * self_in_relocateCallBeforeReturnPCby, sqInt retpc, sqInt delta) NoDbgRegParms;
static void relocateCallsAndSelfReferencesInMethod(CogMethod *cogMethod) NoDbgRegParms;
static void relocateCallsInClosedPIC(CogMethod *cPIC) NoDbgRegParms;
static sqInt relocateIfCallOrMethodReferencemcpcdelta(sqInt annotation, char *mcpc, sqInt delta) NoDbgRegParms;
static AbstractInstruction * relocateJumpBeforeFollowingAddressby(AbstractInstruction * self_in_relocateJumpBeforeFollowingAddressby, sqInt pc, sqInt delta) NoDbgRegParms;
static AbstractInstruction * relocateMethodReferenceBeforeAddressby(AbstractInstruction * self_in_relocateMethodReferenceBeforeAddressby, sqInt pc, sqInt delta) NoDbgRegParms;
static sqInt relocateMethodsPreCompaction(void);
static sqInt remapIfObjectRefpchasYoung(sqInt annotation, char *mcpc, sqInt hasYoungPtr) NoDbgRegParms;
static sqInt remapObject(sqInt oop) NoDbgRegParms;
static sqInt remapOop(sqInt oop) NoDbgRegParms;
static sqInt removeFromOpenPICList(CogMethod *anOpenPIC) NoDbgRegParms;
static AbstractInstruction * resolveJumpTarget(AbstractInstruction * self_in_resolveJumpTarget) NoDbgRegParms;
static sqInt returnRegForStoreCheck(void);
static sqInt rewriteCallAttarget(AbstractInstruction * self_in_rewriteCallAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress) NoDbgRegParms;
static sqInt rewriteInlineCacheAttagtarget(AbstractInstruction * self_in_rewriteInlineCacheAttagtarget, usqInt callSiteReturnAddress, sqInt cacheTag, usqInt callTargetAddress) NoDbgRegParms;
static AbstractInstruction * rewriteInlineCacheTagat(AbstractInstruction * self_in_rewriteInlineCacheTagat, sqInt cacheTag, sqInt callSiteReturnAddress) NoDbgRegParms;
static sqInt rewriteJumpLongAttarget(AbstractInstruction * self_in_rewriteJumpLongAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress) NoDbgRegParms;
void rewritePrimInvocationInto(CogMethod *cogMethod, void (*primFunctionPointer)(void));
static sqInt roomOnYoungReferrersList(void);
static AbstractInstruction * gSubCqR(sqInt quickConstant, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gSubCwR(sqInt wordConstant, sqInt reg) NoDbgRegParms;
static void scanBlock(BlockStart *blockStart) NoDbgRegParms;
static sqInt scanForCleanBlocks(void);
static sqInt scanMethod(void);
void setBreakMethod(sqInt anObj);
static sqInt setLabelOffset(AbstractInstruction * self_in_setLabelOffset, sqInt aValue) NoDbgRegParms;
void setPostCompileHook(void (*aFunction)(CogMethod *, void *));
void setSelectorOfto(CogMethod *cogMethod, sqInt aSelectorOop);
static sqInt setsConditionCodesFor(AbstractInstruction * self_in_setsConditionCodesFor, sqInt aConditionalJumpOpcode) NoDbgRegParms;
static sqInt shiftSetsConditionCodesFor(AbstractInstruction * self_in_shiftSetsConditionCodesFor, sqInt aConditionalJumpOpcode) NoDbgRegParms;
static sqInt shouldAnnotateObjectReference(sqInt anOop) NoDbgRegParms;
static sqInt sizeHasModrmat(AbstractInstruction * self_in_sizeHasModrmat, sqInt op, sqInt pc) NoDbgRegParms;
static sqInt sizeImmediateGroup1at(AbstractInstruction * self_in_sizeImmediateGroup1at, sqInt op, sqInt pc) NoDbgRegParms;
static sqInt sizePCDependentInstructionAt(AbstractInstruction * self_in_sizePCDependentInstructionAt, sqInt eventualAbsoluteAddress) NoDbgRegParms;
static sqInt slotOffsetOfInstVarIndex(sqInt index) NoDbgRegParms;
static sqInt smallIntegerIsOnlyImmediateType(void);
static sqInt spanForCleanBlockStartingAt(sqInt startPC) NoDbgRegParms;
static void ssAllocateCallReg(sqInt requiredReg) NoDbgRegParms;
static void ssAllocateCallRegand(sqInt requiredReg1, sqInt requiredReg2) NoDbgRegParms;
static void ssAllocateCallRegandand(sqInt requiredReg1, sqInt requiredReg2, sqInt requiredReg3) NoDbgRegParms;
static sqInt ssAllocatePreferredReg(sqInt preferredReg) NoDbgRegParms;
static void ssAllocateRequiredRegMaskupThrough(sqInt requiredRegsMask, sqInt stackPtr) NoDbgRegParms;
static void ssAllocateRequiredReg(sqInt requiredReg) NoDbgRegParms;
static void ssAllocateRequiredRegand(sqInt requiredReg1, sqInt requiredReg2) NoDbgRegParms;
static void ssAllocateRequiredRegupThrough(sqInt requiredReg, sqInt stackPtr) NoDbgRegParms;
static void ssFlushTo(sqInt index) NoDbgRegParms;
static void ssFlushUpThroughReceiverVariable(sqInt slotIndex) NoDbgRegParms;
static void ssFlushUpThroughTemporaryVariable(sqInt tempIndex) NoDbgRegParms;
static void ssPop(sqInt n) NoDbgRegParms;
static sqInt ssPushAnnotatedConstant(sqInt literal) NoDbgRegParms;
static sqInt ssPushBaseoffset(sqInt reg, sqInt offset) NoDbgRegParms;
static sqInt ssPushConstant(sqInt literal) NoDbgRegParms;
static sqInt ssPushDesc(CogSimStackEntry simStackEntry) NoDbgRegParms;
static sqInt ssPushRegister(sqInt reg) NoDbgRegParms;
static void ssPush(sqInt n) NoDbgRegParms;
static sqInt ssStorePoptoPreferredReg(sqInt popBoolean, sqInt preferredReg) NoDbgRegParms;
static CogSimStackEntry * ssTop(void);
static CogSimStackEntry ssTopDescriptor(void);
static CogSimStackEntry * ssValue(sqInt n) NoDbgRegParms;
static sqInt stackBytesForNumArgs(AbstractInstruction * self_in_stackBytesForNumArgs, sqInt numArgs) NoDbgRegParms;
static sqInt stackPageInterruptHeadroomBytes(AbstractInstruction * self_in_stackPageInterruptHeadroomBytes) NoDbgRegParms;
static AbstractInstruction * storeLiteralbeforeFollowingAddress(AbstractInstruction * self_in_storeLiteralbeforeFollowingAddress, sqInt literal, sqInt followingAddress) NoDbgRegParms;
static CogSimStackEntry * storeToReg(CogSimStackEntry * self_in_storeToReg, sqInt reg) NoDbgRegParms;
static sqInt sib(AbstractInstruction * self_in_sib, sqInt scale, sqInt indexReg, sqInt baseReg) NoDbgRegParms;
sqInt traceLinkedSendOffset(void);
static char * trampolineNamenumArgs(char *routinePrefix, sqInt numArgs) NoDbgRegParms;
static sqInt tryCollapseTempVectorInitializationOfSize(sqInt slots) NoDbgRegParms;
static sqInt twoByteInstructionSizeAt(AbstractInstruction * self_in_twoByteInstructionSizeAt, sqInt pc) NoDbgRegParms;
static sqInt unimplementedPrimitive(void);
static sqInt unknownBytecode(void);
void unlinkAllSends(void);
static sqInt unlinkIfFreeOrLinkedSendpcof(sqInt annotation, char *mcpc, sqInt theSelector) NoDbgRegParms;
static sqInt unlinkIfLinkedSendToFreepcignored(sqInt annotation, char *mcpc, sqInt superfluity) NoDbgRegParms;
static sqInt unlinkIfLinkedSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity) NoDbgRegParms;
static sqInt unlinkIfLinkedSendpcto(sqInt annotation, char *mcpc, sqInt theCogMethod) NoDbgRegParms;
void unlinkSendsOfisMNUSelector(sqInt selector, sqInt isMNUSelector);
void unlinkSendsToFree(void);
void unlinkSendsToandFreeIf(sqInt targetMethodObject, sqInt freeIfTrue);
static sqInt unsignedShortAt(AbstractInstruction * self_in_unsignedShortAt, sqInt byteAddress) NoDbgRegParms;
static AbstractInstruction * updateLabel(AbstractInstruction * self_in_updateLabel, AbstractInstruction *labelInstruction) NoDbgRegParms;
static sqInt updateMaybeObjRefAt(sqInt mcpc) NoDbgRegParms;
static sqInt v3PushNilSize(sqInt aMethodObj) NoDbgRegParms;
static sqInt v3BlockCodeSize(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
static sqInt v3IsPushNil(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
static sqInt v3LongForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
static sqInt v3LongBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
static sqInt v3ShortForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
void voidCogCompiledCode(void);
static void voidYoungReferrersPostTenureAll(void);
char * whereIsMaybeCodeThing(sqInt anOop);
static AbstractInstruction * gXorCwR(sqInt wordConstant, sqInt reg) NoDbgRegParms;
static void zeroOpcodeIndex(void);


/*** Variables ***/
static AbstractInstruction * abstractOpcodes;
static AbstractInstruction aMethodLabel;
static sqInt annotationIndex;
static InstructionAnnotation * annotations;
static AbstractInstruction * const backEnd = &aMethodLabel;
static usqInt baseAddress;
static sqInt blockCount;
static AbstractInstruction * blockEntryLabel;
static AbstractInstruction * blockEntryNoContextSwitch;
sqInt blockNoContextSwitchOffset;
static BlockStart * blockStarts;
static sqInt breakBlock;
static sqInt breakMethod;
sqInt breakPC;
static sqInt byte0;
static sqInt byte1;
static sqInt byte2;
static sqInt byte3;
static sqInt bytecodePC;
static sqInt bytecodeSetOffset;
void * CFramePointer;
void * CStackPointer;
static sqInt callerSavedRegMask;
static sqInt ceActiveContextTrampoline;
sqInt ceBaseFrameReturnTrampoline;
sqInt ceCannotResumeTrampoline;
void (*ceCaptureCStackPointers)(void);
static unsigned long (*ceCheckFeaturesFunction)(void);
sqInt ceCheckForInterruptTrampoline;
static sqInt ceClosureCopyTrampoline;
static sqInt ceCPICMissTrampoline;
static sqInt ceCreateNewArrayTrampoline;
void (*ceEnter0ArgsPIC)(void);
void (*ceEnter1ArgsPIC)(void);
void (*ceEnter2ArgsPIC)(void);
void (*ceEnterCogCodePopReceiverAndClassRegs)(void);
void (*ceEnterCogCodePopReceiverArg0Regs)(void);
void (*ceEnterCogCodePopReceiverArg1Arg0Regs)(void);
void (*ceEnterCogCodePopReceiverReg)(void);
static sqInt ceFetchContextInstVarTrampoline;
unsigned long (*ceGetSP)(void);
static sqInt ceMethodAbortTrampoline;
static sqInt ceNonLocalReturnTrampoline;
static sqInt cePICAbortTrampoline;
static sqInt cePositive32BitIntegerTrampoline;
static sqInt cePrimReturnEnterCogCode;
static sqInt cePrimReturnEnterCogCodeProfiling;
sqInt ceReturnToInterpreterTrampoline;
static sqInt ceSendMustBeBooleanAddFalseTrampoline;
static sqInt ceSendMustBeBooleanAddTrueTrampoline;
static sqInt ceStoreCheckTrampoline;
static sqInt ceStoreContextInstVarTrampoline;
static sqInt ceTraceBlockActivationTrampoline;
static sqInt ceTraceLinkedSendTrampoline;
static sqInt ceTraceStoreTrampoline;
unsigned long (*ceTryLockVMOwner)(void);
void (*ceUnlockVMOwner)(void);
sqInt cFramePointerInUse;
static sqInt checkedEntryAlignment;
static sqInt closedPICSize;
sqInt cmEntryOffset;
sqInt cmNoCheckEntryOffset;
static sqInt codeBase;
static sqInt codeModified;
static sqInt compilationTrace;
static sqInt cPICCaseSize;
static sqInt cPICEndSize;
static const int cStackAlignment = STACK_ALIGN_BYTES;
static sqInt deadCode;
static sqInt debugFixupBreaks;
unsigned long debugPrimCallStackOffset;
static AbstractInstruction * endCPICCase0;
static AbstractInstruction * endCPICCase1;
static sqInt endPC;
static AbstractInstruction * entry;
static sqInt entryPointMask;
static sqInt expectedFPAlignment;
static sqInt expectedSPAlignment;
static sqInt extA;
static sqInt extB;
static sqInt externalPrimCallOffsets[MaxNumArgs + 1];
static sqInt externalPrimJumpOffsets[MaxNumArgs + 1];
static sqInt firstCPICCaseOffset;
static sqInt firstSend;
static BytecodeFixup * fixups;
static BytecodeDescriptor generatorTable[256] = {
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushConstantTrueBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushConstantFalseBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushConstantNilBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genReturnReceiver, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0 },
	{ genReturnTrue, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0 },
	{ genReturnFalse, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0 },
	{ genReturnNil, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0 },
	{ genReturnTopFromMethod, 0, needsFrameIfInBlock, -1, 0, 1, 0, 0, 1, 0, 0, 1, 0 },
	{ genReturnTopFromBlock, 0, needsFrameNever, -1, 0, 1, 0, 0, 1, 0, 0, 0, 0 },
	{ unknownBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ unknownBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ extendedPushBytecode, 0, needsFrameNever, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0 },
	{ extendedStoreBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0 },
	{ extendedStoreAndPopBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0 },
	{ genExtendedSendBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0 },
	{ doubleExtendedDoAnythingBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0 },
	{ genExtendedSuperBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0 },
	{ genSecondExtendedSendBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0 },
	{ genPopStackBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ duplicateTopBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushActiveContextBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushNewArrayBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0 },
	{ unknownBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushRemoteTempLongBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreRemoteTempLongBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopRemoteTempLongBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushClosureCopyCopiedValuesBytecode, v3BlockCodeSize, 0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, AddRR, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, SubRR, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpLess, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpGreater, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpLessOrEqual, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpGreaterOrEqual, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpZero, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpNonZero, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, AndRR, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, OrRR, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorEqualsEquals, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genSpecialSelectorClass, 0, needsFrameIfStackGreaterThanOne, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0 }
};
static sqInt guardPageSize;
static sqInt hasYoungReferent;
static sqInt inBlock;
static sqInt initialPC;
static AbstractInstruction * interpretCall;
static AbstractInstruction * interpretLabel;
static int labelCounter;
static sqInt lastSend;
static usqInt limitAddress;
static sqInt maxLitIndex;
static CogBlockMethod * maxMethodBefore;
static sqInt methodAbortTrampolines[4];
static sqInt methodBytesFreedSinceLastCompaction;
static sqInt methodCount;
static AbstractInstruction * const methodLabel = &aMethodLabel;
static sqInt methodObj;
static sqInt methodOrBlockNumArgs;
static sqInt methodOrBlockNumTemps;
static sqInt methodZoneBase;
static unsigned long minValidCallAddress;
static sqInt missOffset;
static AbstractInstruction * mnuCall;
static usqInt mzFreeStart;
static sqInt needsFrame;
static AbstractInstruction * noCheckEntry;
static sqInt numAbstractOpcodes;
static sqInt numPICCases;
static sqInt objectReferencesInRuntime[NumObjRefsInRuntime];
static sqInt opcodeIndex;
static CogMethod *openPICList = 0;
static sqInt openPICSize;
static CogSSOptStatus optStatus;
static sqInt picAbortTrampolines[4];
static sqInt picMissTrampolines[4];
static void (*postCompileHook)(CogMethod *, void *);
static BytecodeDescriptor * prevBCDescriptor;
static AbstractInstruction * primInvokeLabel;
static PrimitiveDescriptor primitiveGeneratorTable[MaxCompiledPrimitiveIndex+1] = {
	{ 0, -1, 0 },
	{ genPrimitiveAdd, 1, 0 },
	{ genPrimitiveSubtract, 1, 0 },
	{ genPrimitiveLessThan, 1, 0 },
	{ genPrimitiveGreaterThan, 1, 0 },
	{ genPrimitiveLessOrEqual, 1, 0 },
	{ genPrimitiveGreaterOrEqual, 1, 0 },
	{ genPrimitiveEqual, 1, 0 },
	{ genPrimitiveNotEqual, 1, 0 },
	{ genPrimitiveMultiply, 1, processorHasMultiply },
	{ genPrimitiveDivide, 1, processorHasDivQuoRem },
	{ genPrimitiveMod, 1, processorHasDivQuoRem },
	{ genPrimitiveDiv, 1, processorHasDivQuoRem },
	{ genPrimitiveQuo, 1, processorHasDivQuoRem },
	{ genPrimitiveBitAnd, 1, 0 },
	{ genPrimitiveBitOr, 1, 0 },
	{ genPrimitiveBitXor, 1, 0 },
	{ genPrimitiveBitShift, 1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveAsFloat, 0, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatAdd, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatSubtract, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatLessThan, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatGreaterThan, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatLessOrEqual, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatGreaterOrEqual, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatEqual, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatNotEqual, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatMultiply, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatDivide, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveFloatSquareRoot, 0, processorHasDoublePrecisionFloatingPointSupport },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveAt, 1, 0 },
	{ genPrimitiveAtPut, 2, 0 },
	{ genPrimitiveSize, 0, 0 },
	{ genPrimitiveStringAt, 1, 0 },
	{ genPrimitiveStringAtPut, 2, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveNew, 0, 0 },
	{ genPrimitiveNewWithArg, 1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveIdentityHash, 0, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveNewMethod, 2, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveIdentical, 1, 0 },
	{ genPrimitiveClass, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveNotIdentical, 1, 0 },
	{ genPrimitiveAsCharacter, -1, 0 },
	{ genPrimitiveCharacterValue, 0, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveIdentityHash, 0, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genFastPrimFail, -1, 0 },
	{ genFastPrimFail, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveClosureValue, 0, 0 },
	{ genPrimitiveClosureValue, 1, 0 },
	{ genPrimitiveClosureValue, 2, 0 },
	{ genPrimitiveClosureValue, 3, 0 },
	{ genPrimitiveClosureValue, 4, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveClosureValue, 0, 0 },
	{ genPrimitiveClosureValue, 1, 0 }
};
static sqInt primitiveIndex;
void (*realCEEnterCogCodePopReceiverAndClassRegs)(void);
void (*realCEEnterCogCodePopReceiverArg0Regs)(void);
void (*realCEEnterCogCodePopReceiverArg1Arg0Regs)(void);
void (*realCEEnterCogCodePopReceiverReg)(void);
static sqInt regArgsHaveBeenPushed;
static sqInt runtimeObjectRefIndex;
static AbstractInstruction * sendMiss;
static AbstractInstruction * sendMissCall;
static sqInt sendTrampolines[NumSendTrampolines];
static CogSimStackEntry simSelf;
static sqInt simSpillBase;
static CogSimStackEntry simStack[78];
static sqInt simStackPtr;
static AbstractInstruction * stackCheckLabel;
static AbstractInstruction * stackOverflowCall;
static sqInt superSendTrampolines[NumSendTrampolines];
int traceFlags = 8 /* prim trace log on by default */;
sqInt traceStores;
static char *trampolineAddresses[NumTrampolines*2];
static sqInt trampolineTableIndex;
static sqInt uncheckedEntryAlignment;
static sqInt usesMethodClass;
static usqInt youngReferrers;


/*** Macros ***/
#define abstractInstructionAt(index) (&abstractOpcodes[index])
#define allocateBlockStarts(numBlocks) do { \
		blockStarts = (numBlocks) ? alloca(sizeof(BlockStart) * (numBlocks)) : 0; \
} while (0)
#define allocateOpcodesbytecodes(numberOfAbstractOpcodes,numberOfBytecodes) do { \
		int opcodeSize = sizeof(AbstractInstruction) * (numAbstractOpcodes = (numberOfAbstractOpcodes)); \
		int fixupSize = sizeof(BytecodeFixup) * numAbstractOpcodes; \
		int annotationSize = sizeof(InstructionAnnotation) * ((numAbstractOpcodes + 3) / 4); \
		abstractOpcodes = alloca(opcodeSize + fixupSize + annotationSize); \
		bzero(abstractOpcodes, opcodeSize + fixupSize); \
		fixups = (void *)((char *)abstractOpcodes + opcodeSize); \
		annotations = (void *)((char *)fixups + fixupSize); \
		opcodeIndex = labelCounter = annotationIndex = 0; \
} while (0)
#define allocateOpcodesbytecodesifFail(numberOfAbstractOpcodes,numberOfBytecodes,failBlock) do { \
		int opcodeSize = sizeof(AbstractInstruction) * (numAbstractOpcodes = (numberOfAbstractOpcodes)); \
		int fixupSize = sizeof(BytecodeFixup) * numAbstractOpcodes; \
		int annotationSize = sizeof(InstructionAnnotation) * ((numAbstractOpcodes + 3) / 4); \
		int allocSize = opcodeSize + fixupSize + annotationSize; \
		if (allocSize > MaxStackAllocSize) failBlock; \
		abstractOpcodes = alloca(allocSize); \
		bzero(abstractOpcodes, opcodeSize + fixupSize); \
		fixups = (void *)((char *)abstractOpcodes + opcodeSize); \
		annotations = (void *)((char *)fixups + fixupSize); \
		opcodeIndex = labelCounter = annotationIndex = 0; \
} while (0)
#define backEnd() backEnd
#define blockAlignment(self) 8
#define blockStartAt(index) (&blockStarts[index])
#define breakOnImplicitReceiver() (traceFlags & 64)
#define callerSavedRegMask() callerSavedRegMask
#define ceBaseFrameReturnPC() ceBaseFrameReturnTrampoline
#define ceCannotResumePC() ((usqInt)ceCannotResumeTrampoline)
#define ceCheckFeatures() ceCheckFeaturesFunction()
#define ceReturnToInterpreterPC() ((usqInt)ceReturnToInterpreterTrampoline)
#define cFramePointerAddress() ((unsigned long)&CFramePointer)
#define cPICNumCases stackCheckOffset
#define cPICNumCasesHack hack hack hack i.e. the getter macro does all the work
#define cr() putchar('\n')
#define cStackPointerAddress() ((unsigned long)&CStackPointer)
#define dynSuperEntryOffset() cmDynSuperEntryOffset
#define entryOffset() cmEntryOffset
#define fixupAt(index) (&fixups[index])
#define flushICacheFromto(me,startAddress,endAddress) 0
#define freeStart() mzFreeStart
#define generatorAt(index) (&generatorTable[index])
#define getCFramePointer() CFramePointer
#define getCStackPointer() CStackPointer
#define halt() warning("halt")
#define haltmsg(msg) warning("halt: " msg)
#define limitZony() ((CogMethod *)mzFreeStart)
#define maybeConstant(sse) ((sse)->constant)
#define methodBytesFreedSinceLastCompaction() methodBytesFreedSinceLastCompaction
#define methodZoneBase() methodZoneBase
#define minCallAddress() minValidCallAddress
#define nextOpenPIC methodObject
#define nextOpenPICHack hack hack hack i.e. the getter macro does all the work
#define noCheckEntryOffset() cmNoCheckEntryOffset
#define noContextSwitchBlockEntryOffset() blockNoContextSwitchOffset
#define notYetImplemented() warning("not yet implemented")
#define numberOfSaveableRegisters(self) 6
#define numElementsIn(anArray) (sizeof(anArray)/sizeof(anArray[0]))
#define printNum(n) printf("%ld", (long) n)
#define printOnTrace() (traceFlags & 1)
#define print(aString) printf("%s", aString)
#define recordBlockTrace() (traceFlags & 4)
#define recordEventTrace() (traceFlags & 16)
#define recordOverflowTrace() (traceFlags & 32)
#define recordPrimTrace() (traceFlags & 8)
#define recordSendTrace() (traceFlags & 2)
#define reportError(n) warning("compilation error")
#define roundUpLength(numBytes) ((numBytes) + 7 & -8)
#define setCFramePointer(theFP) (CFramePointer = (void *)(theFP))
#define setCStackPointer(theSP) (CStackPointer = (void *)(theSP))
#define simStackAt(index) (simStack + (index))
#define traceDescriptor(ign) 0
#define traceFixup(ign) 0
#define traceMapbyteatfor(ig,no,re,d) 0
#define traceMerge(ign) 0
#define traceSimStack() 0
#define traceSpill(ign) 0
#define tryLockVMOwner() (ceTryLockVMOwner() != 0)
#define unalignedLongAt(inst,byteAddress) longAt(byteAddress)
#define unalignedLongAtput(inst,byteAddress,aWord) longAtput(byteAddress,aWord)
#define unlockVMOwner() ceUnlockVMOwner()
#define youngReferrers() youngReferrers


static AbstractInstruction *
gAndCqR(sqInt quickConstant, sqInt reg)
{
	// Cogit>>#AndCq:R:
	return genoperandoperand(AndCqR, quickConstant, reg);
}

static AbstractInstruction *
gArithmeticShiftRightRR(sqInt reg1, sqInt reg2)
{
	// Cogit>>#ArithmeticShiftRightR:R:
	return genoperandoperand(ArithmeticShiftRightRR, reg1, reg2);
}

sqInt
abortOffset(void)
{
	// Cogit>>#abortOffset
	return missOffset;
}

static sqInt
abstractInstructionfollows(AbstractInstruction *theAbstractInstruction, AbstractInstruction *anAbstractInstruction)
{
	// Cogit>>#abstractInstruction:follows:
	return theAbstractInstruction > anAbstractInstruction;
}

static sqInt
abstractRegisterForConcreteRegister(AbstractInstruction * self_in_abstractRegisterForConcreteRegister, sqInt reg)
{
	// CogAbstractInstruction>>#abstractRegisterForConcreteRegister:
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, TempReg)) == reg) {
		return TempReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, ReceiverResultReg)) == reg) {
		return ReceiverResultReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, ClassReg)) == reg) {
		return ClassReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, SendNumArgsReg)) == reg) {
		return SendNumArgsReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, Arg0Reg)) == reg) {
		return Arg0Reg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, Arg1Reg)) == reg) {
		return Arg1Reg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, FPReg)) == reg) {
		return FPReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, SPReg)) == reg) {
		return SPReg;
	}
	error("could not find abstract register");
	return 0;
}


/*	Add a blockStart for an embedded block. For a binary tree walk block
	dispatch blocks must be compiled in pc/depth-first order but are scanned
	in breadth-first
	order, so do an insertion sort (which of course is really a bubble sort
	because we
	have to move everything higher to make room). */

static BlockStart *
addBlockStartAtnumArgsnumCopiedspan(sqInt bytecodepc, sqInt numArgs, sqInt numCopied, sqInt span)
{
	// StackToRegisterMappingCogit>>#addBlockStartAt:numArgs:numCopied:span:
    BlockStart *blockStart;
    sqInt i;
    sqInt j;


	/* Transcript ensureCr; nextPutAll: 'addBlockStartAt: '; print: bytecodepc; cr; flush. */

if (blockCount > 0) {

		/* Transcript ensureCr; nextPutAll: 'addBlockStartAt: '; print: bytecodepc; cr; flush. */


		/* Transcript ensureCr; nextPutAll: 'addBlockStartAt: '; print: bytecodepc; cr; flush. */

i = blockCount - 1;
		while (1) {

			/* check for repeat addition during recompilation due to initialNil miscount. */

blockStart = (&(blockStarts[i]));
			if (((blockStart->startpc)) == bytecodepc) {
				return blockStart;
			}
			if (!((((blockStart->startpc)) > bytecodepc)
			 && (i > 0))) break;
			i -= 1;
		}
		for (j = blockCount; j >= (i + 1); j += -1) {
			blockStarts[j] = (blockStarts[j - 1]);
		}
		blockStart = (&(blockStarts[i + 1]));
	}
	else {
blockStart = (&(blockStarts[blockCount]));
	}
	blockCount += 1;
	(blockStart->startpc = bytecodepc);
	(blockStart->numArgs = numArgs);
	(blockStart->numCopied = numCopied);
	(blockStart->numInitialNils = 0);
	(blockStart->stackCheckLabel = null);
	(blockStart->span = span);
	return blockStart;
}

static void
addCleanBlockStarts(void)
{
	// Cogit>>#addCleanBlockStarts
    sqInt i;
    sqInt iLimiT;
    sqInt lit;
    sqInt startPCOrNil;

	for (i = 1, iLimiT = (literalCountOf(methodObj)); i <= iLimiT; i += 1) {
		lit = fetchPointerofObject(i, methodObj);
		startPCOrNil = startPCOrNilOfLiteralin(lit, methodObj);
		if (!(startPCOrNil == null)) {
			maxLitIndex = ((maxLitIndex < i) ? i : maxLitIndex);
			addBlockStartAtnumArgsnumCopiedspan(startPCOrNil - 1, argumentCountOfClosure(lit), copiedValueCountOfClosure(lit), spanForCleanBlockStartingAt(startPCOrNil - 1));
		}
	}
}


/*	Perform an integrity/leak check using the heapMap.
	Set a bit at each cog method's header. */

void
addCogMethodsToHeapMap(void)
{
	// Cogit>>#addCogMethodsToHeapMap
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			heapMapAtWordPut(cogMethod, 1);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

static AbstractInstruction *
addDependent(AbstractInstruction * self_in_addDependent, AbstractInstruction *anInstruction)
{
	// CogAbstractInstruction>>#addDependent:
	if (((self_in_addDependent->dependent)) != null) {
		(anInstruction->dependent = (self_in_addDependent->dependent));
	}
	return ((self_in_addDependent->dependent) = anInstruction);
}

static sqInt
addressIsInFixups(AbstractInstruction *address)
{
	// Cogit>>#addressIsInFixups:
	return address >= (AbstractInstruction *)&fixups[0] && address < (AbstractInstruction *)&fixups[numAbstractOpcodes];
}

static sqInt
addressIsInInstructions(AbstractInstruction *address)
{
	// Cogit>>#addressIsInInstructions:
	return address >= &abstractOpcodes[0] && address < &abstractOpcodes[opcodeIndex];
}


/*	N.B. zero-relative */

static sqInt
addressOfEndOfCaseinCPIC(sqInt n, CogMethod *cPIC)
{
	// Cogit>>#addressOfEndOfCase:inCPIC:
	return ((((sqInt)cPIC)) + firstCPICCaseOffset) + (n * cPICCaseSize);
}

static void
addToOpenPICList(CogMethod *anOpenPIC)
{
	// CogMethodZone>>#addToOpenPICList:
	assert(((anOpenPIC->cmType)) == CMOpenPIC);
	assert((openPICList == null)
	 || (((openPICList->cmType)) == CMOpenPIC));
	(anOpenPIC->nextOpenPIC = ((usqInt)openPICList));
	openPICList = anOpenPIC;
}

static void
addToYoungReferrers(CogMethod *cogMethod)
{
	// CogMethodZone>>#addToYoungReferrers:
	assert(youngReferrers <= limitAddress);
	assert((occurrencesInYoungReferrers(cogMethod)) == 0);
	assert((cogMethod->cmRefersToYoung));
	if (!(asserta(roomOnYoungReferrersList()))) {
		error("no room on youngReferrers list");
	}
	youngReferrers -= BytesPerWord;
	longAtput(youngReferrers, ((usqInt)cogMethod));
}

static sqInt
alignUptoRoutineBoundary(sqInt anAddress)
{
	// Cogit>>#alignUptoRoutineBoundary:
	return (((anAddress + 7) | 7) - 7);
}


/*	Check that all methods have valid selectors, and that all linked sends are
	to valid targets and have valid cache tags
 */

static sqInt
allMachineCodeObjectReferencesValid(void)
{
	// Cogit>>#allMachineCodeObjectReferencesValid
    CogMethod *cogMethod;
    sqInt ok;

	ok = 1;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			if (!(asserta(checkValidOopReference((cogMethod->selector))))) {
				ok = 0;
			}
			if (!(asserta((cogMethodDoesntLookKosher(cogMethod)) == 0))) {
				ok = 0;
			}
		}
		if ((((cogMethod->cmType)) == CMMethod)
		 || (((cogMethod->cmType)) == CMOpenPIC)) {
			if (!(asserta((mapForperformUntilarg(cogMethod, checkIfValidOopRefAndTargetpccogMethod, ((sqInt)cogMethod))) == 0))) {
				ok = 0;
			}
		}
		if (((cogMethod->cmType)) == CMClosedPIC) {
			if (!(asserta(noTargetsFreeInClosedPIC(cogMethod)))) {
				ok = 0;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return ok;
}

static sqInt
allMethodsHaveCorrectHeader(void)
{
	// Cogit>>#allMethodsHaveCorrectHeader
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			if (!(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()))) {
				return 0;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return 1;
}

static sqInt
allocate(sqInt numBytes)
{
	// CogMethodZone>>#allocate:
    sqInt allocation;
    sqInt roundedBytes;

	roundedBytes = (numBytes + 7) & -8;
	if ((mzFreeStart + roundedBytes) >= (limitAddress - (methodCount * BytesPerWord))) {
		return 0;
	}
	allocation = mzFreeStart;
	mzFreeStart += roundedBytes;
	methodCount += 1;
	assert(roomOnYoungReferrersList());
	
return allocation;
}

static sqInt
allYoungObjectsAgeInFullGC(void)
{
	// CogObjectRepresentationForSqueakV3>>#allYoungObjectsAgeInFullGC
	return 1;
}

static AbstractInstruction *
annotateAbsolutePCRef(AbstractInstruction *abstractInstruction)
{
	// Cogit>>#annotateAbsolutePCRef:
	return annotatewith(abstractInstruction, IsAbsPCReference);
}

static void
annotateBytecodeIfAnnotated(CogSimStackEntry *aSimStackEntry)
{
	// StackToRegisterMappingCogit>>#annotateBytecodeIfAnnotated:
    AbstractInstruction *abstractInstruction;

	if ((aSimStackEntry->annotateUse)) {
		/* begin annotateBytecode: */
		abstractInstruction = (prevInstIsPCAnnotated()
			? (/* begin Nop */
				gen(Nop))
			: (/* begin Label */
				genoperandoperand(Label, (labelCounter += 1), bytecodePC)));
		annotatewith(abstractInstruction, HasBytecodePC);
		(aSimStackEntry->annotateUse = 0);
	}
}

static AbstractInstruction *
annotateBytecode(AbstractInstruction *abstractInstruction)
{
	// Cogit>>#annotateBytecode:
	return annotatewith(abstractInstruction, HasBytecodePC);
}

static AbstractInstruction *
annotateobjRef(AbstractInstruction *abstractInstruction, sqInt anOop)
{
	// Cogit>>#annotate:objRef:
	if (shouldAnnotateObjectReference(anOop)) {
		if (isYoungObject(anOop)) {
			hasYoungReferent = 1;
		}
		return annotatewith(abstractInstruction, IsObjectReference);
	}
	return abstractInstruction;
}


/*	<Integer> */

static AbstractInstruction *
annotatewith(AbstractInstruction *abstractInstruction, sqInt annotationFlag)
{
	// Cogit>>#annotate:with:
    InstructionAnnotation *annotation;

	annotation = (&(annotations[annotationIndex]));
	annotationIndex += 1;
	(annotation->instruction = abstractInstruction);
	(annotation->annotation = annotationFlag);
	return abstractInstruction;
}

static sqInt
anyReferencesToRegisterinTopNItems(sqInt reg, sqInt n)
{
	// StackToRegisterMappingCogit>>#anyReferencesToRegister:inTopNItems:
    sqInt i;
    sqInt regMask;

	regMask = registerMaskFor(reg);
	for (i = simStackPtr; i >= ((simStackPtr - n) + 1); i += -1) {
		if ((registerMask(simStackAt(i))) & regMask) {
			return 1;
		}
	}
	return 0;
}

static void
assertSaneJumpTarget(AbstractInstruction *jumpTarget)
{
	// Cogit>>#assertSaneJumpTarget:
	assert((closedPICSize == null)
	 || ((openPICSize == null)
	 || ((addressIsInInstructions(jumpTarget))
	 || ((((((usqInt)jumpTarget)) >= codeBase) && ((((usqInt)jumpTarget)) <= ((((sqInt)(limitZony()))) + (((closedPICSize < openPICSize) ? openPICSize : closedPICSize)))))))));
}

static sqInt
blockCreationBytecodeSizeForHeader(sqInt methodHeader)
{
	// Cogit>>#blockCreationBytecodeSizeForHeader:
	return BlockCreationBytecodeSize;
}


/*	Evaluate binaryFunction with the block start mcpc and supplied arg for
	each entry in the block dispatch. If the function answers non-zero answer
	the value
	it answered. Used to update back-references to the home method in
	compaction.  */

static sqInt
blockDispatchTargetsForperformarg(CogMethod *cogMethod, usqInt (*binaryFunction)(sqInt mcpc, sqInt arg), sqInt arg)
{
	// Cogit>>#blockDispatchTargetsFor:perform:arg:
    sqInt blockEntry;
    sqInt end;
    sqInt pc;
    sqInt result;
    sqInt targetpc;

	if (((cogMethod->blockEntryOffset)) == 0) {
		return null;
	}
	blockEntry = ((cogMethod->blockEntryOffset)) + (((sqInt)cogMethod));
	pc = blockEntry;
	end = (mapEndFor(cogMethod)) - 1;
	while (pc < end) {
if (isJumpAt(backEnd, pc)) {
			targetpc = jumpTargetPCAt(backEnd, pc);
			if (targetpc < blockEntry) {
result = binaryFunction(targetpc, arg);
				if (result != 0) {
return result;
				}
			}
		}
		pc += instructionSizeAt(backEnd, pc);
	}
	return 0;
}


/*	Answer the zero-relative bytecode pc matching the machine code pc argument
	in cogMethod, given the start of the bytecodes for cogMethod's block or
	method object. */

sqInt
bytecodePCForstartBcpcin(sqInt mcpc, sqInt startbcpc, CogBlockMethod *cogMethod)
{
	// Cogit>>#bytecodePCFor:startBcpc:in:
    sqInt aMethodObj;
    sqInt annotation;
    sqInt bcpc;
    sqInt bsOffset;
    sqInt byte;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt endbcpc;
    CogMethod *homeMethod;
    sqInt isBackwardBranch;
    sqInt isInBlock;
    sqInt latestContinuation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc1;
    sqInt methodHeader;
    sqInt methodHeader1;
    sqInt nExts;
    sqInt nextBcpc;
    sqInt result;
    sqInt targetPC;

	/* begin mapFor:bcpc:performUntil:arg: */
	assert(((cogMethod->stackCheckOffset)) > 0);
	if (((cogMethod->cmType)) == CMMethod) {
		isInBlock = 0;
		homeMethod = ((CogMethod *) cogMethod);
		assert(startbcpc == (startPCOfMethodHeader((homeMethod->methodHeader))));
		map = ((((usqInt)homeMethod)) + ((homeMethod->blockSize))) - 1;
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == IsAbsPCReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsObjectReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsRelativeCall)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N))));
		latestContinuation = startbcpc;
		aMethodObj = (homeMethod->methodObject);
		endbcpc = (byteLengthOf(aMethodObj)) - 1;
		/* begin bytecodeSetOffsetForHeader: */
		methodHeader = (homeMethod->methodHeader);
		bsOffset = 0;
	}
	else {
isInBlock = 1;
		homeMethod = cmHomeMethod(cogMethod);
		map = findMapLocationForMcpcinMethod((((usqInt)cogMethod)) + (sizeof(CogBlockMethod)), homeMethod);
		assert(map != 0);
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == HasBytecodePC)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N));
		while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
			map -= 1;
		}

		/* skip fiducial; i.e. the map entry for the pc immediately following the method header. */

map -= 1;
		aMethodObj = (homeMethod->methodObject);
		bcpc = startbcpc - (blockCreationBytecodeSizeForHeader((homeMethod->methodHeader)));
		/* begin bytecodeSetOffsetForHeader: */
		methodHeader1 = (homeMethod->methodHeader);
		bsOffset = 0;
		byte = (fetchByteofObject(bcpc, aMethodObj)) + bsOffset;
		descriptor = generatorAt(byte);
		endbcpc = (bcpc + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc, -1, aMethodObj)
	: 0));
	}
	bcpc = startbcpc;
	mcpc1 = (((usqInt)cogMethod)) + ((cogMethod->stackCheckOffset));

	/* The stack check maps to the start of the first bytecode,
	   the first bytecode being effectively after frame build. */

	nExts = 0;
	result = findIsBackwardBranchMcpcBcpcMatchingMcpc(null, 0, (((char *) mcpc1)), startbcpc, (((void *)mcpc)));
	if (result != 0) {
return result;
	}
	while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
		map -= 1;
	}
	map -= 1;
	while (((mapByte = byteAt(map))) != MapEnd) {

		/* defensive; we exit on bcpc */

if (mapByte >= FirstAnnotation) {

			/* defensive; we exit on bcpc */


			/* defensive; we exit on bcpc */

annotation = ((usqInt) mapByte) >> AnnotationShift;
			mcpc1 += mapByte & DisplacementMask;
			if ((annotation == IsSendCall)
							 || (annotation == HasBytecodePC)) {
while (1) {
byte = (fetchByteofObject(bcpc, aMethodObj)) + bsOffset;
					descriptor = generatorAt(byte);
					if (isInBlock) {
if (bcpc >= endbcpc) {
return 0;
						}
					}
					else {
if (((descriptor->isReturn))
						 && (bcpc >= latestContinuation)) {
							return 0;
						}
						if ((isBranch(descriptor))
						 || ((descriptor->isBlockCreation))) {
							/* begin latestContinuationPCFor:at:exts:in: */
							distance = ((descriptor->spanFunction))(descriptor, bcpc, nExts, aMethodObj);
							targetPC = (bcpc + ((descriptor->numBytes))) + (((distance < 0) ? 0 : distance));
							latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
						}
					}
					nextBcpc = (bcpc + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc, nExts, aMethodObj)
	: 0));
					if (((descriptor->isMapped))
					 || (isInBlock
					 && ((descriptor->isMappedInBlock)))) break;
					bcpc = nextBcpc;
					nExts = ((descriptor->isExtension)
						? nExts + 1
						: 0);
				}
				isBackwardBranch = (isBranch(descriptor))
				 && (isBackwardBranchatextsin(descriptor, bcpc, nExts, aMethodObj));
				result = findIsBackwardBranchMcpcBcpcMatchingMcpc(descriptor, isBackwardBranch, (((char *) mcpc1)), bcpc, (((void *)mcpc)));
				if (result != 0) {
return result;
				}
				bcpc = nextBcpc;
				nExts = ((descriptor->isExtension)
					? nExts + 1
					: 0);
			}
			/* begin maybeRememberPrevMap:absPCMcpc: */
		}
		else {
mcpc1 += (mapByte >= DisplacementX2N
				? (mapByte - DisplacementX2N) << AnnotationShift
				: mapByte);
		}
		map -= 1;
	}
	return 0;
}

static AbstractInstruction *
CallRT(sqInt callTarget)
{
	// Cogit>>#CallRT:
    AbstractInstruction *abstractInstruction;

	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction = genoperand(Call, callTarget);
	return annotatewith(abstractInstruction, IsRelativeCall);
}

static AbstractInstruction *
CallRTregistersToBeSavedMask(sqInt callTarget, sqInt registersToBeSaved)
{
	// Cogit>>#CallRT:registersToBeSavedMask:
    sqInt callerSavedRegsToBeSaved;
    AbstractInstruction *lastInst;
    sqInt reg;

	callerSavedRegsToBeSaved = callerSavedRegMask & registersToBeSaved;
	for (reg = GPRegMax; reg >= GPRegMin; reg += -1) {
if ((reg != TempReg)
		 && (callerSavedRegsToBeSaved & (registerMaskFor(reg)))) {
			/* begin PushR: */
			genoperand(PushR, reg);
		}
	}
	lastInst = CallRT(callTarget);
	for (reg = GPRegMin; reg <= GPRegMax; reg += 1) {
if ((reg != TempReg)
		 && (callerSavedRegsToBeSaved & (registerMaskFor(reg)))) {
			/* begin PopR: */
			lastInst = genoperand(PopR, reg);
		}
	}
	return lastInst;
}

static AbstractInstruction *
CallSend(sqInt callTarget)
{
	// Cogit>>#CallSend:
    AbstractInstruction *abstractInstruction;

	/* begin annotateSend: */
	/* begin Call: */
	abstractInstruction = genoperand(Call, callTarget);
	return annotatewith(abstractInstruction, IsSendCall);
}

static AbstractInstruction *
gCall(sqInt callTarget)
{
	// Cogit>>#Call:
	return genoperand(Call, callTarget);
}

static AbstractInstruction *
gCmpCqR(sqInt quickConstant, sqInt reg)
{
	// Cogit>>#CmpCq:R:
	return genoperandoperand(CmpCqR, quickConstant, reg);
}

static AbstractInstruction *
gCmpCwR(sqInt wordConstant, sqInt reg)
{
	// Cogit>>#CmpCw:R:
	return genoperandoperand(CmpCwR, wordConstant, reg);
}


/*	Answer if the cacheTag is not unmarked, i.e. answer true for compact
	class indices and immediates; only answer false for unmarked objects */

static sqInt
cacheTagIsMarked(sqInt cacheTag)
{
	// CogObjectRepresentationForSqueakV3>>#cacheTagIsMarked:
	if (!(couldBeObject(cacheTag))) {
		return 1;
	}
	assert(addressCouldBeObj(cacheTag));
	return isMarked(cacheTag);
}

static sqInt
callerSavedRegisterMask(AbstractInstruction * self_in_callerSavedRegisterMask)
{
	// CogIA32Compiler>>#callerSavedRegisterMask
	return registerMaskForandand(abstractRegisterForConcreteRegister(self_in_callerSavedRegisterMask, EAX), abstractRegisterForConcreteRegister(self_in_callerSavedRegisterMask, ECX), abstractRegisterForConcreteRegister(self_in_callerSavedRegisterMask, EDX));
}

static sqInt
callInstructionByteSize(AbstractInstruction * self_in_callInstructionByteSize)
{
	// CogIA32Compiler>>#callInstructionByteSize
	return 5;
}

static sqInt
callsAreRelative(AbstractInstruction * self_in_callsAreRelative)
{
	// CogIA32Compiler>>#callsAreRelative
	return 1;
}


/*	Answer the address the call immediately preceeding callSiteReturnAddress
	will jump to.
 */

static sqInt
callTargetFromReturnAddress(AbstractInstruction * self_in_callTargetFromReturnAddress, sqInt callSiteReturnAddress)
{
	// CogIA32Compiler>>#callTargetFromReturnAddress:
    sqInt callDistance;

	callDistance = literalBeforeFollowingAddress(self_in_callTargetFromReturnAddress, callSiteReturnAddress);
	return callSiteReturnAddress + (((sqInt) callDistance));
}

static sqInt
canDivQuoRem(AbstractInstruction * self_in_canDivQuoRem)
{
	// CogIA32Compiler>>#canDivQuoRem
	return 1;
}

sqInt
canLinkToYoungClasses(void)
{
	// CogObjectRepresentationForSqueakV3>>#canLinkToYoungClasses
	return roomOnYoungReferrersList();
}

static sqInt
canMulRR(AbstractInstruction * self_in_canMulRR)
{
	// CogIA32Compiler>>#canMulRR
	return 1;
}


/*	<Integer> */

static sqInt
ceClosureCopyDescriptor(sqInt descriptor)
{
	// SimpleStackBasedCogit>>#ceClosureCopyDescriptor:
	return createClosureNumArgsnumCopiedstartpc(descriptor & 0x3F, (((usqInt) descriptor) >> 6) & 0x3F, ((usqInt) descriptor) >> 12);
}


/*	Code entry closed PIC miss. A send has fallen
	through a closed (finite) polymorphic inline cache.
	Either extend it or patch the send site to an open PIC.
	The stack looks like:
	receiver
	args
	sp=>	sender return address */

sqInt
ceCPICMissreceiver(CogMethod *cPIC, sqInt receiver)
{
	// Cogit>>#ceCPICMiss:receiver:
    sqInt cacheTag;
    sqInt errorSelectorOrNil;
    sqInt errsel;
    sqInt method;
    sqInt methodOrSelectorIndex;
    sqInt newTargetMethodOrNil;
    sqInt outerReturn;
    sqInt result;
    sqInt selector;

	

outerReturn = stackTop();
	if (((cPIC->cPICNumCases)) < numPICCases) {
		/* begin lookup:for:methodAndErrorSelectorInto: */
		selector = (cPIC->selector);
		methodOrSelectorIndex = lookupreceiver(selector, receiver);
		if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
			if (!(isOopCompiledMethod(methodOrSelectorIndex))) {
				newTargetMethodOrNil = methodOrSelectorIndex;
				errorSelectorOrNil = SelectorCannotInterpret;

				goto l1;
			}
			if ((!(methodHasCogMethod(methodOrSelectorIndex)))
			 && (methodShouldBeCogged(methodOrSelectorIndex))) {

				/* We assume cog:selector: will *not* reclaim the method zone */

cogselector(methodOrSelectorIndex, selector);
			}
			newTargetMethodOrNil = methodOrSelectorIndex;
			errorSelectorOrNil = null;

			goto l1;
		}
		if (methodOrSelectorIndex == SelectorDoesNotUnderstand) {
methodOrSelectorIndex = lookupreceiver(splObj(SelectorDoesNotUnderstand), receiver);
			if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
				assert(isOopCompiledMethod(methodOrSelectorIndex));
				if ((!(methodHasCogMethod(methodOrSelectorIndex)))
				 && (methodShouldBeCogged(methodOrSelectorIndex))) {

					/* We assume cog:selector: will *not* reclaim the method zone */

cogselector(methodOrSelectorIndex, selector);
				}
				newTargetMethodOrNil = methodOrSelectorIndex;
				errorSelectorOrNil = SelectorDoesNotUnderstand;

				goto l1;
			}
			newTargetMethodOrNil = null;
			errorSelectorOrNil = SelectorDoesNotUnderstand;

			goto l1;
		}
		newTargetMethodOrNil = null;
		errorSelectorOrNil = methodOrSelectorIndex;

	l1:	/* end lookup:for:methodAndErrorSelectorInto: */;
	}
	else {
newTargetMethodOrNil = (errorSelectorOrNil = null);
	}
	assert(outerReturn == (stackTop()));
	cacheTag = inlineCacheTagForInstance(receiver);
	if ((((cPIC->cPICNumCases)) >= numPICCases)
	 || (((errorSelectorOrNil != null)
	 && (errorSelectorOrNil != SelectorDoesNotUnderstand))
	 || ((inlineCacheTagIsYoung(cacheTag))
	 || ((newTargetMethodOrNil == null)
	 || (isYoung(newTargetMethodOrNil)))))) {
		result = patchToOpenPICFornumArgsreceiver((cPIC->selector), (cPIC->cmNumArgs), receiver);
		assert(!result);
		return ceSendFromInLineCacheMiss(cPIC);
	}
	cogExtendPICCaseNMethodtagisMNUCase(cPIC, newTargetMethodOrNil, cacheTag, errorSelectorOrNil == SelectorDoesNotUnderstand);
	executeCogMethodfromLinkedSendWithReceiverandCacheTag(cPIC, receiver, inlineCacheTagAt(backEnd, outerReturn));
	return null;
}


/*	An in-line cache check in a method has failed. The failing entry check has
	jumped to the ceMethodAbort abort call at the start of the method which
	has called this routine.
	If possible allocate a closed PIC for the current and existing classes.
	The stack looks like:
	receiver
	args
	sender return address
	sp=>	ceMethodAbort call return address
	So we can find the method that did the failing entry check at
	ceMethodAbort call return address - missOffset
	and we can find the send site from the outer return address. */

sqInt
ceSICMiss(sqInt receiver)
{
	// Cogit>>#ceSICMiss:
    sqInt cacheTag;
    sqInt entryPoint;
    sqInt errorSelectorOrNil;
    sqInt errsel;
    sqInt extent;
    sqInt innerReturn;
    sqInt method;
    sqInt methodOrSelectorIndex;
    sqInt newTargetMethodOrNil;
    sqInt outerReturn;
    CogMethod *pic;
    sqInt result;
    sqInt selector;
    CogMethod *targetMethod;


	/* Whether we can relink to a PIC or not we need to pop off the inner return and identify the target method. */


	/* Whether we can relink to a PIC or not we need to pop off the inner return and identify the target method. */

innerReturn = popStack();
	targetMethod = ((CogMethod *) (innerReturn - missOffset));
	
outerReturn = stackTop();
	assert(((outerReturn >= methodZoneBase) && (outerReturn <= (freeStart()))));
	entryPoint = callTargetFromReturnAddress(backEnd, outerReturn);
	assert(((targetMethod->selector)) != (nilObject()));
	
assert(((((sqInt)targetMethod)) + cmEntryOffset) == entryPoint);
	/* begin lookup:for:methodAndErrorSelectorInto: */
	selector = (targetMethod->selector);
	methodOrSelectorIndex = lookupreceiver(selector, receiver);
	if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
		if (!(isOopCompiledMethod(methodOrSelectorIndex))) {
			newTargetMethodOrNil = methodOrSelectorIndex;
			errorSelectorOrNil = SelectorCannotInterpret;

			goto l1;
		}
		if ((!(methodHasCogMethod(methodOrSelectorIndex)))
		 && (methodShouldBeCogged(methodOrSelectorIndex))) {

			/* We assume cog:selector: will *not* reclaim the method zone */

cogselector(methodOrSelectorIndex, selector);
		}
		newTargetMethodOrNil = methodOrSelectorIndex;
		errorSelectorOrNil = null;

		goto l1;
	}
	if (methodOrSelectorIndex == SelectorDoesNotUnderstand) {
methodOrSelectorIndex = lookupreceiver(splObj(SelectorDoesNotUnderstand), receiver);
		if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
			assert(isOopCompiledMethod(methodOrSelectorIndex));
			if ((!(methodHasCogMethod(methodOrSelectorIndex)))
			 && (methodShouldBeCogged(methodOrSelectorIndex))) {

				/* We assume cog:selector: will *not* reclaim the method zone */

cogselector(methodOrSelectorIndex, selector);
			}
			newTargetMethodOrNil = methodOrSelectorIndex;
			errorSelectorOrNil = SelectorDoesNotUnderstand;

			goto l1;
		}
		newTargetMethodOrNil = null;
		errorSelectorOrNil = SelectorDoesNotUnderstand;

		goto l1;
	}
	newTargetMethodOrNil = null;
	errorSelectorOrNil = methodOrSelectorIndex;

l1:	/* end lookup:for:methodAndErrorSelectorInto: */;
	assert(outerReturn == (stackTop()));
	cacheTag = inlineCacheTagForInstance(receiver);
	if (((errorSelectorOrNil != null)
	 && (errorSelectorOrNil != SelectorDoesNotUnderstand))
	 || ((inlineCacheTagIsYoung(cacheTag))
	 || ((newTargetMethodOrNil == null)
	 || (isYoung(newTargetMethodOrNil))))) {
		result = patchToOpenPICFornumArgsreceiver((targetMethod->selector), (targetMethod->cmNumArgs), receiver);
		assert(!result);
		return ceSendFromInLineCacheMiss(targetMethod);
	}
	pic = openPICWithSelector((targetMethod->selector));
	if (pic == null) {

		/* otherwise attempt to create a closed PIC for the two cases. */


		/* otherwise attempt to create a closed PIC for the two cases. */

pic = cogPICSelectornumArgsCase0MethodCase1MethodtagisMNUCase((targetMethod->selector), (targetMethod->cmNumArgs), targetMethod, newTargetMethodOrNil, cacheTag, errorSelectorOrNil == SelectorDoesNotUnderstand);
		if ((((((sqInt)pic)) >= MaxNegativeErrorCode) && ((((sqInt)pic)) <= -1))) {

			/* For some reason the PIC couldn't be generated, most likely a lack of code memory.
			   Continue as if this is an unlinked send. */

			if ((((sqInt)pic)) == InsufficientCodeSpace) {

				/* For some reason the PIC couldn't be generated, most likely a lack of code memory.
				   Continue as if this is an unlinked send. */

				callForCogCompiledCodeCompaction();
			}
			return ceSendFromInLineCacheMiss(targetMethod);
		}
		flushICacheFromto(processor, ((sqInt)pic), (((sqInt)pic)) + closedPICSize);
	}
	extent = (((pic->cmType)) == CMOpenPIC
		? rewriteInlineCacheAttagtarget(backEnd, outerReturn, (targetMethod->selector), (((sqInt)pic)) + cmEntryOffset)
		: rewriteCallAttarget(backEnd, outerReturn, (((sqInt)pic)) + cmEntryOffset));
	flushICacheFromto(processor, (outerReturn - 1) - extent, outerReturn - 1);
	executeCogMethodfromLinkedSendWithReceiverandCacheTag(pic, receiver, inlineCacheTagAt(backEnd, outerReturn));
	return null;
}

void
checkAssertsEnabledInCogit(void)
{
	// Cogit>>#checkAssertsEnabledInCogit
    sqInt assertsAreEnabledInCogit;

	assertsAreEnabledInCogit = 0;
	assert(assertsAreEnabledInCogit);
}

static sqInt
checkIfValidOopRefAndTargetpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
	// Cogit>>#checkIfValidOopRefAndTarget:pc:cogMethod:
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt offset;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObject;
    sqInt targetMethod;
    CogMethod *targetMethod1;

	if (annotation == IsObjectReference) {
literal = literalBeforeFollowingAddress(backEnd, ((sqInt)mcpc));
		if (!(asserta(checkValidOopReference(literal)))) {
			return 1;
		}
		if ((couldBeObject(literal))
		 && (isReallyYoungObject(literal))) {
			if (!(asserta(((((CogMethod *) cogMethod))->cmRefersToYoung)))) {
				return 2;
			}
		}
	}
	if (annotation == IsSendCall) {
if (!(asserta((((((CogMethod *) cogMethod))->cmType)) == CMMethod))) {
			return 3;
		}
		/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */

		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj = (inlineCacheTagsMayBeObjects())
		 || ((entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC))));
		if (tagCouldBeObj) {
if (couldBeObject(cacheTag1)) {
				if (!(asserta(checkValidOopReference(cacheTag1)))) {
					return 4;
				}
			}
			else {
if (!(asserta(checkValidInlineCacheTag(cacheTag1)))) {
					return 5;
				}
			}
			if ((couldBeObject(cacheTag1))
			 && (isReallyYoungObject(cacheTag1))) {
				if (!(asserta(((((CogMethod *) cogMethod))->cmRefersToYoung)))) {
					return 6;
				}
			}
		}
		else {
if (!(asserta(checkValidInlineCacheTag(cacheTag1)))) {
				return 7;
			}
		}

		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send; find which kind. */

/* begin targetMethodAndSendTableFor:into: */
			if ((entryPoint & entryPointMask) == checkedEntryAlignment) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = sendTrampolines;
			}
			else {
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;
			}

			
			/* It's a linked send; find which kind. */

if (!(asserta((((targetMethod1->cmType)) == CMMethod)
				 || ((((targetMethod1->cmType)) == CMClosedPIC)
				 || (((targetMethod1->cmType)) == CMOpenPIC))))) {
				return 8;
			}

		}
	}
	return 0;
}

static sqInt
checkIfValidOopRefpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
	// Cogit>>#checkIfValidOopRef:pc:cogMethod:
    sqInt entryPoint;
    sqInt literal;
    sqInt off;
    sqInt offset;
    sqInt selectorOrCacheTag;
    sqInt table;

	if (annotation == IsObjectReference) {
literal = literalBeforeFollowingAddress(backEnd, ((sqInt)mcpc));
		if (!(checkValidOopReference(literal))) {
			print("object ref leak in CM ");
			printHex(((sqInt)cogMethod));
			print(" @ ");
			printHex(((sqInt)mcpc));
			cr();
			return 1;
		}
	}
	if (annotation == IsSendCall) {
entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint <= methodZoneBase) {
			offset = entryPoint;
		}
		else {
/* begin offsetAndSendTableFor:annotation:into: */
			if ((entryPoint & entryPointMask) == checkedEntryAlignment) {
				offset = cmEntryOffset;

			}
			else {
				offset = cmNoCheckEntryOffset;

			}

		}
		selectorOrCacheTag = inlineCacheTagAt(backEnd, ((sqInt)mcpc));
		if ((entryPoint > methodZoneBase)
		 && ((offset != cmNoCheckEntryOffset)
		 && ((((((CogMethod *) (entryPoint - offset)))->cmType)) != CMOpenPIC))) {

			/* linked non-super send, cacheTag is a cacheTag */

if (!(checkValidInlineCacheTag(selectorOrCacheTag))) {

				/* linked non-super send, cacheTag is a cacheTag */

print("cache tag leak in CM ");
				printHex(((sqInt)cogMethod));
				print(" @ ");
				printHex(((sqInt)mcpc));
				cr();
				return 1;
			}
		}
		else {

			/* unlinked send or super send; cacheTag is a selector */

if (!(checkValidOopReference(selectorOrCacheTag))) {

				/* unlinked send or super send; cacheTag is a selector */

print("selector leak in CM ");
				printHex(((sqInt)cogMethod));
				print(" @ ");
				printHex(((sqInt)mcpc));
				cr();
				return 1;
			}
		}
	}
	return 0;
}


/*	Answer if all references to objects in machine-code are valid. */

sqInt
checkIntegrityOfObjectReferencesInCode(sqInt fullGCFlag)
{
	// Cogit>>#checkIntegrityOfObjectReferencesInCode:
    CogMethod *cogMethod;
    sqInt count;
    sqInt ok;

	cogMethod = ((CogMethod *) methodZoneBase);
	ok = 1;
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			if ((cogMethod->cmRefersToYoung)) {
				if (((count = occurrencesInYoungReferrers(cogMethod))) != 1) {
					print("young referrer CM ");
					printHex(((sqInt)cogMethod));
					if (count == 0) {
print(" is not in youngReferrers");
						cr();
					}
					else {
print(" is in youngReferrers ");
						printNum(count);
						print(" times!");
						cr();
					}
					ok = 0;
				}
			}
			if (!(checkValidOopReference((cogMethod->selector)))) {
				print("object leak in CM ");
				printHex(((sqInt)cogMethod));
				print(" selector");
				cr();
				ok = 0;
			}
			if (((cogMethod->cmType)) == CMMethod) {
				assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
				if (!(checkValidObjectReference((cogMethod->methodObject)))) {
					print("object leak in CM ");
					printHex(((sqInt)cogMethod));
					print(" methodObject");
					cr();
					ok = 0;
				}
				if (!(isOopCompiledMethod((cogMethod->methodObject)))) {
					print("non-method in CM ");
					printHex(((sqInt)cogMethod));
					print(" methodObject");
					cr();
					ok = 0;
				}
				if ((mapForperformUntilarg(cogMethod, checkIfValidOopRefpccogMethod, ((sqInt)cogMethod))) != 0) {
					ok = 0;
				}
				if (!fullGCFlag) {
if (((isYoungObject((cogMethod->methodObject)))
					 || (isYoung((cogMethod->selector))))
					 && (!((cogMethod->cmRefersToYoung)))) {
						print("CM ");
						printHex(((sqInt)cogMethod));
						print(" refers to young but not marked as such");
						cr();
						ok = 0;
					}
				}
			}
			else {
if (((cogMethod->cmType)) == CMClosedPIC) {
					if (!(checkValidObjectReferencesInClosedPIC(cogMethod))) {
						ok = 0;
					}
				}
				else {
if (((cogMethod->cmType)) == CMOpenPIC) {
						if ((mapForperformUntilarg(cogMethod, checkIfValidOopRefpccogMethod, ((sqInt)cogMethod))) != 0) {
							ok = 0;
						}
					}
				}
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return ok;
}

static sqInt
checkMaybeObjRefAt(sqInt mcpc)
{
	// Cogit>>#checkMaybeObjRefAt:
    sqInt maybeObject;

	maybeObject = literalBeforeFollowingAddress(backEnd, mcpc);
	if (maybeObject == 0) {
return 1;
	}
	if (!(couldBeObject(maybeObject))) {
		return 1;
	}
	return checkValidObjectReference(maybeObject);
}


/*	Disable primitive generators with enablers that answer false. */

static void
checkPrimitiveTableEnablers(void)
{
	// Cogit>>#checkPrimitiveTableEnablers
    sqInt i;
    PrimitiveDescriptor *primitiveDescriptor;

	for (i = 1; i <= MaxCompiledPrimitiveIndex; i += 1) {
primitiveDescriptor = (&(primitiveGeneratorTable[i]));
		if (((primitiveDescriptor->enabled)) != null) {
			if (!(((primitiveDescriptor->enabled))(i))) {
				(primitiveDescriptor->primitiveGenerator = null);
			}
		}
	}
}

static sqInt
checkValidInlineCacheTag(sqInt cacheTag)
{
	// CogObjectRepresentationForSqueakV3>>#checkValidInlineCacheTag:
	return (((cacheTag & ((1 << ShiftForWord) - 1)) == 0)
	 && (((cacheTag >= (1 << ShiftForWord)) && (cacheTag <= ((compactClassIndexOfHeader(-1)) << ShiftForWord)))))
	 || (checkValidObjectReference(cacheTag));
}

static sqInt
checkValidObjectReferencesInClosedPIC(CogMethod *cPIC)
{
	// Cogit>>#checkValidObjectReferencesInClosedPIC:
    sqInt i;
    sqInt ok;
    sqInt pc;

	ok = 1;
	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	if (!(checkMaybeObjRefAt(pc - (jumpLongByteSize(backEnd))))) {
		print("object leak in CPIC ");
		printHex(((sqInt)cPIC));
		print(" @ ");
		printHex(pc - (jumpLongByteSize(backEnd)));
		cr();
		ok = 0;
	}
	pc += cPICCaseSize;
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		if (!(checkMaybeObjRefAt((pc - (jumpLongConditionalByteSize(backEnd))) - (loadLiteralByteSize(backEnd))))) {
			print("object leak in CPIC ");
			printHex(((sqInt)cPIC));
			print(" @ ");
			printHex((pc - (jumpLongConditionalByteSize(backEnd))) - (loadLiteralByteSize(backEnd)));
			cr();
			ok = 0;
		}

		if (!(checkMaybeObjRefAt(pc - (jumpLongConditionalByteSize(backEnd))))) {
			print("object leak in CPIC ");
			printHex(((sqInt)cPIC));
			print(" @ ");
			printHex(pc - (jumpLongConditionalByteSize(backEnd)));
			cr();
			ok = 0;
		}
		pc += cPICCaseSize;
	}
	return ok;
}

static sqInt
checkValidObjectReference(sqInt anOop)
{
	// CogObjectRepresentation>>#checkValidObjectReference:
	return (!(isImmediate(anOop)))
	 && ((heapMapAtWord(pointerForOop(anOop))) != 0);
}

static sqInt
checkValidOopReference(sqInt anOop)
{
	// CogObjectRepresentationForSqueakV3>>#checkValidOopReference:
	return ((anOop & 1))
	 || ((heapMapAtWord(pointerForOop(anOop))) != 0);
}


/*	Free all methods */

static void
clearCogCompiledCode(void)
{
	// CogMethodZone>>#clearCogCompiledCode
    CogMethod *cogMethod;

	
cogMethod = ((CogMethod *) baseAddress);
	while ((((usqInt)cogMethod)) < mzFreeStart) {
		if (((cogMethod->cmType)) == CMMethod) {
			freeMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	manageFromto(baseAddress, limitAddress);
}


/*	Answer if the ClosedPIC refers to any unmarked objects or freed/freeable
	target methods,
	applying markAndTraceOrFreeCogMethod:firstVisit: to those targets to
	determine if freed/freeable.
 */

static sqInt
closedPICRefersToUnmarkedObject(CogMethod *cPIC)
{
	// Cogit>>#closedPICRefersToUnmarkedObject:
    sqInt entryPoint;
    sqInt i;
    sqInt object;
    sqInt offsetToLiteral;
    sqInt pc;
    CogMethod *targetMethod;

	if (!(isMarked((cPIC->selector)))) {
		return 1;
	}

	/* First jump is unconditional; subsequent ones are conditional */

pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	offsetToLiteral = jumpLongByteSize(backEnd);
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {
		object = literalBeforeFollowingAddress(backEnd, (pc - offsetToLiteral) - (loadLiteralByteSize(backEnd)));
		if ((couldBeObject(object))
		 && (!(isMarked(object)))) {
			return 1;
		}
		object = literalBeforeFollowingAddress(backEnd, pc - offsetToLiteral);
		if ((couldBeObject(object))
		 && (!(isMarked(object)))) {
			return 1;
		}

		/* Find target from jump.  Ignore jumps to the interpret and MNU calls within this PIC */

entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd, pc);
		if (((((usqInt)entryPoint)) < (((usqInt)cPIC)))
		 || ((((usqInt)entryPoint)) > (((usqInt)((((usqInt)cPIC)) + ((cPIC->blockSize))))))) {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			assert((((targetMethod->cmType)) == CMMethod)
			 || (((targetMethod->cmType)) == CMFree));
			if (markAndTraceOrFreeCogMethodfirstVisit(targetMethod, (((usqInt)targetMethod)) > (((usqInt)pc)))) {
				return 1;
			}
		}
		offsetToLiteral = jumpLongConditionalByteSize(backEnd);
		pc += cPICCaseSize;
	}
	return 0;
}

static CogMethod *
cmHomeMethod(CogBlockMethod * self_in_cmHomeMethod)
{
	// CogBlockMethod>>#cmHomeMethod
	return ((CogMethod *) ((((usqInt)self_in_cmHomeMethod)) - ((self_in_cmHomeMethod->homeOffset))));
}

char *
codeEntryFor(char *address)
{
	// Cogit>>#codeEntryFor:
    sqInt i;

	for (i = 0; i <= (trampolineTableIndex - 3); i += 2) {
		if (((address >= (trampolineAddresses[i + 1])) && (address <= ((trampolineAddresses[i + 3]) - 1)))) {
			return trampolineAddresses[i + 1];
		}
	}
	return null;
}

char *
codeEntryNameFor(char *address)
{
	// Cogit>>#codeEntryNameFor:
    sqInt i;

	for (i = 0; i <= (trampolineTableIndex - 3); i += 2) {
		if (((address >= (trampolineAddresses[i + 1])) && (address <= ((trampolineAddresses[i + 3]) - 1)))) {
			return trampolineAddresses[i];
		}
	}
	return null;
}

sqInt
cogCodeBase(void)
{
	// Cogit>>#cogCodeBase
	return codeBase;
}


/*	Answer the contents of the code zone as an array of pair-wise element,
	address in ascending address order.
	Answer a string for a runtime routine or abstract label (beginning, end,
	etc), a CompiledMethod for a CMMethod,
	or a selector (presumably a Symbol) for a PIC. */

sqInt
cogCodeConstituents(void)
{
	// Cogit>>#cogCodeConstituents
    CogMethod *cogMethod;
    sqInt constituents;
    sqInt count;
    sqInt i;
    sqInt label;
    sqInt value;


	/* + 3 for start, freeStart and end */

count = (((sqInt) trampolineTableIndex >> 1)) + 3;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			count += 1;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	constituents = instantiateClassindexableSize(classArray(), count * 2);
	if (constituents == null) {
return constituents;
	}
	pushRemappableOop(constituents);
	if ((((label = stringForCString("CogCode"))) == null)
	 || (((value = cePositive32BitIntegerFor(codeBase))) == null)) {
		return null;
	}
	storePointerUncheckedofObjectwithValue(0, topRemappableOop(), label);
	storePointerUncheckedofObjectwithValue(1, topRemappableOop(), value);
	for (i = 0; i < trampolineTableIndex; i += 2) {
		if ((((label = stringForCString(trampolineAddresses[i]))) == null)
		 || (((value = cePositive32BitIntegerFor(((usqInt)(trampolineAddresses[i + 1]))))) == null)) {
			popRemappableOop();
			return null;
		}
		storePointerUncheckedofObjectwithValue(2 + i, topRemappableOop(), label);
		storePointerUncheckedofObjectwithValue(3 + i, topRemappableOop(), value);
	}
	count = trampolineTableIndex + 2;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			storePointerUncheckedofObjectwithValue(count, topRemappableOop(), (((cogMethod->cmType)) == CMMethod
				? (cogMethod->methodObject)
				: (cogMethod->selector)));
			if (((value = cePositive32BitIntegerFor(((usqInt)cogMethod)))) == null) {
				popRemappableOop();
				return null;
			}
			storePointerUncheckedofObjectwithValue(count + 1, topRemappableOop(), value);
			count += 2;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if ((((label = stringForCString("CCFree"))) == null)
	 || (((value = cePositive32BitIntegerFor(freeStart()))) == null)) {
		popRemappableOop();
		return null;
	}
	storePointerUncheckedofObjectwithValue(count, topRemappableOop(), label);
	storePointerUncheckedofObjectwithValue(count + 1, topRemappableOop(), value);
	if ((((label = stringForCString("CCEnd"))) == null)
	 || (((value = cePositive32BitIntegerFor(limitAddress))) == null)) {
		popRemappableOop();
		return null;
	}
	storePointerUncheckedofObjectwithValue(count + 2, topRemappableOop(), label);
	storePointerUncheckedofObjectwithValue(count + 3, topRemappableOop(), value);
	constituents = popRemappableOop();
	beRootIfOld(constituents);
	return constituents;
}


/*	Extend the cPIC with the supplied case. If caseNMethod is cogged dispatch
	direct to
	its unchecked entry-point. If caseNMethod is not cogged, jump to the fast
	interpreter dispatch, and if isMNUCase then dispatch to fast MNU
	invocation and mark the cPIC as
	having the MNU case for cache flushing. */
/*	stack allocate the various collections so that they
	are effectively garbage collected on return. */

static sqInt
cogExtendPICCaseNMethodtagisMNUCase(CogMethod *cPIC, sqInt caseNMethod, sqInt caseNTag, sqInt isMNUCase)
{
	// Cogit>>#cogExtendPIC:CaseNMethod:tag:isMNUCase:
    sqInt address;
    sqInt end;
    sqInt jumpTarget;
    sqInt operand;
    sqInt size;
    sqInt target;

	compilationBreakpoint((cPIC->selector), lengthOf((cPIC->selector)));
	allocateOpcodesbytecodes(5, 0);
	assert(!(inlineCacheTagIsYoung(caseNTag)));
	assert((caseNMethod != null)
	 && (!(isYoung(caseNMethod))));
	if ((!isMNUCase)
	 && (methodHasCogMethod(caseNMethod))) {
		operand = 0;
		target = (((sqInt)(cogMethodOf(caseNMethod)))) + cmNoCheckEntryOffset;
	}
	else {
if (isMNUCase) {
(cPIC->cpicHasMNUCase = 1);
		}
		operand = caseNMethod;
		target = (((sqInt)cPIC)) + ((isMNUCase
	? sizeof(CogMethod)
	: (interpretOffset()) - (callInstructionByteSize(backEnd))));
	}
	/* begin CmpCw:R: */
	genoperandoperand(CmpCwR, caseNTag, TempReg);
	/* begin MoveCw:R: */
	genoperandoperand(MoveCwR, operand, SendNumArgsReg);
	/* begin JumpLongZero: */
	genoperand(JumpLongZero, ((sqInt)target));
	/* begin MoveCw:R: */
	genoperandoperand(MoveCwR, ((sqInt)cPIC), ClassReg);
	/* begin JumpLong: */
	jumpTarget = cPICMissTrampolineFor((cPIC->cmNumArgs));
	genoperand(JumpLong, jumpTarget);
	computeMaximumSizes();
	address = addressOfEndOfCaseinCPIC(((cPIC->cPICNumCases)) - 1, cPIC);
	size = generateInstructionsAt(address);
	end = outputInstructionsAt(address);
	flushICacheFromto(processor, address, (((sqInt)cPIC)) + closedPICSize);
	(cPIC->cPICNumCases = ((cPIC->cPICNumCases)) + 1);
	return 0;
}

void
cogitPostGCAction(sqInt gcMode)
{
	// Cogit>>#cogitPostGCAction:
	if ((gcMode == GCModeFull)
	 && (allYoungObjectsAgeInFullGC())) {
		voidYoungReferrersPostTenureAll();
	}
	assert(allMethodsHaveCorrectHeader());
	assert(kosherYoungReferrers());
}


/*	Check that the header fields onf a non-free method are consistent with
	the type. Answer 0 if it is ok, otherwise answer a code for the error. */

sqInt
cogMethodDoesntLookKosher(CogMethod *cogMethod)
{
	// Cogit>>#cogMethodDoesntLookKosher:
	if (((((cogMethod->blockSize)) & (BytesPerWord - 1)) != 0)
	 || ((((cogMethod->blockSize)) < (sizeof(CogMethod)))
	 || (((cogMethod->blockSize)) >= 32768))) {
		return 1;
	}
	if (((cogMethod->cmType)) == CMFree) {
		return 2;
	}
	if (((cogMethod->cmType)) == CMMethod) {
		if (!((((cogMethod->methodHeader)) & 1))) {
			return 11;
		}
		if (!(couldBeObject((cogMethod->methodObject)))) {
			return 12;
		}
		if ((((cogMethod->stackCheckOffset)) > 0)
		 && (((cogMethod->stackCheckOffset)) < cmNoCheckEntryOffset)) {
			return 13;
		}
		return 0;
	}
	if (((cogMethod->cmType)) == CMOpenPIC) {
		if (((cogMethod->blockSize)) != openPICSize) {
			return 21;
		}
		if (((cogMethod->methodHeader)) != 0) {
			return 22;
		}
		if (((cogMethod->objectHeader)) >= 0) {
			if ((((cogMethod->methodObject)) != 0)
			 && ((((cogMethod->methodObject)) < methodZoneBase)
			 || ((((cogMethod->methodObject)) > ((freeStart()) - openPICSize))
			 || (((((cogMethod->methodObject)) & (BytesPerWord - 1)) != 0)
			 || ((((((CogMethod *) ((cogMethod->methodObject))))->cmType)) != CMOpenPIC))))) {
				return 23;
			}
		}
		if (((cogMethod->stackCheckOffset)) != 0) {
			return 24;
		}
		return 0;
	}
	if (((cogMethod->cmType)) == CMClosedPIC) {
		if (((cogMethod->blockSize)) != closedPICSize) {
			return 0x1F;
		}
		if (!(((((cogMethod->cPICNumCases)) >= 1) && (((cogMethod->cPICNumCases)) <= numPICCases)))) {
			return 32;
		}
		if (((cogMethod->methodHeader)) != 0) {
			return 33;
		}
		if (((cogMethod->methodObject)) != 0) {
			return 34;
		}
		return 0;
	}
	return 9;
}


/*	Attempt to create a one-case PIC for an MNU.
	The tag for the case is at the send site and so doesn't need to be
	generated. 
 */

CogMethod *
cogMNUPICSelectormethodOperandnumArgs(sqInt selector, sqInt methodOperand, sqInt numArgs)
{
	// Cogit>>#cogMNUPICSelector:methodOperand:numArgs:
    sqInt end;
    sqInt headerSize;
    sqInt size;
    sqInt startAddress;

	if (isYoung(selector)) {
		return 0;
	}
	compilationBreakpoint(selector, lengthOf(selector));
	assert(endCPICCase0 != null);
	startAddress = allocate(closedPICSize);
	if (startAddress == 0) {
callForCogCompiledCodeCompaction();
		return 0;
	}
	(methodLabel->address = startAddress);
	(methodLabel->dependent = null);
	allocateOpcodesbytecodes(numPICCases * 7, 0);
	compileMNUCPICmethodOperandnumArgs(((CogMethod *) startAddress), methodOperand, numArgs);
	computeMaximumSizes();
	headerSize = sizeof(CogMethod);
	size = generateInstructionsAt(startAddress + headerSize);

	/* The missOffset is the same as the interpretOffset. */

end = outputInstructionsAt(startAddress + headerSize);
	assert(missOffset == ((((interpretCall->address)) + ((interpretCall->machineCodeSize))) - startAddress));
	assert((startAddress + cmEntryOffset) == ((entry->address)));
	return fillInCPICHeadersizenumArgsnumCaseshasMNUCaseselector(((CogMethod *) startAddress), closedPICSize, numArgs, 1, 1, selector);
}


/*	Create an Open PIC. Temporarily create a direct call of
	ceSendFromOpenPIC:. Should become a probe of the first-level method lookup
	cache followed by a
	call of ceSendFromOpenPIC: if the probe fails. */

static CogMethod *
cogOpenPICSelectornumArgs(sqInt selector, sqInt numArgs)
{
	// Cogit>>#cogOpenPICSelector:numArgs:
    sqInt codeSize;
    sqInt end;
    sqInt headerSize;
    sqInt mapSize;
    sqInt startAddress;

	compilationBreakpoint(selector, lengthOf(selector));
	startAddress = allocate(openPICSize);
	if (startAddress == 0) {
return ((CogMethod *) InsufficientCodeSpace);
	}
	(methodLabel->address = startAddress);
	(methodLabel->dependent = null);
	allocateOpcodesbytecodes(100, 0);
	compileOpenPICnumArgs(selector, numArgs);
	computeMaximumSizes();
	concretizeAt(methodLabel, startAddress);
	headerSize = sizeof(CogMethod);
	codeSize = generateInstructionsAt(startAddress + headerSize);
	mapSize = generateMapAtstart((startAddress + openPICSize) - 1, startAddress + cmNoCheckEntryOffset);
	assert((((entry->address)) - startAddress) == cmEntryOffset);
	assert(((headerSize + codeSize) + mapSize) <= openPICSize);
	end = outputInstructionsAt(startAddress + headerSize);
	return fillInOPICHeadersizenumArgsselector(((CogMethod *) startAddress), openPICSize, numArgs, selector);
}


/*	Attempt to create a two-case PIC for case0CogMethod and
	case1Method,case1Tag. The tag for case0CogMethod is at the send site and
	so doesn't need to be generated.
	case1Method may be any of
	- a Cog method; link to its unchecked entry-point
	- a CompiledMethod; link to ceInterpretMethodFromPIC:
	- a CompiledMethod; link to ceMNUFromPICMNUMethod:receiver: */

static CogMethod *
cogPICSelectornumArgsCase0MethodCase1MethodtagisMNUCase(sqInt selector, sqInt numArgs, CogMethod *case0CogMethod, sqInt case1MethodOrNil, sqInt case1Tag, sqInt isMNUCase)
{
	// Cogit>>#cogPICSelector:numArgs:Case0Method:Case1Method:tag:isMNUCase:
    sqInt end;
    sqInt headerSize;
    sqInt size;
    sqInt startAddress;

	if (isYoung(selector)) {
		return ((CogMethod *) YoungSelectorInPIC);
	}
	compilationBreakpoint(selector, lengthOf(selector));
	startAddress = allocate(closedPICSize);
	if (startAddress == 0) {
return ((CogMethod *) InsufficientCodeSpace);
	}
	(methodLabel->address = startAddress);
	(methodLabel->dependent = null);
	allocateOpcodesbytecodes(numPICCases * 7, 0);
	compileCPICCase0Case1MethodtagisMNUCasenumArgs(((CogMethod *) startAddress), case0CogMethod, case1MethodOrNil, case1Tag, isMNUCase, numArgs);
	computeMaximumSizes();
	headerSize = sizeof(CogMethod);
	size = generateInstructionsAt(startAddress + headerSize);

	/* The missOffset is th same as the interpretOffset. */

end = outputInstructionsAt(startAddress + headerSize);
	assert(missOffset == ((((interpretCall->address)) + ((interpretCall->machineCodeSize))) - startAddress));
	assert((startAddress + cmEntryOffset) == ((entry->address)));
	assert(((endCPICCase0->address)) == (startAddress + firstCPICCaseOffset));
	assert(((endCPICCase1->address)) == ((startAddress + firstCPICCaseOffset) + cPICCaseSize));
	return fillInCPICHeadersizenumArgsnumCaseshasMNUCaseselector(((CogMethod *) startAddress), closedPICSize, numArgs, 2, isMNUCase, selector);
}


/*	Attempt to produce a machine code method for the bytecode method
	object aMethodObj. N.B. If there is no code memory available do *NOT*
	attempt to reclaim the method zone. Certain clients (e.g. ceSICMiss:)
	depend on the zone remaining constant across method generation. */

CogMethod *
cogselector(sqInt aMethodObj, sqInt aSelectorOop)
{
	// Cogit>>#cog:selector:
    CogMethod *cogMethod;

	assert((!(methodHasCogMethod(aMethodObj)))
	 || ((noAssertMethodClassAssociationOf(aMethodObj)) == (nilObject())));
	compilationBreakpoint(aSelectorOop, lengthOf(aSelectorOop));
	if (aMethodObj == breakMethod) {
		haltmsg("Compilation of breakMethod");
	}
	
if (methodUsesAlternateBytecodeSet(aMethodObj)) {
		if ((numElementsIn(generatorTable)) <= 256) {
			return null;
		}
		bytecodeSetOffset = 256;
	}
	else {
bytecodeSetOffset = 0;
	}
	extA = (extB = 0);
	/* begin ensureNoForwardedLiteralsIn: */
	methodObj = aMethodObj;
	cogMethod = compileCogMethod(aSelectorOop);
	if ((((((sqInt)cogMethod)) >= MaxNegativeErrorCode) && ((((sqInt)cogMethod)) <= -1))) {
		if ((((sqInt)cogMethod)) == InsufficientCodeSpace) {
			callForCogCompiledCodeCompaction();
		}
		return null;
	}
	return cogMethod;
}

void
compactCogCompiledCode(void)
{
	// Cogit>>#compactCogCompiledCode
	assert(noCogMethodsMaximallyMarked());
	markActiveMethodsAndReferents();
	freeOlderMethodsForCompaction();
	freePICsWithFreedTargets();
	planCompaction();
	updateStackZoneReferencesToCompiledCodePreCompaction();
	relocateMethodsPreCompaction();
	compactCompiledCode();
	assert(allMethodsHaveCorrectHeader());
	assert(kosherYoungReferrers());
	flushICacheFromto(processor, methodZoneBase, freeStart());
}

static void
compactCompiledCode(void)
{
	// CogMethodZone>>#compactCompiledCode
    unsigned short bytes;
    CogMethod *dest;
    sqInt objectHeaderValue;
    CogMethod *source;

	objectHeaderValue = nullHeaderForMachineCodeMethod();
	source = ((CogMethod *) baseAddress);
	openPICList = null;
	methodCount = 0;
	
while ((source < (limitZony()))
	 && (((source->cmType)) != CMFree)) {
		assert((cogMethodDoesntLookKosher(source)) == 0);
		(source->objectHeader = objectHeaderValue);
		if (((source->cmUsageCount)) > 0) {
			(source->cmUsageCount = ((sqInt) ((source->cmUsageCount)) >> 1));
		}
		
if (((source->cmType)) == CMOpenPIC) {
			(source->nextOpenPIC = ((usqInt)openPICList));
			openPICList = source;
		}
		methodCount += 1;
		source = ((CogMethod *) (roundUpLength((((sqInt)source)) + ((source->blockSize)))));
	}
	if (source >= (limitZony())) {
		haltmsg("no free methods; cannot compact.");
		return;
	}
	dest = source;
	while (source < (limitZony())) {
		assert((maybeFreeCogMethodDoesntLookKosher(source)) == 0);
		bytes = (source->blockSize);
		if (((source->cmType)) != CMFree) {
			methodCount += 1;
			memmove(dest, source, bytes);
			(dest->objectHeader = objectHeaderValue);
			if (((dest->cmType)) == CMMethod) {

				/* For non-Newspeak there should be a one-to-one mapping between bytecoded and
				   cog methods.  For Newspeak not necessarily, but only for anonymous accessors. */
				/* Only update the original method's header if it is referring to this CogMethod. */

if ((((sqInt)(rawHeaderOf((dest->methodObject))))) == (((sqInt)source))) {

					/* For non-Newspeak there should be a one-to-one mapping between bytecoded and
					   cog methods.  For Newspeak not necessarily, but only for anonymous accessors. */
					/* Only update the original method's header if it is referring to this CogMethod. */

rawHeaderOfput((dest->methodObject), ((sqInt)dest));
				}
				else {
assert((noAssertMethodClassAssociationOf((dest->methodObject))) == (nilObject()));
					
				}
			}
			else {
if (((dest->cmType)) == CMOpenPIC) {
					(dest->nextOpenPIC = ((usqInt)openPICList));
					openPICList = dest;
				}
			}
			if (((dest->cmUsageCount)) > 0) {
				(dest->cmUsageCount = ((sqInt) ((dest->cmUsageCount)) >> 1));
			}
			dest = ((CogMethod *) ((((usqInt)dest)) + bytes));
		}
		source = ((CogMethod *) ((((usqInt)source)) + bytes));
	}
	mzFreeStart = ((usqInt)dest);
	methodBytesFreedSinceLastCompaction = 0;
}


/*	The start of a CogMethod has a call to a run-time abort routine that
	either handles an in-line cache failure or a stack overflow. The routine
	selects the
	path depending on ReceiverResultReg; if zero it takes the stack overflow
	path; if nonzero the in-line cache miss path. Neither of these paths
	returns. The abort routine must be called; In the callee the method is
	located by
	adding the relevant offset to the return address of the call. */

static void
compileAbort(void)
{
	// Cogit>>#compileAbort
    sqInt callTarget;

	/* begin MoveCq:R: */
	stackOverflowCall = genoperandoperand(MoveCqR, 0, ReceiverResultReg);
	sendMiss = (sendMissCall = gCall(methodAbortTrampolineFor(methodOrBlockNumArgs)));

}


/*	Loop over bytecodes, dispatching to the generator for each bytecode,
	handling fixups in due course.
 */

static sqInt
compileAbstractInstructionsFromthrough(sqInt start, sqInt end)
{
	// StackToRegisterMappingCogit>>#compileAbstractInstructionsFrom:through:
    AbstractInstruction *abstractInstruction;
    sqInt debugBytecodePointers;
    BytecodeDescriptor *descriptor;
    BytecodeFixup *fixup;
    sqInt nExts;
    sqInt nextOpcodeIndex;
    sqInt result;

	traceSimStack();
	bytecodePC = start;
	nExts = 0;
	descriptor = null;
	deadCode = 0;
	while (1) {
;
		fixup = fixupAt(bytecodePC - initialPC);
		if ((((usqInt)((fixup->targetInstruction)))) > 0) {
			deadCode = 0;
			if ((((usqInt)((fixup->targetInstruction)))) >= 2) {
				mergeafterContinuation(fixup, !((descriptor != null)
 && ((isUnconditionalBranch(descriptor))
 || ((descriptor->isReturn)))));
			}
		}
		else {

			/* If there's no fixup following a return there's no jump to that code and it is dead. */

if ((descriptor != null)
			 && ((descriptor->isReturn))) {
				deadCode = 1;
			}
		}
		
byte0 = (fetchByteofObject(bytecodePC, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		loadSubsequentBytesForDescriptorat(descriptor, bytecodePC);
		nextOpcodeIndex = opcodeIndex;
		result = (deadCode
			? ((((descriptor->isMapped))
					 || (inBlock
					 && ((descriptor->isMappedInBlock)))
						? (/* begin annotateBytecode: */
							/* begin Nop */
							(abstractInstruction = gen(Nop)),
							annotatewith(abstractInstruction, HasBytecodePC))
						: 0),
				0)
			: ((descriptor->generator))());
		if (!((descriptor->isExtension))) {

			/* extended bytecodes must consume their extensions */

assert((extA == 0)
			 && (extB == 0));
		}
		traceDescriptor(descriptor);
		traceSimStack();
		if ((((((usqInt)((fixup->targetInstruction)))) >= 1) && ((((usqInt)((fixup->targetInstruction)))) <= 2))) {

			/* There is a fixup for this bytecode.  It must point to the first generated
			   instruction for this bytecode.  If there isn't one we need to add a label. */

			if (opcodeIndex == nextOpcodeIndex) {

				/* There is a fixup for this bytecode.  It must point to the first generated
				   instruction for this bytecode.  If there isn't one we need to add a label. */

				/* begin Label */
				genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
			(fixup->targetInstruction = abstractInstructionAt(nextOpcodeIndex));
		}
		bytecodePC = (bytecodePC + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bytecodePC, nExts, methodObj)
	: 0));
		if (!((result == 0)
		 && (bytecodePC <= end))) break;
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
	}
	/* begin checkEnoughOpcodes */
	if (opcodeIndex > numAbstractOpcodes) {
		error("Cog JIT internal error. Too many abstract opcodes.  Num opcodes heuristic is too optimistic.");
	}
	return result;
}

static sqInt
compileBlockBodies(void)
{
	// StackToRegisterMappingCogit>>#compileBlockBodies
    BlockStart *blockStart;
    sqInt compiledBlocksCount;
    sqInt i;
    sqInt initialAnnotationIndex;
    sqInt initialOpcodeIndex;
    sqInt initialStackPtr;
    sqInt (* const pushNilSizeFunction)(sqInt) = v3PushNilSize;
    sqInt result;
    sqInt savedNeedsFrame;
    sqInt savedNumArgs;
    sqInt savedNumTemps;

	assert(blockCount > 0);
	savedNeedsFrame = needsFrame;
	savedNumArgs = methodOrBlockNumArgs;
	savedNumTemps = methodOrBlockNumTemps;
	inBlock = 1;
	compiledBlocksCount = 0;
	while (compiledBlocksCount < blockCount) {
		blockStart = blockStartAt(compiledBlocksCount);
		scanBlock(blockStart);
		initialOpcodeIndex = opcodeIndex;
		initialAnnotationIndex = annotationIndex;
		while (1) {
compileBlockEntry(blockStart);
			initialStackPtr = simStackPtr;
			if (((result = compileAbstractInstructionsFromthrough(((blockStart->startpc)) + ((pushNilSizeFunction(methodObj)) * ((blockStart->numInitialNils))), (((blockStart->startpc)) + ((blockStart->span))) - 1))) < 0) {
				return result;
			}
			if (initialStackPtr == simStackPtr) break;
			assert(initialStackPtr > simStackPtr);
			(blockStart->numInitialNils = (((blockStart->numInitialNils)) + simStackPtr) - initialStackPtr);
			(((blockStart->fakeHeader))->dependent = null);
			reinitializeFixupsFromthrough(((blockStart->startpc)) + ((blockStart->numInitialNils)), (((blockStart->startpc)) + ((blockStart->span))) - 1);
			bzero(abstractOpcodes + initialOpcodeIndex,
									(opcodeIndex - initialOpcodeIndex) * sizeof(AbstractInstruction));
			opcodeIndex = initialOpcodeIndex;
			annotationIndex = initialAnnotationIndex;
		}
		compiledBlocksCount += 1;
	}
	needsFrame = savedNeedsFrame;
	methodOrBlockNumArgs = savedNumArgs;
	methodOrBlockNumTemps = savedNumTemps;
	return 0;
}


/*	Compile the jump instruction(s) at the end of the method that dispatch to
	each block body.
 */

static sqInt
compileBlockDispatch(void)
{
	// SimpleStackBasedCogit>>#compileBlockDispatch
    AbstractInstruction *jumpSkip;

	assert(blockCount > 0);
	/* begin MoveCq:R: */
	blockEntryNoContextSwitch = genoperandoperand(MoveCqR, 0, SendNumArgsReg);
	/* begin Jump: */
	jumpSkip = genoperand(Jump, ((sqInt)0));
	/* begin MoveR:R: */
	blockEntryLabel = genoperandoperand(MoveRR, ReceiverResultReg, SendNumArgsReg);
	jmpTarget(jumpSkip, gLabel());
	if (blockCount > 1) {
		genLoadSlotsourceRegdestReg(ClosureStartPCIndex, ReceiverResultReg, TempReg);
	}
	compileBlockDispatchFromto(0, blockCount - 1);
	return 0;
}

static sqInt
compileBlockDispatchFromto(sqInt lowBlockStartIndex, sqInt highBlockStartIndex)
{
	// Cogit>>#compileBlockDispatchFrom:to:
    BlockStart *blockStart;
    sqInt halfWay;
    AbstractInstruction *jmp;
    void *jumpTarget;
    void *jumpTarget1;
    void *jumpTarget2;
    sqInt quickConstant;

	if (lowBlockStartIndex == highBlockStartIndex) {
blockStart = blockStartAt(lowBlockStartIndex);
		/* begin Jump: */
		jumpTarget = (blockStart->entryLabel);
		genoperand(Jump, ((sqInt)jumpTarget));
		return null;
	}
	halfWay = ((sqInt) (highBlockStartIndex + lowBlockStartIndex) >> 1);
	assert(((halfWay >= lowBlockStartIndex) && (halfWay <= highBlockStartIndex)));

	/* N.B. FLAGS := TempReg - startpc */

blockStart = blockStartAt(halfWay);
	/* begin CmpCq:R: */
	quickConstant = (((((blockStart->startpc)) + 1) << 1) | 1);
	genoperandoperand(CmpCqR, quickConstant, TempReg);
	if (lowBlockStartIndex == halfWay) {
/* begin JumpLessOrEqual: */
		jumpTarget1 = (blockStart->entryLabel);
		genoperand(JumpLessOrEqual, ((sqInt)jumpTarget1));
		compileBlockDispatchFromto(halfWay + 1, highBlockStartIndex);
		return null;
	}
	if ((halfWay + 1) == highBlockStartIndex) {
		blockStart = blockStartAt(highBlockStartIndex);
		/* begin JumpGreater: */
		jumpTarget2 = (blockStart->entryLabel);
		genoperand(JumpGreater, ((sqInt)jumpTarget2));
		return compileBlockDispatchFromto(lowBlockStartIndex, halfWay);
	}
	/* begin JumpGreater: */
	jmp = genoperand(JumpGreater, ((sqInt)0));
	compileBlockDispatchFromto(lowBlockStartIndex, halfWay);
	if (halfWay == highBlockStartIndex) {
blockStart = blockStartAt(highBlockStartIndex);
		jmpTarget(jmp, (blockStart->entryLabel));
	}
	else {
jmpTarget(jmp, gLabel());
		compileBlockDispatchFromto(halfWay + 1, highBlockStartIndex);
	}
}


/*	Compile a block's entry. This looks like a dummy CogBlockMethod header
	(for frame parsing)
	followed by either a frame build, if a frame is required, or nothing. The
	CogMethodHeader's objectHeader field is a back pointer to the method, but
	this can't be filled in until code generation. */

static void
compileBlockEntry(BlockStart *blockStart)
{
	// Cogit>>#compileBlockEntry:
    sqInt alignment;

	/* begin AlignmentNops: */
	alignment = blockAlignment();
	genoperand(AlignmentNops, alignment);
	(blockStart->fakeHeader = gLabel());
	
	switch (sizeof(CogBlockMethod)) {
	case 2 * BytesPerWord:
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		break;
	case 3 * BytesPerWord:
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	(blockStart->entryLabel = gLabel());
	if (needsFrame) {
		compileBlockFrameBuild(blockStart);
		if (recordBlockTrace()) {
			CallRT(ceTraceBlockActivationTrampoline);
		}
	}
	else {
compileBlockFramelessEntry(blockStart);
	}
}


/*	Build a frame for a block activation. See CoInterpreter
	class>>initializeFrameIndices. closure (in ReceiverResultReg)
	arg0
	...
	argN
	caller's saved ip/this stackPage (for a base frame)
	fp->	saved fp
	method
	context (uninitialized?)
	receiver
	first temp
	...
	sp->	Nth temp
	Avoid use of SendNumArgsReg which is the flag determining whether
	context switch is allowed on stack-overflow. */
/*	Build a frame for a block activation. See CoInterpreter
	class>>initializeFrameIndices. Override to push the register receiver and
	register arguments, if any, and to correctly
	initialize the explicitly nilled/pushed temp entries (they are /not/ of
	type constant nil). */

static void
compileBlockFrameBuild(BlockStart *blockStart)
{
	// StackToRegisterMappingCogit>>#compileBlockFrameBuild:
    AbstractInstruction *abstractInstruction;
    sqInt address;
    AbstractInstruction * cascade0;
    sqInt i;
    sqInt ign;

	/* begin annotateBytecode: */
	/* begin Label */
	abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	annotatewith(abstractInstruction, HasBytecodePC);
	/* begin PushR: */
	genoperand(PushR, FPReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SPReg, FPReg);
	cascade0 = (blockStart->fakeHeader);
	addDependent(cascade0, annotateAbsolutePCRef(gPushCw(((sqInt)((blockStart->fakeHeader))))));
	setLabelOffset(cascade0, MFMethodFlagIsBlockFlag);
	annotateobjRef(gPushCw(nilObject()), nilObject());
	genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ReceiverResultReg, TempReg);
	genLoadSlotsourceRegdestReg(ReceiverIndex, TempReg, ClassReg);
	/* begin PushR: */
	genoperand(PushR, ClassReg);
	for (i = 0; i < ((blockStart->numCopied)); i += 1) {
		genLoadSlotsourceRegdestReg(i + ClosureFirstCopiedValueIndex, ReceiverResultReg, TempReg);
		/* begin PushR: */
		genoperand(PushR, TempReg);
	}
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin MoveAw:R: */
	address = stackLimitAddress();
	genoperandoperand(MoveAwR, address, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, SPReg);
	/* begin JumpBelow: */
	genoperand(JumpBelow, ((sqInt)stackOverflowCall));
	(blockStart->stackCheckLabel = annotateBytecode(gLabel()));
	methodOrBlockNumTemps = (((blockStart->numArgs)) + ((blockStart->numCopied))) + ((blockStart->numInitialNils));
	initSimStackForFramefulMethod((blockStart->startpc));
	if (((blockStart->numInitialNils)) > 0) {
		if (((blockStart->numInitialNils)) > 1) {
			annotateobjRef(gMoveCwR(nilObject(), TempReg), nilObject());
			for (ign = 1; ign <= ((blockStart->numInitialNils)); ign += 1) {
				/* begin PushR: */
				genoperand(PushR, TempReg);
			}
		}
		else {
annotateobjRef(gPushCw(nilObject()), nilObject());
		}
		methodOrBlockNumTemps = ((blockStart->numArgs)) + ((blockStart->numCopied));
	}
}


/*	Make sure ReceiverResultReg holds the receiver, loaded from the closure,
	which is what is initially in ReceiverResultReg. We must annotate the
	first instruction so that findMethodForStartBcpc:inHomeMethod: can
	function. We need two annotations because the first is a fiducial. */
/*	Make sure ReceiverResultReg holds the receiver, loaded from
	the closure, which is what is initially in ReceiverResultReg */

static void
compileBlockFramelessEntry(BlockStart *blockStart)
{
	// StackToRegisterMappingCogit>>#compileBlockFramelessEntry:
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;

	methodOrBlockNumTemps = (((blockStart->numArgs)) + ((blockStart->numCopied))) + ((blockStart->numInitialNils));
	initSimStackForFramelessBlock((blockStart->startpc));
	/* begin annotateBytecode: */
	abstractInstruction = (blockStart->entryLabel);
	annotatewith(abstractInstruction, HasBytecodePC);
	/* begin annotateBytecode: */
	abstractInstruction1 = (blockStart->entryLabel);
	annotatewith(abstractInstruction1, HasBytecodePC);
	genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ReceiverResultReg, TempReg);
	genLoadSlotsourceRegdestReg(ReceiverIndex, TempReg, ReceiverResultReg);
}


/*	Compile the abstract instructions for a full closed PIC used to initialize
	closedPICSize. The loads into SendNumArgsReg are those for optional method
	objects which may be
	used in MNU cases. */

static sqInt
compileClosedPICPrototype(void)
{
	// Cogit>>#compileClosedPICPrototype
    sqInt h;
    AbstractInstruction *jumpNext;
    sqInt jumpTarget;
    sqInt numArgs;

	numArgs = 0;
	compilePICProlog(numArgs);
	jumpNext = compileCPICEntry();
	/* begin MoveCw:R: */
	genoperandoperand(MoveCwR, 99282957, SendNumArgsReg);
	/* begin JumpLong: */
	genoperand(JumpLong, 1592642142);
	jmpTarget(jumpNext, (endCPICCase0 = gLabel()));
	for (h = 1; h < numPICCases; h += 1) {
		/* begin CmpCw:R: */
		genoperandoperand(CmpCwR, 3133021973UL + h, TempReg);
		/* begin MoveCw:R: */
		genoperandoperand(MoveCwR, 195929424 + h, SendNumArgsReg);
		/* begin JumpLongZero: */
		genoperand(JumpLongZero, ((sqInt)3202131424UL));
		if (h == 1) {
/* begin Label */
			endCPICCase1 = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
	}
	/* begin MoveCw:R: */
	genoperandoperand(MoveCwR, 179686997, ClassReg);
	/* begin JumpLong: */
	jumpTarget = cPICMissTrampolineFor(numArgs);
	genoperand(JumpLong, jumpTarget);
	return 0;
}

static CogMethod *
compileCogMethod(sqInt selector)
{
	// StackToRegisterMappingCogit>>#compileCogMethod:
    sqInt debugStackPointers;
    sqInt extra;
    sqInt numBlocks;
    sqInt numBytecodes;
    sqInt numCleanBlocks;
    sqInt result;

	methodOrBlockNumTemps = tempCountOf(methodObj);
	
hasYoungReferent = (isYoungObject(methodObj))
	 || (isYoung(selector));
	methodOrBlockNumArgs = argumentCountOf(methodObj);
	inBlock = 0;
	primInvokeLabel = null;
	postCompileHook = null;
	maxLitIndex = -1;
	usesMethodClass = 0;
	extra = ((((primitiveIndex = primitiveIndexOf(methodObj))) > 0)
	 && (!(isQuickPrimitiveIndex(primitiveIndex)))
		? 30
		: 10);

	/* initial estimate.  Actual endPC is determined in scanMethod. */

initialPC = startPCOfMethod(methodObj);
	endPC = (isQuickPrimitiveIndex(primitiveIndex)
		? initialPC - 1
		: byteLengthOf(methodObj));
	numBytecodes = (endPC - initialPC) + 1;
	allocateOpcodesbytecodesifFail((numBytecodes + extra) * 10, numBytecodes, return ((CogMethod *) MethodTooBig));
	if (((numBlocks = scanMethod())) < 0) {
		return ((CogMethod *) numBlocks);
	}
	numCleanBlocks = scanForCleanBlocks();
	allocateBlockStarts(numBlocks + numCleanBlocks);
	blockCount = 0;
	if (numCleanBlocks > 0) {
addCleanBlockStarts();
	}
	/* begin maybeAllocAndInitCounters */
	blockEntryLabel = null;
	(methodLabel->dependent = null);
	if (((result = compileEntireMethod())) < 0) {
		return ((CogMethod *) result);
	}
	return generateCogMethod(selector);
}


/*	Compile the cache tag computation and the first comparison. Answer the
	address of that comparison. */

static AbstractInstruction *
compileCPICEntry(void)
{
	// Cogit>>#compileCPICEntry
	
entry = getInlineCacheClassTagFrominto(ReceiverResultReg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, ClassReg, TempReg);
	/* begin JumpNonZero: */
	return genoperand(JumpNonZero, ((sqInt)0));
}


/*	Compile the code for a two-case PIC for case0CogMethod and
	case1Method,case1Tag. The tag for case0CogMethod is at the send site and
	so doesn't need to be generated.
	case1Method may be any of
	- a Cog method; jump to its unchecked entry-point
	- a CompiledMethod; jump to the ceInterpretFromPIC trampoline
	- nil; call ceMNUFromPIC */

static sqInt
compileCPICCase0Case1MethodtagisMNUCasenumArgs(CogMethod *cPIC, CogMethod *case0CogMethod, sqInt case1Method, sqInt case1Tag, sqInt isMNUCase, sqInt numArgs)
{
	// Cogit>>#compileCPIC:Case0:Case1Method:tag:isMNUCase:numArgs:
    AbstractInstruction *jumpNext;
    sqInt jumpTarget;
    sqInt jumpTarget1;
    sqInt operand;
    void *targetEntry;

	assert(case1Method != null);
	compilePICProlog(numArgs);
	assert(!(inlineCacheTagIsYoung(case1Tag)));
	if ((!isMNUCase)
	 && (methodHasCogMethod(case1Method))) {
		operand = 0;
		targetEntry = ((void *)((((sqInt)(cogMethodOf(case1Method)))) + cmNoCheckEntryOffset));
	}
	else {
assert((case1Method == null)
		 || (!(isYoungObject(case1Method))));
		operand = case1Method;
		targetEntry = (case1Method == null
			? mnuCall
			: interpretLabel);
	}
	jumpNext = compileCPICEntry();
	/* begin MoveCw:R: */
	genoperandoperand(MoveCwR, 0, SendNumArgsReg);
	/* begin JumpLong: */
	genoperand(JumpLong, (((sqInt)case0CogMethod)) + cmNoCheckEntryOffset);
	/* begin CmpCw:R: */
	endCPICCase0 = genoperandoperand(CmpCwR, case1Tag, TempReg);
	jmpTarget(jumpNext, endCPICCase0);
	/* begin MoveCw:R: */
	genoperandoperand(MoveCwR, operand, SendNumArgsReg);
	/* begin JumpLongZero: */
	jumpTarget = ((sqInt)((isMNUCase
	? mnuCall
	: targetEntry)));
	genoperand(JumpLongZero, ((sqInt)jumpTarget));
	/* begin MoveCw:R: */
	endCPICCase1 = genoperandoperand(MoveCwR, ((sqInt)cPIC), ClassReg);
	/* begin JumpLong: */
	jumpTarget1 = cPICMissTrampolineFor(numArgs);
	genoperand(JumpLong, jumpTarget1);
	return 0;
}


/*	Compile the abstract instructions for the entire method, including blocks. */
/*	Compile the abstract instructions for the entire method, including blocks. */

static sqInt
compileEntireMethod(void)
{
	// StackToRegisterMappingCogit>>#compileEntireMethod
    sqInt result;

	regArgsHaveBeenPushed = 0;
	compileAbort();
	compileEntry();
	if (((result = compilePrimitive())) < 0) {
		return result;
	}
	compileFrameBuild();
	if (((result = compileMethodBody())) < 0) {
		return result;
	}
	if (blockCount == 0) {
		return 0;
	}
	if (((result = compileBlockBodies())) < 0) {
		return result;
	}
	return compileBlockDispatch();
}


/*	The entry code to a method checks that the class of the current receiver
	matches that in the inline cache. Other non-obvious elements are that its
	alignment must be
	different from the alignment of the noCheckEntry so that the method map
	machinery can distinguish normal and super sends (super sends bind to the
	noCheckEntry). In Newspeak we also need to distinguish dynSuperSends from
	normal and super
	and so bind a the preceeding nop (on x86 there happens to be one anyway). */

static void
compileEntry(void)
{
	// Cogit>>#compileEntry
	
entry = getInlineCacheClassTagFrominto(ReceiverResultReg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, ClassReg, TempReg);
	/* begin JumpNonZero: */
	genoperand(JumpNonZero, ((sqInt)sendMiss));
	/* begin Label */
	noCheckEntry = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	if (recordSendTrace()) {
		CallRT(ceTraceLinkedSendTrampoline);
	}
}

static sqInt
compileFallbackToInterpreterPrimitive(void)
{
	// SimpleStackBasedCogit>>#compileFallbackToInterpreterPrimitive
	return compileInterpreterPrimitive(functionPointerForCompiledMethodprimitiveIndex(methodObj, primitiveIndex));
}


/*	Build a frame for a CogMethod activation. See CoInterpreter
	class>>initializeFrameIndices. receiver (in ReceiverResultReg)
	arg0
	...
	argN
	caller's saved ip/this stackPage (for a base frame)
	fp->	saved fp
	method
	context (uninitialized?)
	receiver
	first temp
	...
	sp->	Nth temp
	If there is a primitive and an error code the Nth temp is the error code.
	Ensure SendNumArgsReg is set early on (incidentally to nilObj) because
	it is the flag determining whether context switch is allowed on
	stack-overflow.  */
/*	Build a frame for a CogMethod activation. See CoInterpreter
	class>>initializeFrameIndices. Override to push the register receiver and
	register arguments, if any. */

static sqInt
compileFrameBuild(void)
{
	// StackToRegisterMappingCogit>>#compileFrameBuild
    sqInt address;
    sqInt i;
    sqInt iLimiT;
    AbstractInstruction *jumpSkip;
    sqInt methodHeader;

	if (!needsFrame) {
		initSimStackForFramelessMethod(initialPC);
		return 0;
	}
	genPushRegisterArgs();
	if (!needsFrame) {
		return 0;
	}
	methodHeader = headerOf(methodObj);
	
/* begin PushR: */
	genoperand(PushR, FPReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SPReg, FPReg);
	addDependent(methodLabel, annotateAbsolutePCRef(gPushCw(((sqInt)methodLabel))));
	annotateobjRef(gMoveCwR(nilObject(), SendNumArgsReg), nilObject());
	/* begin PushR: */
	genoperand(PushR, SendNumArgsReg);
	/* begin PushR: */
	genoperand(PushR, ReceiverResultReg);
	for (i = (methodOrBlockNumArgs + 1), iLimiT = (temporaryCountOfMethodHeader(methodHeader)); i <= iLimiT; i += 1) {
		/* begin PushR: */
		genoperand(PushR, SendNumArgsReg);
	}
	if ((primitiveIndex > 0)
	 && ((longStoreBytecodeForHeader(methodHeader)) == (fetchByteofObject(initialPC + (sizeOfCallPrimitiveBytecode(methodHeader)), methodObj)))) {
		compileGetErrorCode();
		initialPC = (initialPC + (sizeOfCallPrimitiveBytecode(methodHeader))) + (sizeOfLongStoreTempBytecode(methodHeader));
	}
	/* begin MoveAw:R: */
	address = stackLimitAddress();
	genoperandoperand(MoveAwR, address, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, SPReg);
	if (canContextSwitchIfActivatingheader(methodObj, methodHeader)) {
		/* begin JumpBelow: */
		genoperand(JumpBelow, ((sqInt)stackOverflowCall));
		/* begin Label */
		stackCheckLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	}
	else {
/* begin JumpAboveOrEqual: */
		jumpSkip = genoperand(JumpAboveOrEqual, ((sqInt)0));
		/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, 0, SendNumArgsReg);
		/* begin Jump: */
		genoperand(Jump, ((sqInt)stackOverflowCall));
		jmpTarget(jumpSkip, (stackCheckLabel = gLabel()));
	}
	/* begin annotateBytecode: */
	annotatewith(stackCheckLabel, HasBytecodePC);
	initSimStackForFramefulMethod(initialPC);
}


/*	After pushing the temporaries but before the stack limit check a primitive
	method needs to fetch the error code, if any, and replace the last temp
	with it. */

static void
compileGetErrorCode(void)
{
	// SimpleStackBasedCogit>>#compileGetErrorCode
    sqInt address;
    sqInt address1;
    AbstractInstruction *jmpGotError;
    AbstractInstruction *jmpIntError;
    AbstractInstruction *jmpNoError;
    sqInt primErrorTable;
    sqInt primErrorTableSize;

	/* begin MoveAw:R: */
	address = primFailCodeAddress();
	genoperandoperand(MoveAwR, address, TempReg);
	flag("ask concrete code gen if move sets condition codes?");
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 0, TempReg);
	/* begin JumpZero: */
	jmpNoError = genoperand(JumpZero, ((sqInt)0));
	primErrorTable = primErrTable();
	primErrorTableSize = lengthOf(primErrorTable);
	flag("use CmpCqR if pc mapping means stable contexts never contain native pcs");
	/* begin CmpCw:R: */
	genoperandoperand(CmpCwR, primErrorTableSize, TempReg);
	/* begin JumpAboveOrEqual: */
	jmpIntError = genoperand(JumpAboveOrEqual, ((sqInt)0));
	genFetchIndexRegisterfrominto(TempReg, primErrorTable, ClassReg);
	/* begin Jump: */
	jmpGotError = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpIntError, gLabel());
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ClassReg);
	jmpTarget(jmpGotError, gMoveRMwr(ClassReg, 0, SPReg));
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, 0, TempReg);
	/* begin MoveR:Aw: */
	address1 = primFailCodeAddress();
	genoperandoperand(MoveRAw, TempReg, address1);
	jmpTarget(jmpNoError, gLabel());
}


/*	Compile a call to an interpreter primitive. Call the C routine with the
	usual stack-switching dance, test the primFailCode and then either
	return on success or continue to the method body. */

static sqInt
compileInterpreterPrimitive(void (*primitiveRoutine)(void))
{
	// SimpleStackBasedCogit>>#compileInterpreterPrimitive:
    sqInt address;
    sqInt address1;
    sqInt address10;
    sqInt address11;
    sqInt address12;
    sqInt address13;
    sqInt address2;
    sqInt address3;
    sqInt address4;
    sqInt address5;
    sqInt address6;
    sqInt address7;
    sqInt address8;
    sqInt address9;
    AbstractInstruction *continuePostSampleNonPrim;
    AbstractInstruction *continuePostSamplePrim;
    sqInt flags;
    AbstractInstruction *jmp;
    AbstractInstruction *jmpSampleNonPrim;
    AbstractInstruction *jmpSamplePrim;
    sqInt offset;
    sqInt retpc;


	/* Save processor fp, sp and return pc in the interpreter's frame stack and instruction pointers */
	/* Switch to the C stack. */

genExternalizePointersForPrimitiveCall();
	genLoadCStackPointersForPrimCall();
	flags = primitivePropertyFlags(primitiveIndex);
	if ((flags & PrimCallCollectsProfileSamples) != 0) {

		/* Test nextProfileTick for being non-zero and call checkProfileTick if so */


		/* Test nextProfileTick for being non-zero and call checkProfileTick if so */

/* begin MoveAw:R: */
		address = nextProfileTickAddress();
		genoperandoperand(MoveAwR, address, TempReg);
		/* begin MoveAw:R: */
		address1 = (nextProfileTickAddress()) + BytesPerWord;
		genoperandoperand(MoveAwR, address1, ClassReg);
		/* begin OrR:R: */
		genoperandoperand(OrRR, TempReg, ClassReg);

		/* begin JumpNonZero: */
		jmpSampleNonPrim = genoperand(JumpNonZero, ((sqInt)0));
		/* begin Label */
		continuePostSampleNonPrim = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	}
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, 0, TempReg);
	/* begin MoveR:Aw: */
	address11 = primFailCodeAddress();
	genoperandoperand(MoveRAw, TempReg, address11);
	if (methodOrBlockNumArgs != 0) {
		/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, methodOrBlockNumArgs, TempReg);
	}
	/* begin MoveR:Aw: */
	address12 = argumentCountAddress();
	genoperandoperand(MoveRAw, TempReg, address12);
	if ((flags & PrimCallNeedsPrimitiveFunction) != 0) {
		/* begin MoveCw:R: */
		genoperandoperand(MoveCwR, ((sqInt)primitiveRoutine), TempReg);
		/* begin MoveR:Aw: */
		address3 = primitiveFunctionPointerAddress();
		genoperandoperand(MoveRAw, TempReg, address3);
	}
	if (recordPrimTrace()) {
		genFastPrimTraceUsingand(ClassReg, SendNumArgsReg);
	}
	if ((flags & (PrimCallNeedsNewMethod + PrimCallMayCallBack)) != 0) {

		/* The ceActivateFailingPrimitiveMethod: machinery can't handle framelessness. */

if ((flags & PrimCallMayCallBack) != 0) {

			/* The ceActivateFailingPrimitiveMethod: machinery can't handle framelessness. */


			/* The ceActivateFailingPrimitiveMethod: machinery can't handle framelessness. */

needsFrame = 1;
		}
		addDependent(methodLabel, annotateAbsolutePCRef(gMoveCwR(((sqInt)methodLabel), ClassReg)));
		/* begin MoveMw:r:R: */
		offset = offsetof(CogMethod, methodObject);
		genoperandoperandoperand(MoveMwrR, offset, ClassReg, TempReg);
		/* begin MoveR:Aw: */
		address4 = newMethodAddress();
		genoperandoperand(MoveRAw, TempReg, address4);
	}
	/* begin PrefetchAw: */
	address13 = primFailCodeAddress();
	genoperand(PrefetchAw, address13);
	if ((flags & PrimCallMayCallBack) != 0) {

		/* Sideways call the C primitive routine so that we return through cePrimReturnEnterCogCode. */

/* begin genSubstituteReturnAddress: */
		retpc = ((flags & PrimCallCollectsProfileSamples) != 0
			? cePrimReturnEnterCogCodeProfiling
			: cePrimReturnEnterCogCode);
		/* begin PushCw: */
		genoperand(PushCw, retpc);
		JumpRT(((sqInt)primitiveRoutine));
		/* begin Label */
		primInvokeLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		jmp = (jmpSamplePrim = (continuePostSamplePrim = null));
	}
	else {

		/* Call the C primitive routine. */

CallRT(((sqInt)primitiveRoutine));
		/* begin Label */
		primInvokeLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		if ((flags & PrimCallCollectsProfileSamples) != 0) {
			assert((flags & PrimCallNeedsNewMethod) != 0);
			/* begin MoveAw:R: */
			address5 = nextProfileTickAddress();
			genoperandoperand(MoveAwR, address5, TempReg);
			/* begin MoveAw:R: */
			address6 = (nextProfileTickAddress()) + BytesPerWord;
			genoperandoperand(MoveAwR, address6, ClassReg);
			/* begin OrR:R: */
			genoperandoperand(OrRR, TempReg, ClassReg);

			/* begin JumpNonZero: */
			jmpSamplePrim = genoperand(JumpNonZero, ((sqInt)0));
			/* begin Label */
			continuePostSamplePrim = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
		maybeCompileAllocFillerCheck();
		/* begin MoveAw:R: */
		address8 = instructionPointerAddress();
		genoperandoperand(MoveAwR, address8, ClassReg);
		genLoadStackPointers(backEnd);
		/* begin MoveAw:R: */
		address9 = primFailCodeAddress();
		genoperandoperand(MoveAwR, address9, TempReg);
		/* begin PushR: */
		genoperand(PushR, ClassReg);
		flag("ask concrete code gen if move sets condition codes?");
		/* begin CmpCq:R: */
		genoperandoperand(CmpCqR, 0, TempReg);
		/* begin JumpNonZero: */
		jmp = genoperand(JumpNonZero, ((sqInt)0));
		/* begin MoveMw:r:R: */
		genoperandoperandoperand(MoveMwrR, BytesPerWord, SPReg, ReceiverResultReg);
		flag("currently caller pushes result");
		/* begin RetN: */
		genoperand(RetN, BytesPerWord);
	}
	if ((flags & PrimCallCollectsProfileSamples) != 0) {

		/* The sample is collected by cePrimReturnEnterCogCode for external calls */
		/* Call ceCheckProfileTick: to record sample and then continue. */

if (jmpSamplePrim != null) {

			/* The sample is collected by cePrimReturnEnterCogCode for external calls */
			/* Call ceCheckProfileTick: to record sample and then continue. */

jmpTarget(jmpSamplePrim, gLabel());
			assert((flags & PrimCallNeedsNewMethod) != 0);
			CallRT((unsigned long)ceCheckProfileTick);
			/* begin Jump: */
			genoperand(Jump, ((sqInt)continuePostSamplePrim));
		}
		jmpTarget(jmpSampleNonPrim, gLabel());
		/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, 0, TempReg);
		/* begin MoveR:Aw: */
		address10 = newMethodAddress();
		genoperandoperand(MoveRAw, TempReg, address10);
		CallRT((unsigned long)ceCheckProfileTick);
		/* begin Jump: */
		genoperand(Jump, ((sqInt)continuePostSampleNonPrim));
	}
	if (jmp != null) {

		/* Jump to restore of receiver reg and proceed to frame build for failure. */
		/* Restore receiver reg from stack. */

jmpTarget(jmp, gLabel());
		/* begin MoveMw:r:R: */
		genoperandoperandoperand(MoveMwrR, BytesPerWord * (methodOrBlockNumArgs + 1), SPReg, ReceiverResultReg);
	}
	return 0;
}


/*	Compile the top-level method body. */

static sqInt
compileMethodBody(void)
{
	// Cogit>>#compileMethodBody
	if (endPC < initialPC) {
		return 0;
	}
	return compileAbstractInstructionsFromthrough(initialPC, endPC);
}


/*	Compile the code for a one-case MNU PIC that calls ceMNUFromPIC for
	case0Tag The tag for case0 is at the send site and so doesn't need to be
	generated. 
 */

static sqInt
compileMNUCPICmethodOperandnumArgs(CogMethod *cPIC, sqInt methodOperand, sqInt numArgs)
{
	// Cogit>>#compileMNUCPIC:methodOperand:numArgs:
    AbstractInstruction *jumpNext;
    sqInt jumpTarget;

	compilePICProlog(numArgs);
	jumpNext = compileCPICEntry();
	/* begin MoveCw:R: */
	genoperandoperand(MoveCwR, methodOperand, SendNumArgsReg);
	/* begin JumpLong: */
	genoperand(JumpLong, ((sqInt)mnuCall));
	jmpTarget(jumpNext, gMoveCwR(((sqInt)cPIC), ClassReg));
	/* begin JumpLong: */
	jumpTarget = cPICMissTrampolineFor(numArgs);
	genoperand(JumpLong, jumpTarget);
	return 0;
}


/*	Compile the code for an open PIC. Perform a probe of the first-level
	method lookup cache followed by a call of ceSendFromInLineCacheMiss: if
	the probe fails.
	Override to push the register args when calling ceSendFromInLineCacheMiss: */

static void
compileOpenPICnumArgs(sqInt selector, sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#compileOpenPIC:numArgs:
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *itsAHit;
    AbstractInstruction *jumpBCMethod;
    AbstractInstruction *jumpClassMiss;
    AbstractInstruction *jumpSelectorMiss;
    sqInt offset;
    sqInt offset1;
    sqInt offset2;
    sqInt offset3;
    sqInt offset4;
    sqInt offset5;
    sqInt offset6;
    sqInt routine;

	compilePICProlog(numArgs);
	

	/* Do first of three probes.  See CoInterpreter>>lookupInMethodCacheSel:classTag: */

entry = genGetClassTagOfintoscratchReg(ReceiverResultReg, ClassReg, TempReg);
	flag("lookupInMethodCacheSel:classTag:");
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, SendNumArgsReg);
	annotateobjRef(gXorCwR(selector, ClassReg), selector);
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, ShiftForWord, ClassReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, MethodCacheMask << ShiftForWord, ClassReg);
	/* begin MoveMw:r:R: */
	offset = (((usqInt)(methodCacheAddress()))) + (MethodCacheSelector << ShiftForWord);
	genoperandoperandoperand(MoveMwrR, offset, ClassReg, TempReg);
	annotateobjRef(gCmpCwR(selector, TempReg), selector);
	/* begin JumpNonZero: */
	jumpSelectorMiss = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset1 = (((usqInt)(methodCacheAddress()))) + (MethodCacheClass << ShiftForWord);
	genoperandoperandoperand(MoveMwrR, offset1, ClassReg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SendNumArgsReg, TempReg);
	/* begin JumpNonZero: */
	jumpClassMiss = genoperand(JumpNonZero, ((sqInt)0));
	/* begin Label */
	itsAHit = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin MoveMw:r:R: */
	offset2 = (((usqInt)(methodCacheAddress()))) + (MethodCacheMethod << ShiftForWord);
	genoperandoperandoperand(MoveMwrR, offset2, ClassReg, SendNumArgsReg);
	genLoadSlotsourceRegdestReg(HeaderIndex, SendNumArgsReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ClassReg);
	jumpBCMethod = genJumpSmallIntegerInScratchReg(TempReg);
	jmpTarget(jumpBCMethod, interpretLabel);
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, cmNoCheckEntryOffset, ClassReg);
	/* begin JumpR: */
	genoperand(JumpR, ClassReg);
	jmpTarget(jumpSelectorMiss, jmpTarget(jumpClassMiss, gLabel()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ClassReg);
	annotateobjRef(gXorCwR(selector, ClassReg), selector);
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, ShiftForWord - 1, ClassReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, MethodCacheMask << ShiftForWord, ClassReg);
	/* begin MoveMw:r:R: */
	offset3 = (((usqInt)(methodCacheAddress()))) + (MethodCacheSelector << ShiftForWord);
	genoperandoperandoperand(MoveMwrR, offset3, ClassReg, TempReg);
	annotateobjRef(gCmpCwR(selector, TempReg), selector);
	/* begin JumpNonZero: */
	jumpSelectorMiss = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset4 = (((usqInt)(methodCacheAddress()))) + (MethodCacheClass << ShiftForWord);
	genoperandoperandoperand(MoveMwrR, offset4, ClassReg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SendNumArgsReg, TempReg);
	/* begin JumpZero: */
	genoperand(JumpZero, ((sqInt)itsAHit));
	jmpTarget(jumpSelectorMiss, gLabel());
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ClassReg);
	annotateobjRef(gXorCwR(selector, ClassReg), selector);
	
/* begin AndCq:R: */
	genoperandoperand(AndCqR, MethodCacheMask << ShiftForWord, ClassReg);
	/* begin MoveMw:r:R: */
	offset5 = (((usqInt)(methodCacheAddress()))) + (MethodCacheSelector << ShiftForWord);
	genoperandoperandoperand(MoveMwrR, offset5, ClassReg, TempReg);
	annotateobjRef(gCmpCwR(selector, TempReg), selector);
	/* begin JumpNonZero: */
	jumpSelectorMiss = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset6 = (((usqInt)(methodCacheAddress()))) + (MethodCacheClass << ShiftForWord);
	genoperandoperandoperand(MoveMwrR, offset6, ClassReg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SendNumArgsReg, TempReg);
	/* begin JumpZero: */
	genoperand(JumpZero, ((sqInt)itsAHit));
	jmpTarget(jumpSelectorMiss, gLabel());
	genPushRegisterArgsForNumArgs(backEnd, numArgs);
	genSmalltalkToCStackSwitch();
	addDependent(methodLabel, annotateAbsolutePCRef(gMoveCwR(((sqInt)methodLabel), SendNumArgsReg)));
	if (cStackAlignment > BytesPerWord) {
		genAlignCStackSavingRegistersnumArgswordAlignment(backEnd, 0, 1, ((sqInt) cStackAlignment >> 2));
	}
	genPassRegasArgument(backEnd, SendNumArgsReg, 0);
	routine = (sqInt)ceSendFromInLineCacheMiss;
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction = genoperand(Call, routine);
	annotatewith(abstractInstruction, IsRelativeCall);
}


/*	The start of a PIC has a call to a run-time abort routine that either
	handles a dispatch to an interpreted method or a dispatch of an MNU case.
	The routine selects the path depending on ClassReg; if zero it takes the
	MNU path; if nonzero the dispatch to interpreter path. Neither of these
	paths returns. The abort routine must be called; In the callee the PIC is
	located by adding the relevant offset to the return address of the call. */

static sqInt
compilePICProlog(sqInt numArgs)
{
	// Cogit>>#compilePICProlog:
    sqInt callTarget;

	/* begin MoveCq:R: */
	mnuCall = genoperandoperand(MoveCqR, 0, ClassReg);
	interpretLabel = (interpretCall = gCall(picAbortTrampolineFor(numArgs)));

	return 0;
}


/*	Compile a primitive. If possible, performance-critical primtiives will
	be generated by their own routines (primitiveGenerator). Otherwise,
	if there is a primitive at all, we call the C routine with the usual
	stack-switching dance, test the primFailCode and then either return
	on success or continue to the method body. */

static sqInt
compilePrimitive(void)
{
	// Cogit>>#compilePrimitive
    PrimitiveDescriptor *primitiveDescriptor;
    void (*primitiveRoutine)(void);

	if (primitiveIndex == 0) {
		return 0;
	}
	if ((((primitiveDescriptor = primitiveGeneratorOrNil())) != null)
	 && (((primitiveDescriptor->primitiveGenerator)) != null)) {

		/* If a descriptor specifies an argument count (by numArgs >= 0)
		   then it must match for the generated code to be correct.  For
		   example for speed many primitives use ResultReceiverReg
		   instead of accessing the stack, so the receiver better be at
		   numArgs down the stack.  Use the interpreter version if not. */
		/* means don't care */

if ((((primitiveDescriptor->primNumArgs)) < 0)
		 || (((primitiveDescriptor->primNumArgs)) == (argumentCountOf(methodObj)))) {
			return ((primitiveDescriptor->primitiveGenerator))();
		}
	}
	if ((((primitiveRoutine = functionPointerForCompiledMethodprimitiveIndex(methodObj, primitiveIndex))) == null)
	 || (primitiveRoutine == (functionPointerForinClass(0, null)))) {
		return genFastPrimFail();
	}
	minValidCallAddress = ((minValidCallAddress < (((usqInt)primitiveRoutine))) ? minValidCallAddress : (((usqInt)primitiveRoutine)));
	return compileInterpreterPrimitive(primitiveRoutine);
}


/*	Generate a trampoline with up to four arguments. Generate either a call or
	a jump to aRoutine
	as requested by callJumpBar. If generating a call and resultRegOrNil is
	non-zero pass the C result
	back in resultRegOrNil.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */
/*	If on a RISC processor, the return address needs to be pushed to the
	stack so that the interpreter sees the same stack layout as on CISC. */

static void
compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNil)
{
	// Cogit>>#compileTrampolineFor:numArgs:arg:arg:arg:arg:saveRegs:pushLinkReg:resultReg:
	if (pushLinkReg
	 && (hasLinkRegister(backEnd))) {
		/* begin PushR: */
		genoperand(PushR, LinkReg);
	}
	genSmalltalkToCStackSwitch();
	if (cStackAlignment > BytesPerWord) {
		genAlignCStackSavingRegistersnumArgswordAlignment(backEnd, saveRegs, numArgs, ((sqInt) cStackAlignment >> 2));
	}
	if (saveRegs) {
genSaveRegisters(backEnd);
	}
	if (numArgs > 0) {
if (numArgs > 1) {
if (numArgs > 2) {
if (numArgs > 3) {
if (regOrConst3 < 0) {
genPassRegasArgument(backEnd, regOrConst3, 3);
					}
					else {
genPassConstasArgument(backEnd, regOrConst3, 3);
					}
				}
				if (regOrConst2 < 0) {
genPassRegasArgument(backEnd, regOrConst2, 2);
				}
				else {
genPassConstasArgument(backEnd, regOrConst2, 2);
				}
			}
			if (regOrConst1 < 0) {
genPassRegasArgument(backEnd, regOrConst1, 1);
			}
			else {
genPassConstasArgument(backEnd, regOrConst1, 1);
			}
		}
		if (regOrConst0 < 0) {
genPassRegasArgument(backEnd, regOrConst0, 0);
		}
		else {
genPassConstasArgument(backEnd, regOrConst0, 0);
		}
	}
	/* begin Call: */
	genoperand(Call, ((usqInt)aRoutine));
	if (!(resultRegOrNil == null)) {
		genWriteCResultIntoReg(backEnd, resultRegOrNil);
	}
	if (saveRegs) {
if (numArgs > 0) {
genRemoveNArgsFromStack(backEnd, numArgs);
		}
		if (resultRegOrNil == null) {
genRestoreRegs(backEnd);
		}
		else {
genRestoreRegsExcept(backEnd, resultRegOrNil);
		}
	}
	genLoadStackPointers(backEnd);
	
/* begin RetN: */
	genoperand(RetN, 0);
}


/*	Generate the entry code for a method to determine cmEntryOffset and
	cmNoCheckEntryOffset. We
	need cmNoCheckEntryOffset up front to be able to generate the map starting
	from cmNoCheckEntryOffset */
/*	stack allocate the various collections so that they
	are effectively garbage collected on return. */

static void
computeEntryOffsets(void)
{
	// Cogit>>#computeEntryOffsets
	allocateOpcodesbytecodes(20, 0);
	methodOrBlockNumArgs = 0;
	compileAbort();
	compileEntry();
	computeMaximumSizes();
	generateInstructionsAt(methodZoneBase + (sizeof(CogMethod)));
	cmEntryOffset = ((entry->address)) - methodZoneBase;
	cmNoCheckEntryOffset = ((noCheckEntry->address)) - methodZoneBase;
	
missOffset = (((sendMissCall->address)) + ((sendMissCall->machineCodeSize))) - methodZoneBase;
	entryPointMask = BytesPerWord - 1;
	while ((cmEntryOffset & entryPointMask) == (cmNoCheckEntryOffset & entryPointMask)) {
entryPointMask = (entryPointMask + entryPointMask) + 1;
	}
	if (entryPointMask >= (roundUpLength(1))) {
		error("cannot differentiate checked and unchecked entry-points with current cog method alignment");
	}
	checkedEntryAlignment = cmEntryOffset & entryPointMask;
	uncheckedEntryAlignment = cmNoCheckEntryOffset & entryPointMask;
	assert(checkedEntryAlignment != uncheckedEntryAlignment);
	
}


/*	Since it's an extraction from other methods. */

static sqInt
computeJumpTargetOffsetPlus(AbstractInstruction * self_in_computeJumpTargetOffsetPlus, sqInt anPCOffset)
{
	// CogAbstractInstruction>>#computeJumpTargetOffsetPlus:
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;

	/* begin jumpTargetAddress */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_computeJumpTargetOffsetPlus->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if (isAnInstruction(self_in_computeJumpTargetOffsetPlus, jumpTarget1)) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	return (((sqInt) jumpTarget)) - (((sqInt) (((self_in_computeJumpTargetOffsetPlus->address)) + anPCOffset)));
}


/*	Compute the maximum size for each opcode. This allows jump offsets to
	be determined, provided that all backward branches are long branches. */
/*	N.B. The ^maxSize := N forms are to get around the compiler's long branch
	limits which are exceeded when each case jumps around the otherwise. */

static sqInt
computeMaximumSize(AbstractInstruction * self_in_computeMaximumSize)
{
	// CogIA32Compiler>>#computeMaximumSize
	
	switch ((self_in_computeMaximumSize->opcode)) {
	case Label:
		return ((self_in_computeMaximumSize->maxSize) = 0);

	case AlignmentNops:
		return ((self_in_computeMaximumSize->maxSize) = (((self_in_computeMaximumSize->operands))[0]) - 1);

	case Fill16:
	case IDIVR:
	case CPUID:
	case XCHGRR:
	case JumpR:
	case AddRR:
	case AndRR:
	case CmpRR:
	case OrRR:
	case XorRR:
	case SubRR:
	case NegateR:
	case MoveRR:
		return ((self_in_computeMaximumSize->maxSize) = 2);

	case Fill32:
	case FillFromWord:
	case AddRdRd:
	case CmpRdRd:
	case SubRdRd:
	case MulRdRd:
	case DivRdRd:
	case SqrtRd:
	case MoveRdRd:
	case ConvertRRd:
		return ((self_in_computeMaximumSize->maxSize) = 4);

	case Nop:
	case CDQ:
	case LOCK:
	case PopR:
	case PushR:
		return ((self_in_computeMaximumSize->maxSize) = 1);

	case IMULRR:
	case LFENCE:
	case MFENCE:
	case SFENCE:
		return ((self_in_computeMaximumSize->maxSize) = 3);

	case CMPXCHGAwR:
	case XCHGMwrR:
		return ((self_in_computeMaximumSize->maxSize) = 7);

	case CMPXCHGMwrR:
		return ((self_in_computeMaximumSize->maxSize) = 8);

	case XCHGAwR:
		return ((self_in_computeMaximumSize->maxSize) = 6);

	case Call:
	case MoveCwR:
	case PushCw:
		return ((self_in_computeMaximumSize->maxSize) = 5);

	case Jump:
	case JumpLong:
		resolveJumpTarget(self_in_computeMaximumSize);
		return ((self_in_computeMaximumSize->maxSize) = 5);

	case JumpZero:
	case JumpNonZero:
	case JumpNegative:
	case JumpNonNegative:
	case JumpOverflow:
	case JumpNoOverflow:
	case JumpCarry:
	case JumpNoCarry:
	case JumpLess:
	case JumpGreaterOrEqual:
	case JumpGreater:
	case JumpLessOrEqual:
	case JumpBelow:
	case JumpAboveOrEqual:
	case JumpAbove:
	case JumpBelowOrEqual:
	case JumpLongZero:
	case JumpLongNonZero:
	case JumpFPEqual:
	case JumpFPNotEqual:
	case JumpFPLess:
	case JumpFPGreaterOrEqual:
	case JumpFPGreater:
	case JumpFPLessOrEqual:
	case JumpFPOrdered:
	case JumpFPUnordered:
		resolveJumpTarget(self_in_computeMaximumSize);
		return ((self_in_computeMaximumSize->maxSize) = 6);

	case RetN:
		return ((self_in_computeMaximumSize->maxSize) = ((((self_in_computeMaximumSize->operands))[0]) == 0
			? 1
			: 3));

	case AddCqR:
	case AndCqR:
	case CmpCqR:
	case OrCqR:
	case SubCqR:
		return ((self_in_computeMaximumSize->maxSize) = (isQuick(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[0])
			? 3
			: ((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])) == EAX
					? 5
					: 6)));

	case AddCwR:
	case AndCwR:
	case CmpCwR:
	case OrCwR:
	case SubCwR:
	case XorCwR:
	case MoveAwR:
		return ((self_in_computeMaximumSize->maxSize) = ((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])) == EAX
			? 5
			: 6));

	case LoadEffectiveAddressMwrR:
	case MoveMbrR:
	case MoveMwrR:
		return ((self_in_computeMaximumSize->maxSize) = ((isQuick(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[0])
	? 3
	: 6)) + (((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])) == ESP
	? 1
	: 0)));

	case LogicalShiftLeftCqR:
	case LogicalShiftRightCqR:
	case ArithmeticShiftRightCqR:
		return ((self_in_computeMaximumSize->maxSize) = ((((self_in_computeMaximumSize->operands))[0]) == 1
			? 2
			: 3));

	case LogicalShiftLeftRR:
	case LogicalShiftRightRR:
	case ArithmeticShiftRightRR:
		computeShiftRRSize(self_in_computeMaximumSize);
		break;
	case MoveCqR:
		return ((self_in_computeMaximumSize->maxSize) = ((((self_in_computeMaximumSize->operands))[0]) == 0
			? 2
			: 5));

	case MoveRAw:
		return ((self_in_computeMaximumSize->maxSize) = ((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[0])) == EAX
			? 5
			: 6));

	case MoveRMwr:
	case MoveRMbr:
		return ((self_in_computeMaximumSize->maxSize) = ((isQuick(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])
	? 3
	: 6)) + (((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[2])) == ESP
	? 1
	: 0)));

	case MoveRdM64r:
		return ((self_in_computeMaximumSize->maxSize) = ((isQuick(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])
	? 5
	: 8)) + (((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[2])) == ESP
	? 1
	: 0)));

	case MoveM16rR:
		return ((self_in_computeMaximumSize->maxSize) = ((isQuick(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[0])
	? 4
	: 7)) + (((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])) == ESP
	? 1
	: 0)));

	case MoveM64rRd:
		return ((self_in_computeMaximumSize->maxSize) = ((isQuick(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[0])
	? 5
	: 8)) + (((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])) == ESP
	? 1
	: 0)));

	case MoveXbrRR:
		assert((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[0])) != ESP);
		return ((self_in_computeMaximumSize->maxSize) = ((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])) == EBP
			? 5
			: 4));

	case MoveRXbrR:
	case MoveRXwrR:
		assert((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])) != ESP);
		return ((self_in_computeMaximumSize->maxSize) = ((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[2])) == EBP
			? 4
			: 3));

	case MoveXwrRR:
		assert((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[0])) != ESP);
		return ((self_in_computeMaximumSize->maxSize) = ((concreteRegister(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])) == EBP
			? 4
			: 3));

	case PrefetchAw:
		return ((self_in_computeMaximumSize->maxSize) = (hasSSEInstructions(self_in_computeMaximumSize)
			? 7
			: 0));

	default:
		error("Case not found and no otherwise clause");
	}
	return 0;
}


/*	This pass assigns maximum sizes to all abstract instructions and
	eliminates jump fixups.
	It hence assigns the maximum address an instruction will occur at which
	allows the next
	pass to conservatively size jumps. */

static void
computeMaximumSizes(void)
{
	// Cogit>>#computeMaximumSizes
    AbstractInstruction *abstractInstruction;
    sqInt i;
    sqInt relativeAddress;

	relativeAddress = 0;
	for (i = 0; i < opcodeIndex; i += 1) {
		abstractInstruction = abstractInstructionAt(i);
		(abstractInstruction->address = relativeAddress);
		computeMaximumSize(abstractInstruction);
		relativeAddress += (abstractInstruction->maxSize);
	}
}


/*	On the x86 the only instructions that shift by the value of a
	register require the shift count to be in %ecx. So we may
	have to use swap instructions to get the count into ecx. */

static sqInt
computeShiftRRSize(AbstractInstruction * self_in_computeShiftRRSize)
{
	// CogIA32Compiler>>#computeShiftRRSize
    sqInt shiftCountReg;

	shiftCountReg = concreteRegister(self_in_computeShiftRRSize, ((self_in_computeShiftRRSize->operands))[0]);
	if (shiftCountReg == ECX) {
return ((self_in_computeShiftRRSize->maxSize) = 2);
	}
	return ((self_in_computeShiftRRSize->maxSize) = (shiftCountReg == EAX
		? (1 + 2) + 1
		: (2 + 2) + 2));
}


/*	Map a possibly abstract double-precision floating-point register into a
	concrete one.
	Abstract registers (defined in CogAbstractOpcodes) are all negative. If
	registerIndex is negative assume it is an abstract register.
	
	[1] IA-32 Intel® Architecture Software Developer's Manual Volume 2A:
	Instruction Set Reference, A-M */

static sqInt
concreteDPFPRegister(AbstractInstruction * self_in_concreteDPFPRegister, sqInt registerIndex)
{
	// CogIA32Compiler>>#concreteDPFPRegister:
	
	switch (registerIndex) {
	case DPFPReg0:
		return ((sqInt) XMM0L >> 1);

	case DPFPReg1:
		return ((sqInt) XMM1L >> 1);

	case DPFPReg2:
		return ((sqInt) XMM2L >> 1);

	case DPFPReg3:
		return ((sqInt) XMM3L >> 1);

	case DPFPReg4:
		return ((sqInt) XMM4L >> 1);

	case DPFPReg5:
		return ((sqInt) XMM5L >> 1);

	case DPFPReg6:
		return ((sqInt) XMM6L >> 1);

	case DPFPReg7:
		return ((sqInt) XMM7L >> 1);

	default:
		assert(((registerIndex >= XMM0L) && (registerIndex <= XMM7L)));
		assert((registerIndex & 1) == 0);
		return ((sqInt) registerIndex >> 1);

	}
}


/*	Map a possibly abstract register into a concrete one. Abstract registers
	(defined in CogAbstractOpcodes) are all negative. If registerIndex is
	negative assume it is an abstract register.
	
	[1] IA-32 Intel® Architecture Software Developer's Manual Volume 2A:
	Instruction Set Reference, A-M
	
	
	N.B. EAX ECX & EDX are caller-save (scratch) registers. Hence we use ECX
	for class and EDC for
	receiver/result since these are written in all normal sends. EBX ESI & EDI
	are callee-save. */

static sqInt
concreteRegister(AbstractInstruction * self_in_concreteRegister, sqInt registerIndex)
{
	// CogIA32Compiler>>#concreteRegister:
	
	switch (registerIndex) {
	case TempReg:
		return EAX;

	case ClassReg:
		return ECX;

	case ReceiverResultReg:
		return EDX;

	case SendNumArgsReg:
		return EBX;

	case SPReg:
		return ESP;

	case FPReg:
		return EBP;

	case Arg0Reg:
		return ESI;

	case Arg1Reg:
		return EDI;

	default:
		assert(((registerIndex >= EAX) && (registerIndex <= EDI)));
		return registerIndex;

	}
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeAddCqR(AbstractInstruction * self_in_concretizeAddCqR)
{
	// CogIA32Compiler>>#concretizeAddCqR
    sqInt reg;
    sqInt value;

	value = ((self_in_concretizeAddCqR->operands))[0];
	reg = concreteRegister(self_in_concretizeAddCqR, ((self_in_concretizeAddCqR->operands))[1]);
	if (isQuick(self_in_concretizeAddCqR, value)) {
		((self_in_concretizeAddCqR->machineCode))[0] = 131;
		((self_in_concretizeAddCqR->machineCode))[1] = (modRMRO(self_in_concretizeAddCqR, ModReg, reg, 0));
		((self_in_concretizeAddCqR->machineCode))[2] = (value & 0xFF);
		return ((self_in_concretizeAddCqR->machineCodeSize) = 3);
	}
	if (reg == EAX) {
((self_in_concretizeAddCqR->machineCode))[0] = 5;
		((self_in_concretizeAddCqR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeAddCqR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeAddCqR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeAddCqR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeAddCqR->machineCodeSize) = 5);
	}
	((self_in_concretizeAddCqR->machineCode))[0] = 129;
	((self_in_concretizeAddCqR->machineCode))[1] = (modRMRO(self_in_concretizeAddCqR, ModReg, reg, 0));
	((self_in_concretizeAddCqR->machineCode))[2] = (value & 0xFF);
	((self_in_concretizeAddCqR->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeAddCqR->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeAddCqR->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeAddCqR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeAddCwR(AbstractInstruction * self_in_concretizeAddCwR)
{
	// CogIA32Compiler>>#concretizeAddCwR
    sqInt reg;
    sqInt value;

	value = ((self_in_concretizeAddCwR->operands))[0];
	reg = concreteRegister(self_in_concretizeAddCwR, ((self_in_concretizeAddCwR->operands))[1]);
	if (reg == EAX) {
((self_in_concretizeAddCwR->machineCode))[0] = 5;
		((self_in_concretizeAddCwR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeAddCwR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeAddCwR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeAddCwR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeAddCwR->machineCodeSize) = 5);
	}
	((self_in_concretizeAddCwR->machineCode))[0] = 129;
	((self_in_concretizeAddCwR->machineCode))[1] = (modRMRO(self_in_concretizeAddCwR, ModReg, reg, 0));
	((self_in_concretizeAddCwR->machineCode))[2] = (value & 0xFF);
	((self_in_concretizeAddCwR->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeAddCwR->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeAddCwR->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeAddCwR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeAddRR(AbstractInstruction * self_in_concretizeAddRR)
{
	// CogIA32Compiler>>#concretizeAddRR
    sqInt regLHS;
    sqInt regRHS;

	regLHS = concreteRegister(self_in_concretizeAddRR, ((self_in_concretizeAddRR->operands))[0]);
	regRHS = concreteRegister(self_in_concretizeAddRR, ((self_in_concretizeAddRR->operands))[1]);
	((self_in_concretizeAddRR->machineCode))[0] = 3;
	((self_in_concretizeAddRR->machineCode))[1] = (modRMRO(self_in_concretizeAddRR, ModReg, regLHS, regRHS));
	return ((self_in_concretizeAddRR->machineCodeSize) = 2);
}

static AbstractInstruction *
concretizeAlignmentNops(AbstractInstruction * self_in_concretizeAlignmentNops)
{
	// CogIA32Compiler>>#concretizeAlignmentNops
    sqInt i;

	flag("if performance is an issue generate longer nops");
	for (i = 0; i < ((self_in_concretizeAlignmentNops->machineCodeSize)); i += 1) {
		((self_in_concretizeAlignmentNops->machineCode))[i] = 144;
	}
	return self_in_concretizeAlignmentNops;
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeAndCqR(AbstractInstruction * self_in_concretizeAndCqR)
{
	// CogIA32Compiler>>#concretizeAndCqR
    sqInt mask;
    sqInt reg;

	mask = ((self_in_concretizeAndCqR->operands))[0];
	reg = concreteRegister(self_in_concretizeAndCqR, ((self_in_concretizeAndCqR->operands))[1]);
	if (isQuick(self_in_concretizeAndCqR, mask)) {
		((self_in_concretizeAndCqR->machineCode))[0] = 131;
		((self_in_concretizeAndCqR->machineCode))[1] = (modRMRO(self_in_concretizeAndCqR, ModReg, reg, 4));
		((self_in_concretizeAndCqR->machineCode))[2] = (mask & 0xFF);
		return ((self_in_concretizeAndCqR->machineCodeSize) = 3);
	}
	if (reg == EAX) {
((self_in_concretizeAndCqR->machineCode))[0] = 37;
		((self_in_concretizeAndCqR->machineCode))[1] = (mask & 0xFF);
		((self_in_concretizeAndCqR->machineCode))[2] = ((((usqInt) mask) >> 8) & 0xFF);
		((self_in_concretizeAndCqR->machineCode))[3] = ((((usqInt) mask) >> 16) & 0xFF);
		((self_in_concretizeAndCqR->machineCode))[4] = ((((usqInt) mask) >> 24) & 0xFF);
		return ((self_in_concretizeAndCqR->machineCodeSize) = 5);
	}
	((self_in_concretizeAndCqR->machineCode))[0] = 129;
	((self_in_concretizeAndCqR->machineCode))[1] = (modRMRO(self_in_concretizeAndCqR, ModReg, reg, 4));
	((self_in_concretizeAndCqR->machineCode))[2] = (mask & 0xFF);
	((self_in_concretizeAndCqR->machineCode))[3] = ((((usqInt) mask) >> 8) & 0xFF);
	((self_in_concretizeAndCqR->machineCode))[4] = ((((usqInt) mask) >> 16) & 0xFF);
	((self_in_concretizeAndCqR->machineCode))[5] = ((((usqInt) mask) >> 24) & 0xFF);
	return ((self_in_concretizeAndCqR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeAndCwR(AbstractInstruction * self_in_concretizeAndCwR)
{
	// CogIA32Compiler>>#concretizeAndCwR
    sqInt reg;
    sqInt value;

	value = ((self_in_concretizeAndCwR->operands))[0];
	reg = concreteRegister(self_in_concretizeAndCwR, ((self_in_concretizeAndCwR->operands))[1]);
	if (reg == EAX) {
((self_in_concretizeAndCwR->machineCode))[0] = 37;
		((self_in_concretizeAndCwR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeAndCwR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeAndCwR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeAndCwR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeAndCwR->machineCodeSize) = 5);
	}
	((self_in_concretizeAndCwR->machineCode))[0] = 131;
	((self_in_concretizeAndCwR->machineCode))[1] = (modRMRO(self_in_concretizeAndCwR, ModReg, reg, 4));
	((self_in_concretizeAndCwR->machineCode))[2] = (value & 0xFF);
	((self_in_concretizeAndCwR->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeAndCwR->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeAndCwR->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeAndCwR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeAndRR(AbstractInstruction * self_in_concretizeAndRR)
{
	// CogIA32Compiler>>#concretizeAndRR
    sqInt regLHS;
    sqInt regRHS;

	regLHS = concreteRegister(self_in_concretizeAndRR, ((self_in_concretizeAndRR->operands))[0]);
	regRHS = concreteRegister(self_in_concretizeAndRR, ((self_in_concretizeAndRR->operands))[1]);
	((self_in_concretizeAndRR->machineCode))[0] = 35;
	((self_in_concretizeAndRR->machineCode))[1] = (modRMRO(self_in_concretizeAndRR, ModReg, regLHS, regRHS));
	return ((self_in_concretizeAndRR->machineCodeSize) = 2);
}

static sqInt
concretizeArithmeticShiftRightCqR(AbstractInstruction * self_in_concretizeArithmeticShiftRightCqR)
{
	// CogIA32Compiler>>#concretizeArithmeticShiftRightCqR
    sqInt reg;
    sqInt shiftCount;

	shiftCount = (((((self_in_concretizeArithmeticShiftRightCqR->operands))[0]) < 0x1F) ? (((self_in_concretizeArithmeticShiftRightCqR->operands))[0]) : 0x1F);
	reg = concreteRegister(self_in_concretizeArithmeticShiftRightCqR, ((self_in_concretizeArithmeticShiftRightCqR->operands))[1]);
	if (shiftCount == 1) {
((self_in_concretizeArithmeticShiftRightCqR->machineCode))[0] = 209;
		((self_in_concretizeArithmeticShiftRightCqR->machineCode))[1] = (modRMRO(self_in_concretizeArithmeticShiftRightCqR, ModReg, reg, 7));
		return ((self_in_concretizeArithmeticShiftRightCqR->machineCodeSize) = 2);
	}
	((self_in_concretizeArithmeticShiftRightCqR->machineCode))[0] = 193;
	((self_in_concretizeArithmeticShiftRightCqR->machineCode))[1] = (modRMRO(self_in_concretizeArithmeticShiftRightCqR, ModReg, reg, 7));
	((self_in_concretizeArithmeticShiftRightCqR->machineCode))[2] = shiftCount;
	return ((self_in_concretizeArithmeticShiftRightCqR->machineCodeSize) = 3);
}


/*	On the x86 the only instructions that shift by the value of a
	register require the shift count to be in %ecx. So we may
	have to use swap instructions to get the count into %ecx. */

static sqInt
concretizeArithmeticShiftRightRR(AbstractInstruction * self_in_concretizeArithmeticShiftRightRR)
{
	// CogIA32Compiler>>#concretizeArithmeticShiftRightRR
    sqInt destReg;
    sqInt regToShift;
    sqInt shiftCountReg;

	shiftCountReg = concreteRegister(self_in_concretizeArithmeticShiftRightRR, ((self_in_concretizeArithmeticShiftRightRR->operands))[0]);
	destReg = concreteRegister(self_in_concretizeArithmeticShiftRightRR, ((self_in_concretizeArithmeticShiftRightRR->operands))[1]);
	if (shiftCountReg == ECX) {
((self_in_concretizeArithmeticShiftRightRR->machineCode))[0] = 211;
		((self_in_concretizeArithmeticShiftRightRR->machineCode))[1] = (modRMRO(self_in_concretizeArithmeticShiftRightRR, ModReg, destReg, 7));
		return ((self_in_concretizeArithmeticShiftRightRR->machineCodeSize) = 2);
	}
	regToShift = (destReg == shiftCountReg
		? ECX
		: (destReg == ECX
				? shiftCountReg
				: destReg));
	if (shiftCountReg == EAX) {
((self_in_concretizeArithmeticShiftRightRR->machineCode))[0] = (144 + ECX);
		((self_in_concretizeArithmeticShiftRightRR->machineCode))[1] = 211;
		((self_in_concretizeArithmeticShiftRightRR->machineCode))[2] = (modRMRO(self_in_concretizeArithmeticShiftRightRR, ModReg, regToShift, 7));
		((self_in_concretizeArithmeticShiftRightRR->machineCode))[3] = (144 + ECX);
		return ((self_in_concretizeArithmeticShiftRightRR->machineCodeSize) = 4);
	}
	((self_in_concretizeArithmeticShiftRightRR->machineCode))[0] = 135;
	((self_in_concretizeArithmeticShiftRightRR->machineCode))[1] = (modRMRO(self_in_concretizeArithmeticShiftRightRR, ModReg, ECX, shiftCountReg));
	((self_in_concretizeArithmeticShiftRightRR->machineCode))[2] = 211;
	((self_in_concretizeArithmeticShiftRightRR->machineCode))[3] = (modRMRO(self_in_concretizeArithmeticShiftRightRR, ModReg, regToShift, 7));
	((self_in_concretizeArithmeticShiftRightRR->machineCode))[4] = 135;
	((self_in_concretizeArithmeticShiftRightRR->machineCode))[5] = (modRMRO(self_in_concretizeArithmeticShiftRightRR, ModReg, ECX, shiftCountReg));
	return ((self_in_concretizeArithmeticShiftRightRR->machineCodeSize) = 6);
}


/*	Generate concrete machine code for the instruction at actualAddress,
	setting machineCodeSize, and answer the following address. */

static sqInt
concretizeAt(AbstractInstruction * self_in_concretizeAt, sqInt actualAddress)
{
	// CogIA32Compiler>>#concretizeAt:
	(self_in_concretizeAt->address) = actualAddress;
	dispatchConcretize(self_in_concretizeAt);
	assert((((self_in_concretizeAt->maxSize)) == null)
	 || (((self_in_concretizeAt->maxSize)) >= ((self_in_concretizeAt->machineCodeSize))));
	return actualAddress + ((self_in_concretizeAt->machineCodeSize));
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeCall(AbstractInstruction * self_in_concretizeCall)
{
	// CogIA32Compiler>>#concretizeCall
    sqInt offset;

	assert((((self_in_concretizeCall->operands))[0]) != 0);
	offset = (((sqInt) (((self_in_concretizeCall->operands))[0]))) - (((sqInt) (((self_in_concretizeCall->address)) + 5)));
	((self_in_concretizeCall->machineCode))[0] = 232;
	((self_in_concretizeCall->machineCode))[1] = (offset & 0xFF);
	((self_in_concretizeCall->machineCode))[2] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeCall->machineCode))[3] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeCall->machineCode))[4] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeCall->machineCodeSize) = 5);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeCDQ(AbstractInstruction * self_in_concretizeCDQ)
{
	// CogIA32Compiler>>#concretizeCDQ
	((self_in_concretizeCDQ->machineCode))[0] = 153;
	return ((self_in_concretizeCDQ->machineCodeSize) = 1);
}

static sqInt
concretizeCMPXCHGAwR(AbstractInstruction * self_in_concretizeCMPXCHGAwR)
{
	// CogIA32Compiler>>#concretizeCMPXCHGAwR
    sqInt addressOperand;
    sqInt reg;

	addressOperand = ((self_in_concretizeCMPXCHGAwR->operands))[0];
	reg = concreteRegister(self_in_concretizeCMPXCHGAwR, ((self_in_concretizeCMPXCHGAwR->operands))[1]);
	((self_in_concretizeCMPXCHGAwR->machineCode))[0] = 15;
	((self_in_concretizeCMPXCHGAwR->machineCode))[1] = 177;
	((self_in_concretizeCMPXCHGAwR->machineCode))[2] = (modRMRO(self_in_concretizeCMPXCHGAwR, ModRegInd, 5, reg));
	((self_in_concretizeCMPXCHGAwR->machineCode))[3] = (addressOperand & 0xFF);
	((self_in_concretizeCMPXCHGAwR->machineCode))[4] = ((((usqInt) addressOperand) >> 8) & 0xFF);
	((self_in_concretizeCMPXCHGAwR->machineCode))[5] = ((((usqInt) addressOperand) >> 16) & 0xFF);
	((self_in_concretizeCMPXCHGAwR->machineCode))[6] = ((((usqInt) addressOperand) >> 24) & 0xFF);
	return ((self_in_concretizeCMPXCHGAwR->machineCodeSize) = 7);
}

static sqInt
concretizeCMPXCHGMwrR(AbstractInstruction * self_in_concretizeCMPXCHGMwrR)
{
	// CogIA32Compiler>>#concretizeCMPXCHGMwrR
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	offset = ((self_in_concretizeCMPXCHGMwrR->operands))[0];
	srcReg = concreteRegister(self_in_concretizeCMPXCHGMwrR, ((self_in_concretizeCMPXCHGMwrR->operands))[1]);
	destReg = concreteRegister(self_in_concretizeCMPXCHGMwrR, ((self_in_concretizeCMPXCHGMwrR->operands))[2]);
	if (srcReg != ESP) {
if (isQuick(self_in_concretizeCMPXCHGMwrR, offset)) {
			((self_in_concretizeCMPXCHGMwrR->machineCode))[0] = 15;
			((self_in_concretizeCMPXCHGMwrR->machineCode))[1] = 177;
			((self_in_concretizeCMPXCHGMwrR->machineCode))[2] = (modRMRO(self_in_concretizeCMPXCHGMwrR, ModRegRegDisp8, srcReg, destReg));
			((self_in_concretizeCMPXCHGMwrR->machineCode))[3] = (offset & 0xFF);
			return ((self_in_concretizeCMPXCHGMwrR->machineCodeSize) = 4);
		}
		((self_in_concretizeCMPXCHGMwrR->machineCode))[0] = 15;
		((self_in_concretizeCMPXCHGMwrR->machineCode))[1] = 177;
		((self_in_concretizeCMPXCHGMwrR->machineCode))[2] = (modRMRO(self_in_concretizeCMPXCHGMwrR, ModRegRegDisp32, srcReg, destReg));
		((self_in_concretizeCMPXCHGMwrR->machineCode))[3] = (offset & 0xFF);
		((self_in_concretizeCMPXCHGMwrR->machineCode))[4] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeCMPXCHGMwrR->machineCode))[5] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeCMPXCHGMwrR->machineCode))[6] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeCMPXCHGMwrR->machineCodeSize) = 7);
	}
	if (isQuick(self_in_concretizeCMPXCHGMwrR, offset)) {
		((self_in_concretizeCMPXCHGMwrR->machineCode))[0] = 15;
		((self_in_concretizeCMPXCHGMwrR->machineCode))[1] = 177;
		((self_in_concretizeCMPXCHGMwrR->machineCode))[2] = (modRMRO(self_in_concretizeCMPXCHGMwrR, ModRegRegDisp8, srcReg, destReg));
		((self_in_concretizeCMPXCHGMwrR->machineCode))[3] = (sib(self_in_concretizeCMPXCHGMwrR, SIB1, 4, srcReg));
		((self_in_concretizeCMPXCHGMwrR->machineCode))[4] = (offset & 0xFF);
		return ((self_in_concretizeCMPXCHGMwrR->machineCodeSize) = 5);
	}
	((self_in_concretizeCMPXCHGMwrR->machineCode))[0] = 15;
	((self_in_concretizeCMPXCHGMwrR->machineCode))[1] = 177;
	((self_in_concretizeCMPXCHGMwrR->machineCode))[2] = (modRMRO(self_in_concretizeCMPXCHGMwrR, ModRegRegDisp32, srcReg, destReg));
	((self_in_concretizeCMPXCHGMwrR->machineCode))[3] = (sib(self_in_concretizeCMPXCHGMwrR, SIB1, 4, srcReg));
	((self_in_concretizeCMPXCHGMwrR->machineCode))[4] = (offset & 0xFF);
	((self_in_concretizeCMPXCHGMwrR->machineCode))[5] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeCMPXCHGMwrR->machineCode))[6] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeCMPXCHGMwrR->machineCode))[7] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeCMPXCHGMwrR->machineCodeSize) = 8);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeCmpCqR(AbstractInstruction * self_in_concretizeCmpCqR)
{
	// CogIA32Compiler>>#concretizeCmpCqR
    sqInt reg;
    sqInt value;

	value = ((self_in_concretizeCmpCqR->operands))[0];
	reg = concreteRegister(self_in_concretizeCmpCqR, ((self_in_concretizeCmpCqR->operands))[1]);
	if (isQuick(self_in_concretizeCmpCqR, value)) {
		((self_in_concretizeCmpCqR->machineCode))[0] = 131;
		((self_in_concretizeCmpCqR->machineCode))[1] = (modRMRO(self_in_concretizeCmpCqR, ModReg, reg, 7));
		((self_in_concretizeCmpCqR->machineCode))[2] = (value & 0xFF);
		return ((self_in_concretizeCmpCqR->machineCodeSize) = 3);
	}
	if (reg == EAX) {
((self_in_concretizeCmpCqR->machineCode))[0] = 61;
		((self_in_concretizeCmpCqR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeCmpCqR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeCmpCqR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeCmpCqR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeCmpCqR->machineCodeSize) = 5);
	}
	((self_in_concretizeCmpCqR->machineCode))[0] = 129;
	((self_in_concretizeCmpCqR->machineCode))[1] = (modRMRO(self_in_concretizeCmpCqR, ModReg, reg, 7));
	((self_in_concretizeCmpCqR->machineCode))[2] = (value & 0xFF);
	((self_in_concretizeCmpCqR->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeCmpCqR->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeCmpCqR->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeCmpCqR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeCmpCwR(AbstractInstruction * self_in_concretizeCmpCwR)
{
	// CogIA32Compiler>>#concretizeCmpCwR
    sqInt reg;
    sqInt value;

	value = ((self_in_concretizeCmpCwR->operands))[0];
	reg = concreteRegister(self_in_concretizeCmpCwR, ((self_in_concretizeCmpCwR->operands))[1]);
	if (reg == EAX) {
((self_in_concretizeCmpCwR->machineCode))[0] = 61;
		((self_in_concretizeCmpCwR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeCmpCwR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeCmpCwR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeCmpCwR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeCmpCwR->machineCodeSize) = 5);
	}
	((self_in_concretizeCmpCwR->machineCode))[0] = 129;
	((self_in_concretizeCmpCwR->machineCode))[1] = (modRMRO(self_in_concretizeCmpCwR, ModReg, reg, 7));
	((self_in_concretizeCmpCwR->machineCode))[2] = (value & 0xFF);
	((self_in_concretizeCmpCwR->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeCmpCwR->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeCmpCwR->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeCmpCwR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch.
	We use UCOMISD (see p 4-260 [2]) */
/*	CmpRR RHS LHS computes LHS - RHS, i.e. apparently reversed. You have to
	think subtract. */

static sqInt
concretizeCmpRdRd(AbstractInstruction * self_in_concretizeCmpRdRd)
{
	// CogIA32Compiler>>#concretizeCmpRdRd
    sqInt regLHS;
    sqInt regRHS;

	regRHS = concreteDPFPRegister(self_in_concretizeCmpRdRd, ((self_in_concretizeCmpRdRd->operands))[0]);
	regLHS = concreteDPFPRegister(self_in_concretizeCmpRdRd, ((self_in_concretizeCmpRdRd->operands))[1]);
	((self_in_concretizeCmpRdRd->machineCode))[0] = 102;
	((self_in_concretizeCmpRdRd->machineCode))[1] = 15;
	((self_in_concretizeCmpRdRd->machineCode))[2] = 46;
	((self_in_concretizeCmpRdRd->machineCode))[3] = (modRMRO(self_in_concretizeCmpRdRd, ModReg, regRHS, regLHS));
	return ((self_in_concretizeCmpRdRd->machineCodeSize) = 4);
}


/*	Will get inlined into concretizeAt: switch. */
/*	CmpRR RHS LHS computes LHS - RHS, i.e. apparently reversed. You have to
	think subtract. */

static sqInt
concretizeCmpRR(AbstractInstruction * self_in_concretizeCmpRR)
{
	// CogIA32Compiler>>#concretizeCmpRR
    sqInt regLHS;
    sqInt regRHS;

	regRHS = concreteRegister(self_in_concretizeCmpRR, ((self_in_concretizeCmpRR->operands))[0]);
	regLHS = concreteRegister(self_in_concretizeCmpRR, ((self_in_concretizeCmpRR->operands))[1]);
	((self_in_concretizeCmpRR->machineCode))[0] = 57;
	((self_in_concretizeCmpRR->machineCode))[1] = (modRMRO(self_in_concretizeCmpRR, ModReg, regLHS, regRHS));
	return ((self_in_concretizeCmpRR->machineCodeSize) = 2);
}


/*	Will get inlined into concretizeAt: switch. */
/*	Sizing/generating jumps.
	Jump targets can be to absolute addresses or other abstract instructions.
	Generating initial trampolines instructions may have no maxSize and be to
	absolute addresses.
	Otherwise instructions must have a machineCodeSize which must be kept to. */

static sqInt
concretizeConditionalJumpLong(AbstractInstruction * self_in_concretizeConditionalJumpLong, sqInt conditionCode)
{
	// CogIA32Compiler>>#concretizeConditionalJumpLong:
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    sqInt offset;

	/* begin computeJumpTargetOffsetPlus: */
	/* begin jumpTargetAddress */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeConditionalJumpLong->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if (isAnInstruction(self_in_concretizeConditionalJumpLong, jumpTarget1)) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((sqInt) jumpTarget)) - (((sqInt) (((self_in_concretizeConditionalJumpLong->address)) + 6)));
	((self_in_concretizeConditionalJumpLong->machineCode))[0] = 15;
	((self_in_concretizeConditionalJumpLong->machineCode))[1] = (128 + conditionCode);
	((self_in_concretizeConditionalJumpLong->machineCode))[2] = (offset & 0xFF);
	((self_in_concretizeConditionalJumpLong->machineCode))[3] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeConditionalJumpLong->machineCode))[4] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeConditionalJumpLong->machineCode))[5] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeConditionalJumpLong->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */
/*	Sizing/generating jumps.
	Jump targets can be to absolute addresses or other abstract instructions.
	Generating initial trampolines instructions may have no maxSize and be to
	absolute addresses.
	Otherwise instructions must have a machineCodeSize which must be kept to. */

static sqInt
concretizeConditionalJump(AbstractInstruction * self_in_concretizeConditionalJump, sqInt conditionCode)
{
	// CogIA32Compiler>>#concretizeConditionalJump:
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    AbstractInstruction *jumpTarget11;
    AbstractInstruction *jumpTarget2;
    sqInt offset;
    sqInt offset1;

	/* begin computeJumpTargetOffsetPlus: */
	/* begin jumpTargetAddress */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeConditionalJump->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if (isAnInstruction(self_in_concretizeConditionalJump, jumpTarget1)) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((sqInt) jumpTarget)) - (((sqInt) (((self_in_concretizeConditionalJump->address)) + 2)));
	if ((((self_in_concretizeConditionalJump->machineCodeSize)) == 0
		? isQuick(self_in_concretizeConditionalJump, offset)
		: ((self_in_concretizeConditionalJump->machineCodeSize)) == 2)) {
		((self_in_concretizeConditionalJump->machineCode))[0] = (112 + conditionCode);
		((self_in_concretizeConditionalJump->machineCode))[1] = (offset & 0xFF);
		return ((self_in_concretizeConditionalJump->machineCodeSize) = 2);
	}
	/* begin concretizeConditionalJumpLong: */
	/* begin computeJumpTargetOffsetPlus: */
	/* begin jumpTargetAddress */
	jumpTarget11 = ((AbstractInstruction *) (((self_in_concretizeConditionalJump->operands))[0]));
	assertSaneJumpTarget(jumpTarget11);
	if (isAnInstruction(self_in_concretizeConditionalJump, jumpTarget11)) {
		jumpTarget11 = ((AbstractInstruction *) ((jumpTarget11->address)));
	}
	assert(jumpTarget11 != 0);
	jumpTarget2 = jumpTarget11;
	offset1 = (((sqInt) jumpTarget2)) - (((sqInt) (((self_in_concretizeConditionalJump->address)) + 6)));
	((self_in_concretizeConditionalJump->machineCode))[0] = 15;
	((self_in_concretizeConditionalJump->machineCode))[1] = (128 + conditionCode);
	((self_in_concretizeConditionalJump->machineCode))[2] = (offset1 & 0xFF);
	((self_in_concretizeConditionalJump->machineCode))[3] = ((((usqInt) offset1) >> 8) & 0xFF);
	((self_in_concretizeConditionalJump->machineCode))[4] = ((((usqInt) offset1) >> 16) & 0xFF);
	((self_in_concretizeConditionalJump->machineCode))[5] = ((((usqInt) offset1) >> 24) & 0xFF);
	return ((self_in_concretizeConditionalJump->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeConvertRRd(AbstractInstruction * self_in_concretizeConvertRRd)
{
	// CogIA32Compiler>>#concretizeConvertRRd
    sqInt destReg;
    sqInt srcReg;

	srcReg = concreteRegister(self_in_concretizeConvertRRd, ((self_in_concretizeConvertRRd->operands))[0]);
	destReg = concreteDPFPRegister(self_in_concretizeConvertRRd, ((self_in_concretizeConvertRRd->operands))[1]);
	((self_in_concretizeConvertRRd->machineCode))[0] = 242;
	((self_in_concretizeConvertRRd->machineCode))[1] = 15;
	((self_in_concretizeConvertRRd->machineCode))[2] = 42;
	((self_in_concretizeConvertRRd->machineCode))[3] = (modRMRO(self_in_concretizeConvertRRd, ModReg, srcReg, destReg));
	return ((self_in_concretizeConvertRRd->machineCodeSize) = 4);
}

static sqInt
concretizeCPUID(AbstractInstruction * self_in_concretizeCPUID)
{
	// CogIA32Compiler>>#concretizeCPUID
	((self_in_concretizeCPUID->machineCode))[0] = 15;
	((self_in_concretizeCPUID->machineCode))[1] = 162;
	return ((self_in_concretizeCPUID->machineCodeSize) = 2);
}

static sqInt
concretizeFENCE(AbstractInstruction * self_in_concretizeFENCE, sqInt regOpcode)
{
	// CogIA32Compiler>>#concretizeFENCE:
	((self_in_concretizeFENCE->machineCode))[0] = 15;
	((self_in_concretizeFENCE->machineCode))[1] = 174;
	((self_in_concretizeFENCE->machineCode))[2] = (modRMRO(self_in_concretizeFENCE, ModReg, 0, regOpcode));
	return ((self_in_concretizeFENCE->machineCodeSize) = 3);
}

static sqInt
concretizeFill16(AbstractInstruction * self_in_concretizeFill16)
{
	// CogIA32Compiler>>#concretizeFill16
    unsigned short word;

	assert(((self_in_concretizeFill16->maxSize)) == 2);
	word = ((self_in_concretizeFill16->operands))[0];
	((self_in_concretizeFill16->machineCode))[0] = (word & 0xFF);
	((self_in_concretizeFill16->machineCode))[1] = (((usqInt) word) >> 8);
	return ((self_in_concretizeFill16->machineCodeSize) = 2);
}

static sqInt
concretizeFill32(AbstractInstruction * self_in_concretizeFill32)
{
	// CogIA32Compiler>>#concretizeFill32
    unsigned long word;

	word = ((self_in_concretizeFill32->operands))[0];
	((self_in_concretizeFill32->machineCode))[0] = (word & 0xFF);
	((self_in_concretizeFill32->machineCode))[1] = (((usqInt) word) >> 8);
	((self_in_concretizeFill32->machineCode))[2] = (((usqInt) word) >> 16);
	((self_in_concretizeFill32->machineCode))[3] = (((usqInt) word) >> 24);
	return ((self_in_concretizeFill32->machineCodeSize) = 4);
}

static sqInt
concretizeFillFromWord(AbstractInstruction * self_in_concretizeFillFromWord)
{
	// CogIA32Compiler>>#concretizeFillFromWord
    sqInt i;
    unsigned long word;

	assert(((self_in_concretizeFillFromWord->maxSize)) == 4);
	word = (((self_in_concretizeFillFromWord->operands))[0]) + (((self_in_concretizeFillFromWord->operands))[1]);
	for (i = 0; i <= 3; i += 1) {
((self_in_concretizeFillFromWord->machineCode))[i] = (word & 0xFF);
		word = ((usqInt) word) >> 8;
	}
	return ((self_in_concretizeFillFromWord->machineCodeSize) = (self_in_concretizeFillFromWord->maxSize));
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeIDIVR(AbstractInstruction * self_in_concretizeIDIVR)
{
	// CogIA32Compiler>>#concretizeIDIVR
    sqInt regDivisor;

	regDivisor = concreteRegister(self_in_concretizeIDIVR, ((self_in_concretizeIDIVR->operands))[0]);
	((self_in_concretizeIDIVR->machineCode))[0] = 247;
	((self_in_concretizeIDIVR->machineCode))[1] = (modRMRO(self_in_concretizeIDIVR, ModReg, regDivisor, 7));
	return ((self_in_concretizeIDIVR->machineCodeSize) = 2);
}


/*	Will get inlined into concretizeAt: switch. */
/*	Sizing/generating jumps.
	Jump targets can be to absolute addresses or other abstract instructions.
	Generating initial trampolines instructions may have no maxSize and be to
	absolute addresses.
	Otherwise instructions must have a machineCodeSize which must be kept to. */

static sqInt
concretizeJump(AbstractInstruction * self_in_concretizeJump)
{
	// CogIA32Compiler>>#concretizeJump
    AbstractInstruction *jumpTarget;
    sqInt offset;

	jumpTarget = ((AbstractInstruction *) (((self_in_concretizeJump->operands))[0]));
	assertSaneJumpTarget(jumpTarget);
	if (isAnInstruction(self_in_concretizeJump, jumpTarget)) {
		jumpTarget = ((AbstractInstruction *) ((jumpTarget->address)));
	}
	assert(jumpTarget != 0);
	offset = (((sqInt) jumpTarget)) - (((sqInt) (((self_in_concretizeJump->address)) + 2)));
	if ((((self_in_concretizeJump->machineCodeSize)) == 0
		? isQuick(self_in_concretizeJump, offset)
		: ((self_in_concretizeJump->machineCodeSize)) == 2)) {
		((self_in_concretizeJump->machineCode))[0] = 235;
		((self_in_concretizeJump->machineCode))[1] = (offset & 0xFF);
		return ((self_in_concretizeJump->machineCodeSize) = 2);
	}
	offset = (((sqInt) jumpTarget)) - (((sqInt) (((self_in_concretizeJump->address)) + 5)));
	((self_in_concretizeJump->machineCode))[0] = 233;
	((self_in_concretizeJump->machineCode))[1] = (offset & 0xFF);
	((self_in_concretizeJump->machineCode))[2] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeJump->machineCode))[3] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeJump->machineCode))[4] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeJump->machineCodeSize) = 5);
}


/*	Will get inlined into concretizeAt: switch. */
/*	Sizing/generating jumps.
	Jump targets can be to absolute addresses or other abstract instructions.
	Generating initial trampolines instructions may have no maxSize and be to
	absolute addresses.
	Otherwise instructions must have a machineCodeSize which must be kept to. */

static sqInt
concretizeJumpLong(AbstractInstruction * self_in_concretizeJumpLong)
{
	// CogIA32Compiler>>#concretizeJumpLong
    AbstractInstruction *jumpTarget;
    sqInt offset;

	jumpTarget = ((AbstractInstruction *) (((self_in_concretizeJumpLong->operands))[0]));
	if (isAnInstruction(self_in_concretizeJumpLong, jumpTarget)) {
		jumpTarget = ((AbstractInstruction *) ((jumpTarget->address)));
	}
	assert(jumpTarget != 0);
	offset = (((sqInt) jumpTarget)) - (((sqInt) (((self_in_concretizeJumpLong->address)) + 5)));
	((self_in_concretizeJumpLong->machineCode))[0] = 233;
	((self_in_concretizeJumpLong->machineCode))[1] = (offset & 0xFF);
	((self_in_concretizeJumpLong->machineCode))[2] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeJumpLong->machineCode))[3] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeJumpLong->machineCode))[4] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeJumpLong->machineCodeSize) = 5);
}

static sqInt
concretizeJumpR(AbstractInstruction * self_in_concretizeJumpR)
{
	// CogIA32Compiler>>#concretizeJumpR
    sqInt reg;

	reg = concreteRegister(self_in_concretizeJumpR, ((self_in_concretizeJumpR->operands))[0]);
	((self_in_concretizeJumpR->machineCode))[0] = 0xFF;
	((self_in_concretizeJumpR->machineCode))[1] = (modRMRO(self_in_concretizeJumpR, ModReg, reg, 4));
	return ((self_in_concretizeJumpR->machineCodeSize) = 2);
}

static sqInt
concretizeLabel(AbstractInstruction * self_in_concretizeLabel)
{
	// CogAbstractInstruction>>#concretizeLabel
    AbstractInstruction *dependentChain;

	dependentChain = (self_in_concretizeLabel->dependent);
	while (!(dependentChain == null)) {
		updateLabel(dependentChain, self_in_concretizeLabel);
		dependentChain = (dependentChain->dependent);
	}
	return ((self_in_concretizeLabel->machineCodeSize) = 0);
}

static sqInt
concretizeLOCK(AbstractInstruction * self_in_concretizeLOCK)
{
	// CogIA32Compiler>>#concretizeLOCK
	((self_in_concretizeLOCK->machineCode))[0] = 240;
	return ((self_in_concretizeLOCK->machineCodeSize) = 1);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeLoadEffectiveAddressMwrR(AbstractInstruction * self_in_concretizeLoadEffectiveAddressMwrR)
{
	// CogIA32Compiler>>#concretizeLoadEffectiveAddressMwrR
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	offset = ((self_in_concretizeLoadEffectiveAddressMwrR->operands))[0];
	srcReg = concreteRegister(self_in_concretizeLoadEffectiveAddressMwrR, ((self_in_concretizeLoadEffectiveAddressMwrR->operands))[1]);
	destReg = concreteRegister(self_in_concretizeLoadEffectiveAddressMwrR, ((self_in_concretizeLoadEffectiveAddressMwrR->operands))[2]);
	if (srcReg != ESP) {
if (isQuick(self_in_concretizeLoadEffectiveAddressMwrR, offset)) {
			((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[0] = 141;
			((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[1] = (modRMRO(self_in_concretizeLoadEffectiveAddressMwrR, ModRegRegDisp8, srcReg, destReg));
			((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[2] = (offset & 0xFF);
			return ((self_in_concretizeLoadEffectiveAddressMwrR->machineCodeSize) = 3);
		}
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[0] = 141;
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[1] = (modRMRO(self_in_concretizeLoadEffectiveAddressMwrR, ModRegRegDisp32, srcReg, destReg));
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[2] = (offset & 0xFF);
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[3] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[4] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[5] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeLoadEffectiveAddressMwrR->machineCodeSize) = 6);
	}
	if (isQuick(self_in_concretizeLoadEffectiveAddressMwrR, offset)) {
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[0] = 141;
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[1] = (modRMRO(self_in_concretizeLoadEffectiveAddressMwrR, ModRegRegDisp8, srcReg, destReg));
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[2] = (sib(self_in_concretizeLoadEffectiveAddressMwrR, SIB1, 4, srcReg));
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[3] = (offset & 0xFF);
		return ((self_in_concretizeLoadEffectiveAddressMwrR->machineCodeSize) = 4);
	}
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[0] = 141;
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[1] = (modRMRO(self_in_concretizeLoadEffectiveAddressMwrR, ModRegRegDisp32, srcReg, destReg));
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[2] = (sib(self_in_concretizeLoadEffectiveAddressMwrR, SIB1, 4, srcReg));
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[3] = (offset & 0xFF);
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[4] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[5] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[6] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeLoadEffectiveAddressMwrR->machineCodeSize) = 7);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeLogicalShiftLeftCqR(AbstractInstruction * self_in_concretizeLogicalShiftLeftCqR)
{
	// CogIA32Compiler>>#concretizeLogicalShiftLeftCqR
    sqInt distance;
    sqInt reg;

	distance = (((((self_in_concretizeLogicalShiftLeftCqR->operands))[0]) < 0x1F) ? (((self_in_concretizeLogicalShiftLeftCqR->operands))[0]) : 0x1F);
	reg = concreteRegister(self_in_concretizeLogicalShiftLeftCqR, ((self_in_concretizeLogicalShiftLeftCqR->operands))[1]);
	if (distance == 1) {
((self_in_concretizeLogicalShiftLeftCqR->machineCode))[0] = 209;
		((self_in_concretizeLogicalShiftLeftCqR->machineCode))[1] = (modRMRO(self_in_concretizeLogicalShiftLeftCqR, ModReg, reg, 4));
		return ((self_in_concretizeLogicalShiftLeftCqR->machineCodeSize) = 2);
	}
	((self_in_concretizeLogicalShiftLeftCqR->machineCode))[0] = 193;
	((self_in_concretizeLogicalShiftLeftCqR->machineCode))[1] = (modRMRO(self_in_concretizeLogicalShiftLeftCqR, ModReg, reg, 4));
	((self_in_concretizeLogicalShiftLeftCqR->machineCode))[2] = distance;
	return ((self_in_concretizeLogicalShiftLeftCqR->machineCodeSize) = 3);
}


/*	On the x86 the only instructions that shift by the value of a
	register require the shift count to be in %ecx. So we may
	have to use swap instructions to get the count into %ecx. */

static sqInt
concretizeLogicalShiftLeftRR(AbstractInstruction * self_in_concretizeLogicalShiftLeftRR)
{
	// CogIA32Compiler>>#concretizeLogicalShiftLeftRR
    sqInt destReg;
    sqInt regToShift;
    sqInt shiftCountReg;

	shiftCountReg = concreteRegister(self_in_concretizeLogicalShiftLeftRR, ((self_in_concretizeLogicalShiftLeftRR->operands))[0]);
	destReg = concreteRegister(self_in_concretizeLogicalShiftLeftRR, ((self_in_concretizeLogicalShiftLeftRR->operands))[1]);
	if (shiftCountReg == ECX) {
((self_in_concretizeLogicalShiftLeftRR->machineCode))[0] = 211;
		((self_in_concretizeLogicalShiftLeftRR->machineCode))[1] = (modRMRO(self_in_concretizeLogicalShiftLeftRR, ModReg, destReg, 4));
		return ((self_in_concretizeLogicalShiftLeftRR->machineCodeSize) = 2);
	}
	regToShift = (destReg == shiftCountReg
		? ECX
		: (destReg == ECX
				? shiftCountReg
				: destReg));
	if (shiftCountReg == EAX) {
((self_in_concretizeLogicalShiftLeftRR->machineCode))[0] = (144 + ECX);
		((self_in_concretizeLogicalShiftLeftRR->machineCode))[1] = 211;
		((self_in_concretizeLogicalShiftLeftRR->machineCode))[2] = (modRMRO(self_in_concretizeLogicalShiftLeftRR, ModReg, regToShift, 4));
		((self_in_concretizeLogicalShiftLeftRR->machineCode))[3] = (144 + ECX);
		return ((self_in_concretizeLogicalShiftLeftRR->machineCodeSize) = 4);
	}
	((self_in_concretizeLogicalShiftLeftRR->machineCode))[0] = 135;
	((self_in_concretizeLogicalShiftLeftRR->machineCode))[1] = (modRMRO(self_in_concretizeLogicalShiftLeftRR, ModReg, ECX, shiftCountReg));
	((self_in_concretizeLogicalShiftLeftRR->machineCode))[2] = 211;
	((self_in_concretizeLogicalShiftLeftRR->machineCode))[3] = (modRMRO(self_in_concretizeLogicalShiftLeftRR, ModReg, regToShift, 4));
	((self_in_concretizeLogicalShiftLeftRR->machineCode))[4] = 135;
	((self_in_concretizeLogicalShiftLeftRR->machineCode))[5] = (modRMRO(self_in_concretizeLogicalShiftLeftRR, ModReg, ECX, shiftCountReg));
	return ((self_in_concretizeLogicalShiftLeftRR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeLogicalShiftRightCqR(AbstractInstruction * self_in_concretizeLogicalShiftRightCqR)
{
	// CogIA32Compiler>>#concretizeLogicalShiftRightCqR
    sqInt distance;
    sqInt reg;

	distance = (((((self_in_concretizeLogicalShiftRightCqR->operands))[0]) < 0x1F) ? (((self_in_concretizeLogicalShiftRightCqR->operands))[0]) : 0x1F);
	reg = concreteRegister(self_in_concretizeLogicalShiftRightCqR, ((self_in_concretizeLogicalShiftRightCqR->operands))[1]);
	if (distance == 1) {
((self_in_concretizeLogicalShiftRightCqR->machineCode))[0] = 209;
		((self_in_concretizeLogicalShiftRightCqR->machineCode))[1] = (modRMRO(self_in_concretizeLogicalShiftRightCqR, ModReg, reg, 5));
		return ((self_in_concretizeLogicalShiftRightCqR->machineCodeSize) = 2);
	}
	((self_in_concretizeLogicalShiftRightCqR->machineCode))[0] = 193;
	((self_in_concretizeLogicalShiftRightCqR->machineCode))[1] = (modRMRO(self_in_concretizeLogicalShiftRightCqR, ModReg, reg, 5));
	((self_in_concretizeLogicalShiftRightCqR->machineCode))[2] = distance;
	return ((self_in_concretizeLogicalShiftRightCqR->machineCodeSize) = 3);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveAwR(AbstractInstruction * self_in_concretizeMoveAwR)
{
	// CogIA32Compiler>>#concretizeMoveAwR
    unsigned long addressOperand;
    sqInt reg;

	addressOperand = ((self_in_concretizeMoveAwR->operands))[0];
	if (isAnInstruction(self_in_concretizeMoveAwR, ((AbstractInstruction *) addressOperand))) {
		addressOperand = ((((AbstractInstruction *) addressOperand))->address);
	}
	reg = concreteRegister(self_in_concretizeMoveAwR, ((self_in_concretizeMoveAwR->operands))[1]);
	if (reg == EAX) {
((self_in_concretizeMoveAwR->machineCode))[0] = 161;
		((self_in_concretizeMoveAwR->machineCode))[1] = (addressOperand & 0xFF);
		((self_in_concretizeMoveAwR->machineCode))[2] = ((((usqInt) addressOperand) >> 8) & 0xFF);
		((self_in_concretizeMoveAwR->machineCode))[3] = ((((usqInt) addressOperand) >> 16) & 0xFF);
		((self_in_concretizeMoveAwR->machineCode))[4] = ((((usqInt) addressOperand) >> 24) & 0xFF);
		return ((self_in_concretizeMoveAwR->machineCodeSize) = 5);
	}
	((self_in_concretizeMoveAwR->machineCode))[0] = 139;
	((self_in_concretizeMoveAwR->machineCode))[1] = (modRMRO(self_in_concretizeMoveAwR, ModRegInd, 5, reg));
	((self_in_concretizeMoveAwR->machineCode))[2] = (addressOperand & 0xFF);
	((self_in_concretizeMoveAwR->machineCode))[3] = ((((usqInt) addressOperand) >> 8) & 0xFF);
	((self_in_concretizeMoveAwR->machineCode))[4] = ((((usqInt) addressOperand) >> 16) & 0xFF);
	((self_in_concretizeMoveAwR->machineCode))[5] = ((((usqInt) addressOperand) >> 24) & 0xFF);
	return ((self_in_concretizeMoveAwR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch.
	Note that for quick constants, xor reg,reg, movq r8 may be shorter. But
	we don't consider it worthwhile and so just provide concretizeMoveCwR. */

static sqInt
concretizeMoveCqR(AbstractInstruction * self_in_concretizeMoveCqR)
{
	// CogIA32Compiler>>#concretizeMoveCqR
    sqInt reg;
    sqInt value;

	if ((((self_in_concretizeMoveCqR->operands))[0]) != 0) {
		/* begin concretizeMoveCwR */
		value = ((self_in_concretizeMoveCqR->operands))[0];
		((self_in_concretizeMoveCqR->machineCode))[0] = (184 + (concreteRegister(self_in_concretizeMoveCqR, ((self_in_concretizeMoveCqR->operands))[1])));
		((self_in_concretizeMoveCqR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeMoveCqR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeMoveCqR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeMoveCqR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeMoveCqR->machineCodeSize) = 5);
	}
	reg = concreteRegister(self_in_concretizeMoveCqR, ((self_in_concretizeMoveCqR->operands))[1]);
	((self_in_concretizeMoveCqR->machineCode))[0] = 49;
	((self_in_concretizeMoveCqR->machineCode))[1] = (modRMRO(self_in_concretizeMoveCqR, ModReg, reg, reg));
	return ((self_in_concretizeMoveCqR->machineCodeSize) = 2);
}


/*	Will get inlined into concretizeAt: switch.
	Note that for quick constants, xor reg,reg, movq r8 may be shorter.
	We don't consider it worthwhile for other than 0. */

static sqInt
concretizeMoveCwR(AbstractInstruction * self_in_concretizeMoveCwR)
{
	// CogIA32Compiler>>#concretizeMoveCwR
    sqInt value;

	value = ((self_in_concretizeMoveCwR->operands))[0];
	((self_in_concretizeMoveCwR->machineCode))[0] = (184 + (concreteRegister(self_in_concretizeMoveCwR, ((self_in_concretizeMoveCwR->operands))[1])));
	((self_in_concretizeMoveCwR->machineCode))[1] = (value & 0xFF);
	((self_in_concretizeMoveCwR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeMoveCwR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeMoveCwR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeMoveCwR->machineCodeSize) = 5);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveM16rR(AbstractInstruction * self_in_concretizeMoveM16rR)
{
	// CogIA32Compiler>>#concretizeMoveM16rR
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	offset = ((self_in_concretizeMoveM16rR->operands))[0];
	srcReg = concreteRegister(self_in_concretizeMoveM16rR, ((self_in_concretizeMoveM16rR->operands))[1]);
	destReg = concreteRegister(self_in_concretizeMoveM16rR, ((self_in_concretizeMoveM16rR->operands))[2]);
	if (srcReg != ESP) {
if (isQuick(self_in_concretizeMoveM16rR, offset)) {
			((self_in_concretizeMoveM16rR->machineCode))[0] = 15;
			((self_in_concretizeMoveM16rR->machineCode))[1] = 183;
			((self_in_concretizeMoveM16rR->machineCode))[2] = (modRMRO(self_in_concretizeMoveM16rR, ModRegRegDisp8, srcReg, destReg));
			((self_in_concretizeMoveM16rR->machineCode))[3] = (offset & 0xFF);
			return ((self_in_concretizeMoveM16rR->machineCodeSize) = 4);
		}
		((self_in_concretizeMoveM16rR->machineCode))[0] = 15;
		((self_in_concretizeMoveM16rR->machineCode))[1] = 183;
		((self_in_concretizeMoveM16rR->machineCode))[2] = (modRMRO(self_in_concretizeMoveM16rR, ModRegRegDisp32, srcReg, destReg));
		((self_in_concretizeMoveM16rR->machineCode))[3] = (offset & 0xFF);
		((self_in_concretizeMoveM16rR->machineCode))[4] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeMoveM16rR->machineCode))[5] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeMoveM16rR->machineCode))[6] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeMoveM16rR->machineCodeSize) = 7);
	}
	if (isQuick(self_in_concretizeMoveM16rR, offset)) {
		((self_in_concretizeMoveM16rR->machineCode))[0] = 15;
		((self_in_concretizeMoveM16rR->machineCode))[1] = 183;
		((self_in_concretizeMoveM16rR->machineCode))[2] = (modRMRO(self_in_concretizeMoveM16rR, ModRegRegDisp8, srcReg, destReg));
		((self_in_concretizeMoveM16rR->machineCode))[3] = (sib(self_in_concretizeMoveM16rR, SIB1, 4, srcReg));
		((self_in_concretizeMoveM16rR->machineCode))[4] = (offset & 0xFF);
		return ((self_in_concretizeMoveM16rR->machineCodeSize) = 5);
	}
	((self_in_concretizeMoveM16rR->machineCode))[0] = 15;
	((self_in_concretizeMoveM16rR->machineCode))[1] = 183;
	((self_in_concretizeMoveM16rR->machineCode))[2] = (modRMRO(self_in_concretizeMoveM16rR, ModRegRegDisp32, srcReg, destReg));
	((self_in_concretizeMoveM16rR->machineCode))[3] = (sib(self_in_concretizeMoveM16rR, SIB1, 4, srcReg));
	((self_in_concretizeMoveM16rR->machineCode))[4] = (offset & 0xFF);
	((self_in_concretizeMoveM16rR->machineCode))[5] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeMoveM16rR->machineCode))[6] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeMoveM16rR->machineCode))[7] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeMoveM16rR->machineCodeSize) = 8);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveM64rRd(AbstractInstruction * self_in_concretizeMoveM64rRd)
{
	// CogIA32Compiler>>#concretizeMoveM64rRd
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	offset = ((self_in_concretizeMoveM64rRd->operands))[0];
	srcReg = concreteRegister(self_in_concretizeMoveM64rRd, ((self_in_concretizeMoveM64rRd->operands))[1]);
	destReg = concreteDPFPRegister(self_in_concretizeMoveM64rRd, ((self_in_concretizeMoveM64rRd->operands))[2]);
	if (srcReg != ESP) {
if (isQuick(self_in_concretizeMoveM64rRd, offset)) {
			((self_in_concretizeMoveM64rRd->machineCode))[0] = 242;
			((self_in_concretizeMoveM64rRd->machineCode))[1] = 15;
			((self_in_concretizeMoveM64rRd->machineCode))[2] = 16;
			((self_in_concretizeMoveM64rRd->machineCode))[3] = (modRMRO(self_in_concretizeMoveM64rRd, ModRegRegDisp8, srcReg, destReg));
			((self_in_concretizeMoveM64rRd->machineCode))[4] = (offset & 0xFF);
			return ((self_in_concretizeMoveM64rRd->machineCodeSize) = 5);
		}
		((self_in_concretizeMoveM64rRd->machineCode))[0] = 242;
		((self_in_concretizeMoveM64rRd->machineCode))[1] = 15;
		((self_in_concretizeMoveM64rRd->machineCode))[2] = 16;
		((self_in_concretizeMoveM64rRd->machineCode))[3] = (modRMRO(self_in_concretizeMoveM64rRd, ModRegRegDisp32, srcReg, destReg));
		((self_in_concretizeMoveM64rRd->machineCode))[4] = (offset & 0xFF);
		((self_in_concretizeMoveM64rRd->machineCode))[5] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeMoveM64rRd->machineCode))[6] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeMoveM64rRd->machineCode))[7] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeMoveM64rRd->machineCodeSize) = 8);
	}
	if (isQuick(self_in_concretizeMoveM64rRd, offset)) {
		((self_in_concretizeMoveM64rRd->machineCode))[0] = 242;
		((self_in_concretizeMoveM64rRd->machineCode))[1] = 15;
		((self_in_concretizeMoveM64rRd->machineCode))[2] = 16;
		((self_in_concretizeMoveM64rRd->machineCode))[3] = (modRMRO(self_in_concretizeMoveM64rRd, ModRegRegDisp8, srcReg, destReg));
		((self_in_concretizeMoveM64rRd->machineCode))[4] = (sib(self_in_concretizeMoveM64rRd, SIB1, 4, srcReg));
		((self_in_concretizeMoveM64rRd->machineCode))[5] = (offset & 0xFF);
		return ((self_in_concretizeMoveM64rRd->machineCodeSize) = 6);
	}
	((self_in_concretizeMoveM64rRd->machineCode))[0] = 242;
	((self_in_concretizeMoveM64rRd->machineCode))[1] = 15;
	((self_in_concretizeMoveM64rRd->machineCode))[2] = 16;
	((self_in_concretizeMoveM64rRd->machineCode))[3] = (modRMRO(self_in_concretizeMoveM64rRd, ModRegRegDisp32, srcReg, destReg));
	((self_in_concretizeMoveM64rRd->machineCode))[4] = (sib(self_in_concretizeMoveM64rRd, SIB1, 4, srcReg));
	((self_in_concretizeMoveM64rRd->machineCode))[5] = (offset & 0xFF);
	((self_in_concretizeMoveM64rRd->machineCode))[6] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeMoveM64rRd->machineCode))[7] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeMoveM64rRd->machineCode))[8] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeMoveM64rRd->machineCodeSize) = 9);
}


/*	N.B. The Cogit compiler makes no assumption about the upper bits being set
	to zero.
	It will clear the register before hand if necessary. */
/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveMbrR(AbstractInstruction * self_in_concretizeMoveMbrR)
{
	// CogIA32Compiler>>#concretizeMoveMbrR
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	offset = ((self_in_concretizeMoveMbrR->operands))[0];
	srcReg = concreteRegister(self_in_concretizeMoveMbrR, ((self_in_concretizeMoveMbrR->operands))[1]);
	destReg = concreteRegister(self_in_concretizeMoveMbrR, ((self_in_concretizeMoveMbrR->operands))[2]);
	if (srcReg != ESP) {
if (isQuick(self_in_concretizeMoveMbrR, offset)) {
			((self_in_concretizeMoveMbrR->machineCode))[0] = 138;
			((self_in_concretizeMoveMbrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMbrR, ModRegRegDisp8, srcReg, destReg));
			((self_in_concretizeMoveMbrR->machineCode))[2] = (offset & 0xFF);
			return ((self_in_concretizeMoveMbrR->machineCodeSize) = 3);
		}
		((self_in_concretizeMoveMbrR->machineCode))[0] = 138;
		((self_in_concretizeMoveMbrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMbrR, ModRegRegDisp32, srcReg, destReg));
		((self_in_concretizeMoveMbrR->machineCode))[2] = (offset & 0xFF);
		((self_in_concretizeMoveMbrR->machineCode))[3] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeMoveMbrR->machineCode))[4] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeMoveMbrR->machineCode))[5] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeMoveMbrR->machineCodeSize) = 6);
	}
	if (isQuick(self_in_concretizeMoveMbrR, offset)) {
		((self_in_concretizeMoveMbrR->machineCode))[0] = 138;
		((self_in_concretizeMoveMbrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMbrR, ModRegRegDisp8, srcReg, destReg));
		((self_in_concretizeMoveMbrR->machineCode))[2] = (sib(self_in_concretizeMoveMbrR, SIB1, 4, srcReg));
		((self_in_concretizeMoveMbrR->machineCode))[3] = (offset & 0xFF);
		return ((self_in_concretizeMoveMbrR->machineCodeSize) = 4);
	}
	((self_in_concretizeMoveMbrR->machineCode))[0] = 138;
	((self_in_concretizeMoveMbrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMbrR, ModRegRegDisp32, srcReg, destReg));
	((self_in_concretizeMoveMbrR->machineCode))[2] = (sib(self_in_concretizeMoveMbrR, SIB1, 4, srcReg));
	((self_in_concretizeMoveMbrR->machineCode))[3] = (offset & 0xFF);
	((self_in_concretizeMoveMbrR->machineCode))[4] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeMoveMbrR->machineCode))[5] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeMoveMbrR->machineCode))[6] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeMoveMbrR->machineCodeSize) = 7);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveMwrR(AbstractInstruction * self_in_concretizeMoveMwrR)
{
	// CogIA32Compiler>>#concretizeMoveMwrR
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	offset = ((self_in_concretizeMoveMwrR->operands))[0];
	srcReg = concreteRegister(self_in_concretizeMoveMwrR, ((self_in_concretizeMoveMwrR->operands))[1]);
	destReg = concreteRegister(self_in_concretizeMoveMwrR, ((self_in_concretizeMoveMwrR->operands))[2]);
	if (srcReg != ESP) {
if ((offset == 0)
		 && (srcReg != EBP)) {
			((self_in_concretizeMoveMwrR->machineCode))[0] = 139;
			((self_in_concretizeMoveMwrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMwrR, ModRegInd, srcReg, destReg));
			return ((self_in_concretizeMoveMwrR->machineCodeSize) = 2);
		}
		if (isQuick(self_in_concretizeMoveMwrR, offset)) {
			((self_in_concretizeMoveMwrR->machineCode))[0] = 139;
			((self_in_concretizeMoveMwrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMwrR, ModRegRegDisp8, srcReg, destReg));
			((self_in_concretizeMoveMwrR->machineCode))[2] = (offset & 0xFF);
			return ((self_in_concretizeMoveMwrR->machineCodeSize) = 3);
		}
		((self_in_concretizeMoveMwrR->machineCode))[0] = 139;
		((self_in_concretizeMoveMwrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMwrR, ModRegRegDisp32, srcReg, destReg));
		((self_in_concretizeMoveMwrR->machineCode))[2] = (offset & 0xFF);
		((self_in_concretizeMoveMwrR->machineCode))[3] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeMoveMwrR->machineCode))[4] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeMoveMwrR->machineCode))[5] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeMoveMwrR->machineCodeSize) = 6);
	}
	if (offset == 0) {
((self_in_concretizeMoveMwrR->machineCode))[0] = 139;
		((self_in_concretizeMoveMwrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMwrR, ModRegInd, srcReg, destReg));
		((self_in_concretizeMoveMwrR->machineCode))[2] = (sib(self_in_concretizeMoveMwrR, SIB1, 4, srcReg));
		return ((self_in_concretizeMoveMwrR->machineCodeSize) = 3);
	}
	if (isQuick(self_in_concretizeMoveMwrR, offset)) {
		((self_in_concretizeMoveMwrR->machineCode))[0] = 139;
		((self_in_concretizeMoveMwrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMwrR, ModRegRegDisp8, srcReg, destReg));
		((self_in_concretizeMoveMwrR->machineCode))[2] = (sib(self_in_concretizeMoveMwrR, SIB1, 4, srcReg));
		((self_in_concretizeMoveMwrR->machineCode))[3] = (offset & 0xFF);
		return ((self_in_concretizeMoveMwrR->machineCodeSize) = 4);
	}
	((self_in_concretizeMoveMwrR->machineCode))[0] = 139;
	((self_in_concretizeMoveMwrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveMwrR, ModRegRegDisp32, srcReg, destReg));
	((self_in_concretizeMoveMwrR->machineCode))[2] = (sib(self_in_concretizeMoveMwrR, SIB1, 4, srcReg));
	((self_in_concretizeMoveMwrR->machineCode))[3] = (offset & 0xFF);
	((self_in_concretizeMoveMwrR->machineCode))[4] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeMoveMwrR->machineCode))[5] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeMoveMwrR->machineCode))[6] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeMoveMwrR->machineCodeSize) = 7);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveRAw(AbstractInstruction * self_in_concretizeMoveRAw)
{
	// CogIA32Compiler>>#concretizeMoveRAw
    unsigned long addressOperand;
    sqInt reg;

	reg = concreteRegister(self_in_concretizeMoveRAw, ((self_in_concretizeMoveRAw->operands))[0]);
	addressOperand = ((self_in_concretizeMoveRAw->operands))[1];
	if (isAnInstruction(self_in_concretizeMoveRAw, ((AbstractInstruction *) addressOperand))) {
		addressOperand = ((((AbstractInstruction *) addressOperand))->address);
	}
	if (reg == EAX) {
((self_in_concretizeMoveRAw->machineCode))[0] = 163;
		((self_in_concretizeMoveRAw->machineCode))[1] = (addressOperand & 0xFF);
		((self_in_concretizeMoveRAw->machineCode))[2] = ((((usqInt) addressOperand) >> 8) & 0xFF);
		((self_in_concretizeMoveRAw->machineCode))[3] = ((((usqInt) addressOperand) >> 16) & 0xFF);
		((self_in_concretizeMoveRAw->machineCode))[4] = ((((usqInt) addressOperand) >> 24) & 0xFF);
		return ((self_in_concretizeMoveRAw->machineCodeSize) = 5);
	}
	((self_in_concretizeMoveRAw->machineCode))[0] = 137;
	((self_in_concretizeMoveRAw->machineCode))[1] = (modRMRO(self_in_concretizeMoveRAw, ModRegInd, 5, reg));
	((self_in_concretizeMoveRAw->machineCode))[2] = (addressOperand & 0xFF);
	((self_in_concretizeMoveRAw->machineCode))[3] = ((((usqInt) addressOperand) >> 8) & 0xFF);
	((self_in_concretizeMoveRAw->machineCode))[4] = ((((usqInt) addressOperand) >> 16) & 0xFF);
	((self_in_concretizeMoveRAw->machineCode))[5] = ((((usqInt) addressOperand) >> 24) & 0xFF);
	return ((self_in_concretizeMoveRAw->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveRdM64r(AbstractInstruction * self_in_concretizeMoveRdM64r)
{
	// CogIA32Compiler>>#concretizeMoveRdM64r
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	srcReg = concreteDPFPRegister(self_in_concretizeMoveRdM64r, ((self_in_concretizeMoveRdM64r->operands))[0]);
	offset = ((self_in_concretizeMoveRdM64r->operands))[1];
	destReg = concreteRegister(self_in_concretizeMoveRdM64r, ((self_in_concretizeMoveRdM64r->operands))[2]);
	if (destReg != ESP) {
if (isQuick(self_in_concretizeMoveRdM64r, offset)) {
			((self_in_concretizeMoveRdM64r->machineCode))[0] = 242;
			((self_in_concretizeMoveRdM64r->machineCode))[1] = 15;
			((self_in_concretizeMoveRdM64r->machineCode))[2] = 17;
			((self_in_concretizeMoveRdM64r->machineCode))[3] = (modRMRO(self_in_concretizeMoveRdM64r, ModRegRegDisp8, destReg, srcReg));
			((self_in_concretizeMoveRdM64r->machineCode))[4] = (offset & 0xFF);
			return ((self_in_concretizeMoveRdM64r->machineCodeSize) = 5);
		}
		((self_in_concretizeMoveRdM64r->machineCode))[0] = 242;
		((self_in_concretizeMoveRdM64r->machineCode))[1] = 15;
		((self_in_concretizeMoveRdM64r->machineCode))[2] = 17;
		((self_in_concretizeMoveRdM64r->machineCode))[3] = (modRMRO(self_in_concretizeMoveRdM64r, ModRegRegDisp32, destReg, srcReg));
		((self_in_concretizeMoveRdM64r->machineCode))[4] = (offset & 0xFF);
		((self_in_concretizeMoveRdM64r->machineCode))[5] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeMoveRdM64r->machineCode))[6] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeMoveRdM64r->machineCode))[7] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeMoveRdM64r->machineCodeSize) = 8);
	}
	if (isQuick(self_in_concretizeMoveRdM64r, offset)) {
		((self_in_concretizeMoveRdM64r->machineCode))[0] = 242;
		((self_in_concretizeMoveRdM64r->machineCode))[1] = 15;
		((self_in_concretizeMoveRdM64r->machineCode))[2] = 17;
		((self_in_concretizeMoveRdM64r->machineCode))[3] = (modRMRO(self_in_concretizeMoveRdM64r, ModRegRegDisp8, destReg, srcReg));
		((self_in_concretizeMoveRdM64r->machineCode))[4] = (sib(self_in_concretizeMoveRdM64r, SIB1, 4, destReg));
		((self_in_concretizeMoveRdM64r->machineCode))[5] = (offset & 0xFF);
		return ((self_in_concretizeMoveRdM64r->machineCodeSize) = 6);
	}
	((self_in_concretizeMoveRdM64r->machineCode))[0] = 242;
	((self_in_concretizeMoveRdM64r->machineCode))[1] = 15;
	((self_in_concretizeMoveRdM64r->machineCode))[2] = 17;
	((self_in_concretizeMoveRdM64r->machineCode))[3] = (modRMRO(self_in_concretizeMoveRdM64r, ModRegRegDisp32, destReg, srcReg));
	((self_in_concretizeMoveRdM64r->machineCode))[4] = (sib(self_in_concretizeMoveRdM64r, SIB1, 4, destReg));
	((self_in_concretizeMoveRdM64r->machineCode))[5] = (offset & 0xFF);
	((self_in_concretizeMoveRdM64r->machineCode))[6] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeMoveRdM64r->machineCode))[7] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeMoveRdM64r->machineCode))[8] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeMoveRdM64r->machineCodeSize) = 9);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveRMbr(AbstractInstruction * self_in_concretizeMoveRMbr)
{
	// CogIA32Compiler>>#concretizeMoveRMbr
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	offset = ((self_in_concretizeMoveRMbr->operands))[1];
	srcReg = concreteRegister(self_in_concretizeMoveRMbr, ((self_in_concretizeMoveRMbr->operands))[0]);
	destReg = concreteRegister(self_in_concretizeMoveRMbr, ((self_in_concretizeMoveRMbr->operands))[2]);
	if (srcReg >= 4) {
error("invalid register");
	}
	if (destReg != ESP) {
if (isQuick(self_in_concretizeMoveRMbr, offset)) {
			((self_in_concretizeMoveRMbr->machineCode))[0] = 136;
			((self_in_concretizeMoveRMbr->machineCode))[1] = (modRMRO(self_in_concretizeMoveRMbr, ModRegRegDisp8, destReg, srcReg));
			((self_in_concretizeMoveRMbr->machineCode))[2] = (offset & 0xFF);
			return ((self_in_concretizeMoveRMbr->machineCodeSize) = 3);
		}
		((self_in_concretizeMoveRMbr->machineCode))[0] = 136;
		((self_in_concretizeMoveRMbr->machineCode))[1] = (modRMRO(self_in_concretizeMoveRMbr, ModRegRegDisp32, destReg, srcReg));
		((self_in_concretizeMoveRMbr->machineCode))[2] = (offset & 0xFF);
		((self_in_concretizeMoveRMbr->machineCode))[3] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeMoveRMbr->machineCode))[4] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeMoveRMbr->machineCode))[5] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeMoveRMbr->machineCodeSize) = 6);
	}
	((self_in_concretizeMoveRMbr->machineCode))[0] = 136;
	((self_in_concretizeMoveRMbr->machineCode))[1] = (modRMRO(self_in_concretizeMoveRMbr, ModRegRegDisp32, destReg, srcReg));
	((self_in_concretizeMoveRMbr->machineCode))[2] = (sib(self_in_concretizeMoveRMbr, SIB1, 4, destReg));
	((self_in_concretizeMoveRMbr->machineCode))[3] = (offset & 0xFF);
	((self_in_concretizeMoveRMbr->machineCode))[4] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeMoveRMbr->machineCode))[5] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeMoveRMbr->machineCode))[6] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeMoveRMbr->machineCodeSize) = 7);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveRMwr(AbstractInstruction * self_in_concretizeMoveRMwr)
{
	// CogIA32Compiler>>#concretizeMoveRMwr
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	srcReg = concreteRegister(self_in_concretizeMoveRMwr, ((self_in_concretizeMoveRMwr->operands))[0]);
	offset = ((self_in_concretizeMoveRMwr->operands))[1];
	destReg = concreteRegister(self_in_concretizeMoveRMwr, ((self_in_concretizeMoveRMwr->operands))[2]);
	if (destReg != ESP) {
if ((offset == 0)
		 && (destReg != EBP)) {
			((self_in_concretizeMoveRMwr->machineCode))[0] = 137;
			((self_in_concretizeMoveRMwr->machineCode))[1] = (modRMRO(self_in_concretizeMoveRMwr, ModRegInd, destReg, srcReg));
			return ((self_in_concretizeMoveRMwr->machineCodeSize) = 2);
		}
		if (isQuick(self_in_concretizeMoveRMwr, offset)) {
			((self_in_concretizeMoveRMwr->machineCode))[0] = 137;
			((self_in_concretizeMoveRMwr->machineCode))[1] = (modRMRO(self_in_concretizeMoveRMwr, ModRegRegDisp8, destReg, srcReg));
			((self_in_concretizeMoveRMwr->machineCode))[2] = (offset & 0xFF);
			return ((self_in_concretizeMoveRMwr->machineCodeSize) = 3);
		}
		((self_in_concretizeMoveRMwr->machineCode))[0] = 137;
		((self_in_concretizeMoveRMwr->machineCode))[1] = (modRMRO(self_in_concretizeMoveRMwr, ModRegRegDisp32, destReg, srcReg));
		((self_in_concretizeMoveRMwr->machineCode))[2] = (offset & 0xFF);
		((self_in_concretizeMoveRMwr->machineCode))[3] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeMoveRMwr->machineCode))[4] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeMoveRMwr->machineCode))[5] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeMoveRMwr->machineCodeSize) = 6);
	}
	if (offset == 0) {
((self_in_concretizeMoveRMwr->machineCode))[0] = 137;
		((self_in_concretizeMoveRMwr->machineCode))[1] = (modRMRO(self_in_concretizeMoveRMwr, ModRegInd, destReg, srcReg));
		((self_in_concretizeMoveRMwr->machineCode))[2] = (sib(self_in_concretizeMoveRMwr, SIB1, 4, destReg));
		return ((self_in_concretizeMoveRMwr->machineCodeSize) = 3);
	}
	if (isQuick(self_in_concretizeMoveRMwr, offset)) {
		((self_in_concretizeMoveRMwr->machineCode))[0] = 137;
		((self_in_concretizeMoveRMwr->machineCode))[1] = (modRMRO(self_in_concretizeMoveRMwr, ModRegRegDisp8, destReg, srcReg));
		((self_in_concretizeMoveRMwr->machineCode))[2] = (sib(self_in_concretizeMoveRMwr, SIB1, 4, destReg));
		((self_in_concretizeMoveRMwr->machineCode))[3] = (offset & 0xFF);
		return ((self_in_concretizeMoveRMwr->machineCodeSize) = 4);
	}
	((self_in_concretizeMoveRMwr->machineCode))[0] = 137;
	((self_in_concretizeMoveRMwr->machineCode))[1] = (modRMRO(self_in_concretizeMoveRMwr, ModRegRegDisp32, destReg, srcReg));
	((self_in_concretizeMoveRMwr->machineCode))[2] = (sib(self_in_concretizeMoveRMwr, SIB1, 4, destReg));
	((self_in_concretizeMoveRMwr->machineCode))[3] = (offset & 0xFF);
	((self_in_concretizeMoveRMwr->machineCode))[4] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeMoveRMwr->machineCode))[5] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeMoveRMwr->machineCode))[6] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeMoveRMwr->machineCodeSize) = 7);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveRR(AbstractInstruction * self_in_concretizeMoveRR)
{
	// CogIA32Compiler>>#concretizeMoveRR
    sqInt destReg;
    sqInt srcReg;

	srcReg = concreteRegister(self_in_concretizeMoveRR, ((self_in_concretizeMoveRR->operands))[0]);
	destReg = concreteRegister(self_in_concretizeMoveRR, ((self_in_concretizeMoveRR->operands))[1]);
	((self_in_concretizeMoveRR->machineCode))[0] = 137;
	((self_in_concretizeMoveRR->machineCode))[1] = (modRMRO(self_in_concretizeMoveRR, ModReg, destReg, srcReg));
	return ((self_in_concretizeMoveRR->machineCodeSize) = 2);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveRXbrR(AbstractInstruction * self_in_concretizeMoveRXbrR)
{
	// CogIA32Compiler>>#concretizeMoveRXbrR
    sqInt base;
    sqInt index;
    sqInt src;

	src = concreteRegister(self_in_concretizeMoveRXbrR, ((self_in_concretizeMoveRXbrR->operands))[0]);
	index = concreteRegister(self_in_concretizeMoveRXbrR, ((self_in_concretizeMoveRXbrR->operands))[1]);
	base = concreteRegister(self_in_concretizeMoveRXbrR, ((self_in_concretizeMoveRXbrR->operands))[2]);
	if (base != EBP) {
((self_in_concretizeMoveRXbrR->machineCode))[0] = 136;
		((self_in_concretizeMoveRXbrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveRXbrR, ModRegInd, 4, src));
		((self_in_concretizeMoveRXbrR->machineCode))[2] = (sib(self_in_concretizeMoveRXbrR, SIB1, index, base));
		return ((self_in_concretizeMoveRXbrR->machineCodeSize) = 3);
	}
	((self_in_concretizeMoveRXbrR->machineCode))[0] = 136;
	((self_in_concretizeMoveRXbrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveRXbrR, ModRegRegDisp8, 4, src));
	((self_in_concretizeMoveRXbrR->machineCode))[2] = (sib(self_in_concretizeMoveRXbrR, SIB1, index, base));
	((self_in_concretizeMoveRXbrR->machineCode))[3] = 0;
	return ((self_in_concretizeMoveRXbrR->machineCodeSize) = 4);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveRXwrR(AbstractInstruction * self_in_concretizeMoveRXwrR)
{
	// CogIA32Compiler>>#concretizeMoveRXwrR
    sqInt base;
    sqInt index;
    sqInt src;

	src = concreteRegister(self_in_concretizeMoveRXwrR, ((self_in_concretizeMoveRXwrR->operands))[0]);
	index = concreteRegister(self_in_concretizeMoveRXwrR, ((self_in_concretizeMoveRXwrR->operands))[1]);
	base = concreteRegister(self_in_concretizeMoveRXwrR, ((self_in_concretizeMoveRXwrR->operands))[2]);
	if (base != EBP) {
((self_in_concretizeMoveRXwrR->machineCode))[0] = 137;
		((self_in_concretizeMoveRXwrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveRXwrR, ModRegInd, 4, src));
		((self_in_concretizeMoveRXwrR->machineCode))[2] = (sib(self_in_concretizeMoveRXwrR, SIB4, index, base));
		return ((self_in_concretizeMoveRXwrR->machineCodeSize) = 3);
	}
	((self_in_concretizeMoveRXwrR->machineCode))[0] = 137;
	((self_in_concretizeMoveRXwrR->machineCode))[1] = (modRMRO(self_in_concretizeMoveRXwrR, ModRegRegDisp8, 4, src));
	((self_in_concretizeMoveRXwrR->machineCode))[2] = (sib(self_in_concretizeMoveRXwrR, SIB4, index, base));
	((self_in_concretizeMoveRXwrR->machineCode))[3] = 0;
	return ((self_in_concretizeMoveRXwrR->machineCodeSize) = 4);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveXbrRR(AbstractInstruction * self_in_concretizeMoveXbrRR)
{
	// CogIA32Compiler>>#concretizeMoveXbrRR
    sqInt base;
    sqInt dest;
    sqInt index;

	index = concreteRegister(self_in_concretizeMoveXbrRR, ((self_in_concretizeMoveXbrRR->operands))[0]);
	base = concreteRegister(self_in_concretizeMoveXbrRR, ((self_in_concretizeMoveXbrRR->operands))[1]);
	dest = concreteRegister(self_in_concretizeMoveXbrRR, ((self_in_concretizeMoveXbrRR->operands))[2]);
	if (base != EBP) {
((self_in_concretizeMoveXbrRR->machineCode))[0] = 15;
		((self_in_concretizeMoveXbrRR->machineCode))[1] = 182;
		((self_in_concretizeMoveXbrRR->machineCode))[2] = (modRMRO(self_in_concretizeMoveXbrRR, ModRegInd, 4, dest));
		((self_in_concretizeMoveXbrRR->machineCode))[3] = (sib(self_in_concretizeMoveXbrRR, SIB1, index, base));
		return ((self_in_concretizeMoveXbrRR->machineCodeSize) = 4);
	}
	((self_in_concretizeMoveXbrRR->machineCode))[0] = 15;
	((self_in_concretizeMoveXbrRR->machineCode))[1] = 182;
	((self_in_concretizeMoveXbrRR->machineCode))[2] = (modRMRO(self_in_concretizeMoveXbrRR, ModRegRegDisp8, 4, dest));
	((self_in_concretizeMoveXbrRR->machineCode))[3] = (sib(self_in_concretizeMoveXbrRR, SIB1, index, base));
	((self_in_concretizeMoveXbrRR->machineCode))[4] = 0;
	return ((self_in_concretizeMoveXbrRR->machineCodeSize) = 5);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMoveXwrRR(AbstractInstruction * self_in_concretizeMoveXwrRR)
{
	// CogIA32Compiler>>#concretizeMoveXwrRR
    sqInt base;
    sqInt dest;
    sqInt index;

	index = concreteRegister(self_in_concretizeMoveXwrRR, ((self_in_concretizeMoveXwrRR->operands))[0]);
	base = concreteRegister(self_in_concretizeMoveXwrRR, ((self_in_concretizeMoveXwrRR->operands))[1]);
	dest = concreteRegister(self_in_concretizeMoveXwrRR, ((self_in_concretizeMoveXwrRR->operands))[2]);
	if (base != EBP) {
((self_in_concretizeMoveXwrRR->machineCode))[0] = 139;
		((self_in_concretizeMoveXwrRR->machineCode))[1] = (modRMRO(self_in_concretizeMoveXwrRR, ModRegInd, 4, dest));
		((self_in_concretizeMoveXwrRR->machineCode))[2] = (sib(self_in_concretizeMoveXwrRR, SIB4, index, base));
		return ((self_in_concretizeMoveXwrRR->machineCodeSize) = 3);
	}
	((self_in_concretizeMoveXwrRR->machineCode))[0] = 139;
	((self_in_concretizeMoveXwrRR->machineCode))[1] = (modRMRO(self_in_concretizeMoveXwrRR, ModRegRegDisp8, 4, dest));
	((self_in_concretizeMoveXwrRR->machineCode))[2] = (sib(self_in_concretizeMoveXwrRR, SIB4, index, base));
	((self_in_concretizeMoveXwrRR->machineCode))[3] = 0;
	return ((self_in_concretizeMoveXwrRR->machineCodeSize) = 4);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeMulRR(AbstractInstruction * self_in_concretizeMulRR)
{
	// CogIA32Compiler>>#concretizeMulRR
    sqInt reg1;
    sqInt reg2;

	reg1 = concreteRegister(self_in_concretizeMulRR, ((self_in_concretizeMulRR->operands))[0]);
	reg2 = concreteRegister(self_in_concretizeMulRR, ((self_in_concretizeMulRR->operands))[1]);
	((self_in_concretizeMulRR->machineCode))[0] = 15;
	((self_in_concretizeMulRR->machineCode))[1] = 175;
	((self_in_concretizeMulRR->machineCode))[2] = (modRMRO(self_in_concretizeMulRR, ModReg, reg1, reg2));
	return ((self_in_concretizeMulRR->machineCodeSize) = 3);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeNegateR(AbstractInstruction * self_in_concretizeNegateR)
{
	// CogIA32Compiler>>#concretizeNegateR
    sqInt reg;

	reg = concreteRegister(self_in_concretizeNegateR, ((self_in_concretizeNegateR->operands))[0]);
	((self_in_concretizeNegateR->machineCode))[0] = 247;
	((self_in_concretizeNegateR->machineCode))[1] = (modRMRO(self_in_concretizeNegateR, ModReg, reg, 3));
	return ((self_in_concretizeNegateR->machineCodeSize) = 2);
}

static sqInt
concretizeNop(AbstractInstruction * self_in_concretizeNop)
{
	// CogIA32Compiler>>#concretizeNop
	((self_in_concretizeNop->machineCode))[0] = 144;
	return ((self_in_concretizeNop->machineCodeSize) = 1);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeOrCqR(AbstractInstruction * self_in_concretizeOrCqR)
{
	// CogIA32Compiler>>#concretizeOrCqR
    sqInt mask;
    sqInt reg;

	mask = ((self_in_concretizeOrCqR->operands))[0];
	reg = concreteRegister(self_in_concretizeOrCqR, ((self_in_concretizeOrCqR->operands))[1]);
	if (isQuick(self_in_concretizeOrCqR, mask)) {
		((self_in_concretizeOrCqR->machineCode))[0] = 131;
		((self_in_concretizeOrCqR->machineCode))[1] = (modRMRO(self_in_concretizeOrCqR, ModReg, reg, 1));
		((self_in_concretizeOrCqR->machineCode))[2] = (mask & 0xFF);
		return ((self_in_concretizeOrCqR->machineCodeSize) = 3);
	}
	if (reg == EAX) {
((self_in_concretizeOrCqR->machineCode))[0] = 13;
		((self_in_concretizeOrCqR->machineCode))[1] = (mask & 0xFF);
		((self_in_concretizeOrCqR->machineCode))[2] = ((((usqInt) mask) >> 8) & 0xFF);
		((self_in_concretizeOrCqR->machineCode))[3] = ((((usqInt) mask) >> 16) & 0xFF);
		((self_in_concretizeOrCqR->machineCode))[4] = ((((usqInt) mask) >> 24) & 0xFF);
		return ((self_in_concretizeOrCqR->machineCodeSize) = 5);
	}
	((self_in_concretizeOrCqR->machineCode))[0] = 129;
	((self_in_concretizeOrCqR->machineCode))[1] = (modRMRO(self_in_concretizeOrCqR, ModReg, reg, 1));
	((self_in_concretizeOrCqR->machineCode))[2] = (mask & 0xFF);
	((self_in_concretizeOrCqR->machineCode))[3] = ((((usqInt) mask) >> 8) & 0xFF);
	((self_in_concretizeOrCqR->machineCode))[4] = ((((usqInt) mask) >> 16) & 0xFF);
	((self_in_concretizeOrCqR->machineCode))[5] = ((((usqInt) mask) >> 24) & 0xFF);
	return ((self_in_concretizeOrCqR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeOrCwR(AbstractInstruction * self_in_concretizeOrCwR)
{
	// CogIA32Compiler>>#concretizeOrCwR
    sqInt reg;
    sqInt value;

	value = ((self_in_concretizeOrCwR->operands))[0];
	reg = concreteRegister(self_in_concretizeOrCwR, ((self_in_concretizeOrCwR->operands))[1]);
	if (reg == EAX) {
((self_in_concretizeOrCwR->machineCode))[0] = 13;
		((self_in_concretizeOrCwR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeOrCwR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeOrCwR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeOrCwR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeOrCwR->machineCodeSize) = 5);
	}
	((self_in_concretizeOrCwR->machineCode))[0] = 131;
	((self_in_concretizeOrCwR->machineCode))[1] = (modRMRO(self_in_concretizeOrCwR, ModReg, reg, 1));
	((self_in_concretizeOrCwR->machineCode))[2] = (value & 0xFF);
	((self_in_concretizeOrCwR->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeOrCwR->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeOrCwR->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeOrCwR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeOrRR(AbstractInstruction * self_in_concretizeOrRR)
{
	// CogIA32Compiler>>#concretizeOrRR
    sqInt regLHS;
    sqInt regRHS;

	regLHS = concreteRegister(self_in_concretizeOrRR, ((self_in_concretizeOrRR->operands))[0]);
	regRHS = concreteRegister(self_in_concretizeOrRR, ((self_in_concretizeOrRR->operands))[1]);
	((self_in_concretizeOrRR->machineCode))[0] = 11;
	((self_in_concretizeOrRR->machineCode))[1] = (modRMRO(self_in_concretizeOrRR, ModReg, regLHS, regRHS));
	return ((self_in_concretizeOrRR->machineCodeSize) = 2);
}

static sqInt
concretizePopR(AbstractInstruction * self_in_concretizePopR)
{
	// CogIA32Compiler>>#concretizePopR
	((self_in_concretizePopR->machineCode))[0] = (88 + (concreteRegister(self_in_concretizePopR, ((self_in_concretizePopR->operands))[0])));
	return ((self_in_concretizePopR->machineCodeSize) = 1);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizePrefetchAw(AbstractInstruction * self_in_concretizePrefetchAw)
{
	// CogIA32Compiler>>#concretizePrefetchAw
    sqInt addressOperand;

	(self_in_concretizePrefetchAw->machineCodeSize) = (self_in_concretizePrefetchAw->maxSize);
	if (((self_in_concretizePrefetchAw->maxSize)) > 0) {
		addressOperand = ((self_in_concretizePrefetchAw->operands))[0];
		((self_in_concretizePrefetchAw->machineCode))[0] = 15;
		((self_in_concretizePrefetchAw->machineCode))[1] = 24;
		((self_in_concretizePrefetchAw->machineCode))[2] = (modRMRO(self_in_concretizePrefetchAw, 0, 5, 1));
		((self_in_concretizePrefetchAw->machineCode))[3] = (addressOperand & 0xFF);
		((self_in_concretizePrefetchAw->machineCode))[4] = ((((usqInt) addressOperand) >> 8) & 0xFF);
		((self_in_concretizePrefetchAw->machineCode))[5] = ((((usqInt) addressOperand) >> 16) & 0xFF);
		((self_in_concretizePrefetchAw->machineCode))[6] = ((((usqInt) addressOperand) >> 24) & 0xFF);
	}
	return (self_in_concretizePrefetchAw->maxSize);
}

static sqInt
concretizePushCw(AbstractInstruction * self_in_concretizePushCw)
{
	// CogIA32Compiler>>#concretizePushCw
    sqInt value;

	value = ((self_in_concretizePushCw->operands))[0];
	((self_in_concretizePushCw->machineCode))[0] = 104;
	((self_in_concretizePushCw->machineCode))[1] = (value & 0xFF);
	((self_in_concretizePushCw->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizePushCw->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizePushCw->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizePushCw->machineCodeSize) = 5);
}

static sqInt
concretizePushR(AbstractInstruction * self_in_concretizePushR)
{
	// CogIA32Compiler>>#concretizePushR
	((self_in_concretizePushR->machineCode))[0] = (80 + (concreteRegister(self_in_concretizePushR, ((self_in_concretizePushR->operands))[0])));
	return ((self_in_concretizePushR->machineCodeSize) = 1);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeRetN(AbstractInstruction * self_in_concretizeRetN)
{
	// CogIA32Compiler>>#concretizeRetN
    sqInt offset;

	offset = ((self_in_concretizeRetN->operands))[0];
	if (offset == 0) {
((self_in_concretizeRetN->machineCode))[0] = 195;
		return ((self_in_concretizeRetN->machineCodeSize) = 1);
	}
	((self_in_concretizeRetN->machineCode))[0] = 194;
	((self_in_concretizeRetN->machineCode))[1] = (offset & 0xFF);
	((self_in_concretizeRetN->machineCode))[2] = (((usqInt) offset) >> 8);
	return ((self_in_concretizeRetN->machineCodeSize) = 3);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeSEE2OpRdRd(AbstractInstruction * self_in_concretizeSEE2OpRdRd, sqInt opCode)
{
	// CogIA32Compiler>>#concretizeSEE2OpRdRd:
    sqInt regLHS;
    sqInt regRHS;

	regRHS = concreteDPFPRegister(self_in_concretizeSEE2OpRdRd, ((self_in_concretizeSEE2OpRdRd->operands))[0]);
	regLHS = concreteDPFPRegister(self_in_concretizeSEE2OpRdRd, ((self_in_concretizeSEE2OpRdRd->operands))[1]);
	((self_in_concretizeSEE2OpRdRd->machineCode))[0] = 242;
	((self_in_concretizeSEE2OpRdRd->machineCode))[1] = 15;
	((self_in_concretizeSEE2OpRdRd->machineCode))[2] = opCode;
	((self_in_concretizeSEE2OpRdRd->machineCode))[3] = (modRMRO(self_in_concretizeSEE2OpRdRd, ModReg, regRHS, regLHS));
	return ((self_in_concretizeSEE2OpRdRd->machineCodeSize) = 4);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeSqrtRd(AbstractInstruction * self_in_concretizeSqrtRd)
{
	// CogIA32Compiler>>#concretizeSqrtRd
    sqInt reg;

	reg = concreteDPFPRegister(self_in_concretizeSqrtRd, ((self_in_concretizeSqrtRd->operands))[0]);
	((self_in_concretizeSqrtRd->machineCode))[0] = 242;
	((self_in_concretizeSqrtRd->machineCode))[1] = 15;
	((self_in_concretizeSqrtRd->machineCode))[2] = 81;
	((self_in_concretizeSqrtRd->machineCode))[3] = (modRMRO(self_in_concretizeSqrtRd, ModReg, reg, reg));
	return ((self_in_concretizeSqrtRd->machineCodeSize) = 4);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeSubCqR(AbstractInstruction * self_in_concretizeSubCqR)
{
	// CogIA32Compiler>>#concretizeSubCqR
    sqInt reg;
    sqInt value;

	value = ((self_in_concretizeSubCqR->operands))[0];
	reg = concreteRegister(self_in_concretizeSubCqR, ((self_in_concretizeSubCqR->operands))[1]);
	if (isQuick(self_in_concretizeSubCqR, value)) {
		((self_in_concretizeSubCqR->machineCode))[0] = 131;
		((self_in_concretizeSubCqR->machineCode))[1] = (modRMRO(self_in_concretizeSubCqR, ModReg, reg, 5));
		((self_in_concretizeSubCqR->machineCode))[2] = (value & 0xFF);
		return ((self_in_concretizeSubCqR->machineCodeSize) = 3);
	}
	if (reg == EAX) {
((self_in_concretizeSubCqR->machineCode))[0] = 45;
		((self_in_concretizeSubCqR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeSubCqR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeSubCqR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeSubCqR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeSubCqR->machineCodeSize) = 5);
	}
	((self_in_concretizeSubCqR->machineCode))[0] = 129;
	((self_in_concretizeSubCqR->machineCode))[1] = (modRMRO(self_in_concretizeSubCqR, ModReg, reg, 5));
	((self_in_concretizeSubCqR->machineCode))[2] = (value & 0xFF);
	((self_in_concretizeSubCqR->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeSubCqR->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeSubCqR->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeSubCqR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeSubCwR(AbstractInstruction * self_in_concretizeSubCwR)
{
	// CogIA32Compiler>>#concretizeSubCwR
    sqInt reg;
    sqInt value;

	value = ((self_in_concretizeSubCwR->operands))[0];
	reg = concreteRegister(self_in_concretizeSubCwR, ((self_in_concretizeSubCwR->operands))[1]);
	if (reg == EAX) {
((self_in_concretizeSubCwR->machineCode))[0] = 45;
		((self_in_concretizeSubCwR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeSubCwR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeSubCwR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeSubCwR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeSubCwR->machineCodeSize) = 5);
	}
	((self_in_concretizeSubCwR->machineCode))[0] = 129;
	((self_in_concretizeSubCwR->machineCode))[1] = (modRMRO(self_in_concretizeSubCwR, ModReg, reg, 5));
	((self_in_concretizeSubCwR->machineCode))[2] = (value & 0xFF);
	((self_in_concretizeSubCwR->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeSubCwR->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeSubCwR->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeSubCwR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeSubRR(AbstractInstruction * self_in_concretizeSubRR)
{
	// CogIA32Compiler>>#concretizeSubRR
    sqInt regLHS;
    sqInt regRHS;

	regLHS = concreteRegister(self_in_concretizeSubRR, ((self_in_concretizeSubRR->operands))[0]);
	regRHS = concreteRegister(self_in_concretizeSubRR, ((self_in_concretizeSubRR->operands))[1]);
	((self_in_concretizeSubRR->machineCode))[0] = 43;
	((self_in_concretizeSubRR->machineCode))[1] = (modRMRO(self_in_concretizeSubRR, ModReg, regLHS, regRHS));
	return ((self_in_concretizeSubRR->machineCodeSize) = 2);
}

static sqInt
concretizeXCHGAwR(AbstractInstruction * self_in_concretizeXCHGAwR)
{
	// CogIA32Compiler>>#concretizeXCHGAwR
    sqInt addressOperand;
    sqInt reg;

	addressOperand = ((self_in_concretizeXCHGAwR->operands))[0];
	reg = concreteRegister(self_in_concretizeXCHGAwR, ((self_in_concretizeXCHGAwR->operands))[1]);
	((self_in_concretizeXCHGAwR->machineCode))[0] = 135;
	((self_in_concretizeXCHGAwR->machineCode))[1] = (modRMRO(self_in_concretizeXCHGAwR, ModRegInd, 5, reg));
	((self_in_concretizeXCHGAwR->machineCode))[2] = (addressOperand & 0xFF);
	((self_in_concretizeXCHGAwR->machineCode))[3] = ((((usqInt) addressOperand) >> 8) & 0xFF);
	((self_in_concretizeXCHGAwR->machineCode))[4] = ((((usqInt) addressOperand) >> 16) & 0xFF);
	((self_in_concretizeXCHGAwR->machineCode))[5] = ((((usqInt) addressOperand) >> 24) & 0xFF);
	return ((self_in_concretizeXCHGAwR->machineCodeSize) = 6);
}

static sqInt
concretizeXCHGMwrR(AbstractInstruction * self_in_concretizeXCHGMwrR)
{
	// CogIA32Compiler>>#concretizeXCHGMwrR
    sqInt destReg;
    sqInt offset;
    sqInt srcReg;

	offset = ((self_in_concretizeXCHGMwrR->operands))[0];
	srcReg = concreteRegister(self_in_concretizeXCHGMwrR, ((self_in_concretizeXCHGMwrR->operands))[1]);
	destReg = concreteRegister(self_in_concretizeXCHGMwrR, ((self_in_concretizeXCHGMwrR->operands))[2]);
	if (srcReg != ESP) {
if (isQuick(self_in_concretizeXCHGMwrR, offset)) {
			((self_in_concretizeXCHGMwrR->machineCode))[0] = 135;
			((self_in_concretizeXCHGMwrR->machineCode))[1] = (modRMRO(self_in_concretizeXCHGMwrR, ModRegRegDisp8, srcReg, destReg));
			((self_in_concretizeXCHGMwrR->machineCode))[2] = (offset & 0xFF);
			return ((self_in_concretizeXCHGMwrR->machineCodeSize) = 3);
		}
		((self_in_concretizeXCHGMwrR->machineCode))[0] = 135;
		((self_in_concretizeXCHGMwrR->machineCode))[1] = (modRMRO(self_in_concretizeXCHGMwrR, ModRegRegDisp32, srcReg, destReg));
		((self_in_concretizeXCHGMwrR->machineCode))[2] = (offset & 0xFF);
		((self_in_concretizeXCHGMwrR->machineCode))[3] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_concretizeXCHGMwrR->machineCode))[4] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_concretizeXCHGMwrR->machineCode))[5] = ((((usqInt) offset) >> 24) & 0xFF);
		return ((self_in_concretizeXCHGMwrR->machineCodeSize) = 6);
	}
	if (isQuick(self_in_concretizeXCHGMwrR, offset)) {
		((self_in_concretizeXCHGMwrR->machineCode))[0] = 135;
		((self_in_concretizeXCHGMwrR->machineCode))[1] = (modRMRO(self_in_concretizeXCHGMwrR, ModRegRegDisp8, srcReg, destReg));
		((self_in_concretizeXCHGMwrR->machineCode))[2] = (sib(self_in_concretizeXCHGMwrR, SIB1, 4, srcReg));
		((self_in_concretizeXCHGMwrR->machineCode))[3] = (offset & 0xFF);
		return ((self_in_concretizeXCHGMwrR->machineCodeSize) = 4);
	}
	((self_in_concretizeXCHGMwrR->machineCode))[0] = 135;
	((self_in_concretizeXCHGMwrR->machineCode))[1] = (modRMRO(self_in_concretizeXCHGMwrR, ModRegRegDisp32, srcReg, destReg));
	((self_in_concretizeXCHGMwrR->machineCode))[2] = (sib(self_in_concretizeXCHGMwrR, SIB1, 4, srcReg));
	((self_in_concretizeXCHGMwrR->machineCode))[3] = (offset & 0xFF);
	((self_in_concretizeXCHGMwrR->machineCode))[4] = ((((usqInt) offset) >> 8) & 0xFF);
	((self_in_concretizeXCHGMwrR->machineCode))[5] = ((((usqInt) offset) >> 16) & 0xFF);
	((self_in_concretizeXCHGMwrR->machineCode))[6] = ((((usqInt) offset) >> 24) & 0xFF);
	return ((self_in_concretizeXCHGMwrR->machineCodeSize) = 7);
}

static sqInt
concretizeXCHGRR(AbstractInstruction * self_in_concretizeXCHGRR)
{
	// CogIA32Compiler>>#concretizeXCHGRR
    sqInt reg1;
    sqInt reg2;

	reg1 = concreteRegister(self_in_concretizeXCHGRR, ((self_in_concretizeXCHGRR->operands))[0]);
	reg2 = concreteRegister(self_in_concretizeXCHGRR, ((self_in_concretizeXCHGRR->operands))[1]);
	if (reg2 == EAX) {
reg2 = reg1;
		reg1 = EAX;
	}
	if (reg1 == EAX) {
((self_in_concretizeXCHGRR->machineCode))[0] = (144 + reg2);
		return ((self_in_concretizeXCHGRR->machineCodeSize) = 1);
	}
	((self_in_concretizeXCHGRR->machineCode))[0] = 135;
	((self_in_concretizeXCHGRR->machineCode))[1] = (modRMRO(self_in_concretizeXCHGRR, ModReg, reg1, reg2));
	return ((self_in_concretizeXCHGRR->machineCodeSize) = 2);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeXorCwR(AbstractInstruction * self_in_concretizeXorCwR)
{
	// CogIA32Compiler>>#concretizeXorCwR
    sqInt reg;
    sqInt value;

	value = ((self_in_concretizeXorCwR->operands))[0];
	reg = concreteRegister(self_in_concretizeXorCwR, ((self_in_concretizeXorCwR->operands))[1]);
	if (reg == EAX) {
((self_in_concretizeXorCwR->machineCode))[0] = 53;
		((self_in_concretizeXorCwR->machineCode))[1] = (value & 0xFF);
		((self_in_concretizeXorCwR->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_concretizeXorCwR->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_concretizeXorCwR->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
		return ((self_in_concretizeXorCwR->machineCodeSize) = 5);
	}
	((self_in_concretizeXorCwR->machineCode))[0] = 129;
	((self_in_concretizeXorCwR->machineCode))[1] = (modRMRO(self_in_concretizeXorCwR, ModReg, reg, 6));
	((self_in_concretizeXorCwR->machineCode))[2] = (value & 0xFF);
	((self_in_concretizeXorCwR->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
	((self_in_concretizeXorCwR->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
	((self_in_concretizeXorCwR->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
	return ((self_in_concretizeXorCwR->machineCodeSize) = 6);
}


/*	Will get inlined into concretizeAt: switch. */

static sqInt
concretizeXorRR(AbstractInstruction * self_in_concretizeXorRR)
{
	// CogIA32Compiler>>#concretizeXorRR
    sqInt regLHS;
    sqInt regRHS;

	regLHS = concreteRegister(self_in_concretizeXorRR, ((self_in_concretizeXorRR->operands))[0]);
	regRHS = concreteRegister(self_in_concretizeXorRR, ((self_in_concretizeXorRR->operands))[1]);
	((self_in_concretizeXorRR->machineCode))[0] = 51;
	((self_in_concretizeXorRR->machineCode))[1] = (modRMRO(self_in_concretizeXorRR, ModReg, regLHS, regRHS));
	return ((self_in_concretizeXorRR->machineCodeSize) = 2);
}


/*	Note this version filters-out compact class indices via the >= nilObj
	clause 
 */

static sqInt
couldBeObject(sqInt oop)
{
	// CogObjectRepresentationForSqueakV3>>#couldBeObject:
	return (isNonIntegerObject(oop))
	 && (oopisGreaterThanOrEqualTo(oop, nilObject()));
}


/*	Answer the address of the MoveAw:R or MoveR:Aw: instruction preceeding
	nextInstructionAddress 
 */

static sqInt
counterTargetFromFollowingAddress(AbstractInstruction * self_in_counterTargetFromFollowingAddress, sqInt nextInstructionAddress)
{
	// CogIA32Compiler>>#counterTargetFromFollowingAddress:
	return literalBeforeFollowingAddress(self_in_counterTargetFromFollowingAddress, nextInstructionAddress);
}

static sqInt
cPICHasFreedTargets(CogMethod *cPIC)
{
	// Cogit>>#cPICHasFreedTargets:
    sqInt entryPoint;
    sqInt i;
    sqInt pc;
    CogMethod *targetMethod;

	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {

		/* Find target from jump.  Ignore jumps to the interpret and MNU calls within this PIC */

entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd, pc);
		if ((entryPoint < (((sqInt)cPIC)))
		 || (entryPoint > ((((sqInt)cPIC)) + ((cPIC->blockSize))))) {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			assert((((targetMethod->cmType)) == CMMethod)
			 || (((targetMethod->cmType)) == CMFree));
			if (((targetMethod->cmType)) == CMFree) {
				return 1;
			}
		}
		pc += cPICCaseSize;
	}
	return 0;
}

static sqInt
cPICMissTrampolineFor(sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#cPICMissTrampolineFor:
	return picMissTrampolines[((numArgs < (1 + 1)) ? numArgs : (1 + 1))];
}

static sqInt
cPICHasTarget(CogMethod *cPIC, CogMethod *targetMethod)
{
	// Cogit>>#cPIC:HasTarget:
    sqInt i;
    sqInt pc;
    sqInt target;

	target = (((usqInt)targetMethod)) + cmNoCheckEntryOffset;
	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {
		if (target == (jumpLongTargetBeforeFollowingAddress(backEnd, pc))) {
			return 1;
		}
		pc += cPICCaseSize;
	}
	return 0;
}


/*	Answer the abstract register for the C result register.
	Only partially implemented. Works on x86 since TempReg = EAX = C result
	reg.  */

static sqInt
cResultRegister(AbstractInstruction * self_in_cResultRegister)
{
	// CogIA32Compiler>>#cResultRegister
	return abstractRegisterForConcreteRegister(self_in_cResultRegister, EAX);
}


/*	Answer if the object representation allocates closures inline. By
	default answer false. Better code can be generated when creating
	closures inline if copied values are /not/ flushed to the stack. */

static sqInt
createsClosuresInline(void)
{
	// CogObjectRepresentation>>#createsClosuresInline
	return 0;
}


/*	Division is a little weird on some processors. Defer to the backEnd
	to allow it to generate any special code it may need to. */

static AbstractInstruction *
gDivRRQuoRem(sqInt rDivisor, sqInt rDividend, sqInt rQuotient, sqInt rRemainder)
{
	// Cogit>>#DivR:R:Quo:Rem:
	genDivRRQuoRem(backEnd, rDivisor, rDividend, rQuotient, rRemainder);
	return abstractInstructionAt(opcodeIndex - 1);
}


/*	Attempt to generate concrete machine code for the instruction at address.
	This is the inner dispatch of concretizeAt: actualAddress which exists
	only to get around the branch size limits in the SqueakV3 (blue book
	derived) bytecode set. */

static void
dispatchConcretize(AbstractInstruction * self_in_dispatchConcretize)
{
	// CogIA32Compiler>>#dispatchConcretize
    sqInt addressOperand;
    sqInt addressOperand1;
    unsigned long addressOperand2;
    unsigned long addressOperand3;
    sqInt addressOperand4;
    sqInt base;
    sqInt base1;
    sqInt base2;
    sqInt base3;
    AbstractInstruction *dependentChain;
    sqInt dest;
    sqInt dest1;
    sqInt destReg;
    sqInt destReg1;
    sqInt destReg10;
    sqInt destReg11;
    sqInt destReg12;
    sqInt destReg13;
    sqInt destReg2;
    sqInt destReg3;
    sqInt destReg4;
    sqInt destReg5;
    sqInt destReg6;
    sqInt destReg7;
    sqInt destReg8;
    sqInt destReg9;
    sqInt distance;
    sqInt distance1;
    sqInt i;
    sqInt i1;
    sqInt index;
    sqInt index1;
    sqInt index2;
    sqInt index3;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    AbstractInstruction *jumpTarget10;
    AbstractInstruction *jumpTarget11;
    AbstractInstruction *jumpTarget110;
    AbstractInstruction *jumpTarget111;
    AbstractInstruction *jumpTarget1110;
    AbstractInstruction *jumpTarget1111;
    AbstractInstruction *jumpTarget1112;
    AbstractInstruction *jumpTarget1113;
    AbstractInstruction *jumpTarget1114;
    AbstractInstruction *jumpTarget1115;
    AbstractInstruction *jumpTarget1116;
    AbstractInstruction *jumpTarget112;
    AbstractInstruction *jumpTarget113;
    AbstractInstruction *jumpTarget114;
    AbstractInstruction *jumpTarget115;
    AbstractInstruction *jumpTarget116;
    AbstractInstruction *jumpTarget117;
    AbstractInstruction *jumpTarget118;
    AbstractInstruction *jumpTarget119;
    AbstractInstruction *jumpTarget12;
    AbstractInstruction *jumpTarget120;
    AbstractInstruction *jumpTarget121;
    AbstractInstruction *jumpTarget122;
    AbstractInstruction *jumpTarget123;
    AbstractInstruction *jumpTarget124;
    AbstractInstruction *jumpTarget125;
    AbstractInstruction *jumpTarget126;
    AbstractInstruction *jumpTarget127;
    AbstractInstruction *jumpTarget13;
    AbstractInstruction *jumpTarget14;
    AbstractInstruction *jumpTarget15;
    AbstractInstruction *jumpTarget16;
    AbstractInstruction *jumpTarget17;
    AbstractInstruction *jumpTarget18;
    AbstractInstruction *jumpTarget19;
    AbstractInstruction *jumpTarget2;
    AbstractInstruction *jumpTarget20;
    AbstractInstruction *jumpTarget21;
    AbstractInstruction *jumpTarget210;
    AbstractInstruction *jumpTarget211;
    AbstractInstruction *jumpTarget212;
    AbstractInstruction *jumpTarget213;
    AbstractInstruction *jumpTarget214;
    AbstractInstruction *jumpTarget215;
    AbstractInstruction *jumpTarget216;
    AbstractInstruction *jumpTarget22;
    AbstractInstruction *jumpTarget23;
    AbstractInstruction *jumpTarget24;
    AbstractInstruction *jumpTarget25;
    AbstractInstruction *jumpTarget26;
    AbstractInstruction *jumpTarget27;
    AbstractInstruction *jumpTarget28;
    AbstractInstruction *jumpTarget29;
    AbstractInstruction *jumpTarget3;
    AbstractInstruction *jumpTarget30;
    AbstractInstruction *jumpTarget31;
    AbstractInstruction *jumpTarget32;
    AbstractInstruction *jumpTarget33;
    AbstractInstruction *jumpTarget34;
    AbstractInstruction *jumpTarget35;
    AbstractInstruction *jumpTarget36;
    AbstractInstruction *jumpTarget37;
    AbstractInstruction *jumpTarget4;
    AbstractInstruction *jumpTarget5;
    AbstractInstruction *jumpTarget6;
    AbstractInstruction *jumpTarget7;
    AbstractInstruction *jumpTarget8;
    AbstractInstruction *jumpTarget9;
    sqInt mask;
    sqInt mask1;
    sqInt offset;
    sqInt offset1;
    sqInt offset10;
    sqInt offset11;
    sqInt offset110;
    sqInt offset111;
    sqInt offset112;
    sqInt offset113;
    sqInt offset114;
    sqInt offset115;
    sqInt offset116;
    sqInt offset117;
    sqInt offset118;
    sqInt offset119;
    sqInt offset12;
    sqInt offset120;
    sqInt offset121;
    sqInt offset122;
    sqInt offset123;
    sqInt offset13;
    sqInt offset14;
    sqInt offset15;
    sqInt offset16;
    sqInt offset17;
    sqInt offset18;
    sqInt offset19;
    sqInt offset2;
    sqInt offset20;
    sqInt offset21;
    sqInt offset22;
    sqInt offset23;
    sqInt offset24;
    sqInt offset25;
    sqInt offset26;
    sqInt offset27;
    sqInt offset28;
    sqInt offset29;
    sqInt offset3;
    sqInt offset30;
    sqInt offset31;
    sqInt offset32;
    sqInt offset33;
    sqInt offset4;
    sqInt offset5;
    sqInt offset6;
    sqInt offset7;
    sqInt offset8;
    sqInt offset9;
    sqInt reg;
    sqInt reg1;
    sqInt reg10;
    sqInt reg11;
    sqInt reg12;
    sqInt reg13;
    sqInt reg14;
    sqInt reg15;
    sqInt reg16;
    sqInt reg17;
    sqInt reg18;
    sqInt reg19;
    sqInt reg2;
    sqInt reg20;
    sqInt reg21;
    sqInt reg22;
    sqInt reg23;
    sqInt reg24;
    sqInt reg25;
    sqInt reg3;
    sqInt reg4;
    sqInt reg5;
    sqInt reg6;
    sqInt reg7;
    sqInt reg8;
    sqInt reg9;
    sqInt regDivisor;
    sqInt regLHS;
    sqInt regLHS1;
    sqInt regLHS10;
    sqInt regLHS2;
    sqInt regLHS3;
    sqInt regLHS4;
    sqInt regLHS5;
    sqInt regLHS6;
    sqInt regLHS7;
    sqInt regLHS8;
    sqInt regLHS9;
    sqInt regRHS;
    sqInt regRHS1;
    sqInt regRHS10;
    sqInt regRHS2;
    sqInt regRHS3;
    sqInt regRHS4;
    sqInt regRHS5;
    sqInt regRHS6;
    sqInt regRHS7;
    sqInt regRHS8;
    sqInt regRHS9;
    sqInt regToShift;
    sqInt regToShift1;
    sqInt shiftCount;
    sqInt shiftCountReg;
    sqInt shiftCountReg1;
    sqInt src;
    sqInt src1;
    sqInt srcReg;
    sqInt srcReg1;
    sqInt srcReg10;
    sqInt srcReg11;
    sqInt srcReg2;
    sqInt srcReg3;
    sqInt srcReg4;
    sqInt srcReg5;
    sqInt srcReg6;
    sqInt srcReg7;
    sqInt srcReg8;
    sqInt srcReg9;
    sqInt value;
    sqInt value1;
    sqInt value10;
    sqInt value11;
    sqInt value2;
    sqInt value3;
    sqInt value4;
    sqInt value5;
    sqInt value6;
    sqInt value7;
    sqInt value8;
    sqInt value9;
    unsigned short word;
    unsigned long word1;
    unsigned long word2;

	
	switch ((self_in_dispatchConcretize->opcode)) {
	case Label:
		/* begin concretizeLabel */
		dependentChain = (self_in_dispatchConcretize->dependent);
		while (!(dependentChain == null)) {
			updateLabel(dependentChain, self_in_dispatchConcretize);
			dependentChain = (dependentChain->dependent);
		}
		((self_in_dispatchConcretize->machineCodeSize) = 0);
		return;

	case AlignmentNops:
		/* begin concretizeAlignmentNops */
		flag("if performance is an issue generate longer nops");
		for (i = 0; i < ((self_in_dispatchConcretize->machineCodeSize)); i += 1) {
			((self_in_dispatchConcretize->machineCode))[i] = 144;
		}
		return;

	case Fill16:
		/* begin concretizeFill16 */
		assert(((self_in_dispatchConcretize->maxSize)) == 2);
		word = ((self_in_dispatchConcretize->operands))[0];
		((self_in_dispatchConcretize->machineCode))[0] = (word & 0xFF);
		((self_in_dispatchConcretize->machineCode))[1] = (((usqInt) word) >> 8);
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case Fill32:
		/* begin concretizeFill32 */
		word1 = ((self_in_dispatchConcretize->operands))[0];
		((self_in_dispatchConcretize->machineCode))[0] = (word1 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[1] = (((usqInt) word1) >> 8);
		((self_in_dispatchConcretize->machineCode))[2] = (((usqInt) word1) >> 16);
		((self_in_dispatchConcretize->machineCode))[3] = (((usqInt) word1) >> 24);
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case FillFromWord:
		/* begin concretizeFillFromWord */
		assert(((self_in_dispatchConcretize->maxSize)) == 4);
		word2 = (((self_in_dispatchConcretize->operands))[0]) + (((self_in_dispatchConcretize->operands))[1]);
		for (i1 = 0; i1 <= 3; i1 += 1) {
((self_in_dispatchConcretize->machineCode))[i1] = (word2 & 0xFF);
			word2 = ((usqInt) word2) >> 8;
		}
		((self_in_dispatchConcretize->machineCodeSize) = (self_in_dispatchConcretize->maxSize));
		return;

	case Nop:
		/* begin concretizeNop */
		((self_in_dispatchConcretize->machineCode))[0] = 144;
		((self_in_dispatchConcretize->machineCodeSize) = 1);
		return;

	case CDQ:
		/* begin concretizeCDQ */
		((self_in_dispatchConcretize->machineCode))[0] = 153;
		((self_in_dispatchConcretize->machineCodeSize) = 1);
		return;

	case IDIVR:
		/* begin concretizeIDIVR */
		regDivisor = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		((self_in_dispatchConcretize->machineCode))[0] = 247;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, regDivisor, 7));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case IMULRR:
		/* begin concretizeMulRR */
		reg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		reg2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = 175;
		((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModReg, reg1, reg2));
		((self_in_dispatchConcretize->machineCodeSize) = 3);
		return;

	case CPUID:
		/* begin concretizeCPUID */
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = 162;
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case CMPXCHGAwR:
		/* begin concretizeCMPXCHGAwR */
		addressOperand = ((self_in_dispatchConcretize->operands))[0];
		reg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = 177;
		((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegInd, 5, reg));
		((self_in_dispatchConcretize->machineCode))[3] = (addressOperand & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) addressOperand) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) addressOperand) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) addressOperand) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 7);
		return;

	case CMPXCHGMwrR:
		/* begin concretizeCMPXCHGMwrR */
		offset = ((self_in_dispatchConcretize->operands))[0];
		srcReg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (srcReg != ESP) {
if (isQuick(self_in_dispatchConcretize, offset)) {
				((self_in_dispatchConcretize->machineCode))[0] = 15;
				((self_in_dispatchConcretize->machineCode))[1] = 177;
				((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg, destReg));
				((self_in_dispatchConcretize->machineCode))[3] = (offset & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 15;
			((self_in_dispatchConcretize->machineCode))[1] = 177;
			((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg, destReg));
			((self_in_dispatchConcretize->machineCode))[3] = (offset & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 7);
			return;
		}
		if (isQuick(self_in_dispatchConcretize, offset)) {
			((self_in_dispatchConcretize->machineCode))[0] = 15;
			((self_in_dispatchConcretize->machineCode))[1] = 177;
			((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg, destReg));
			((self_in_dispatchConcretize->machineCode))[3] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg));
			((self_in_dispatchConcretize->machineCode))[4] = (offset & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = 177;
		((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg, destReg));
		((self_in_dispatchConcretize->machineCode))[3] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg));
		((self_in_dispatchConcretize->machineCode))[4] = (offset & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[7] = ((((usqInt) offset) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case LFENCE:
		/* begin concretizeFENCE: */
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = 174;
		((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModReg, 0, 5));
		((self_in_dispatchConcretize->machineCodeSize) = 3);
		return;

	case MFENCE:
		/* begin concretizeFENCE: */
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = 174;
		((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModReg, 0, 6));
		((self_in_dispatchConcretize->machineCodeSize) = 3);
		return;

	case SFENCE:
		/* begin concretizeFENCE: */
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = 174;
		((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModReg, 0, 7));
		((self_in_dispatchConcretize->machineCodeSize) = 3);
		return;

	case LOCK:
		/* begin concretizeLOCK */
		((self_in_dispatchConcretize->machineCode))[0] = 240;
		((self_in_dispatchConcretize->machineCodeSize) = 1);
		return;

	case XCHGAwR:
		/* begin concretizeXCHGAwR */
		addressOperand1 = ((self_in_dispatchConcretize->operands))[0];
		reg3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 135;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, 5, reg3));
		((self_in_dispatchConcretize->machineCode))[2] = (addressOperand1 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) addressOperand1) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) addressOperand1) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) addressOperand1) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case XCHGMwrR:
		/* begin concretizeXCHGMwrR */
		offset1 = ((self_in_dispatchConcretize->operands))[0];
		srcReg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (srcReg1 != ESP) {
if (isQuick(self_in_dispatchConcretize, offset1)) {
				((self_in_dispatchConcretize->machineCode))[0] = 135;
				((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg1, destReg1));
				((self_in_dispatchConcretize->machineCode))[2] = (offset1 & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 3);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 135;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg1, destReg1));
			((self_in_dispatchConcretize->machineCode))[2] = (offset1 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset1) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset1) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset1) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 6);
			return;
		}
		if (isQuick(self_in_dispatchConcretize, offset1)) {
			((self_in_dispatchConcretize->machineCode))[0] = 135;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg1, destReg1));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg1));
			((self_in_dispatchConcretize->machineCode))[3] = (offset1 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 135;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg1, destReg1));
		((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg1));
		((self_in_dispatchConcretize->machineCode))[3] = (offset1 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset1) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset1) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset1) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 7);
		return;

	case XCHGRR:
		/* begin concretizeXCHGRR */
		reg11 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		reg21 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (reg21 == EAX) {
reg21 = reg11;
			reg11 = EAX;
		}
		if (reg11 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = (144 + reg21);
			((self_in_dispatchConcretize->machineCodeSize) = 1);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 135;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg11, reg21));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case Call:
		/* begin concretizeCall */
		assert((((self_in_dispatchConcretize->operands))[0]) != 0);
		offset2 = (((sqInt) (((self_in_dispatchConcretize->operands))[0]))) - (((sqInt) (((self_in_dispatchConcretize->address)) + 5)));
		((self_in_dispatchConcretize->machineCode))[0] = 232;
		((self_in_dispatchConcretize->machineCode))[1] = (offset2 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) offset2) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset2) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset2) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 5);
		return;

	case JumpR:
		/* begin concretizeJumpR */
		reg4 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		((self_in_dispatchConcretize->machineCode))[0] = 0xFF;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg4, 4));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case JumpLong:
		/* begin concretizeJumpLong */
		jumpTarget = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget)) {
			jumpTarget = ((AbstractInstruction *) ((jumpTarget->address)));
		}
		assert(jumpTarget != 0);
		offset3 = (((sqInt) jumpTarget)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 5)));
		((self_in_dispatchConcretize->machineCode))[0] = 233;
		((self_in_dispatchConcretize->machineCode))[1] = (offset3 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) offset3) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset3) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset3) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 5);
		return;

	case JumpLongZero:
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget11 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget11);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget11)) {
			jumpTarget11 = ((AbstractInstruction *) ((jumpTarget11->address)));
		}
		assert(jumpTarget11 != 0);
		jumpTarget2 = jumpTarget11;
		offset14 = (((sqInt) jumpTarget2)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 4);
		((self_in_dispatchConcretize->machineCode))[2] = (offset14 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset14) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset14) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset14) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpLongNonZero:
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget12 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget12);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget12)) {
			jumpTarget12 = ((AbstractInstruction *) ((jumpTarget12->address)));
		}
		assert(jumpTarget12 != 0);
		jumpTarget3 = jumpTarget12;
		offset15 = (((sqInt) jumpTarget3)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 5);
		((self_in_dispatchConcretize->machineCode))[2] = (offset15 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset15) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset15) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset15) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case Jump:
		/* begin concretizeJump */
		jumpTarget1 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget1);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget1)) {
			jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
		}
		assert(jumpTarget1 != 0);
		offset4 = (((sqInt) jumpTarget1)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset4)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = 235;
			((self_in_dispatchConcretize->machineCode))[1] = (offset4 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		offset4 = (((sqInt) jumpTarget1)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 5)));
		((self_in_dispatchConcretize->machineCode))[0] = 233;
		((self_in_dispatchConcretize->machineCode))[1] = (offset4 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) offset4) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset4) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset4) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 5);
		return;

	case JumpZero:
	case JumpFPEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget13 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget13);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget13)) {
			jumpTarget13 = ((AbstractInstruction *) ((jumpTarget13->address)));
		}
		assert(jumpTarget13 != 0);
		jumpTarget4 = jumpTarget13;
		offset16 = (((sqInt) jumpTarget4)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset16)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 4);
			((self_in_dispatchConcretize->machineCode))[1] = (offset16 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget111 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget111);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget111)) {
			jumpTarget111 = ((AbstractInstruction *) ((jumpTarget111->address)));
		}
		assert(jumpTarget111 != 0);
		jumpTarget21 = jumpTarget111;
		offset17 = (((sqInt) jumpTarget21)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 4);
		((self_in_dispatchConcretize->machineCode))[2] = (offset17 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset17) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset17) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset17) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpNonZero:
	case JumpFPNotEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget14 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget14);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget14)) {
			jumpTarget14 = ((AbstractInstruction *) ((jumpTarget14->address)));
		}
		assert(jumpTarget14 != 0);
		jumpTarget5 = jumpTarget14;
		offset18 = (((sqInt) jumpTarget5)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset18)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 5);
			((self_in_dispatchConcretize->machineCode))[1] = (offset18 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget112 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget112);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget112)) {
			jumpTarget112 = ((AbstractInstruction *) ((jumpTarget112->address)));
		}
		assert(jumpTarget112 != 0);
		jumpTarget22 = jumpTarget112;
		offset19 = (((sqInt) jumpTarget22)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 5);
		((self_in_dispatchConcretize->machineCode))[2] = (offset19 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset19) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset19) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset19) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpNegative:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget15 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget15);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget15)) {
			jumpTarget15 = ((AbstractInstruction *) ((jumpTarget15->address)));
		}
		assert(jumpTarget15 != 0);
		jumpTarget6 = jumpTarget15;
		offset20 = (((sqInt) jumpTarget6)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset20)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 8);
			((self_in_dispatchConcretize->machineCode))[1] = (offset20 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget113 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget113);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget113)) {
			jumpTarget113 = ((AbstractInstruction *) ((jumpTarget113->address)));
		}
		assert(jumpTarget113 != 0);
		jumpTarget23 = jumpTarget113;
		offset110 = (((sqInt) jumpTarget23)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 8);
		((self_in_dispatchConcretize->machineCode))[2] = (offset110 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset110) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset110) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset110) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpNonNegative:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget16 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget16);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget16)) {
			jumpTarget16 = ((AbstractInstruction *) ((jumpTarget16->address)));
		}
		assert(jumpTarget16 != 0);
		jumpTarget7 = jumpTarget16;
		offset21 = (((sqInt) jumpTarget7)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset21)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 9);
			((self_in_dispatchConcretize->machineCode))[1] = (offset21 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget114 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget114);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget114)) {
			jumpTarget114 = ((AbstractInstruction *) ((jumpTarget114->address)));
		}
		assert(jumpTarget114 != 0);
		jumpTarget24 = jumpTarget114;
		offset111 = (((sqInt) jumpTarget24)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 9);
		((self_in_dispatchConcretize->machineCode))[2] = (offset111 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset111) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset111) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset111) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpOverflow:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget17 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget17);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget17)) {
			jumpTarget17 = ((AbstractInstruction *) ((jumpTarget17->address)));
		}
		assert(jumpTarget17 != 0);
		jumpTarget8 = jumpTarget17;
		offset22 = (((sqInt) jumpTarget8)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset22)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 0);
			((self_in_dispatchConcretize->machineCode))[1] = (offset22 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget115 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget115);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget115)) {
			jumpTarget115 = ((AbstractInstruction *) ((jumpTarget115->address)));
		}
		assert(jumpTarget115 != 0);
		jumpTarget25 = jumpTarget115;
		offset112 = (((sqInt) jumpTarget25)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 0);
		((self_in_dispatchConcretize->machineCode))[2] = (offset112 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset112) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset112) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset112) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpNoOverflow:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget18 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget18);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget18)) {
			jumpTarget18 = ((AbstractInstruction *) ((jumpTarget18->address)));
		}
		assert(jumpTarget18 != 0);
		jumpTarget9 = jumpTarget18;
		offset23 = (((sqInt) jumpTarget9)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset23)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 1);
			((self_in_dispatchConcretize->machineCode))[1] = (offset23 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget116 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget116);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget116)) {
			jumpTarget116 = ((AbstractInstruction *) ((jumpTarget116->address)));
		}
		assert(jumpTarget116 != 0);
		jumpTarget26 = jumpTarget116;
		offset113 = (((sqInt) jumpTarget26)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 1);
		((self_in_dispatchConcretize->machineCode))[2] = (offset113 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset113) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset113) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset113) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpCarry:
	case JumpBelow:
	case JumpFPLess:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget19 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget19);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget19)) {
			jumpTarget19 = ((AbstractInstruction *) ((jumpTarget19->address)));
		}
		assert(jumpTarget19 != 0);
		jumpTarget10 = jumpTarget19;
		offset24 = (((sqInt) jumpTarget10)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset24)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 2);
			((self_in_dispatchConcretize->machineCode))[1] = (offset24 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget117 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget117);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget117)) {
			jumpTarget117 = ((AbstractInstruction *) ((jumpTarget117->address)));
		}
		assert(jumpTarget117 != 0);
		jumpTarget27 = jumpTarget117;
		offset114 = (((sqInt) jumpTarget27)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 2);
		((self_in_dispatchConcretize->machineCode))[2] = (offset114 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset114) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset114) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset114) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpNoCarry:
	case JumpAboveOrEqual:
	case JumpFPGreaterOrEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget110 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget110);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget110)) {
			jumpTarget110 = ((AbstractInstruction *) ((jumpTarget110->address)));
		}
		assert(jumpTarget110 != 0);
		jumpTarget20 = jumpTarget110;
		offset25 = (((sqInt) jumpTarget20)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset25)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 3);
			((self_in_dispatchConcretize->machineCode))[1] = (offset25 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget118 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget118);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget118)) {
			jumpTarget118 = ((AbstractInstruction *) ((jumpTarget118->address)));
		}
		assert(jumpTarget118 != 0);
		jumpTarget28 = jumpTarget118;
		offset115 = (((sqInt) jumpTarget28)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 3);
		((self_in_dispatchConcretize->machineCode))[2] = (offset115 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset115) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset115) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset115) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpLess:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget120 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget120);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget120)) {
			jumpTarget120 = ((AbstractInstruction *) ((jumpTarget120->address)));
		}
		assert(jumpTarget120 != 0);
		jumpTarget30 = jumpTarget120;
		offset26 = (((sqInt) jumpTarget30)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset26)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 12);
			((self_in_dispatchConcretize->machineCode))[1] = (offset26 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget119 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget119);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget119)) {
			jumpTarget119 = ((AbstractInstruction *) ((jumpTarget119->address)));
		}
		assert(jumpTarget119 != 0);
		jumpTarget29 = jumpTarget119;
		offset116 = (((sqInt) jumpTarget29)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 12);
		((self_in_dispatchConcretize->machineCode))[2] = (offset116 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset116) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset116) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset116) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpGreaterOrEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget121 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget121);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget121)) {
			jumpTarget121 = ((AbstractInstruction *) ((jumpTarget121->address)));
		}
		assert(jumpTarget121 != 0);
		jumpTarget31 = jumpTarget121;
		offset27 = (((sqInt) jumpTarget31)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset27)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 13);
			((self_in_dispatchConcretize->machineCode))[1] = (offset27 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget1110 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget1110);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget1110)) {
			jumpTarget1110 = ((AbstractInstruction *) ((jumpTarget1110->address)));
		}
		assert(jumpTarget1110 != 0);
		jumpTarget210 = jumpTarget1110;
		offset117 = (((sqInt) jumpTarget210)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 13);
		((self_in_dispatchConcretize->machineCode))[2] = (offset117 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset117) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset117) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset117) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpGreater:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget122 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget122);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget122)) {
			jumpTarget122 = ((AbstractInstruction *) ((jumpTarget122->address)));
		}
		assert(jumpTarget122 != 0);
		jumpTarget32 = jumpTarget122;
		offset28 = (((sqInt) jumpTarget32)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset28)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 15);
			((self_in_dispatchConcretize->machineCode))[1] = (offset28 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget1111 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget1111);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget1111)) {
			jumpTarget1111 = ((AbstractInstruction *) ((jumpTarget1111->address)));
		}
		assert(jumpTarget1111 != 0);
		jumpTarget211 = jumpTarget1111;
		offset118 = (((sqInt) jumpTarget211)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 15);
		((self_in_dispatchConcretize->machineCode))[2] = (offset118 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset118) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset118) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset118) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpLessOrEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget123 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget123);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget123)) {
			jumpTarget123 = ((AbstractInstruction *) ((jumpTarget123->address)));
		}
		assert(jumpTarget123 != 0);
		jumpTarget33 = jumpTarget123;
		offset29 = (((sqInt) jumpTarget33)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset29)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 14);
			((self_in_dispatchConcretize->machineCode))[1] = (offset29 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget1112 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget1112);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget1112)) {
			jumpTarget1112 = ((AbstractInstruction *) ((jumpTarget1112->address)));
		}
		assert(jumpTarget1112 != 0);
		jumpTarget212 = jumpTarget1112;
		offset119 = (((sqInt) jumpTarget212)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 14);
		((self_in_dispatchConcretize->machineCode))[2] = (offset119 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset119) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset119) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset119) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpAbove:
	case JumpFPGreater:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget124 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget124);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget124)) {
			jumpTarget124 = ((AbstractInstruction *) ((jumpTarget124->address)));
		}
		assert(jumpTarget124 != 0);
		jumpTarget34 = jumpTarget124;
		offset30 = (((sqInt) jumpTarget34)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset30)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 7);
			((self_in_dispatchConcretize->machineCode))[1] = (offset30 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget1113 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget1113);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget1113)) {
			jumpTarget1113 = ((AbstractInstruction *) ((jumpTarget1113->address)));
		}
		assert(jumpTarget1113 != 0);
		jumpTarget213 = jumpTarget1113;
		offset120 = (((sqInt) jumpTarget213)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 7);
		((self_in_dispatchConcretize->machineCode))[2] = (offset120 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset120) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset120) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset120) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpBelowOrEqual:
	case JumpFPLessOrEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget125 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget125);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget125)) {
			jumpTarget125 = ((AbstractInstruction *) ((jumpTarget125->address)));
		}
		assert(jumpTarget125 != 0);
		jumpTarget35 = jumpTarget125;
		offset31 = (((sqInt) jumpTarget35)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset31)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 6);
			((self_in_dispatchConcretize->machineCode))[1] = (offset31 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget1114 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget1114);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget1114)) {
			jumpTarget1114 = ((AbstractInstruction *) ((jumpTarget1114->address)));
		}
		assert(jumpTarget1114 != 0);
		jumpTarget214 = jumpTarget1114;
		offset121 = (((sqInt) jumpTarget214)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 6);
		((self_in_dispatchConcretize->machineCode))[2] = (offset121 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset121) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset121) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset121) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpFPOrdered:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget126 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget126);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget126)) {
			jumpTarget126 = ((AbstractInstruction *) ((jumpTarget126->address)));
		}
		assert(jumpTarget126 != 0);
		jumpTarget36 = jumpTarget126;
		offset32 = (((sqInt) jumpTarget36)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset32)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 11);
			((self_in_dispatchConcretize->machineCode))[1] = (offset32 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget1115 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget1115);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget1115)) {
			jumpTarget1115 = ((AbstractInstruction *) ((jumpTarget1115->address)));
		}
		assert(jumpTarget1115 != 0);
		jumpTarget215 = jumpTarget1115;
		offset122 = (((sqInt) jumpTarget215)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 11);
		((self_in_dispatchConcretize->machineCode))[2] = (offset122 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset122) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset122) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset122) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case JumpFPUnordered:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget127 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget127);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget127)) {
			jumpTarget127 = ((AbstractInstruction *) ((jumpTarget127->address)));
		}
		assert(jumpTarget127 != 0);
		jumpTarget37 = jumpTarget127;
		offset33 = (((sqInt) jumpTarget37)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 2)));
		if ((((self_in_dispatchConcretize->machineCodeSize)) == 0
			? isQuick(self_in_dispatchConcretize, offset33)
			: ((self_in_dispatchConcretize->machineCodeSize)) == 2)) {
			((self_in_dispatchConcretize->machineCode))[0] = (112 + 10);
			((self_in_dispatchConcretize->machineCode))[1] = (offset33 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		/* begin concretizeConditionalJumpLong: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget1116 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget1116);
		if (isAnInstruction(self_in_dispatchConcretize, jumpTarget1116)) {
			jumpTarget1116 = ((AbstractInstruction *) ((jumpTarget1116->address)));
		}
		assert(jumpTarget1116 != 0);
		jumpTarget216 = jumpTarget1116;
		offset123 = (((sqInt) jumpTarget216)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 6)));
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = (128 + 10);
		((self_in_dispatchConcretize->machineCode))[2] = (offset123 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset123) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset123) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset123) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case RetN:
		/* begin concretizeRetN */
		offset5 = ((self_in_dispatchConcretize->operands))[0];
		if (offset5 == 0) {
((self_in_dispatchConcretize->machineCode))[0] = 195;
			((self_in_dispatchConcretize->machineCodeSize) = 1);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 194;
		((self_in_dispatchConcretize->machineCode))[1] = (offset5 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[2] = (((usqInt) offset5) >> 8);
		((self_in_dispatchConcretize->machineCodeSize) = 3);
		return;

	case AddCqR:
		/* begin concretizeAddCqR */
		value = ((self_in_dispatchConcretize->operands))[0];
		reg5 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (isQuick(self_in_dispatchConcretize, value)) {
			((self_in_dispatchConcretize->machineCode))[0] = 131;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg5, 0));
			((self_in_dispatchConcretize->machineCode))[2] = (value & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		if (reg5 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 5;
			((self_in_dispatchConcretize->machineCode))[1] = (value & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 129;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg5, 0));
		((self_in_dispatchConcretize->machineCode))[2] = (value & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) value) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case AddCwR:
		/* begin concretizeAddCwR */
		value1 = ((self_in_dispatchConcretize->operands))[0];
		reg6 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (reg6 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 5;
			((self_in_dispatchConcretize->machineCode))[1] = (value1 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value1) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value1) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value1) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 129;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg6, 0));
		((self_in_dispatchConcretize->machineCode))[2] = (value1 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value1) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value1) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) value1) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case AddRR:
		/* begin concretizeAddRR */
		regLHS = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regRHS = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 3;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, regLHS, regRHS));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case AddRdRd:
		/* begin concretizeSEE2OpRdRd: */
		regRHS1 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS1 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 242;
		((self_in_dispatchConcretize->machineCode))[1] = 15;
		((self_in_dispatchConcretize->machineCode))[2] = 88;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModReg, regRHS1, regLHS1));
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case AndCqR:
		/* begin concretizeAndCqR */
		mask = ((self_in_dispatchConcretize->operands))[0];
		reg7 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (isQuick(self_in_dispatchConcretize, mask)) {
			((self_in_dispatchConcretize->machineCode))[0] = 131;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg7, 4));
			((self_in_dispatchConcretize->machineCode))[2] = (mask & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		if (reg7 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 37;
			((self_in_dispatchConcretize->machineCode))[1] = (mask & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) mask) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) mask) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) mask) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 129;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg7, 4));
		((self_in_dispatchConcretize->machineCode))[2] = (mask & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) mask) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) mask) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) mask) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case AndCwR:
		/* begin concretizeAndCwR */
		value2 = ((self_in_dispatchConcretize->operands))[0];
		reg8 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (reg8 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 37;
			((self_in_dispatchConcretize->machineCode))[1] = (value2 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value2) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value2) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value2) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 131;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg8, 4));
		((self_in_dispatchConcretize->machineCode))[2] = (value2 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value2) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value2) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) value2) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case AndRR:
		/* begin concretizeAndRR */
		regLHS2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regRHS2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 35;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, regLHS2, regRHS2));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case CmpCqR:
		/* begin concretizeCmpCqR */
		value3 = ((self_in_dispatchConcretize->operands))[0];
		reg9 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (isQuick(self_in_dispatchConcretize, value3)) {
			((self_in_dispatchConcretize->machineCode))[0] = 131;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg9, 7));
			((self_in_dispatchConcretize->machineCode))[2] = (value3 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		if (reg9 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 61;
			((self_in_dispatchConcretize->machineCode))[1] = (value3 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value3) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value3) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value3) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 129;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg9, 7));
		((self_in_dispatchConcretize->machineCode))[2] = (value3 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value3) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value3) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) value3) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case CmpCwR:
		/* begin concretizeCmpCwR */
		value4 = ((self_in_dispatchConcretize->operands))[0];
		reg10 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (reg10 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 61;
			((self_in_dispatchConcretize->machineCode))[1] = (value4 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value4) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value4) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value4) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 129;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg10, 7));
		((self_in_dispatchConcretize->machineCode))[2] = (value4 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value4) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value4) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) value4) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case CmpRR:
		/* begin concretizeCmpRR */
		regRHS3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 57;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, regLHS3, regRHS3));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case CmpRdRd:
		/* begin concretizeCmpRdRd */
		regRHS4 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS4 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 102;
		((self_in_dispatchConcretize->machineCode))[1] = 15;
		((self_in_dispatchConcretize->machineCode))[2] = 46;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModReg, regRHS4, regLHS4));
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case DivRdRd:
		/* begin concretizeSEE2OpRdRd: */
		regRHS5 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS5 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 242;
		((self_in_dispatchConcretize->machineCode))[1] = 15;
		((self_in_dispatchConcretize->machineCode))[2] = 94;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModReg, regRHS5, regLHS5));
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MulRdRd:
		/* begin concretizeSEE2OpRdRd: */
		regRHS6 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS6 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 242;
		((self_in_dispatchConcretize->machineCode))[1] = 15;
		((self_in_dispatchConcretize->machineCode))[2] = 89;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModReg, regRHS6, regLHS6));
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case OrCqR:
		/* begin concretizeOrCqR */
		mask1 = ((self_in_dispatchConcretize->operands))[0];
		reg12 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (isQuick(self_in_dispatchConcretize, mask1)) {
			((self_in_dispatchConcretize->machineCode))[0] = 131;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg12, 1));
			((self_in_dispatchConcretize->machineCode))[2] = (mask1 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		if (reg12 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 13;
			((self_in_dispatchConcretize->machineCode))[1] = (mask1 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) mask1) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) mask1) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) mask1) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 129;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg12, 1));
		((self_in_dispatchConcretize->machineCode))[2] = (mask1 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) mask1) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) mask1) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) mask1) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case OrCwR:
		/* begin concretizeOrCwR */
		value5 = ((self_in_dispatchConcretize->operands))[0];
		reg13 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (reg13 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 13;
			((self_in_dispatchConcretize->machineCode))[1] = (value5 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value5) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value5) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value5) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 131;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg13, 1));
		((self_in_dispatchConcretize->machineCode))[2] = (value5 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value5) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value5) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) value5) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case OrRR:
		/* begin concretizeOrRR */
		regLHS7 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regRHS7 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 11;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, regLHS7, regRHS7));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case SubCqR:
		/* begin concretizeSubCqR */
		value6 = ((self_in_dispatchConcretize->operands))[0];
		reg14 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (isQuick(self_in_dispatchConcretize, value6)) {
			((self_in_dispatchConcretize->machineCode))[0] = 131;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg14, 5));
			((self_in_dispatchConcretize->machineCode))[2] = (value6 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		if (reg14 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 45;
			((self_in_dispatchConcretize->machineCode))[1] = (value6 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value6) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value6) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value6) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 129;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg14, 5));
		((self_in_dispatchConcretize->machineCode))[2] = (value6 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value6) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value6) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) value6) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case SubCwR:
		/* begin concretizeSubCwR */
		value7 = ((self_in_dispatchConcretize->operands))[0];
		reg15 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (reg15 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 45;
			((self_in_dispatchConcretize->machineCode))[1] = (value7 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value7) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value7) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value7) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 129;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg15, 5));
		((self_in_dispatchConcretize->machineCode))[2] = (value7 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value7) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value7) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) value7) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case SubRR:
		/* begin concretizeSubRR */
		regLHS8 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regRHS8 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 43;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, regLHS8, regRHS8));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case SubRdRd:
		/* begin concretizeSEE2OpRdRd: */
		regRHS9 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS9 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 242;
		((self_in_dispatchConcretize->machineCode))[1] = 15;
		((self_in_dispatchConcretize->machineCode))[2] = 92;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModReg, regRHS9, regLHS9));
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case SqrtRd:
		/* begin concretizeSqrtRd */
		reg16 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		((self_in_dispatchConcretize->machineCode))[0] = 242;
		((self_in_dispatchConcretize->machineCode))[1] = 15;
		((self_in_dispatchConcretize->machineCode))[2] = 81;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModReg, reg16, reg16));
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case XorCwR:
		/* begin concretizeXorCwR */
		value8 = ((self_in_dispatchConcretize->operands))[0];
		reg17 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (reg17 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 53;
			((self_in_dispatchConcretize->machineCode))[1] = (value8 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value8) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value8) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value8) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 129;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg17, 6));
		((self_in_dispatchConcretize->machineCode))[2] = (value8 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value8) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value8) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) value8) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case XorRR:
		/* begin concretizeXorRR */
		regLHS10 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regRHS10 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 51;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, regLHS10, regRHS10));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case NegateR:
		/* begin concretizeNegateR */
		reg18 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		((self_in_dispatchConcretize->machineCode))[0] = 247;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg18, 3));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case LoadEffectiveAddressMwrR:
		/* begin concretizeLoadEffectiveAddressMwrR */
		offset6 = ((self_in_dispatchConcretize->operands))[0];
		srcReg2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (srcReg2 != ESP) {
if (isQuick(self_in_dispatchConcretize, offset6)) {
				((self_in_dispatchConcretize->machineCode))[0] = 141;
				((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg2, destReg2));
				((self_in_dispatchConcretize->machineCode))[2] = (offset6 & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 3);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 141;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg2, destReg2));
			((self_in_dispatchConcretize->machineCode))[2] = (offset6 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset6) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset6) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset6) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 6);
			return;
		}
		if (isQuick(self_in_dispatchConcretize, offset6)) {
			((self_in_dispatchConcretize->machineCode))[0] = 141;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg2, destReg2));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg2));
			((self_in_dispatchConcretize->machineCode))[3] = (offset6 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 141;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg2, destReg2));
		((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg2));
		((self_in_dispatchConcretize->machineCode))[3] = (offset6 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset6) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset6) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset6) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 7);
		return;

	case ArithmeticShiftRightCqR:
		/* begin concretizeArithmeticShiftRightCqR */
		shiftCount = (((((self_in_dispatchConcretize->operands))[0]) < 0x1F) ? (((self_in_dispatchConcretize->operands))[0]) : 0x1F);
		reg19 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (shiftCount == 1) {
((self_in_dispatchConcretize->machineCode))[0] = 209;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg19, 7));
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 193;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg19, 7));
		((self_in_dispatchConcretize->machineCode))[2] = shiftCount;
		((self_in_dispatchConcretize->machineCodeSize) = 3);
		return;

	case LogicalShiftRightCqR:
		/* begin concretizeLogicalShiftRightCqR */
		distance = (((((self_in_dispatchConcretize->operands))[0]) < 0x1F) ? (((self_in_dispatchConcretize->operands))[0]) : 0x1F);
		reg20 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (distance == 1) {
((self_in_dispatchConcretize->machineCode))[0] = 209;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg20, 5));
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 193;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg20, 5));
		((self_in_dispatchConcretize->machineCode))[2] = distance;
		((self_in_dispatchConcretize->machineCodeSize) = 3);
		return;

	case LogicalShiftLeftCqR:
		/* begin concretizeLogicalShiftLeftCqR */
		distance1 = (((((self_in_dispatchConcretize->operands))[0]) < 0x1F) ? (((self_in_dispatchConcretize->operands))[0]) : 0x1F);
		reg22 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (distance1 == 1) {
((self_in_dispatchConcretize->machineCode))[0] = 209;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg22, 4));
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 193;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg22, 4));
		((self_in_dispatchConcretize->machineCode))[2] = distance1;
		((self_in_dispatchConcretize->machineCodeSize) = 3);
		return;

	case ArithmeticShiftRightRR:
		/* begin concretizeArithmeticShiftRightRR */
		shiftCountReg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		destReg3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (shiftCountReg == ECX) {
((self_in_dispatchConcretize->machineCode))[0] = 211;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, destReg3, 7));
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		regToShift = (destReg3 == shiftCountReg
			? ECX
			: (destReg3 == ECX
					? shiftCountReg
					: destReg3));
		if (shiftCountReg == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = (144 + ECX);
			((self_in_dispatchConcretize->machineCode))[1] = 211;
			((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModReg, regToShift, 7));
			((self_in_dispatchConcretize->machineCode))[3] = (144 + ECX);
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 135;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, ECX, shiftCountReg));
		((self_in_dispatchConcretize->machineCode))[2] = 211;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModReg, regToShift, 7));
		((self_in_dispatchConcretize->machineCode))[4] = 135;
		((self_in_dispatchConcretize->machineCode))[5] = (modRMRO(self_in_dispatchConcretize, ModReg, ECX, shiftCountReg));
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case LogicalShiftLeftRR:
		/* begin concretizeLogicalShiftLeftRR */
		shiftCountReg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		destReg4 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (shiftCountReg1 == ECX) {
((self_in_dispatchConcretize->machineCode))[0] = 211;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, destReg4, 4));
			((self_in_dispatchConcretize->machineCodeSize) = 2);
			return;
		}
		regToShift1 = (destReg4 == shiftCountReg1
			? ECX
			: (destReg4 == ECX
					? shiftCountReg1
					: destReg4));
		if (shiftCountReg1 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = (144 + ECX);
			((self_in_dispatchConcretize->machineCode))[1] = 211;
			((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModReg, regToShift1, 4));
			((self_in_dispatchConcretize->machineCode))[3] = (144 + ECX);
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 135;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, ECX, shiftCountReg1));
		((self_in_dispatchConcretize->machineCode))[2] = 211;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModReg, regToShift1, 4));
		((self_in_dispatchConcretize->machineCode))[4] = 135;
		((self_in_dispatchConcretize->machineCode))[5] = (modRMRO(self_in_dispatchConcretize, ModReg, ECX, shiftCountReg1));
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case MoveCqR:
		/* begin concretizeMoveCqR */
		if ((((self_in_dispatchConcretize->operands))[0]) != 0) {
			/* begin concretizeMoveCwR */
			value11 = ((self_in_dispatchConcretize->operands))[0];
			((self_in_dispatchConcretize->machineCode))[0] = (184 + (concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1])));
			((self_in_dispatchConcretize->machineCode))[1] = (value11 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value11) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value11) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value11) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		reg23 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 49;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, reg23, reg23));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case MoveCwR:
		/* begin concretizeMoveCwR */
		value9 = ((self_in_dispatchConcretize->operands))[0];
		((self_in_dispatchConcretize->machineCode))[0] = (184 + (concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1])));
		((self_in_dispatchConcretize->machineCode))[1] = (value9 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value9) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value9) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value9) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 5);
		return;

	case MoveRR:
		/* begin concretizeMoveRR */
		srcReg3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		destReg5 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 137;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModReg, destReg5, srcReg3));
		((self_in_dispatchConcretize->machineCodeSize) = 2);
		return;

	case MoveAwR:
		/* begin concretizeMoveAwR */
		addressOperand2 = ((self_in_dispatchConcretize->operands))[0];
		if (isAnInstruction(self_in_dispatchConcretize, ((AbstractInstruction *) addressOperand2))) {
			addressOperand2 = ((((AbstractInstruction *) addressOperand2))->address);
		}
		reg24 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if (reg24 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 161;
			((self_in_dispatchConcretize->machineCode))[1] = (addressOperand2 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) addressOperand2) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) addressOperand2) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) addressOperand2) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 139;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, 5, reg24));
		((self_in_dispatchConcretize->machineCode))[2] = (addressOperand2 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) addressOperand2) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) addressOperand2) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) addressOperand2) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case MoveRAw:
		/* begin concretizeMoveRAw */
		reg25 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		addressOperand3 = ((self_in_dispatchConcretize->operands))[1];
		if (isAnInstruction(self_in_dispatchConcretize, ((AbstractInstruction *) addressOperand3))) {
			addressOperand3 = ((((AbstractInstruction *) addressOperand3))->address);
		}
		if (reg25 == EAX) {
((self_in_dispatchConcretize->machineCode))[0] = 163;
			((self_in_dispatchConcretize->machineCode))[1] = (addressOperand3 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) addressOperand3) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) addressOperand3) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) addressOperand3) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 137;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, 5, reg25));
		((self_in_dispatchConcretize->machineCode))[2] = (addressOperand3 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) addressOperand3) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) addressOperand3) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) addressOperand3) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 6);
		return;

	case MoveMbrR:
		/* begin concretizeMoveMbrR */
		offset7 = ((self_in_dispatchConcretize->operands))[0];
		srcReg4 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg6 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (srcReg4 != ESP) {
if (isQuick(self_in_dispatchConcretize, offset7)) {
				((self_in_dispatchConcretize->machineCode))[0] = 138;
				((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg4, destReg6));
				((self_in_dispatchConcretize->machineCode))[2] = (offset7 & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 3);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 138;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg4, destReg6));
			((self_in_dispatchConcretize->machineCode))[2] = (offset7 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset7) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset7) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset7) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 6);
			return;
		}
		if (isQuick(self_in_dispatchConcretize, offset7)) {
			((self_in_dispatchConcretize->machineCode))[0] = 138;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg4, destReg6));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg4));
			((self_in_dispatchConcretize->machineCode))[3] = (offset7 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 138;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg4, destReg6));
		((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg4));
		((self_in_dispatchConcretize->machineCode))[3] = (offset7 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset7) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset7) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset7) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 7);
		return;

	case MoveRMbr:
		/* begin concretizeMoveRMbr */
		offset8 = ((self_in_dispatchConcretize->operands))[1];
		srcReg5 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		destReg7 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (srcReg5 >= 4) {
error("invalid register");
		}
		if (destReg7 != ESP) {
if (isQuick(self_in_dispatchConcretize, offset8)) {
				((self_in_dispatchConcretize->machineCode))[0] = 136;
				((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, destReg7, srcReg5));
				((self_in_dispatchConcretize->machineCode))[2] = (offset8 & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 3);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 136;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, destReg7, srcReg5));
			((self_in_dispatchConcretize->machineCode))[2] = (offset8 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset8) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset8) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset8) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 6);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 136;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, destReg7, srcReg5));
		((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, destReg7));
		((self_in_dispatchConcretize->machineCode))[3] = (offset8 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset8) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset8) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset8) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 7);
		return;

	case MoveM16rR:
		/* begin concretizeMoveM16rR */
		offset9 = ((self_in_dispatchConcretize->operands))[0];
		srcReg6 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg8 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (srcReg6 != ESP) {
if (isQuick(self_in_dispatchConcretize, offset9)) {
				((self_in_dispatchConcretize->machineCode))[0] = 15;
				((self_in_dispatchConcretize->machineCode))[1] = 183;
				((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg6, destReg8));
				((self_in_dispatchConcretize->machineCode))[3] = (offset9 & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 15;
			((self_in_dispatchConcretize->machineCode))[1] = 183;
			((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg6, destReg8));
			((self_in_dispatchConcretize->machineCode))[3] = (offset9 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset9) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset9) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset9) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 7);
			return;
		}
		if (isQuick(self_in_dispatchConcretize, offset9)) {
			((self_in_dispatchConcretize->machineCode))[0] = 15;
			((self_in_dispatchConcretize->machineCode))[1] = 183;
			((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg6, destReg8));
			((self_in_dispatchConcretize->machineCode))[3] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg6));
			((self_in_dispatchConcretize->machineCode))[4] = (offset9 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 5);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = 183;
		((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg6, destReg8));
		((self_in_dispatchConcretize->machineCode))[3] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg6));
		((self_in_dispatchConcretize->machineCode))[4] = (offset9 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset9) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset9) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[7] = ((((usqInt) offset9) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case MoveM64rRd:
		/* begin concretizeMoveM64rRd */
		offset10 = ((self_in_dispatchConcretize->operands))[0];
		srcReg7 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg9 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (srcReg7 != ESP) {
if (isQuick(self_in_dispatchConcretize, offset10)) {
				((self_in_dispatchConcretize->machineCode))[0] = 242;
				((self_in_dispatchConcretize->machineCode))[1] = 15;
				((self_in_dispatchConcretize->machineCode))[2] = 16;
				((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg7, destReg9));
				((self_in_dispatchConcretize->machineCode))[4] = (offset10 & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 5);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 242;
			((self_in_dispatchConcretize->machineCode))[1] = 15;
			((self_in_dispatchConcretize->machineCode))[2] = 16;
			((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg7, destReg9));
			((self_in_dispatchConcretize->machineCode))[4] = (offset10 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset10) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset10) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[7] = ((((usqInt) offset10) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 8);
			return;
		}
		if (isQuick(self_in_dispatchConcretize, offset10)) {
			((self_in_dispatchConcretize->machineCode))[0] = 242;
			((self_in_dispatchConcretize->machineCode))[1] = 15;
			((self_in_dispatchConcretize->machineCode))[2] = 16;
			((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg7, destReg9));
			((self_in_dispatchConcretize->machineCode))[4] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg7));
			((self_in_dispatchConcretize->machineCode))[5] = (offset10 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 6);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 242;
		((self_in_dispatchConcretize->machineCode))[1] = 15;
		((self_in_dispatchConcretize->machineCode))[2] = 16;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg7, destReg9));
		((self_in_dispatchConcretize->machineCode))[4] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg7));
		((self_in_dispatchConcretize->machineCode))[5] = (offset10 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset10) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[7] = ((((usqInt) offset10) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[8] = ((((usqInt) offset10) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 9);
		return;

	case MoveMwrR:
		/* begin concretizeMoveMwrR */
		offset11 = ((self_in_dispatchConcretize->operands))[0];
		srcReg8 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg10 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (srcReg8 != ESP) {
if ((offset11 == 0)
			 && (srcReg8 != EBP)) {
				((self_in_dispatchConcretize->machineCode))[0] = 139;
				((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, srcReg8, destReg10));
				((self_in_dispatchConcretize->machineCodeSize) = 2);
				return;
			}
			if (isQuick(self_in_dispatchConcretize, offset11)) {
				((self_in_dispatchConcretize->machineCode))[0] = 139;
				((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg8, destReg10));
				((self_in_dispatchConcretize->machineCode))[2] = (offset11 & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 3);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 139;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg8, destReg10));
			((self_in_dispatchConcretize->machineCode))[2] = (offset11 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset11) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset11) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset11) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 6);
			return;
		}
		if (offset11 == 0) {
((self_in_dispatchConcretize->machineCode))[0] = 139;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, srcReg8, destReg10));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg8));
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		if (isQuick(self_in_dispatchConcretize, offset11)) {
			((self_in_dispatchConcretize->machineCode))[0] = 139;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, srcReg8, destReg10));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg8));
			((self_in_dispatchConcretize->machineCode))[3] = (offset11 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 139;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, srcReg8, destReg10));
		((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, srcReg8));
		((self_in_dispatchConcretize->machineCode))[3] = (offset11 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset11) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset11) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset11) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 7);
		return;

	case MoveXbrRR:
		/* begin concretizeMoveXbrRR */
		index = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		base = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		dest = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (base != EBP) {
((self_in_dispatchConcretize->machineCode))[0] = 15;
			((self_in_dispatchConcretize->machineCode))[1] = 182;
			((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegInd, 4, dest));
			((self_in_dispatchConcretize->machineCode))[3] = (sib(self_in_dispatchConcretize, SIB1, index, base));
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 15;
		((self_in_dispatchConcretize->machineCode))[1] = 182;
		((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, 4, dest));
		((self_in_dispatchConcretize->machineCode))[3] = (sib(self_in_dispatchConcretize, SIB1, index, base));
		((self_in_dispatchConcretize->machineCode))[4] = 0;
		((self_in_dispatchConcretize->machineCodeSize) = 5);
		return;

	case MoveRXbrR:
		/* begin concretizeMoveRXbrR */
		src = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		index1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		base1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (base1 != EBP) {
((self_in_dispatchConcretize->machineCode))[0] = 136;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, 4, src));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, index1, base1));
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 136;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, 4, src));
		((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, index1, base1));
		((self_in_dispatchConcretize->machineCode))[3] = 0;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MoveXwrRR:
		/* begin concretizeMoveXwrRR */
		index2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		base2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		dest1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (base2 != EBP) {
((self_in_dispatchConcretize->machineCode))[0] = 139;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, 4, dest1));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB4, index2, base2));
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 139;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, 4, dest1));
		((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB4, index2, base2));
		((self_in_dispatchConcretize->machineCode))[3] = 0;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MoveRXwrR:
		/* begin concretizeMoveRXwrR */
		src1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		index3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		base3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (base3 != EBP) {
((self_in_dispatchConcretize->machineCode))[0] = 137;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, 4, src1));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB4, index3, base3));
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 137;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, 4, src1));
		((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB4, index3, base3));
		((self_in_dispatchConcretize->machineCode))[3] = 0;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MoveRMwr:
		/* begin concretizeMoveRMwr */
		srcReg9 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		offset12 = ((self_in_dispatchConcretize->operands))[1];
		destReg11 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (destReg11 != ESP) {
if ((offset12 == 0)
			 && (destReg11 != EBP)) {
				((self_in_dispatchConcretize->machineCode))[0] = 137;
				((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, destReg11, srcReg9));
				((self_in_dispatchConcretize->machineCodeSize) = 2);
				return;
			}
			if (isQuick(self_in_dispatchConcretize, offset12)) {
				((self_in_dispatchConcretize->machineCode))[0] = 137;
				((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, destReg11, srcReg9));
				((self_in_dispatchConcretize->machineCode))[2] = (offset12 & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 3);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 137;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, destReg11, srcReg9));
			((self_in_dispatchConcretize->machineCode))[2] = (offset12 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) offset12) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset12) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset12) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 6);
			return;
		}
		if (offset12 == 0) {
((self_in_dispatchConcretize->machineCode))[0] = 137;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegInd, destReg11, srcReg9));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, destReg11));
			((self_in_dispatchConcretize->machineCodeSize) = 3);
			return;
		}
		if (isQuick(self_in_dispatchConcretize, offset12)) {
			((self_in_dispatchConcretize->machineCode))[0] = 137;
			((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, destReg11, srcReg9));
			((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, destReg11));
			((self_in_dispatchConcretize->machineCode))[3] = (offset12 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 137;
		((self_in_dispatchConcretize->machineCode))[1] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, destReg11, srcReg9));
		((self_in_dispatchConcretize->machineCode))[2] = (sib(self_in_dispatchConcretize, SIB1, 4, destReg11));
		((self_in_dispatchConcretize->machineCode))[3] = (offset12 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) offset12) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset12) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset12) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 7);
		return;

	case MoveRdM64r:
		/* begin concretizeMoveRdM64r */
		srcReg10 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		offset13 = ((self_in_dispatchConcretize->operands))[1];
		destReg12 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		if (destReg12 != ESP) {
if (isQuick(self_in_dispatchConcretize, offset13)) {
				((self_in_dispatchConcretize->machineCode))[0] = 242;
				((self_in_dispatchConcretize->machineCode))[1] = 15;
				((self_in_dispatchConcretize->machineCode))[2] = 17;
				((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, destReg12, srcReg10));
				((self_in_dispatchConcretize->machineCode))[4] = (offset13 & 0xFF);
				((self_in_dispatchConcretize->machineCodeSize) = 5);
				return;
			}
			((self_in_dispatchConcretize->machineCode))[0] = 242;
			((self_in_dispatchConcretize->machineCode))[1] = 15;
			((self_in_dispatchConcretize->machineCode))[2] = 17;
			((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, destReg12, srcReg10));
			((self_in_dispatchConcretize->machineCode))[4] = (offset13 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) offset13) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset13) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[7] = ((((usqInt) offset13) >> 24) & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 8);
			return;
		}
		if (isQuick(self_in_dispatchConcretize, offset13)) {
			((self_in_dispatchConcretize->machineCode))[0] = 242;
			((self_in_dispatchConcretize->machineCode))[1] = 15;
			((self_in_dispatchConcretize->machineCode))[2] = 17;
			((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp8, destReg12, srcReg10));
			((self_in_dispatchConcretize->machineCode))[4] = (sib(self_in_dispatchConcretize, SIB1, 4, destReg12));
			((self_in_dispatchConcretize->machineCode))[5] = (offset13 & 0xFF);
			((self_in_dispatchConcretize->machineCodeSize) = 6);
			return;
		}
		((self_in_dispatchConcretize->machineCode))[0] = 242;
		((self_in_dispatchConcretize->machineCode))[1] = 15;
		((self_in_dispatchConcretize->machineCode))[2] = 17;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModRegRegDisp32, destReg12, srcReg10));
		((self_in_dispatchConcretize->machineCode))[4] = (sib(self_in_dispatchConcretize, SIB1, 4, destReg12));
		((self_in_dispatchConcretize->machineCode))[5] = (offset13 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) offset13) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[7] = ((((usqInt) offset13) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[8] = ((((usqInt) offset13) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 9);
		return;

	case PopR:
		/* begin concretizePopR */
		((self_in_dispatchConcretize->machineCode))[0] = (88 + (concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0])));
		((self_in_dispatchConcretize->machineCodeSize) = 1);
		return;

	case PushR:
		/* begin concretizePushR */
		((self_in_dispatchConcretize->machineCode))[0] = (80 + (concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0])));
		((self_in_dispatchConcretize->machineCodeSize) = 1);
		return;

	case PushCw:
		/* begin concretizePushCw */
		value10 = ((self_in_dispatchConcretize->operands))[0];
		((self_in_dispatchConcretize->machineCode))[0] = 104;
		((self_in_dispatchConcretize->machineCode))[1] = (value10 & 0xFF);
		((self_in_dispatchConcretize->machineCode))[2] = ((((usqInt) value10) >> 8) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[3] = ((((usqInt) value10) >> 16) & 0xFF);
		((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) value10) >> 24) & 0xFF);
		((self_in_dispatchConcretize->machineCodeSize) = 5);
		return;

	case PrefetchAw:
		/* begin concretizePrefetchAw */
		(self_in_dispatchConcretize->machineCodeSize) = (self_in_dispatchConcretize->maxSize);
		if (((self_in_dispatchConcretize->maxSize)) > 0) {
			addressOperand4 = ((self_in_dispatchConcretize->operands))[0];
			((self_in_dispatchConcretize->machineCode))[0] = 15;
			((self_in_dispatchConcretize->machineCode))[1] = 24;
			((self_in_dispatchConcretize->machineCode))[2] = (modRMRO(self_in_dispatchConcretize, 0, 5, 1));
			((self_in_dispatchConcretize->machineCode))[3] = (addressOperand4 & 0xFF);
			((self_in_dispatchConcretize->machineCode))[4] = ((((usqInt) addressOperand4) >> 8) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[5] = ((((usqInt) addressOperand4) >> 16) & 0xFF);
			((self_in_dispatchConcretize->machineCode))[6] = ((((usqInt) addressOperand4) >> 24) & 0xFF);
		}
		(self_in_dispatchConcretize->maxSize);
		return;

	case ConvertRRd:
		/* begin concretizeConvertRRd */
		srcReg11 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		destReg13 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = 242;
		((self_in_dispatchConcretize->machineCode))[1] = 15;
		((self_in_dispatchConcretize->machineCode))[2] = 42;
		((self_in_dispatchConcretize->machineCode))[3] = (modRMRO(self_in_dispatchConcretize, ModReg, srcReg11, destReg13));
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	default:
		error("Case not found and no otherwise clause");
	}
	return;
}


/*	Replaces the Blue Book double-extended send [132], in which the first byte
	was wasted on 8 bits of argument count. 
	Here we use 3 bits for the operation sub-type (opType), and the remaining
	5 bits for argument count where needed. 
	The last byte give access to 256 instVars or literals. 
	See also secondExtendedSendBytecode
 */

static sqInt
doubleExtendedDoAnythingBytecode(void)
{
	// StackToRegisterMappingCogit>>#doubleExtendedDoAnythingBytecode
    AbstractInstruction *abstractInstruction;
    sqInt opType;

	opType = ((usqInt) byte1) >> 5;
	if (opType == 0) {
return genSendnumArgs(getLiteral(byte2), byte1 & 0x1F);
	}
	if (opType == 1) {
return genSendSupernumArgs(getLiteral(byte2), byte1 & 0x1F);
	}
	
	switch (opType) {
	case 2:
		if (isReadMediatedContextInstVarIndex(byte2)) {
			genPushMaybeContextReceiverVariable(byte2);
		}
		else {
genPushReceiverVariable(byte2);
			((ssTop())->annotateUse = 1);
			return 0;
		}
		break;
	case 3:
		genPushLiteralIndex(byte2);
		((ssTop())->annotateUse = 1);
		return 0;

	case 4:
		genPushLiteralVariable(byte2);
		break;
	case 7:
		genStorePopLiteralVariable(0, byte2);
		break;
	default:
		
		/* 5 & 6 */

if (isWriteMediatedContextInstVarIndex(byte2)) {

			/* 5 & 6 */

genStorePopMaybeContextReceiverVariable(opType == 6, byte2);
		}
		else {
genStorePopReceiverVariable(opType == 6, byte2);
		}

	}
	assert(needsFrame);
	assert(!(prevInstIsPCAnnotated()));
	/* begin annotateBytecode: */
	/* begin Label */
	abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	annotatewith(abstractInstruction, HasBytecodePC);
	return 0;
}

static sqInt
duplicateTopBytecode(void)
{
	// StackToRegisterMappingCogit>>#duplicateTopBytecode
    CogSimStackEntry desc;

	desc = ssTopDescriptor();
	return ssPushDesc(desc);
}

static sqInt
endPCOf(sqInt aMethod)
{
	// Cogit>>#endPCOf:
    sqInt bsOffset;
    sqInt byte;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt end;
    sqInt latestContinuation;
    sqInt nExts;
    sqInt pc;
    sqInt prim;
    sqInt targetPC;

	pc = (latestContinuation = startPCOfMethod(aMethod));
	if (((prim = primitiveIndexOf(aMethod))) > 0) {
		if (isQuickPrimitiveIndex(prim)) {
			return pc - 1;
		}
	}
	bsOffset = 0;
	nExts = 0;
	end = byteLengthOf(aMethod);
	while (pc <= end) {
byte = fetchByteofObject(pc, aMethod);
		descriptor = generatorAt(byte + bsOffset);
		if (((descriptor->isReturn))
		 && (pc >= latestContinuation)) {
			end = pc;
		}
		if ((isBranch(descriptor))
		 || ((descriptor->isBlockCreation))) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, aMethod);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
			if ((descriptor->isBlockCreation)) {
				pc += distance;
			}
		}
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
		pc += (descriptor->numBytes);
	}
	return end;
}


/*	Make sure there's a flagged fixup at the targetIndex (pc relative to first
	pc) in fixups.
	Initially a fixup's target is just a flag. Later on it is replaced with a
	proper instruction. */

static BytecodeFixup *
ensureFixupAt(sqInt targetIndex)
{
	// StackToRegisterMappingCogit>>#ensureFixupAt:
    BytecodeFixup *fixup;

	fixup = fixupAt(targetIndex);
	traceFixup(fixup);
	
if ((((usqInt)((fixup->targetInstruction)))) <= 1) {

		/* convert a non-merge into a merge */

(fixup->targetInstruction = ((AbstractInstruction *) 2));
		(fixup->simStackPtr = simStackPtr);
	}
	else {
if (((fixup->simStackPtr)) <= -2) {

			/* this is the target of a backward branch and
			   so doesn't have a simStackPtr assigned yet. */

			(fixup->simStackPtr = simStackPtr);
		}
		else {
assert(((fixup->simStackPtr)) == simStackPtr);
		}
	}
	return fixup;
}


/*	Make sure there's a flagged fixup at the targetIndex (pc relative to first
	pc) in fixups.
	Initially a fixup's target is just a flag. Later on it is replaced with a
	proper instruction. */

static BytecodeFixup *
ensureNonMergeFixupAt(sqInt targetIndex)
{
	// StackToRegisterMappingCogit>>#ensureNonMergeFixupAt:
    BytecodeFixup *fixup;

	fixup = fixupAt(targetIndex);
	if (((fixup->targetInstruction)) == 0) {
		(fixup->targetInstruction = ((AbstractInstruction *) 1));
	}
	
return fixup;
}

static void
ensureReceiverResultRegContainsSelf(void)
{
	// StackToRegisterMappingCogit>>#ensureReceiverResultRegContainsSelf
	if (needsFrame) {
		if (!(((optStatus.isReceiverResultRegLive))
			 && (((optStatus.ssEntry)) == ((&simSelf))))) {
			ssAllocateRequiredReg(ReceiverResultReg);
			storeToReg((&simSelf), ReceiverResultReg);
		}
		(optStatus.isReceiverResultRegLive = 1);
		(optStatus.ssEntry = (&simSelf));
	}
	else {
assert((((simSelf.type)) == SSRegister)
		 && (((simSelf.registerr)) == ReceiverResultReg));
		assert(((optStatus.isReceiverResultRegLive))
		 && (((optStatus.ssEntry)) == ((&simSelf))));
	}
}

static CogSimStackEntry *
ensureSpilledAtfrom(CogSimStackEntry * self_in_ensureSpilledAtfrom, sqInt baseOffset, sqInt baseRegister)
{
	// CogSimStackEntry>>#ensureSpilledAt:from:
    sqInt baseReg;
    AbstractInstruction *inst;
    sqInt offset;
    sqInt reg;

	if ((self_in_ensureSpilledAtfrom->spilled)) {
		if (((self_in_ensureSpilledAtfrom->type)) == SSSpill) {
			assert((((self_in_ensureSpilledAtfrom->offset)) == baseOffset)
			 && (((self_in_ensureSpilledAtfrom->registerr)) == baseRegister));
			return self_in_ensureSpilledAtfrom;
		}
	}
	assert(((self_in_ensureSpilledAtfrom->type)) != SSSpill);
	traceSpill(self_in_ensureSpilledAtfrom);
	if (((self_in_ensureSpilledAtfrom->type)) == SSConstant) {
		inst = annotateobjRef(gPushCw((self_in_ensureSpilledAtfrom->constant)), (self_in_ensureSpilledAtfrom->constant));
	}
	else {
if (((self_in_ensureSpilledAtfrom->type)) == SSBaseOffset) {
			/* begin MoveMw:r:R: */
			offset = (self_in_ensureSpilledAtfrom->offset);
			baseReg = (self_in_ensureSpilledAtfrom->registerr);
			genoperandoperandoperand(MoveMwrR, offset, baseReg, TempReg);
			/* begin PushR: */
			inst = genoperand(PushR, TempReg);
		}
		else {
assert(((self_in_ensureSpilledAtfrom->type)) == SSRegister);
			/* begin PushR: */
			reg = (self_in_ensureSpilledAtfrom->registerr);
			inst = genoperand(PushR, reg);
		}
		(self_in_ensureSpilledAtfrom->type) = SSSpill;
		(self_in_ensureSpilledAtfrom->offset) = baseOffset;
		(self_in_ensureSpilledAtfrom->registerr) = baseRegister;
	}
	(self_in_ensureSpilledAtfrom->spilled) = 1;
	if ((self_in_ensureSpilledAtfrom->annotateUse)) {
		/* begin annotateBytecode: */
		annotatewith(inst, HasBytecodePC);
		(self_in_ensureSpilledAtfrom->annotateUse) = 0;
	}
	return self_in_ensureSpilledAtfrom;
}


/*	This is a static version of ceEnterCogCodePopReceiverReg
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

void
enterCogCodePopReceiver(void)
{
	// Cogit>>#enterCogCodePopReceiver
	realCEEnterCogCodePopReceiverReg();
	error("what??");

}


/*	This is a static version of ceEnterCogCodePopReceiverAndClassRegs
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

void
enterCogCodePopReceiverAndClassRegs(void)
{
	// Cogit>>#enterCogCodePopReceiverAndClassRegs
	realCEEnterCogCodePopReceiverAndClassRegs();
}


/*	This is a static version of ceEnterCogCodePopReceiverArg0Regs
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

void
enterCogCodePopReceiverArg0Regs(void)
{
	// StackToRegisterMappingCogit>>#enterCogCodePopReceiverArg0Regs
	realCEEnterCogCodePopReceiverArg0Regs();
}


/*	This is a static version of ceEnterCogCodePopReceiverArg1Arg0Regs
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

void
enterCogCodePopReceiverArg1Arg0Regs(void)
{
	// StackToRegisterMappingCogit>>#enterCogCodePopReceiverArg1Arg0Regs
	realCEEnterCogCodePopReceiverArg1Arg0Regs();
}

static void
evaluateat(BytecodeDescriptor *descriptor, sqInt pc)
{
	// StackToRegisterMappingCogit>>#evaluate:at:
	byte0 = fetchByteofObject(pc, methodObj);
	assert(descriptor == (generatorAt(bytecodeSetOffset + byte0)));
	loadSubsequentBytesForDescriptorat(descriptor, pc);
	((descriptor->generator))();
}

static sqInt
extendedPushBytecode(void)
{
	// SimpleStackBasedCogit>>#extendedPushBytecode
    sqInt variableIndex;
    sqInt variableType;

	variableType = (((usqInt) byte1) >> 6) & 3;
	variableIndex = byte1 & 0x3F;
	if (variableType == 0) {
return genPushReceiverVariable(variableIndex);
	}
	if (variableType == 1) {
return genPushTemporaryVariable(variableIndex);
	}
	if (variableType == 2) {
return genPushLiteralIndex(variableIndex);
	}
	return genPushLiteralVariable(variableIndex);
}

static sqInt
extendedStoreAndPopBytecode(void)
{
	// SimpleStackBasedCogit>>#extendedStoreAndPopBytecode
    sqInt variableIndex;
    sqInt variableType;

	variableType = (((usqInt) byte1) >> 6) & 3;
	variableIndex = byte1 & 0x3F;
	if (variableType == 0) {
return genStorePopReceiverVariable(1, variableIndex);
	}
	if (variableType == 1) {
return genStorePopTemporaryVariable(1, variableIndex);
	}
	if (variableType == 3) {
return genStorePopLiteralVariable(1, variableIndex);
	}
	return EncounteredUnknownBytecode;
}

static sqInt
extendedStoreBytecode(void)
{
	// SimpleStackBasedCogit>>#extendedStoreBytecode
    sqInt variableIndex;
    sqInt variableType;

	variableType = (((usqInt) byte1) >> 6) & 3;
	variableIndex = byte1 & 0x3F;
	if (variableType == 0) {
return genStorePopReceiverVariable(0, variableIndex);
	}
	if (variableType == 1) {
return genStorePopTemporaryVariable(0, variableIndex);
	}
	if (variableType == 3) {
return genStorePopLiteralVariable(0, variableIndex);
	}
	return EncounteredUnknownBytecode;
}


/*	Fill in the block headers now we know the exact layout of the code. */

static sqInt
fillInBlockHeadersAt(sqInt startAddress)
{
	// Cogit>>#fillInBlockHeadersAt:
    CogBlockMethod *blockHeader;
    BlockStart *blockStart;
    sqInt i;

	if (!(needsFrame
		 && (blockCount > 0))) {
		return null;
	}
	if (blockNoContextSwitchOffset == null) {
		blockNoContextSwitchOffset = ((blockEntryLabel->address)) - ((blockEntryNoContextSwitch->address));
	}
	else {
assert(blockNoContextSwitchOffset == (((blockEntryLabel->address)) - ((blockEntryNoContextSwitch->address))));
	}
	for (i = 0; i < blockCount; i += 1) {
		blockStart = blockStartAt(i);
		blockHeader = ((CogBlockMethod *) ((((blockStart->fakeHeader))->address)));
		(blockHeader->homeOffset = ((((blockStart->fakeHeader))->address)) - startAddress);
		(blockHeader->startpc = (blockStart->startpc));
		(blockHeader->cmType = CMBlock);
		(blockHeader->cmNumArgs = (blockStart->numArgs));
		(blockHeader->stackCheckOffset = (((blockStart->stackCheckLabel)) == null
			? 0
			: ((((blockStart->stackCheckLabel))->address)) - ((((blockStart->fakeHeader))->address))));
	}
}

static CogMethod *
fillInCPICHeadersizenumArgsnumCaseshasMNUCaseselector(CogMethod *pic, sqInt size, sqInt numArgs, sqInt numCases, sqInt hasMNUCase, sqInt selector)
{
	// Cogit>>#fillInCPICHeader:size:numArgs:numCases:hasMNUCase:selector:
	assert(!(isYoung(selector)));
	(pic->cmType = CMClosedPIC);
	(pic->objectHeader = 0);
	(pic->blockSize = size);
	(pic->methodObject = 0);
	(pic->methodHeader = 0);
	(pic->selector = selector);
	(pic->cmNumArgs = numArgs);
	(pic->cmRefersToYoung = 0);
	(pic->cmUsageCount = initialClosedPICUsageCount());
	(pic->cpicHasMNUCase = hasMNUCase);
	(pic->cPICNumCases = numCases);
	(pic->blockEntryOffset = 0);
	assert(((pic->cmType)) == CMClosedPIC);
	assert(((pic->selector)) == selector);
	assert(((pic->cmNumArgs)) == numArgs);
	assert(((pic->cPICNumCases)) == numCases);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)pic)) + missOffset)) == (picAbortTrampolineFor(numArgs)));
	assert(size == (roundUpLength(size)));
	return pic;
}

static CogMethod *
fillInMethodHeadersizeselector(CogMethod *method, sqInt size, sqInt selector)
{
	// Cogit>>#fillInMethodHeader:size:selector:
    sqInt methodHeader;
    CogMethod *originalMethod;

	(method->cmType = CMMethod);
	(method->objectHeader = nullHeaderForMachineCodeMethod());
	(method->blockSize = size);
	(method->methodObject = methodObj);

	/* If the method has already been cogged (e.g. Newspeak accessors) then
	   leave the original method attached to its cog method, but get the right header. */

	methodHeader = rawHeaderOf(methodObj);
	if (isCogMethodReference(methodHeader)) {
		originalMethod = ((CogMethod *) methodHeader);
		assert(((originalMethod->blockSize)) == size);
		methodHeader = (originalMethod->methodHeader);
		
	}
	else {
rawHeaderOfput(methodObj, ((sqInt)method));
	}
	(method->methodHeader = methodHeader);
	(method->selector = selector);
	(method->cmNumArgs = argumentCountOfMethodHeader(methodHeader));
	if ((method->cmRefersToYoung = hasYoungReferent)) {
		addToYoungReferrers(method);
	}
	(method->cmUsageCount = initialMethodUsageCount());
	(method->cpicHasMNUCase = 0);
	(method->cmUsesPenultimateLit = maxLitIndex >= ((literalCountOfHeader(methodHeader)) - 2));
	(method->cmUsesMethodClass = usesMethodClass);
	(method->blockEntryOffset = (blockEntryLabel != null
		? ((blockEntryLabel->address)) - (((sqInt)method))
		: 0));
	if (needsFrame) {
		if (!((((stackCheckLabel->address)) - (((sqInt)method))) <= MaxStackCheckOffset)) {
			error("too much code for stack check offset");
		}
	}
	(method->stackCheckOffset = (needsFrame
		? ((stackCheckLabel->address)) - (((sqInt)method))
		: 0));
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)method)) + missOffset)) == (methodAbortTrampolineFor((method->cmNumArgs))));
	assert(size == (roundUpLength(size)));
	return method;
}

static CogMethod *
fillInOPICHeadersizenumArgsselector(CogMethod *pic, sqInt size, sqInt numArgs, sqInt selector)
{
	// Cogit>>#fillInOPICHeader:size:numArgs:selector:
	(pic->cmType = CMOpenPIC);
	(pic->objectHeader = 0);
	(pic->blockSize = size);
	addToOpenPICList(pic);
	(pic->methodHeader = 0);
	(pic->selector = selector);
	(pic->cmNumArgs = numArgs);
	if ((pic->cmRefersToYoung = isYoung(selector))) {
		addToYoungReferrers(pic);
	}
	(pic->cmUsageCount = initialOpenPICUsageCount());
	(pic->cpicHasMNUCase = 0);
	(pic->cPICNumCases = 0);
	(pic->blockEntryOffset = 0);
	assert(((pic->cmType)) == CMOpenPIC);
	assert(((pic->selector)) == selector);
	assert(((pic->cmNumArgs)) == numArgs);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)pic)) + missOffset)) == (picAbortTrampolineFor(numArgs)));
	assert(size == (roundUpLength(size)));
	return pic;
}

static usqInt
findBlockMethodWithEntrystartBcpc(sqInt blockEntryMcpc, sqInt startBcpc)
{
	// Cogit>>#findBlockMethodWithEntry:startBcpc:
    CogBlockMethod *cogBlockMethod;

	cogBlockMethod = ((CogBlockMethod *) (blockEntryMcpc - (sizeof(CogBlockMethod))));
	if (((cogBlockMethod->startpc)) == startBcpc) {
		return ((usqInt)cogBlockMethod);
	}
	return 0;
}

static sqInt
findMapLocationForMcpcinMethod(sqInt targetMcpc, CogMethod *cogMethod)
{
	// Cogit>>#findMapLocationForMcpc:inMethod:
    sqInt annotation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;

	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	if (mcpc == targetMcpc) {
return map;
	}
	while (((mapByte = byteAt(map))) != MapEnd) {
		annotation = ((usqInt) mapByte) >> AnnotationShift;
		mcpc += (annotation == IsDisplacementX2N
			? (mapByte - DisplacementX2N) << AnnotationShift
			: mapByte & DisplacementMask);
		if (mcpc >= targetMcpc) {
assert(mcpc == targetMcpc);
			return map;
		}
		map -= 1;
	}
	return 0;
}


/*	Find the CMMethod or CMBlock that has zero-relative startbcpc as its first
	bytecode pc.
	As this is for cannot resume processing and/or conversion to machine-code
	on backward
	branch, it doesn't have to be fast. Enumerate block returns and map to
	bytecode pcs. */

CogBlockMethod *
findMethodForStartBcpcinHomeMethod(sqInt startbcpc, CogMethod *cogMethod)
{
	// Cogit>>#findMethodForStartBcpc:inHomeMethod:
	assert(((cogMethod->cmType)) == CMMethod);
	if (startbcpc == (startPCOfMethodHeader((cogMethod->methodHeader)))) {
		return ((CogBlockMethod *) cogMethod);
	}
	assert(((cogMethod->blockEntryOffset)) != 0);
	return ((CogBlockMethod *) (blockDispatchTargetsForperformarg(cogMethod, findBlockMethodWithEntrystartBcpc, startbcpc)));
}


/*	Machine code addresses map to the following bytecode for all bytecodes
	except backward branches, where they map to the backward branch itself.
	This is so that loops continue, rather than terminate prematurely. */

static sqInt
findIsBackwardBranchMcpcBcpcMatchingMcpc(BytecodeDescriptor *descriptor, sqInt isBackwardBranch, char *mcpc, sqInt bcpc, void *targetMcpc)
{
	// Cogit>>#find:IsBackwardBranch:Mcpc:Bcpc:MatchingMcpc:
	return (targetMcpc == mcpc
		? ((descriptor == null)
			 || (isBackwardBranch)
				? bcpc
				: bcpc + ((descriptor->numBytes)))
		: 0);
}

static sqInt
frameOffsetOfTemporary(sqInt index)
{
	// SimpleStackBasedCogit>>#frameOffsetOfTemporary:
	return (index < methodOrBlockNumArgs
		? FoxCallerSavedIP + ((methodOrBlockNumArgs - index) * BytesPerWord)
		: (FoxMFReceiver - BytesPerWord) + ((methodOrBlockNumArgs - index) * BytesPerWord));
}

static void
freeMethod(CogMethod *cogMethod)
{
	// CogMethodZone>>#freeMethod:
	assert(((cogMethod->cmType)) != CMFree);
	assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
	if (((cogMethod->cmType)) == CMMethod) {

		/* For non-Newspeak there should ne a one-to-one mapping between bytecoded and
		   cog methods.  For Newspeak not necessarily, but only for anonymous accessors. */
		/* Only reset the original method's header if it is referring to this CogMethod. */

if ((((sqInt)(rawHeaderOf((cogMethod->methodObject))))) == (((sqInt)cogMethod))) {

			/* For non-Newspeak there should ne a one-to-one mapping between bytecoded and
			   cog methods.  For Newspeak not necessarily, but only for anonymous accessors. */
			/* Only reset the original method's header if it is referring to this CogMethod. */

rawHeaderOfput((cogMethod->methodObject), (cogMethod->methodHeader));
		}
		else {
assert((noAssertMethodClassAssociationOf((cogMethod->methodObject))) == (nilObject()));
			
		}
		(cogMethod->cmRefersToYoung = 0);
	}
	if (((cogMethod->cmType)) == CMOpenPIC) {
		removeFromOpenPICList(cogMethod);
		(cogMethod->cmRefersToYoung = 0);
	}
	(cogMethod->cmType = CMFree);
	methodBytesFreedSinceLastCompaction += (cogMethod->blockSize);
}


/*	Free methods, preferring older methods for compaction, up to some
	fraction. 
 */

static void
freeOlderMethodsForCompaction(void)
{
	// CogMethodZone>>#freeOlderMethodsForCompaction
    sqInt amountToFree;
    sqInt cascade0;
    sqInt cascade1;
    CogMethod *cogMethod;
    sqInt freeableUsage;
    sqInt freedSoFar;
    sqInt initialFreeSpace;
    sqInt zoneSize;

	zoneSize = limitAddress - baseAddress;
	initialFreeSpace = (limitAddress - mzFreeStart) + methodBytesFreedSinceLastCompaction;
	freedSoFar = initialFreeSpace;

	/* 4 needs to be e.g. a start-up parameter */

amountToFree = ((sqInt) zoneSize >> 2);
	freeableUsage = 0;
	do {
;
		cogMethod = ((CogMethod *) baseAddress);
		while (((((usqInt)cogMethod)) < mzFreeStart)
		 && (freedSoFar < amountToFree)) {
			if ((((cogMethod->cmType)) != CMFree)
			 && (((cogMethod->cmUsageCount)) <= freeableUsage)) {
				freeMethod(cogMethod);
				freedSoFar += (cogMethod->blockSize);
			}
			cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		}
	} while((freedSoFar < amountToFree)
		 && (((freeableUsage += 1)) < CMMaxUsageCount));
	
}

static void
freePICsWithFreedTargets(void)
{
	// Cogit>>#freePICsWithFreedTargets
    CogMethod *cogMethod;
    sqInt count;

	cogMethod = ((CogMethod *) methodZoneBase);
	count = 0;
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMClosedPIC)
		 && (cPICHasFreedTargets(cogMethod))) {
			(cogMethod->cmType = CMFree);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		count += 1;
	}
	assert(count == (numMethods()));
}


/*	Free machine-code methods whose compiled methods are unmarked
	and open PICs whose selectors are not marked. */

void
freeUnmarkedMachineCode(void)
{
	// Cogit>>#freeUnmarkedMachineCode
    CogMethod *cogMethod;
    sqInt freedMethod;

	freedMethod = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMMethod)
		 && (!(isMarked((cogMethod->methodObject))))) {
			freedMethod = 1;
			freeMethod(cogMethod);
		}
		if ((((cogMethod->cmType)) == CMOpenPIC)
		 && ((!(isImmediate((cogMethod->selector))))
		 && (!(isMarked((cogMethod->selector)))))) {
			freedMethod = 1;
			freeMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freedMethod) {
unlinkSendsToFree();
		pruneYoungReferrers();
		flushICacheFromto(processor, codeBase, ((sqInt)(limitZony())));
	}
}


/*	Short-circuit the interpreter call if a frame is already married. */

static sqInt
genActiveContextTrampoline(void)
{
	// CogObjectRepresentationForSqueakV3>>#genActiveContextTrampoline
    AbstractInstruction *jumpSingle;

	zeroOpcodeIndex();
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, FoxMethod, FPReg, TempReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, MFMethodFlagHasContextFlag, TempReg);
	/* begin JumpZero: */
	jumpSingle = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, FoxThisContext, FPReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpSingle, gLabel());
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceActiveContext, "ceActiveContextTrampoline", 0, null, null, null, null, 0, 1, ReceiverResultReg, 1);
}

static sqInt
genAddSmallIntegerTagsTo(sqInt aRegister)
{
	// CogObjectRepresentationForSqueakV3>>#genAddSmallIntegerTagsTo:
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, 1, aRegister);
	return 0;
}

static sqInt
genAlignCStackSavingRegistersnumArgswordAlignment(AbstractInstruction * self_in_genAlignCStackSavingRegistersnumArgswordAlignment, sqInt saveRegs, sqInt numArgs, sqInt alignment)
{
	// CogAbstractInstruction>>#genAlignCStackSavingRegisters:numArgs:wordAlignment:
    sqInt delta;
    sqInt wordsPushedModAlignment;

	wordsPushedModAlignment = (((saveRegs
	? numberOfSaveableRegisters(self_in_genAlignCStackSavingRegistersnumArgswordAlignment)
	: 0)) + numArgs) % alignment;
	if (wordsPushedModAlignment != 0) {
delta = alignment - wordsPushedModAlignment;
		/* begin SubCq:R: */
		genoperandoperand(SubCqR, delta * 4, SPReg);
	}
	return 0;
}

static AbstractInstruction *
genAllocFloatValueintoscratchRegscratchReg(sqInt dpreg, sqInt resultReg, sqInt scratch1, sqInt scratch2)
{
	// CogObjectRepresentationForSqueakV3>>#genAllocFloatValue:into:scratchReg:scratchReg:
    sqInt address;
    sqInt address1;
    sqInt address2;
    sqInt allocSize;
    AbstractInstruction *jumpFail;
    sqInt newFloatHeaderSansHash;

	allocSize = BaseHeaderSize + (sizeof(double));
	newFloatHeaderSansHash = ((((classFloatCompactIndex()) << (compactClassFieldLSB())) | (formatOfClass(classFloat()))) | allocSize) | HeaderTypeShort;
	/* begin MoveAw:R: */
	address = freeStartAddress();
	genoperandoperand(MoveAwR, address, resultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, resultReg, scratch1);
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, allocSize, scratch1);
	/* begin MoveAw:R: */
	address1 = scavengeThresholdAddress();
	genoperandoperand(MoveAwR, address1, scratch2);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, scratch2, scratch1);
	/* begin JumpAboveOrEqual: */
	jumpFail = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, resultReg, scratch2);
	flag("newObjectHash");
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, HashMaskUnshifted << BytesPerWord, scratch2);
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, HashBitsOffset - BytesPerWord, scratch2);
	/* begin OrCq:R: */
	genoperandoperand(OrCqR, newFloatHeaderSansHash, scratch2);
	/* begin MoveR:Mw:r: */
	genoperandoperandoperand(MoveRMwr, scratch2, 0, resultReg);
	/* begin MoveRd:M64:r: */
	genoperandoperandoperand(MoveRdM64r, dpreg, BaseHeaderSize, resultReg);
	/* begin MoveR:Aw: */
	address2 = freeStartAddress();
	genoperandoperand(MoveRAw, scratch1, address2);
	return jumpFail;
}

static sqInt
genCheckForInterruptsTrampoline(void)
{
	// Cogit>>#genCheckForInterruptsTrampoline
    sqInt address;
    sqInt address1;

	opcodeIndex = 0;
	/* begin PopR: */
	genoperand(PopR, TempReg);
	/* begin MoveR:Aw: */
	address1 = instructionPointerAddress();
	genoperandoperand(MoveRAw, TempReg, address1);

	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceCheckForInterrupts, "ceCheckForInterruptsTrampoline", 0, null, null, null, null, 0, 0, null, 1);
}

static sqInt
genConvertIntegerToSmallIntegerInReg(sqInt reg)
{
	// CogObjectRepresentationForSqueakV3>>#genConvertIntegerToSmallIntegerInReg:
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, 1, reg);
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, 1, reg);
	return 0;
}

static sqInt
genConvertIntegerToSmallIntegerInScratchReg(sqInt scratchReg)
{
	// CogObjectRepresentationForSqueakV3>>#genConvertIntegerToSmallIntegerInScratchReg:
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, 1, scratchReg);
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, 1, scratchReg);
	return 0;
}

static sqInt
genConvertSmallIntegerToIntegerInReg(sqInt reg)
{
	// CogObjectRepresentationForSqueakV3>>#genConvertSmallIntegerToIntegerInReg:
	/* begin ArithmeticShiftRightCq:R: */
	genoperandoperand(ArithmeticShiftRightCqR, 1, reg);
	return 0;
}


/*	Create a closure with the given startpc, numArgs and numCopied
	within a context with ctxtNumArgs, large if isLargeCtxt that is in a
	block if isInBlock. If numCopied > 0 pop those values off the stack. */
/*	see ceClosureCopyDescriptor: */

static sqInt
genCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock)
{
	// CogObjectRepresentationForSqueakV3>>#genCreateClosureAt:numArgs:numCopied:contextNumArgs:large:inBlock:
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, (numArgs + (numCopied << 6)) + (bcpc << 12), SendNumArgsReg);
	CallRT(ceClosureCopyTrampoline);
	if (numCopied > 0) {
/* begin AddCq:R: */
		genoperandoperand(AddCqR, numCopied * BytesPerWord, SPReg);
	}
	return 0;
}

static AbstractInstruction *
genDivRRQuoRem(AbstractInstruction * self_in_genDivRRQuoRem, sqInt abstractRegDivisor, sqInt abstractRegDividend, sqInt abstractRegQuotient, sqInt abstractRegRemainder)
{
	// CogIA32Compiler>>#genDivR:R:Quo:Rem:
    sqInt rDividend;
    sqInt rDivisor;
    sqInt reg;
    sqInt rQuotient;
    sqInt rRemainder;
    sqInt rUnused;
    sqInt saveRestoreEAX;
    sqInt saveRestoreEDX;
    sqInt saveRestoreExchanged;

	assert(abstractRegDividend != abstractRegDivisor);
	assert(abstractRegQuotient != abstractRegRemainder);
	rDividend = concreteRegister(self_in_genDivRRQuoRem, abstractRegDividend);
	rDivisor = concreteRegister(self_in_genDivRRQuoRem, abstractRegDivisor);
	rQuotient = concreteRegister(self_in_genDivRRQuoRem, abstractRegQuotient);

	/* IDIV r does a signed divide of EDX:EAX by r, EAX := Quotient, EDX := Remainder.
	   Since we must sign extend the dividend into EDX we must substitute another register if EDX is an input */

	rRemainder = concreteRegister(self_in_genDivRRQuoRem, abstractRegRemainder);
	if ((rDividend == EDX)
	 || (rDivisor == EDX)) {

		/* Slang, sigh... */


		/* Slang, sigh... */

rUnused = EAX;
		while (rUnused <= EDI) {
if ((rUnused != ESP)
			 && ((rUnused != EBP)
			 && ((rUnused != EDX)
			 && ((rUnused != rDividend)
			 && ((rUnused != rDivisor)
			 && ((rUnused != rQuotient)
			 && (rUnused != rRemainder))))))) {
				/* begin PushR: */
				genoperand(PushR, rUnused);
				/* begin MoveR:R: */
				genoperandoperand(MoveRR, EDX, rUnused);
				if (rDividend == EDX) {
genDivRRQuoRem(self_in_genDivRRQuoRem, rDivisor, rUnused, rQuotient, rRemainder);
				}
				else {
genDivRRQuoRem(self_in_genDivRRQuoRem, rUnused, rDividend, rQuotient, rRemainder);
				}
				/* begin PopR: */
				genoperand(PopR, rUnused);
				return self_in_genDivRRQuoRem;
			}
			rUnused += 1;
		}
		error("couldn't find unused register in genDivR:R:Quo:Rem:");
	}
	if ((saveRestoreEAX = (rQuotient != EAX)
	 && (rRemainder != EAX))) {
		/* begin PushR: */
		genoperand(PushR, EAX);
	}
	if ((saveRestoreEDX = (rQuotient != EDX)
	 && (rRemainder != EDX))) {
		/* begin PushR: */
		genoperand(PushR, EDX);
	}
	saveRestoreExchanged = -1;
	if (rDividend != EAX) {
if (rDivisor == EAX) {
if (((rDividend != rQuotient)
			 && (rDividend != rRemainder))
			 && ((rDividend != EDX)
			 || (!saveRestoreEDX))) {
				/* begin PushR: */
				reg = (saveRestoreExchanged = rDividend);
				genoperand(PushR, reg);
			}
			genoperandoperand(XCHGRR, rDivisor, rDividend);
		}
		else {
/* begin MoveR:R: */
			genoperandoperand(MoveRR, rDividend, EAX);
		}
	}
	gen(CDQ);
	genoperand(IDIVR, (rDivisor == EAX
		? rDividend
		: rDivisor));
	if ((rQuotient == EDX)
	 && (rRemainder == EAX)) {
		genoperandoperand(XCHGRR, rQuotient, rRemainder);
	}
	else {
if (rQuotient == EDX) {
if (rRemainder != EDX) {
/* begin MoveR:R: */
				genoperandoperand(MoveRR, EDX, rRemainder);
			}
			if (rQuotient != EAX) {
/* begin MoveR:R: */
				genoperandoperand(MoveRR, EAX, rQuotient);
			}
		}
		else {
if (rQuotient != EAX) {
/* begin MoveR:R: */
				genoperandoperand(MoveRR, EAX, rQuotient);
			}
			if (rRemainder != EDX) {
/* begin MoveR:R: */
				genoperandoperand(MoveRR, EDX, rRemainder);
			}
		}
	}
	if (saveRestoreExchanged >= 0) {
/* begin PopR: */
		genoperand(PopR, saveRestoreExchanged);
	}
	if (saveRestoreEDX) {
/* begin PopR: */
		genoperand(PopR, EDX);
	}
	if (saveRestoreEAX) {
/* begin PopR: */
		genoperand(PopR, EAX);
	}
	return self_in_genDivRRQuoRem;
}


/*	Receiver and arg in registers.
	Stack looks like
	return address */

static sqInt
genDoubleArithmeticpreOpCheck(sqInt arithmeticOperator, AbstractInstruction *(*preOpCheckOrNil)(int rcvrReg, int argReg))
{
	// StackToRegisterMappingCogit>>#genDoubleArithmetic:preOpCheck:
    AbstractInstruction *doOp;
    AbstractInstruction *jumpFailAlloc;
    AbstractInstruction *jumpFailCheck;
    AbstractInstruction *jumpFailClass;
    AbstractInstruction *jumpImmediate;
    AbstractInstruction *jumpNonInt;
    sqInt quickConstant;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	genGetDoubleValueOfinto(ReceiverResultReg, DPFPReg0);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	jumpImmediate = genJumpImmediateInScratchReg(TempReg);
	genGetCompactClassIndexNonImmOfinto(Arg0Reg, SendNumArgsReg);
	/* begin CmpCq:R: */
	quickConstant = classFloatCompactIndex();
	genoperandoperand(CmpCqR, quickConstant, SendNumArgsReg);
	/* begin JumpNonZero: */
	jumpFailClass = genoperand(JumpNonZero, ((sqInt)0));
	genGetDoubleValueOfinto(Arg0Reg, DPFPReg1);
	/* begin Label */
	doOp = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	if (!(preOpCheckOrNil == null)) {
		jumpFailCheck = preOpCheckOrNil(DPFPReg0, DPFPReg1);
	}
	genoperandoperand(arithmeticOperator, DPFPReg1, DPFPReg0);
	jumpFailAlloc = genAllocFloatValueintoscratchRegscratchReg(DPFPReg0, SendNumArgsReg, ClassReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	jmpTarget(jumpFailClass, gLabel());
	if (!(preOpCheckOrNil == null)) {
		jmpTarget(jumpFailCheck, getJmpTarget(jumpFailClass));
	}
	genPushRegisterArgsForNumArgs(backEnd, methodOrBlockNumArgs);
	/* begin Jump: */
	jumpFailClass = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpImmediate, gLabel());
	
genConvertSmallIntegerToIntegerInReg(ClassReg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, ClassReg, DPFPReg1);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)doOp));
	jmpTarget(jumpFailAlloc, gLabel());
	compileFallbackToInterpreterPrimitive();
	jmpTarget(jumpFailClass, gLabel());
	
return 0;
}


/*	Receiver and arg in registers.
	Stack looks like
	return address */

static sqInt
genDoubleComparisoninvert(AbstractInstruction *(*jumpOpcodeGenerator)(void *), sqInt invertComparison)
{
	// StackToRegisterMappingCogit>>#genDoubleComparison:invert:
    AbstractInstruction *compare;
    AbstractInstruction *jumpCond;
    AbstractInstruction *jumpFail;
    AbstractInstruction *jumpImmediate;
    AbstractInstruction *jumpNonInt;
    sqInt quickConstant;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	genGetDoubleValueOfinto(ReceiverResultReg, DPFPReg0);
	jumpImmediate = genJumpImmediateInScratchReg(TempReg);
	genGetCompactClassIndexNonImmOfinto(Arg0Reg, SendNumArgsReg);
	/* begin CmpCq:R: */
	quickConstant = classFloatCompactIndex();
	genoperandoperand(CmpCqR, quickConstant, SendNumArgsReg);
	/* begin JumpNonZero: */
	jumpFail = genoperand(JumpNonZero, ((sqInt)0));
	genGetDoubleValueOfinto(Arg0Reg, DPFPReg1);
	if (invertComparison) {

		/* May need to invert for NaNs */

/* begin CmpRd:Rd: */
		compare = genoperandoperand(CmpRdRd, DPFPReg0, DPFPReg1);
	}
	else {
/* begin CmpRd:Rd: */
		compare = genoperandoperand(CmpRdRd, DPFPReg1, DPFPReg0);
	}

	/* FP jumps are a little weird */

jumpCond = jumpOpcodeGenerator(0);
	annotateobjRef(gMoveCwR(falseObject(), ReceiverResultReg), falseObject());
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpCond, annotateobjRef(gMoveCwR(trueObject(), ReceiverResultReg), trueObject()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpImmediate, gLabel());
	
genConvertSmallIntegerToIntegerInReg(Arg0Reg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, Arg0Reg, DPFPReg1);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)compare));
	jmpTarget(jumpFail, gLabel());
	
return 0;
}

static AbstractInstruction *
genDoubleFailIfZeroArgRcvrarg(sqInt rcvrReg, sqInt argReg)
{
	// SimpleStackBasedCogit>>#genDoubleFailIfZeroArgRcvr:arg:
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, 0, TempReg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, TempReg, DPFPReg2);
	/* begin CmpRd:Rd: */
	genoperandoperand(CmpRdRd, DPFPReg2, argReg);
	return gJumpFPEqual(0);
}


/*	An enilopmart (the reverse of a trampoline) is a piece of code that makes
	the system-call-like transition from the C runtime into generated machine
	code. The desired arguments and entry-point are pushed on a stackPage's
	stack. The enilopmart pops off the values to be loaded into registers and
	then executes a return instruction to pop off the entry-point and jump to
	it.  */

static void (*genEnilopmartForandandcalled(sqInt regArg1, sqInt regArg2, sqInt regArg3, char *trampolineName))(void)

{
	// Cogit>>#genEnilopmartFor:and:and:called:
    sqInt endAddress;
    sqInt enilopmart;
    sqInt size;

	opcodeIndex = 0;
	genLoadStackPointers(backEnd);
	/* begin PopR: */
	genoperand(PopR, regArg3);
	/* begin PopR: */
	genoperand(PopR, regArg2);
	/* begin PopR: */
	genoperand(PopR, regArg1);
	
/* begin RetN: */
	genoperand(RetN, 0);
	computeMaximumSizes();
	size = generateInstructionsAt(methodZoneBase);
	endAddress = outputInstructionsAt(methodZoneBase);
	assert((methodZoneBase + size) == endAddress);
	enilopmart = methodZoneBase;
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	nopsFromto(backEnd, endAddress, methodZoneBase - 1);
	recordGeneratedRunTimeaddress(trampolineName, enilopmart);
	return ((void (*)(void)) enilopmart);
}


/*	An enilopmart (the reverse of a trampoline) is a piece of code that makes
	the system-call-like transition from the C runtime into generated machine
	code. The desired arguments and entry-point are pushed on a stackPage's
	stack. The enilopmart pops off the values to be loaded into registers and
	then executes a return instruction to pop off the entry-point and jump to
	it.  */

static void (*genEnilopmartForandcalled(sqInt regArg1, sqInt regArg2, char *trampolineName))(void)

{
	// Cogit>>#genEnilopmartFor:and:called:
    sqInt endAddress;
    sqInt enilopmart;
    sqInt size;

	opcodeIndex = 0;
	genLoadStackPointers(backEnd);
	/* begin PopR: */
	genoperand(PopR, regArg2);
	/* begin PopR: */
	genoperand(PopR, regArg1);
	
/* begin RetN: */
	genoperand(RetN, 0);
	computeMaximumSizes();
	size = generateInstructionsAt(methodZoneBase);
	endAddress = outputInstructionsAt(methodZoneBase);
	assert((methodZoneBase + size) == endAddress);
	enilopmart = methodZoneBase;
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	nopsFromto(backEnd, endAddress, methodZoneBase - 1);
	recordGeneratedRunTimeaddress(trampolineName, enilopmart);
	return ((void (*)(void)) enilopmart);
}


/*	An enilopmart (the reverse of a trampoline) is a piece of code that makes
	the system-call-like transition from the C runtime into generated machine
	code. The desired arguments and entry-point are pushed on a stackPage's
	stack. The enilopmart pops off the values to be loaded into registers and
	then executes a return instruction to pop off the entry-point and jump to
	it.  */

static void (*genEnilopmartForcalled(sqInt regArg, char *trampolineName))(void)

{
	// Cogit>>#genEnilopmartFor:called:
    sqInt endAddress;
    sqInt enilopmart;
    sqInt size;

	opcodeIndex = 0;
	genLoadStackPointers(backEnd);
	/* begin PopR: */
	genoperand(PopR, regArg);
	
/* begin RetN: */
	genoperand(RetN, 0);
	computeMaximumSizes();
	size = generateInstructionsAt(methodZoneBase);
	endAddress = outputInstructionsAt(methodZoneBase);
	assert((methodZoneBase + size) == endAddress);
	enilopmart = methodZoneBase;
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	nopsFromto(backEnd, endAddress, methodZoneBase - 1);
	recordGeneratedRunTimeaddress(trampolineName, enilopmart);
	return ((void (*)(void)) enilopmart);
}


/*	Make sure that the object in reg is not forwarded. By default there is
	nothing to do. Subclasses for memory managers that forward will override. */

static sqInt
genEnsureObjInRegNotForwardedscratchReg(sqInt reg, sqInt scratch)
{
	// CogObjectRepresentation>>#genEnsureObjInRegNotForwarded:scratchReg:
	return 0;
}


/*	Make sure that the oop in reg is not forwarded. By default there is
	nothing to do. Subclasses for memory managers that forward will override. */

static sqInt
genEnsureOopInRegNotForwardedscratchReg(sqInt reg, sqInt scratch)
{
	// CogObjectRepresentation>>#genEnsureOopInRegNotForwarded:scratchReg:
	return 0;
}


/*	Generate special versions of the ceEnterCogCodePopReceiverAndClassRegs
	enilopmart that also pop register args from the stack to undo the pushing
	of register args in the abort/miss trampolines. */

static void (*genEnterPICEnilopmartNumArgs(sqInt numArgs))(void)

{
	// StackToRegisterMappingCogit>>#genEnterPICEnilopmartNumArgs:
    sqInt endAddress;
    sqInt enilopmart;
    sqInt size;

	opcodeIndex = 0;
	genLoadStackPointers(backEnd);
	/* begin PopR: */
	genoperand(PopR, ClassReg);
	/* begin PopR: */
	genoperand(PopR, TempReg);
	/* begin PopR: */
	genoperand(PopR, SendNumArgsReg);
	if (numArgs > 0) {
if (numArgs > 1) {
/* begin PopR: */
			genoperand(PopR, Arg1Reg);
			assert((numRegArgs()) == 2);
		}
		/* begin PopR: */
		genoperand(PopR, Arg0Reg);
	}
	/* begin PopR: */
	genoperand(PopR, ReceiverResultReg);
	/* begin PushR: */
	genoperand(PushR, SendNumArgsReg);
	/* begin JumpR: */
	genoperand(JumpR, TempReg);
	computeMaximumSizes();
	size = generateInstructionsAt(methodZoneBase);
	endAddress = outputInstructionsAt(methodZoneBase);
	assert((methodZoneBase + size) == endAddress);
	enilopmart = methodZoneBase;
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	nopsFromto(backEnd, endAddress, methodZoneBase - 1);
	recordGeneratedRunTimeaddress(trampolineNamenumArgs("ceEnterPIC", numArgs), enilopmart);
	return ((void (*)(void)) enilopmart);
}


/*	Can use any of the first 32 literals for the selector and pass up to 7
	arguments. 
 */

static sqInt
genExtendedSendBytecode(void)
{
	// SimpleStackBasedCogit>>#genExtendedSendBytecode
	return genSendnumArgs(getLiteral(byte1 & 0x1F), ((usqInt) byte1) >> 5);
}

static sqInt
genExtendedSuperBytecode(void)
{
	// SimpleStackBasedCogit>>#genExtendedSuperBytecode
	return genSendSupernumArgs(getLiteral(byte1 & 0x1F), ((usqInt) byte1) >> 5);
}


/*	Override to push the register receiver and register arguments, if any. */

static sqInt
genExternalizePointersForPrimitiveCall(void)
{
	// StackToRegisterMappingCogit>>#genExternalizePointersForPrimitiveCall
    sqInt address;
    sqInt address1;
    sqInt address2;
    sqInt address3;
    sqInt address4;

	genPushRegisterArgs();
	/* begin MoveR:Aw: */
	address4 = framePointerAddress();
	genoperandoperand(MoveRAw, FPReg, address4);
	/* begin PopR: */
	genoperand(PopR, TempReg);
	/* begin MoveR:Aw: */
	address2 = instructionPointerAddress();
	genoperandoperand(MoveRAw, TempReg, address2);
	/* begin MoveR:Aw: */
	address3 = stackPointerAddress();
	genoperandoperand(MoveRAw, SPReg, address3);

	return 0;
}


/*	Generate the routine that writes the current values of the C frame and
	stack pointers into
	variables. These are used to establish the C stack in trampolines back
	into the C run-time.
	
	This is a presumptuous quick hack for x86. It is presumptuous for two
	reasons. Firstly
	the system's frame and stack pointers may differ from those we use in
	generated code,
	e.g. on register-rich RISCs. Secondly the ABI may not support a simple
	frameless call
	as written here (for example 128-bit stack alignment on Mac OS X). */

static void
generateCaptureCStackPointers(sqInt captureFramePointer)
{
	// Cogit>>#generateCaptureCStackPointers:
    sqInt address;
    sqInt address1;
    sqInt address2;
    sqInt quickConstant;
    sqInt startAddress;

	allocateOpcodesbytecodes(32, 0);
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	if (captureFramePointer) {
/* begin MoveR:Aw: */
		address = cFramePointerAddress();
		genoperandoperand(MoveRAw, FPReg, address);
	}
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SPReg, TempReg);
	/* begin AddCq:R: */
	quickConstant = leafCallStackPointerDelta(backEnd);
	genoperandoperand(AddCqR, quickConstant, TempReg);
	/* begin MoveR:Aw: */
	address2 = cStackPointerAddress();
	genoperandoperand(MoveRAw, TempReg, address2);

	/* begin RetN: */
	genoperand(RetN, 0);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceCaptureCStackPointers", startAddress);
	ceCaptureCStackPointers = ((void (*)(void)) startAddress);
}

static AbstractInstruction *
generateCheckFeatures(AbstractInstruction * self_in_generateCheckFeatures)
{
	// CogIA32Compiler>>#generateCheckFeatures
	/* begin PushR: */
	genoperand(PushR, EDX);
	/* begin PushR: */
	genoperand(PushR, ECX);
	/* begin PushR: */
	genoperand(PushR, EBX);
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, 1, EAX);
	gen(CPUID);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, EDX, EAX);
	/* begin PopR: */
	genoperand(PopR, EBX);
	/* begin PopR: */
	genoperand(PopR, ECX);
	/* begin PopR: */
	genoperand(PopR, EDX);
	/* begin RetN: */
	genoperand(RetN, 0);
	return self_in_generateCheckFeatures;
}


/*	Generate the prototype ClosedPIC to determine how much space as full PIC
	takes. When we first allocate a closed PIC it only has one or two cases
	and we want to grow it.
	So we have to determine how big a full one is before hand. */

static void
generateClosedPICPrototype(void)
{
	// Cogit>>#generateClosedPICPrototype
    sqInt headerSize;


	/* stack allocate the various collections so that they
	   are effectively garbage collected on return. */

	numPICCases = 6;
	allocateOpcodesbytecodes(numPICCases * 7, 0);
	compileClosedPICPrototype();
	computeMaximumSizes();
	headerSize = sizeof(CogMethod);
	closedPICSize = headerSize + (generateInstructionsAt(methodZoneBase + headerSize));
	firstCPICCaseOffset = ((endCPICCase0->address)) - methodZoneBase;
	cPICCaseSize = ((endCPICCase1->address)) - ((endCPICCase0->address));
	cPICEndSize = closedPICSize - (((numPICCases - 1) * cPICCaseSize) + firstCPICCaseOffset);

	/* self cCode: ''
	   inSmalltalk:
	   [| end |
	   end := self outputInstructionsAt: methodZoneBase + headerSize.
	   self disassembleFrom: methodZoneBase + headerSize to: end - 1.
	   self halt] */

	closedPICSize = roundUpLength(closedPICSize);
}


/*	We handle jump sizing simply. First we make a pass that asks each
	instruction to compute its maximum size. Then we make a pass that
	sizes jumps based on the maxmimum sizes. Then we make a pass
	that fixes up jumps. When fixing up a jump the jump is not allowed to
	choose a smaller offset but must stick to the size set in the second pass. */

static CogMethod *
generateCogMethod(sqInt selector)
{
	// Cogit>>#generateCogMethod:
    sqInt codeSize;
    sqInt headerSize;
    sqInt mapSize;
    CogMethod *method;
    sqInt result;
    sqInt startAddress;
    sqInt totalSize;

	headerSize = sizeof(CogMethod);
	(methodLabel->address = -headerSize);
	computeMaximumSizes();
	concretizeAt(methodLabel, freeStart());
	codeSize = generateInstructionsAt(((methodLabel->address)) + headerSize);
	mapSize = generateMapAtstart(0, ((methodLabel->address)) + cmNoCheckEntryOffset);
	totalSize = roundUpLength((headerSize + codeSize) + mapSize);
	if (totalSize > MaxMethodSize) {
return ((CogMethod *) MethodTooBig);
	}
	startAddress = allocate(totalSize);
	if (startAddress == 0) {
return ((CogMethod *) InsufficientCodeSpace);
	}
	assert((startAddress + cmEntryOffset) == ((entry->address)));
	assert((startAddress + cmNoCheckEntryOffset) == ((noCheckEntry->address)));
	result = outputInstructionsAt(startAddress + headerSize);
	assert(((startAddress + headerSize) + codeSize) == result);
	padIfPossibleWithNopsFromto(backEnd, result, (startAddress + totalSize) - mapSize);
	generateMapAtstart((startAddress + totalSize) - 1, startAddress + cmNoCheckEntryOffset);
	fillInBlockHeadersAt(startAddress);
	method = fillInMethodHeadersizeselector(((CogMethod *) startAddress), totalSize, selector);
	if (postCompileHook != null) {
		postCompileHook(method, primInvokeLabel);
		postCompileHook = null;
	}
	flushICacheFromto(processor, startAddress, (startAddress + headerSize) + codeSize);
	return method;
}


/*	Enilopmarts transfer control from C into machine code (backwards
	trampolines). 
 */
/*	Enilopmarts transfer control from C into machine code (backwards
	trampolines). Override to add version for generic and PIC-specific entry
	with reg args. */

static void
generateEnilopmarts(void)
{
	// StackToRegisterMappingCogit>>#generateEnilopmarts
	
#  if Debug
	realCEEnterCogCodePopReceiverReg = genEnilopmartForcalled(ReceiverResultReg, "realCEEnterCogCodePopReceiverReg");
	ceEnterCogCodePopReceiverReg = enterCogCodePopReceiver;
	realCEEnterCogCodePopReceiverAndClassRegs = genEnilopmartForandcalled(ReceiverResultReg, ClassReg, "realCEEnterCogCodePopReceiverAndClassRegs");
	ceEnterCogCodePopReceiverAndClassRegs = enterCogCodePopReceiverAndClassRegs;

#  else /* Debug */
	ceEnterCogCodePopReceiverReg = genEnilopmartForcalled(ReceiverResultReg, "ceEnterCogCodePopReceiverReg");
	ceEnterCogCodePopReceiverAndClassRegs = genEnilopmartForandcalled(ReceiverResultReg, ClassReg, "ceEnterCogCodePopReceiverAndClassRegs");

#  endif /* Debug */

	genPrimReturnEnterCogCodeEnilopmart(0);
	cePrimReturnEnterCogCode = methodZoneBase;
	outputInstructionsForGeneratedRuntimeAt(cePrimReturnEnterCogCode);
	recordGeneratedRunTimeaddress("cePrimReturnEnterCogCode", cePrimReturnEnterCogCode);
	genPrimReturnEnterCogCodeEnilopmart(1);
	cePrimReturnEnterCogCodeProfiling = methodZoneBase;
	outputInstructionsForGeneratedRuntimeAt(cePrimReturnEnterCogCodeProfiling);
	recordGeneratedRunTimeaddress("cePrimReturnEnterCogCodeProfiling", cePrimReturnEnterCogCodeProfiling);
	
#  if Debug
	realCEEnterCogCodePopReceiverArg0Regs = genEnilopmartForandcalled(ReceiverResultReg, Arg0Reg, "realCEEnterCogCodePopReceiverArg0Regs");
	ceEnterCogCodePopReceiverArg0Regs = enterCogCodePopReceiverArg0Regs;
	realCEEnterCogCodePopReceiverArg1Arg0Regs = genEnilopmartForandandcalled(ReceiverResultReg, Arg0Reg, Arg1Reg, "realCEEnterCogCodePopReceiverArg1Arg0Regs");
	ceEnterCogCodePopReceiverArg1Arg0Regs = enterCogCodePopReceiverArg1Arg0Regs;

#  else /* Debug */
	ceEnterCogCodePopReceiverArg0Regs = genEnilopmartForandcalled(ReceiverResultReg, Arg0Reg, "ceEnterCogCodePopReceiverArg0Regs");
	ceEnterCogCodePopReceiverArg1Arg0Regs = genEnilopmartForandandcalled(ReceiverResultReg, Arg0Reg, Arg1Reg, "ceEnterCogCodePopReceiverArg1Arg0Regs");

#  endif /* Debug */

	ceEnter0ArgsPIC = genEnterPICEnilopmartNumArgs(0);
	ceEnter1ArgsPIC = genEnterPICEnilopmartNumArgs(1);
	

}


/*	A dummy routine.
	Processors that can generate code to flush the icache can override. */

static AbstractInstruction *
generateICacheFlush(AbstractInstruction * self_in_generateICacheFlush)
{
	// CogAbstractInstruction>>#generateICacheFlush
	return self_in_generateICacheFlush;
}


/*	Size pc-dependent instructions and assign eventual addresses to all
	instructions. Answer the size of the code.
	Compute forward branches based on virtual address (abstract code starts at
	0), assuming that any branches branched over are long.
	Compute backward branches based on actual address.
	Reuse the fixups array to record the pc-dependent instructions that need
	to have
	their code generation postponed until after the others. */

static sqInt
generateInstructionsAt(sqInt eventualAbsoluteAddress)
{
	// Cogit>>#generateInstructionsAt:
    sqInt absoluteAddress;
    AbstractInstruction *abstractInstruction;
    BytecodeFixup *fixup;
    sqInt i;
    sqInt pcDependentIndex;

	absoluteAddress = eventualAbsoluteAddress;
	pcDependentIndex = 0;
	for (i = 0; i < opcodeIndex; i += 1) {
		if (breakPC == absoluteAddress) {
			haltmsg("breakPC reached in generateInstructionsAt:");
		}
		abstractInstruction = abstractInstructionAt(i);
		if (isPCDependent(abstractInstruction)) {
			sizePCDependentInstructionAt(abstractInstruction, absoluteAddress);
			fixup = fixupAt(pcDependentIndex);
			pcDependentIndex += 1;
			(fixup->instructionIndex = i);
			absoluteAddress += (abstractInstruction->machineCodeSize);
		}
		else {
absoluteAddress = concretizeAt(abstractInstruction, absoluteAddress);
		}
	}
	for (i = 0; i < pcDependentIndex; i += 1) {
fixup = fixupAt(i);
		abstractInstruction = abstractInstructionAt((fixup->instructionIndex));
		if (breakPC == absoluteAddress) {
			haltmsg("breakPC reached in generateInstructionsAt:");
		}
		concretizeAt(abstractInstruction, (abstractInstruction->address));
	}
	
return absoluteAddress - eventualAbsoluteAddress;
}


/*	Generate a function that attempts to lock the vmOwnerLock and answers
	true if it succeeded. */

static AbstractInstruction *
generateLowLevelTryLock(AbstractInstruction * self_in_generateLowLevelTryLock, sqInt vmOwnerLockAddress)
{
	// CogIA32Compiler>>#generateLowLevelTryLock:
	if (vmOwnerLockAddress == 0) {
/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, 1, EAX);
		/* begin RetN: */
		genoperand(RetN, 0);
		return self_in_generateLowLevelTryLock;
	}
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, 1, EAX);
	gen(MFENCE);
	genoperandoperand(XCHGAwR, vmOwnerLockAddress, EAX);
	gen(SFENCE);
	/* begin SubCq:R: */
	genoperandoperand(SubCqR, 1, EAX);
	/* begin RetN: */
	genoperand(RetN, 0);
	return self_in_generateLowLevelTryLock;
}

static AbstractInstruction *
generateLowLevelUnlock(AbstractInstruction * self_in_generateLowLevelUnlock, sqInt vmOwnerLockAddress)
{
	// CogIA32Compiler>>#generateLowLevelUnlock:
	if (vmOwnerLockAddress != 0) {
/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, 0, EAX);
		/* begin MoveR:Aw: */
		genoperandoperand(MoveRAw, EAX, vmOwnerLockAddress);
		gen(SFENCE);
	}
	/* begin RetN: */
	genoperand(RetN, 0);
	return self_in_generateLowLevelUnlock;
}


/*	Generate the method map at addressrNull (or compute it if adressOrNull is
	null). Answer the length of the map in byes. Each entry in the map is in
	two parts. In the
	least signficant bits are a displacement of how far from the start or
	previous entry.
	In the most signficant bits are the type of annotation at the point
	reached. A null
	byte ends the map. */

static sqInt
generateMapAtstart(sqInt addressOrNull, sqInt startAddress)
{
	// Cogit>>#generateMapAt:start:
    InstructionAnnotation *annotation;
    sqInt delta;
    sqInt i;
    sqInt length;
    sqInt location;
    sqInt mapEntry;
    sqInt maxDelta;
    sqInt mcpc;

	length = 0;
	location = startAddress;
	for (i = 0; i < annotationIndex; i += 1) {
		annotation = (&(annotations[i]));
		mcpc = ((((annotation->instruction))->address)) + ((((annotation->instruction))->machineCodeSize));
		while (((delta = mcpc - location)) > MaxUnitDisplacement) {
			maxDelta = (((((delta < MaxX2NDisplacement) ? delta : MaxX2NDisplacement)) | DisplacementMask) - DisplacementMask);
			assert((((usqInt) maxDelta) >> AnnotationShift) <= DisplacementMask);
			if (addressOrNull != 0) {
byteAtput(addressOrNull - length, (((usqInt) maxDelta) >> AnnotationShift) + DisplacementX2N);
				traceMapbyteatfor(IsDisplacementX2N, (((usqInt) maxDelta) >> AnnotationShift) + DisplacementX2N, addressOrNull - length, mcpc);
			}
			location += maxDelta;
			length += 1;
		}
		if (addressOrNull != 0) {
mapEntry = delta + (((annotation->annotation)) << AnnotationShift);
			byteAtput(addressOrNull - length, mapEntry);
			traceMapbyteatfor(annotation, mapEntry, addressOrNull - length, mcpc);
		}
		location += delta;
		length += 1;
	}
	if (addressOrNull != 0) {
byteAtput(addressOrNull - length, MapEnd);
		traceMapbyteatfor(MapEnd, MapEnd, addressOrNull - length, 0);
	}
	return length + 1;
}


/*	Generate the run-time entries for the various method and PIC entry misses
	and aborts.
	Read the class-side method trampolines for documentation on the various
	trampolines 
 */
/*	Slang needs these apparently superfluous asSymbol sends. */

static void
generateMissAbortTrampolines(void)
{
	// StackToRegisterMappingCogit>>#generateMissAbortTrampolines
    sqInt numArgs;
    sqInt numArgsLimiT;

	for (numArgs = 0, numArgsLimiT = (1 + 1); numArgs <= numArgsLimiT; numArgs += 1) {
		methodAbortTrampolines[numArgs] = (genMethodAbortTrampolineFor(numArgs));
	}
	for (numArgs = 0, numArgsLimiT = (1 + 1); numArgs <= numArgsLimiT; numArgs += 1) {
		picAbortTrampolines[numArgs] = (genPICAbortTrampolineFor(numArgs));
	}
	for (numArgs = 0, numArgsLimiT = (1 + 1); numArgs <= numArgsLimiT; numArgs += 1) {
		picMissTrampolines[numArgs] = (genPICMissTrampolineFor(numArgs));
	}
	
}

static void
generateObjectRepresentationTrampolines(void)
{
	// CogObjectRepresentationForSqueakV3>>#generateObjectRepresentationTrampolines
	ceStoreCheckTrampoline = genTrampolineForcalledargresult(ceStoreCheck, "ceStoreCheckTrampoline", ReceiverResultReg, returnRegForStoreCheck());
	ceCreateNewArrayTrampoline = genTrampolineForcalledargresult(ceNewArraySlotSize, "ceCreateNewArrayTrampoline", SendNumArgsReg, ReceiverResultReg);
	cePositive32BitIntegerTrampoline = genTrampolineForcalledargresult(cePositive32BitIntegerFor, "cePositive32BitIntegerTrampoline", ReceiverResultReg, TempReg);
	ceActiveContextTrampoline = genActiveContextTrampoline();
	ceClosureCopyTrampoline = genTrampolineForcalledargresult(ceClosureCopyDescriptor, "ceClosureCopyTrampoline", SendNumArgsReg, ReceiverResultReg);
}


/*	Generate the prototype ClosedPIC to determine how much space as full PIC
	takes. When we first allocate a closed PIC it only has one or two cases
	and we want to grow it.
	So we have to determine how big a full one is before hand. */
/*	stack allocate the various collections so that they
	are effectively garbage collected on return. */

static void
generateOpenPICPrototype(void)
{
	// Cogit>>#generateOpenPICPrototype
    sqInt codeSize;
    sqInt headerSize;
    sqInt mapSize;

	allocateOpcodesbytecodes(100, 0);
	compileOpenPICnumArgs(specialSelector(0), 1);
	computeMaximumSizes();
	headerSize = sizeof(CogMethod);
	concretizeAt(methodLabel, methodZoneBase);
	codeSize = generateInstructionsAt(methodZoneBase + headerSize);
	mapSize = generateMapAtstart(0, methodZoneBase + cmNoCheckEntryOffset);
	openPICSize = (roundUpLength(headerSize + codeSize)) + (roundUpLength(mapSize));
}


/*	Generate the run-time entries at the base of the native code zone and
	update the base.
 */

static void
generateRunTimeTrampolines(void)
{
	// Cogit>>#generateRunTimeTrampolines
	ceSendMustBeBooleanAddFalseTrampoline = genMustBeBooleanTrampolineForcalled(falseObject(), "ceSendMustBeBooleanAddFalseTrampoline");
	ceSendMustBeBooleanAddTrueTrampoline = genMustBeBooleanTrampolineForcalled(trueObject(), "ceSendMustBeBooleanAddTrueTrampoline");
	ceNonLocalReturnTrampoline = genNonLocalReturnTrampoline();
	ceBaseFrameReturnTrampoline = genTrampolineForcalledarg(ceBaseFrameReturn, "ceBaseFrameReturnTrampoline", ReceiverResultReg);
	ceCheckForInterruptTrampoline = genCheckForInterruptsTrampoline();
	ceFetchContextInstVarTrampoline = genTrampolineForcalledargargresult(ceContextinstVar, "ceFetchContextInstVarTrampoline", ReceiverResultReg, SendNumArgsReg, SendNumArgsReg);

	/* to keep ReceiverResultReg live. */

ceStoreContextInstVarTrampoline = genTrampolineForcalledargargargresult(ceContextinstVarvalue, "ceStoreContextInstVarTrampoline", ReceiverResultReg, SendNumArgsReg, ClassReg, ReceiverResultReg);
	ceReturnToInterpreterTrampoline = genTrampolineForcalledarg(ceReturnToInterpreter, "ceReturnToInterpreterTrampoline", ReceiverResultReg);
	ceCannotResumeTrampoline = genTrampolineForcalled(ceCannotResume, "ceCannotResumeTrampoline");
}


/*	Override to generate code to push the register arg(s) for <= numRegArg
	arity sends.
 */

static void
generateSendTrampolines(void)
{
	// StackToRegisterMappingCogit>>#generateSendTrampolines
    sqInt numArgs;

	for (numArgs = 0; numArgs <= (NumSendTrampolines - 2); numArgs += 1) {
		sendTrampolines[numArgs] = (genSendTrampolineFornumArgscalledargargargarg(ceSendsupertonumArgs, numArgs, trampolineNamenumArgs("ceSend", numArgs), ClassReg, 0, ReceiverResultReg, numArgs));
	}
	sendTrampolines[NumSendTrampolines - 1] = (genSendTrampolineFornumArgscalledargargargarg(ceSendsupertonumArgs, 1 + 1, trampolineNamenumArgs("ceSend", -1), ClassReg, 0, ReceiverResultReg, SendNumArgsReg));
	
for (numArgs = 0; numArgs <= (NumSendTrampolines - 2); numArgs += 1) {
		superSendTrampolines[numArgs] = (genSendTrampolineFornumArgscalledargargargarg(ceSendsupertonumArgs, numArgs, trampolineNamenumArgs("ceSuperSend", numArgs), ClassReg, 1, ReceiverResultReg, numArgs));
	}
	superSendTrampolines[NumSendTrampolines - 1] = (genSendTrampolineFornumArgscalledargargargarg(ceSendsupertonumArgs, 1 + 1, trampolineNamenumArgs("ceSuperSend", -1), ClassReg, 1, ReceiverResultReg, SendNumArgsReg));
	firstSend = sendTrampolines[0];
	lastSend = superSendTrampolines[NumSendTrampolines - 1];
}


/*	Generate a routine ceCaptureCStackPointers that will capture the C stack
	pointer, and, if it is in use, the C frame pointer. These are used in
	trampolines to call
	run-time routines in the interpreter from machine-code. */

static void
generateStackPointerCapture(void)
{
	// Cogit>>#generateStackPointerCapture
    sqInt oldMethodZoneBase;
    sqInt oldTrampolineTableIndex;

	assertCStackWellAligned();
	oldMethodZoneBase = methodZoneBase;
	oldTrampolineTableIndex = trampolineTableIndex;
	generateCaptureCStackPointers(1);
	ceCaptureCStackPointers();
	if (!((cFramePointerInUse = isCFramePointerInUse()))) {
		methodZoneBase = oldMethodZoneBase;
		trampolineTableIndex = oldTrampolineTableIndex;
		generateCaptureCStackPointers(0);
	}
}


/*	Generate trampolines for tracing. In the simulator we can save a lot of
	time and avoid noise instructions in the lastNInstructions log by
	short-cutting these
	trampolines, but we need them in the real vm. */

static void
generateTracingTrampolines(void)
{
	// StackToRegisterMappingCogit>>#generateTracingTrampolines
	ceTraceLinkedSendTrampoline = genSafeTrampolineForcalledarg(ceTraceLinkedSend, "ceTraceLinkedSendTrampoline", ReceiverResultReg);
	ceTraceBlockActivationTrampoline = genTrampolineForcalled(ceTraceBlockActivation, "ceTraceBlockActivationTrampoline");
	ceTraceStoreTrampoline = genSafeTrampolineForcalledargarg(ceTraceStoreOfinto, "ceTraceStoreTrampoline", TempReg, ReceiverResultReg);
}


/*	Generate the run-time entries and exits at the base of the native code
	zone and update the base.
	Read the class-side method trampolines for documentation on the various
	trampolines 
 */

static void
generateTrampolines(void)
{
	// Cogit>>#generateTrampolines
    sqInt addr;
    sqInt methodZoneStart;
    sqInt selector;

	methodZoneStart = methodZoneBase;
	allocateOpcodesbytecodes(80, 0);
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	hasYoungReferent = 0;
	generateSendTrampolines();
	generateMissAbortTrampolines();
	generateObjectRepresentationTrampolines();
	generateRunTimeTrampolines();
	
generateEnilopmarts();
	generateTracingTrampolines();
	recordGeneratedRunTimeaddress("methodZoneBase", methodZoneBase);
	flushICacheFromto(processor, methodZoneStart, methodZoneBase);
	
}

static void
generateVMOwnerLockFunctions(void)
{
	// Cogit>>#generateVMOwnerLockFunctions
    sqInt startAddress;

	
#  if COGMTVM
	allocateOpcodesbytecodes(numLowLevelLockOpcodes(backEnd), 0);
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	generateLowLevelTryLock(backEnd, vmOwnerLockAddress());
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceTryLockVMOwner", startAddress);
	ceTryLockVMOwner = ((unsigned long (*)(void)) startAddress);
	opcodeIndex = 0;
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	generateLowLevelUnlock(backEnd, vmOwnerLockAddress());
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceUnlockVMOwner", startAddress);
	ceUnlockVMOwner = ((void (*)(void)) startAddress);

#  endif /* COGMTVM */

}

static sqInt
genFastPrimFail(void)
{
	// SimpleStackBasedCogit>>#genFastPrimFail
	primitiveIndex = 0;
	return 0;
}


/*	Suport for compileInterpreterPrimitive. Generate inline code so as to
	record the primitive
	trace as fast as possible. */

static void
genFastPrimTraceUsingand(sqInt r1, sqInt r2)
{
	// SimpleStackBasedCogit>>#genFastPrimTraceUsing:and:
    sqInt offset;
    sqInt offset1;
    sqInt offset2;
    sqInt wordConstant;

	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, 0, TempReg);
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, 0, r2);
	/* begin MoveMb:r:R: */
	offset = primTraceLogIndexAddress();
	genoperandoperandoperand(MoveMbrR, offset, TempReg, r2);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, r2, r1);
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, 1, r1);
	/* begin MoveR:Mb:r: */
	offset1 = primTraceLogIndexAddress();
	genoperandoperandoperand(MoveRMbr, r1, offset1, TempReg);
	addDependent(methodLabel, annotateAbsolutePCRef(gMoveCwR(((sqInt)methodLabel), r1)));
	/* begin MoveMw:r:R: */
	offset2 = offsetof(CogMethod, selector);
	genoperandoperandoperand(MoveMwrR, offset2, r1, TempReg);
	/* begin MoveCw:R: */
	wordConstant = ((sqInt)(primTraceLogAddress()));
	genoperandoperand(MoveCwR, wordConstant, r1);
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, r2, r1);
}


/*	indexReg contains the 1-relative index of an element in tableObj.
	Since BaseHeaderSize = BytesPerOop we can use it as a
	zero-relative index from the beginning of the object. */

static sqInt
genFetchIndexRegisterfrominto(sqInt indexReg, sqInt tableObj, sqInt destReg)
{
	// CogObjectRepresentationForSqueakV3>>#genFetchIndexRegister:from:into:
	assert(indexReg != destReg);
	annotateobjRef(gMoveCwR(tableObj, destReg), tableObj);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, indexReg, destReg, destReg);
	return 0;
}

static sqInt
genFramelessStorePopReceiverVariable(sqInt popBoolean, sqInt slotIndex)
{
	// StackToRegisterMappingCogit>>#genFramelessStorePop:ReceiverVariable:
    sqInt constVal;
    sqInt topReg;
    sqInt valueReg;

	assert(!needsFrame);
	ssFlushUpThroughReceiverVariable(slotIndex);
	constVal = maybeConstant(ssTop());
	if (((((ssTop())->type)) == SSConstant)
	 && (!(shouldAnnotateObjectReference(constVal)))) {
		ensureReceiverResultRegContainsSelf();
		ssStorePoptoPreferredReg(popBoolean, TempReg);
		if (traceStores > 0) {
			CallRT(ceTraceStoreTrampoline);
		}
		return genStoreImmediateInSourceRegslotIndexdestReg(TempReg, slotIndex, ReceiverResultReg);
	}
	if (((topReg = registerOrNil(ssTop()))) == null) {
		topReg = ClassReg;
	}

	/* Note that ReceiverResultReg remains live after ceStoreCheckTrampoline. */

valueReg = ssStorePoptoPreferredReg(popBoolean, topReg);
	ensureReceiverResultRegContainsSelf();
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, valueReg, TempReg);
		CallRT(ceTraceStoreTrampoline);
	}
	return genStoreSourceRegslotIndexdestRegscratchReg(valueReg, slotIndex, ReceiverResultReg, TempReg);
}


/*	Get the active context into ReceiverResultReg, creating it if necessary. */

static void
genGetActiveContextNumArgslargeinBlock(sqInt numArgs, sqInt isLargeContext, sqInt isInBlock)
{
	// CogObjectRepresentationForSqueakV3>>#genGetActiveContextNumArgs:large:inBlock:
	CallRT(ceActiveContextTrampoline);
}


/*	Fetch the instance's class format into destReg, assuming the object is
	non-int. 
 */

static sqInt
genGetClassFormatOfNonIntintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg)
{
	// CogObjectRepresentationForSqueakV3>>#genGetClassFormatOfNonInt:into:scratchReg:
    AbstractInstruction *jumpCompact;
    AbstractInstruction *jumpGotClass;
    sqInt offset;
    sqInt quickConstant;
    sqInt quickConstant1;


	/* Get header word in destReg */
	/* Form the byte index of the compact class field */

/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, instReg, destReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = (compactClassFieldLSB()) - ShiftForWord;
	genoperandoperand(LogicalShiftRightCqR, quickConstant, destReg);
	/* begin AndCq:R: */
	quickConstant1 = ((1 << (compactClassFieldWidth())) - 1) << ShiftForWord;
	genoperandoperand(AndCqR, quickConstant1, destReg);
	/* begin JumpNonZero: */
	jumpCompact = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset = classFieldOffset();
	genoperandoperandoperand(MoveMwrR, offset, instReg, scratchReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, ((sqInt) AllButTypeMask), scratchReg);
	/* begin Jump: */
	jumpGotClass = genoperand(Jump, ((sqInt)0));
	assert(BaseHeaderSize == BytesPerWord);
	jmpTarget(jumpCompact, annotateobjRef(gMoveMwrR(splObj(CompactClasses), destReg, scratchReg), splObj(CompactClasses)));
	jmpTarget(jumpGotClass, gMoveMwrR((InstanceSpecificationIndex << ShiftForWord) + BytesPerWord, scratchReg, destReg));
	return 0;
}


/*	Fetch the instance's class into destReg. This is almost identical
	to genGetClassFormatOfNonInt:into:scratchReg: but because we
	put the fetch of SmallInteger between the then and the else for 
	compact class/non-compact class we cannot easily share code.
	instRegIsReceiver is ignored. It is for Spur compatibility where
	objects may be forwarded. */

static sqInt
genGetClassObjectOfintoscratchReginstRegIsReceiver(sqInt instReg, sqInt destReg, sqInt scratchReg, sqInt instRegIsReceiver)
{
	// CogObjectRepresentationForSqueakV3>>#genGetClassObjectOf:into:scratchReg:instRegIsReceiver:
    AbstractInstruction *jumpCompact;
    AbstractInstruction *jumpGotClass;
    AbstractInstruction *jumpGotClass2;
    AbstractInstruction *jumpIsInt;
    sqInt offset;
    sqInt quickConstant;
    sqInt quickConstant1;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instReg, scratchReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 1, scratchReg);
	/* begin JumpNonZero: */
	jumpIsInt = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, instReg, scratchReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = (compactClassFieldLSB()) - ShiftForWord;
	genoperandoperand(LogicalShiftRightCqR, quickConstant, scratchReg);
	/* begin AndCq:R: */
	quickConstant1 = ((1 << (compactClassFieldWidth())) - 1) << ShiftForWord;
	genoperandoperand(AndCqR, quickConstant1, scratchReg);
	/* begin JumpNonZero: */
	jumpCompact = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset = classFieldOffset();
	genoperandoperandoperand(MoveMwrR, offset, instReg, destReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, ((sqInt) AllButTypeMask), destReg);
	/* begin Jump: */
	jumpGotClass = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsInt, annotateobjRef(gMoveCwR(classSmallInteger(), destReg), classSmallInteger()));
	/* begin Jump: */
	jumpGotClass2 = genoperand(Jump, ((sqInt)0));
	assert(BaseHeaderSize == BytesPerWord);
	jmpTarget(jumpCompact, annotateobjRef(gMoveMwrR(splObj(CompactClasses), scratchReg, destReg), splObj(CompactClasses)));
	jmpTarget(jumpGotClass, jmpTarget(jumpGotClass2, gLabel()));
	return 0;
}


/*	Compatibility with SpurObjectRepresentation/SpurMemoryManager. */

static AbstractInstruction *
genGetClassTagOfintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg)
{
	// CogObjectRepresentationForSqueakV3>>#genGetClassTagOf:into:scratchReg:
    AbstractInstruction *entryLabel;

	/* begin AlignmentNops: */
	genoperand(AlignmentNops, ((BytesPerWord < 8) ? 8 : BytesPerWord));
	/* begin Label */
	entryLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	genGetClassObjectOfintoscratchReginstRegIsReceiver(instReg, destReg, scratchReg, null);
	return entryLabel;
}


/*	Fetch the instance's compact class index into destReg. */
/*	Get header word in scratchReg */

static sqInt
genGetCompactClassIndexNonImmOfinto(sqInt instReg, sqInt destReg)
{
	// CogObjectRepresentationForSqueakV3>>#genGetCompactClassIndexNonImmOf:into:
    sqInt quickConstant;
    sqInt quickConstant1;

	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, instReg, destReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = compactClassFieldLSB();
	genoperandoperand(LogicalShiftRightCqR, quickConstant, destReg);
	/* begin AndCq:R: */
	quickConstant1 = (1 << (compactClassFieldWidth())) - 1;
	genoperandoperand(AndCqR, quickConstant1, destReg);
	return 0;
}

static sqInt
genGetDoubleValueOfinto(sqInt srcReg, sqInt destFPReg)
{
	// CogObjectRepresentationForSqueakV3>>#genGetDoubleValueOf:into:
	/* begin MoveM64:r:Rd: */
	genoperandoperandoperand(MoveM64rRd, BaseHeaderSize, srcReg, destFPReg);
	return 0;
}


/*	Fetch the instance's class format into destReg, assuming the object is
	pointers and non-int
 */

static sqInt
genGetFixedFieldsOfPointerNonIntintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg)
{
	// CogObjectRepresentationForSqueakV3>>#genGetFixedFieldsOfPointerNonInt:into:scratchReg:
	genGetClassFormatOfNonIntintoscratchReg(instReg, destReg, scratchReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, destReg, scratchReg);
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, 2, destReg);
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, 11, scratchReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 0x3F, destReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 192, scratchReg);
	/* begin SubCq:R: */
	genoperandoperand(SubCqR, 1, destReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, scratchReg, destReg);
	return 0;
}


/*	Fetch the instance's identity hash into destReg, encoded as a
	SmallInteger. 
 */
/*	Get header word in scratchReg */

static sqInt
genGetHashFieldNonImmOfasSmallIntegerInto(sqInt instReg, sqInt destReg)
{
	// CogObjectRepresentationForSqueakV3>>#genGetHashFieldNonImmOf:asSmallIntegerInto:
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, instReg, destReg);
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, HashBitsOffset - 1, destReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, HashMaskUnshifted << 1, destReg);
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, 1, destReg);
	return 0;
}


/*	Generate a routine that answers the stack pointer immedately
	after a leaf call, used for checking stack pointer alignment. */

static sqInt
genGetLeafCallStackPointer(void)
{
	// Cogit>>#genGetLeafCallStackPointer
    sqInt startAddress;

	allocateOpcodesbytecodes(32, 0);
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	genGetLeafCallStackPointerFunction(backEnd);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceGetSP", startAddress);
	return startAddress;
}

static AbstractInstruction *
genGetLeafCallStackPointerFunction(AbstractInstruction * self_in_genGetLeafCallStackPointerFunction)
{
	// CogIA32Compiler>>#genGetLeafCallStackPointerFunction
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ESP, EAX);
	/* begin RetN: */
	genoperand(RetN, 0);
	return self_in_genGetLeafCallStackPointerFunction;
}


/*	Generate the abort for a PIC. This abort performs either a call of
	ceInterpretMethodFromPIC:receiver: to handle invoking an uncogged
	target or a call of ceMNUFromPICMNUMethod:receiver: to handle an
	MNU dispatch in a closed PIC. It distinguishes the two by testing
	ClassReg. If the register is zero then this is an MNU. */

static sqInt
genInnerPICAbortTrampoline(char *name)
{
	// Cogit>>#genInnerPICAbortTrampoline:
    AbstractInstruction *jumpMNUCase;

	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 0, ClassReg);
	/* begin JumpZero: */
	jumpMNUCase = genoperand(JumpZero, ((sqInt)0));
	compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(ceInterpretMethodFromPICreceiver, 2, SendNumArgsReg, ReceiverResultReg, null, null, 0, 1, null);
	jmpTarget(jumpMNUCase, gLabel());
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceMNUFromPICMNUMethodreceiver, name, 2, SendNumArgsReg, ReceiverResultReg, null, null, 0, 1, null, 1);
}


/*	subclasses override if they can */

static sqInt
genInnerPrimitiveAsCharacterinReg(sqInt retNOffset, sqInt reg)
{
	// CogObjectRepresentation>>#genInnerPrimitiveAsCharacter:inReg:
	return unimplementedPrimitive();
}


/*	subclasses override if they can */

static sqInt
genInnerPrimitiveAtPut(sqInt retNoffset)
{
	// CogObjectRepresentation>>#genInnerPrimitiveAtPut:
	return unimplementedPrimitive();
}


/*	c.f. StackInterpreter>>stSizeOf: lengthOf:baseHeader:format:
	fixedFieldsOf:format:length: 
 */

static sqInt
genInnerPrimitiveAt(sqInt retNoffset)
{
	// CogObjectRepresentationForSqueakV3>>#genInnerPrimitiveAt:
    sqInt jic;
    AbstractInstruction *jmpFmtGeFirstByte;
    sqInt jnx;
    AbstractInstruction *jumpBounds;
    AbstractInstruction *jumpFmtEq2;
    AbstractInstruction *jumpFmtGt11;
    AbstractInstruction *jumpFmtGt4;
    AbstractInstruction *jumpFmtIsArray;
    AbstractInstruction *jumpFmtLeWeakArray;
    AbstractInstruction *jumpFmtLt8;
    AbstractInstruction *jumpGotByteSize;
    AbstractInstruction *jumpGotWordSize;
    AbstractInstruction *jumpIsContext;
    AbstractInstruction *jumpIsContext1;
    AbstractInstruction *jumpLarge;
    AbstractInstruction *jumpNotIndexable;
    AbstractInstruction *jumpNotIndexable1;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpShortHeader;
    AbstractInstruction *jumpSI;
    AbstractInstruction *jumpSkip;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant11;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;
    sqInt quickConstant6;
    sqInt quickConstant7;
    sqInt quickConstant8;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	jumpSI = genJumpSmallIntegerInScratchReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, Arg1Reg);
	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin genGetSizeOf:into:formatReg:scratchReg:abortJumpsInto: */
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, ReceiverResultReg, SendNumArgsReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ClassReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant8 = instFormatFieldLSB();
	genoperandoperand(LogicalShiftRightCqR, quickConstant8, SendNumArgsReg);
	/* begin AndCq:R: */
	quickConstant11 = (1 << (instFormatFieldWidth())) - 1;
	genoperandoperand(AndCqR, quickConstant11, SendNumArgsReg);
	/* begin CmpCq:R: */
	quickConstant2 = arrayFormat();
	genoperandoperand(CmpCqR, quickConstant2, SendNumArgsReg);
	/* begin JumpLess: */
	jumpNotIndexable1 = genoperand(JumpLess, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, TempReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant3 = compactClassFieldLSB();
	genoperandoperand(LogicalShiftRightCqR, quickConstant3, TempReg);
	/* begin AndCq:R: */
	quickConstant4 = (1 << (compactClassFieldWidth())) - 1;
	genoperandoperand(AndCqR, quickConstant4, TempReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, TempReg);
	/* begin JumpZero: */
	jumpIsContext1 = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, TempReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, TypeMask, TempReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, HeaderTypeSizeAndClass, TempReg);
	/* begin JumpNonZero: */
	jumpShortHeader = genoperand(JumpNonZero, ((sqInt)0));
	assert(Size4Bit == 0);
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0 - (2 * BytesPerWord), ReceiverResultReg, ClassReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, ((sqInt) LongSizeMask), ClassReg);
	/* begin Jump: */
	jumpSkip = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpShortHeader, gAndCqR(SizeMask, ClassReg));
	jmpTarget(jumpSkip, gSubCqR(BaseHeaderSize, ClassReg));
	/* begin CmpCq:R: */
	quickConstant5 = weakArrayFormat();
	genoperandoperand(CmpCqR, quickConstant5, SendNumArgsReg);
	/* begin JumpLessOrEqual: */
	jumpFmtLeWeakArray = genoperand(JumpLessOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant6 = firstByteFormat();
	genoperandoperand(CmpCqR, quickConstant6, SendNumArgsReg);
	/* begin JumpLess: */
	jmpFmtGeFirstByte = genoperand(JumpLess, ((sqInt)0));
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 3, SendNumArgsReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	/* begin Jump: */
	jumpGotByteSize = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpFmtGeFirstByte, gLogicalShiftRightCqR(2, ClassReg));
	/* begin Jump: */
	jumpGotWordSize = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpFmtLeWeakArray, gLabel());
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, ShiftForWord, ClassReg);
	/* begin CmpCq:R: */
	quickConstant7 = arrayFormat();
	genoperandoperand(CmpCqR, quickConstant7, SendNumArgsReg);
	/* begin JumpZero: */
	jumpFmtIsArray = genoperand(JumpZero, ((sqInt)0));
	genGetFixedFieldsOfPointerNonIntintoscratchReg(ReceiverResultReg, SendNumArgsReg, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	jmpTarget(jumpFmtIsArray, jmpTarget(jumpGotWordSize, jmpTarget(jumpGotByteSize, gLabel())));
	jumpNotIndexable = jumpNotIndexable1;
	jumpIsContext = jumpIsContext1;

	genConvertSmallIntegerToIntegerInReg(Arg1Reg);
	/* begin SubCq:R: */
	genoperandoperand(SubCqR, 1, Arg1Reg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, ClassReg, Arg1Reg);
	/* begin JumpAboveOrEqual: */
	jumpBounds = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, ReceiverResultReg, ClassReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = instFormatFieldLSB();
	genoperandoperand(LogicalShiftRightCqR, quickConstant, ClassReg);
	/* begin AndCq:R: */
	quickConstant1 = (1 << (instFormatFieldWidth())) - 1;
	genoperandoperand(AndCqR, quickConstant1, ClassReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 4, ClassReg);
	/* begin JumpGreater: */
	jumpFmtGt4 = genoperand(JumpGreater, ((sqInt)0));
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 2, ClassReg);
	/* begin JumpZero: */
	jumpFmtEq2 = genoperand(JumpZero, ((sqInt)0));
	/* begin AddR:R: */
	genoperandoperand(AddRR, SendNumArgsReg, Arg1Reg);
	jmpTarget(jumpFmtEq2, gLabel());
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, ((sqInt) BaseHeaderSize >> 2), Arg1Reg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpFmtGt4, gLabel());
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 8, ClassReg);
	/* begin JumpLess: */
	jumpFmtLt8 = genoperand(JumpLess, ((sqInt)0));
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 11, ClassReg);
	/* begin JumpGreater: */
	jumpFmtGt11 = genoperand(JumpGreater, ((sqInt)0));
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, BaseHeaderSize, Arg1Reg);
	/* begin MoveXbr:R:R: */
	genoperandoperandoperand(MoveXbrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	genConvertIntegerToSmallIntegerInReg(ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpFmtLt8, gLabel());
	assert(BytesPerWord == 4);
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, ((sqInt) BaseHeaderSize >> 2), Arg1Reg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 0x3FFFFFFF, ReceiverResultReg);
	/* begin JumpAbove: */
	jumpLarge = genoperand(JumpAbove, ((sqInt)0));
	genConvertIntegerToSmallIntegerInScratchReg(ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpLarge, CallRT(cePositive32BitIntegerTrampoline));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpSI, jmpTarget(jumpNotSI, jmpTarget(jumpNotIndexable, jmpTarget(jumpIsContext, jmpTarget(jumpBounds, jmpTarget(jumpFmtGt11, gLabel()))))));
	return 0;
}


/*	subclasses override if they can */

static sqInt
genInnerPrimitiveCharacterValue(sqInt retNOffset)
{
	// CogObjectRepresentation>>#genInnerPrimitiveCharacterValue:
	return unimplementedPrimitive();
}

static sqInt
genInnerPrimitiveIdenticalorNotIf(sqInt retNoffset, sqInt orNot)
{
	// CogObjectRepresentationForSqueakV3>>#genInnerPrimitiveIdentical:orNotIf:
    AbstractInstruction *jumpCmp;

	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ReceiverResultReg);
	jumpCmp = (orNot
		? (/* begin JumpZero: */
			genoperand(JumpZero, ((sqInt)0)))
		: (/* begin JumpNonZero: */
			genoperand(JumpNonZero, ((sqInt)0))));
	annotateobjRef(gMoveCwR(trueObject(), ReceiverResultReg), trueObject());
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpCmp, annotateobjRef(gMoveCwR(falseObject(), ReceiverResultReg), falseObject()));
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	return 0;
}

static sqInt
genInnerPrimitiveIdentityHash(sqInt retNOffset)
{
	// CogObjectRepresentationForSqueakV3>>#genInnerPrimitiveIdentityHash:
    AbstractInstruction *jumpSI;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, ClassReg);
	jumpSI = genJumpSmallIntegerInScratchReg(ClassReg);
	genGetHashFieldNonImmOfasSmallIntegerInto(ReceiverResultReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNOffset);
	jmpTarget(jumpSI, gLabel());
	return 0;
}


/*	subclasses override if they can */

static sqInt
genInnerPrimitiveNewMethod(sqInt retNoffset)
{
	// CogObjectRepresentation>>#genInnerPrimitiveNewMethod:
	return unimplementedPrimitive();
}


/*	subclasses override if they can */

static sqInt
genInnerPrimitiveNewWithArg(sqInt retNoffset)
{
	// CogObjectRepresentation>>#genInnerPrimitiveNewWithArg:
	return unimplementedPrimitive();
}


/*	subclasses override if they can */

static sqInt
genInnerPrimitiveNew(sqInt retNoffset)
{
	// CogObjectRepresentation>>#genInnerPrimitiveNew:
	return unimplementedPrimitive();
}


/*	c.f. StackInterpreter>>stSizeOf: lengthOf:baseHeader:format:
	fixedFieldsOf:format:length: 
 */

static sqInt
genInnerPrimitiveSize(sqInt retNoffset)
{
	// CogObjectRepresentationForSqueakV3>>#genInnerPrimitiveSize:
    sqInt jic;
    AbstractInstruction *jmpFmtGeFirstByte;
    sqInt jnx;
    AbstractInstruction *jumpFmtIsArray;
    AbstractInstruction *jumpFmtLeWeakArray;
    AbstractInstruction *jumpGotByteSize;
    AbstractInstruction *jumpGotWordSize;
    AbstractInstruction *jumpIsContext;
    AbstractInstruction *jumpIsContext1;
    AbstractInstruction *jumpNotIndexable;
    AbstractInstruction *jumpNotIndexable1;
    AbstractInstruction *jumpShortHeader;
    AbstractInstruction *jumpSI;
    AbstractInstruction *jumpSkip;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;
    sqInt quickConstant6;
    sqInt quickConstant7;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	jumpSI = genJumpSmallIntegerInScratchReg(TempReg);
	/* begin genGetSizeOf:into:formatReg:scratchReg:abortJumpsInto: */
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, ReceiverResultReg, SendNumArgsReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ClassReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = instFormatFieldLSB();
	genoperandoperand(LogicalShiftRightCqR, quickConstant, SendNumArgsReg);
	/* begin AndCq:R: */
	quickConstant1 = (1 << (instFormatFieldWidth())) - 1;
	genoperandoperand(AndCqR, quickConstant1, SendNumArgsReg);
	/* begin CmpCq:R: */
	quickConstant2 = arrayFormat();
	genoperandoperand(CmpCqR, quickConstant2, SendNumArgsReg);
	/* begin JumpLess: */
	jumpNotIndexable1 = genoperand(JumpLess, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, TempReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant3 = compactClassFieldLSB();
	genoperandoperand(LogicalShiftRightCqR, quickConstant3, TempReg);
	/* begin AndCq:R: */
	quickConstant4 = (1 << (compactClassFieldWidth())) - 1;
	genoperandoperand(AndCqR, quickConstant4, TempReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, TempReg);
	/* begin JumpZero: */
	jumpIsContext1 = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, TempReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, TypeMask, TempReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, HeaderTypeSizeAndClass, TempReg);
	/* begin JumpNonZero: */
	jumpShortHeader = genoperand(JumpNonZero, ((sqInt)0));
	assert(Size4Bit == 0);
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0 - (2 * BytesPerWord), ReceiverResultReg, ClassReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, ((sqInt) LongSizeMask), ClassReg);
	/* begin Jump: */
	jumpSkip = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpShortHeader, gAndCqR(SizeMask, ClassReg));
	jmpTarget(jumpSkip, gSubCqR(BaseHeaderSize, ClassReg));
	/* begin CmpCq:R: */
	quickConstant5 = weakArrayFormat();
	genoperandoperand(CmpCqR, quickConstant5, SendNumArgsReg);
	/* begin JumpLessOrEqual: */
	jumpFmtLeWeakArray = genoperand(JumpLessOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant6 = firstByteFormat();
	genoperandoperand(CmpCqR, quickConstant6, SendNumArgsReg);
	/* begin JumpLess: */
	jmpFmtGeFirstByte = genoperand(JumpLess, ((sqInt)0));
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 3, SendNumArgsReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	/* begin Jump: */
	jumpGotByteSize = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpFmtGeFirstByte, gLogicalShiftRightCqR(2, ClassReg));
	/* begin Jump: */
	jumpGotWordSize = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpFmtLeWeakArray, gLabel());
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, ShiftForWord, ClassReg);
	/* begin CmpCq:R: */
	quickConstant7 = arrayFormat();
	genoperandoperand(CmpCqR, quickConstant7, SendNumArgsReg);
	/* begin JumpZero: */
	jumpFmtIsArray = genoperand(JumpZero, ((sqInt)0));
	genGetFixedFieldsOfPointerNonIntintoscratchReg(ReceiverResultReg, SendNumArgsReg, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	jmpTarget(jumpFmtIsArray, jmpTarget(jumpGotWordSize, jmpTarget(jumpGotByteSize, gLabel())));
	jumpNotIndexable = jumpNotIndexable1;
	jumpIsContext = jumpIsContext1;

	genConvertIntegerToSmallIntegerInReg(ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpSI, jmpTarget(jumpNotIndexable, jmpTarget(jumpIsContext, gLabel())));
	return 0;
}


/*	subclasses override if they can */

static sqInt
genInnerPrimitiveStringAtPut(sqInt retNoffset)
{
	// CogObjectRepresentation>>#genInnerPrimitiveStringAtPut:
	return unimplementedPrimitive();
}


/*	c.f. StackInterpreter>>stSizeOf: lengthOf:baseHeader:format:
	fixedFieldsOf:format:length: 
 */

static sqInt
genInnerPrimitiveStringAt(sqInt retNOffset)
{
	// CogObjectRepresentationForSqueakV3>>#genInnerPrimitiveStringAt:
    AbstractInstruction *jumpBounds;
    AbstractInstruction *jumpNotByteIndexable;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpShortHeader;
    AbstractInstruction *jumpSI;
    AbstractInstruction *jumpSkip;
    sqInt quickConstant;
    sqInt quickConstant1;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	jumpSI = genJumpSmallIntegerInScratchReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, Arg1Reg);
	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, ReceiverResultReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ClassReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = instFormatFieldLSB();
	genoperandoperand(LogicalShiftRightCqR, quickConstant, TempReg);
	/* begin AndCq:R: */
	quickConstant1 = (1 << (instFormatFieldWidth())) - 1;
	genoperandoperand(AndCqR, quickConstant1, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, SendNumArgsReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 3, SendNumArgsReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, TempReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 8, TempReg);
	/* begin JumpNonZero: */
	jumpNotByteIndexable = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, TempReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, TypeMask, TempReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, HeaderTypeSizeAndClass, TempReg);
	/* begin JumpNonZero: */
	jumpShortHeader = genoperand(JumpNonZero, ((sqInt)0));
	assert(Size4Bit == 0);
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0 - (2 * BytesPerWord), ReceiverResultReg, ClassReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, ((sqInt) LongSizeMask), ClassReg);
	/* begin Jump: */
	jumpSkip = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpShortHeader, gAndCqR(SizeMask, ClassReg));
	jmpTarget(jumpSkip, gSubCqR(BaseHeaderSize, ClassReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	genConvertSmallIntegerToIntegerInReg(Arg1Reg);
	/* begin SubCq:R: */
	genoperandoperand(SubCqR, 1, Arg1Reg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, ClassReg, Arg1Reg);
	/* begin JumpAboveOrEqual: */
	jumpBounds = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, BaseHeaderSize, Arg1Reg);
	annotateobjRef(gMoveCwR(characterTable(), Arg0Reg), characterTable());
	/* begin MoveXbr:R:R: */
	genoperandoperandoperand(MoveXbrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, ((sqInt) BaseHeaderSize >> 2), ReceiverResultReg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, ReceiverResultReg, Arg0Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNOffset);
	jmpTarget(jumpSI, jmpTarget(jumpNotSI, jmpTarget(jumpNotByteIndexable, jmpTarget(jumpBounds, gLabel()))));
	return 0;
}

static sqInt
genJumpBackTo(sqInt targetBytecodePC)
{
	// StackToRegisterMappingCogit>>#genJumpBackTo:
    AbstractInstruction *abstractInstruction;
    sqInt address;
    void *jumpTarget;
    void *jumpTarget1;

	ssFlushTo(simStackPtr);
	/* begin MoveAw:R: */
	address = stackLimitAddress();
	genoperandoperand(MoveAwR, address, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, SPReg);
	/* begin JumpAboveOrEqual: */
	jumpTarget = fixupAt(targetBytecodePC - initialPC);
	genoperand(JumpAboveOrEqual, ((sqInt)jumpTarget));
	/* begin annotateBytecode: */
	abstractInstruction = CallRT(ceCheckForInterruptTrampoline);
	annotatewith(abstractInstruction, HasBytecodePC);
	/* begin Jump: */
	jumpTarget1 = fixupAt(targetBytecodePC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget1));
	return 0;
}

static AbstractInstruction *
genJumpFPEqual(AbstractInstruction * self_in_genJumpFPEqual, void *jumpTarget)
{
	// CogIA32Compiler>>#genJumpFPEqual:
    AbstractInstruction *jumpToTarget;
    AbstractInstruction *jumpUnordered;

	jumpUnordered = gen(JumpFPUnordered);
	jumpToTarget = genoperand(JumpFPEqual, ((sqInt)jumpTarget));
	jmpTarget(jumpUnordered, gLabel());
	return jumpToTarget;
}

static AbstractInstruction *
genJumpFPGreaterOrEqual(AbstractInstruction * self_in_genJumpFPGreaterOrEqual, void *jumpTarget)
{
	// CogAbstractInstruction>>#genJumpFPGreaterOrEqual:
	return genoperand(JumpFPGreaterOrEqual, ((sqInt)jumpTarget));
}

static AbstractInstruction *
genJumpFPGreater(AbstractInstruction * self_in_genJumpFPGreater, void *jumpTarget)
{
	// CogAbstractInstruction>>#genJumpFPGreater:
	return genoperand(JumpFPGreater, ((sqInt)jumpTarget));
}

static AbstractInstruction *
genJumpFPLessOrEqual(AbstractInstruction * self_in_genJumpFPLessOrEqual, void *jumpTarget)
{
	// CogAbstractInstruction>>#genJumpFPLessOrEqual:
	return genoperand(JumpFPLessOrEqual, ((sqInt)jumpTarget));
}

static AbstractInstruction *
genJumpFPLess(AbstractInstruction * self_in_genJumpFPLess, void *jumpTarget)
{
	// CogAbstractInstruction>>#genJumpFPLess:
	return genoperand(JumpFPLess, ((sqInt)jumpTarget));
}

static AbstractInstruction *
genJumpFPNotEqual(AbstractInstruction * self_in_genJumpFPNotEqual, void *jumpTarget)
{
	// CogIA32Compiler>>#genJumpFPNotEqual:
    AbstractInstruction *jumpToTarget;
    AbstractInstruction *jumpUnordered;

	jumpToTarget = genoperand(JumpFPNotEqual, ((sqInt)jumpTarget));
	jumpUnordered = genoperand(JumpFPUnordered, ((sqInt)jumpTarget));
	addDependent(jumpToTarget, jumpUnordered);
	return jumpToTarget;
}

static sqInt
genJumpIfto(sqInt boolean, sqInt targetBytecodePC)
{
	// StackToRegisterMappingCogit>>#genJumpIf:to:
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    CogSimStackEntry *desc;
    BytecodeFixup *fixup;
    void *jumpTarget;
    AbstractInstruction *ok;
    sqInt quickConstant;

	ssFlushTo(simStackPtr - 1);
	desc = ssTop();
	ssPop(1);
	if ((((desc->type)) == SSConstant)
	 && ((((desc->constant)) == (trueObject()))
	 || (((desc->constant)) == (falseObject())))) {

		/* Must arrange there's a fixup at the target whether it is jumped to or
		   not so that the simStackPtr can be kept correct. */
		/* Must enter any annotatedConstants into the map */


		/* Must arrange there's a fixup at the target whether it is jumped to or
		   not so that the simStackPtr can be kept correct. */
		/* Must enter any annotatedConstants into the map */

fixup = ensureFixupAt(targetBytecodePC - initialPC);
		if ((desc->annotateUse)) {
			/* begin annotateBytecode: */
			abstractInstruction = (prevInstIsPCAnnotated()
				? (/* begin Nop */
					gen(Nop))
				: (/* begin Label */
					genoperandoperand(Label, (labelCounter += 1), bytecodePC)));
			annotatewith(abstractInstruction, HasBytecodePC);
		}
		/* begin annotateBytecode: */
		abstractInstruction1 = (((desc->constant)) == boolean
			? (/* begin Jump: */
				genoperand(Jump, ((sqInt)fixup)))
			: (prevInstIsPCAnnotated()
					? (/* begin Nop */
						gen(Nop))
					: (/* begin Label */
						genoperandoperand(Label, (labelCounter += 1), bytecodePC))));
		annotatewith(abstractInstruction1, HasBytecodePC);
		return 0;
	}
	popToReg(desc, TempReg);
	assert((objectAfter(falseObject())) == (trueObject()));
	annotateobjRef(gSubCwR(boolean, TempReg), boolean);
	/* begin JumpZero: */
	jumpTarget = ensureFixupAt(targetBytecodePC - initialPC);
	genoperand(JumpZero, ((sqInt)jumpTarget));
	/* begin CmpCq:R: */
	quickConstant = (boolean == (falseObject())
		? (trueObject()) - (falseObject())
		: (falseObject()) - (trueObject()));
	genoperandoperand(CmpCqR, quickConstant, TempReg);
	/* begin JumpZero: */
	ok = genoperand(JumpZero, ((sqInt)0));
	CallRT((boolean == (falseObject())
		? ceSendMustBeBooleanAddFalseTrampoline
		: ceSendMustBeBooleanAddTrueTrampoline));
	jmpTarget(ok, annotateBytecode(gLabel()));
	return 0;
}

static AbstractInstruction *
genJumpImmediateInScratchReg(sqInt aRegister)
{
	// CogObjectRepresentationForSqueakV3>>#genJumpImmediateInScratchReg:
	return genJumpSmallIntegerInScratchReg(aRegister);
}

static AbstractInstruction *
genJumpNotSmallIntegerInScratchReg(sqInt aRegister)
{
	// CogObjectRepresentationForSqueakV3>>#genJumpNotSmallIntegerInScratchReg:
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 1, aRegister);
	/* begin JumpZero: */
	return genoperand(JumpZero, ((sqInt)0));
}

static AbstractInstruction *
genJumpSmallIntegerInScratchReg(sqInt aRegister)
{
	// CogObjectRepresentationForSqueakV3>>#genJumpSmallIntegerInScratchReg:
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 1, aRegister);
	/* begin JumpNonZero: */
	return genoperand(JumpNonZero, ((sqInt)0));
}

static sqInt
genJumpTo(sqInt targetBytecodePC)
{
	// StackToRegisterMappingCogit>>#genJumpTo:
    void *jumpTarget;

	ssFlushTo(simStackPtr);
	/* begin Jump: */
	jumpTarget = ensureFixupAt(targetBytecodePC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget));
	return 0;
}


/*	Load the stack pointer register with that of the C stack, effecting
	a switch to the C stack. Used when machine code calls into the
	CoInterpreter run-time (e.g. to invoke interpreter primitives). */

static sqInt
genLoadCStackPointer(AbstractInstruction * self_in_genLoadCStackPointer)
{
	// CogIA32Compiler>>#genLoadCStackPointer
    sqInt address;

	/* begin MoveAw:R: */
	address = cStackPointerAddress();
	genoperandoperand(MoveAwR, address, SPReg);
	return 0;
}


/*	Load the frame and stack pointer registers with those of the C stack,
	effecting a switch to the C stack. Used when machine code calls into
	the CoInterpreter run-time (e.g. to invoke interpreter primitives). */

static sqInt
genLoadCStackPointers(AbstractInstruction * self_in_genLoadCStackPointers)
{
	// CogIA32Compiler>>#genLoadCStackPointers
    sqInt address;
    sqInt address1;

	/* begin MoveAw:R: */
	address = cStackPointerAddress();
	genoperandoperand(MoveAwR, address, SPReg);
	/* begin MoveAw:R: */
	address1 = cFramePointerAddress();
	genoperandoperand(MoveAwR, address1, FPReg);
	return 0;
}

static sqInt
genLoadCStackPointersForPrimCall(void)
{
	// Cogit>>#genLoadCStackPointersForPrimCall
    sqInt address;
    sqInt address1;
    sqInt address2;

	if (debugPrimCallStackOffset == 0) {
		/* begin MoveAw:R: */
		address = cStackPointerAddress();
		genoperandoperand(MoveAwR, address, SPReg);
	}
	else {
/* begin MoveAw:R: */
		address1 = cStackPointerAddress();
		genoperandoperand(MoveAwR, address1, TempReg);
		/* begin SubCq:R: */
		genoperandoperand(SubCqR, debugPrimCallStackOffset, TempReg);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, TempReg, SPReg);
	}
	if (cFramePointerInUse) {
		/* begin MoveAw:R: */
		address2 = cFramePointerAddress();
		genoperandoperand(MoveAwR, address2, FPReg);
	}
	return 0;
}

static sqInt
genLoadSlotsourceRegdestReg(sqInt index, sqInt sourceReg, sqInt destReg)
{
	// CogObjectRepresentationForSqueakV3>>#genLoadSlot:sourceReg:destReg:
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, (index * BytesPerWord) + BaseHeaderSize, sourceReg, destReg);
	return 0;
}


/*	Switch back to the Smalltalk stack. Assign SPReg first
	because typically it is used immediately afterwards. */

static sqInt
genLoadStackPointers(AbstractInstruction * self_in_genLoadStackPointers)
{
	// CogIA32Compiler>>#genLoadStackPointers
    sqInt address;
    sqInt address1;

	/* begin MoveAw:R: */
	address = stackPointerAddress();
	genoperandoperand(MoveAwR, address, SPReg);
	/* begin MoveAw:R: */
	address1 = framePointerAddress();
	genoperandoperand(MoveAwR, address1, FPReg);
	return 0;
}

static sqInt
genLongJumpIfFalse(void)
{
	// SimpleStackBasedCogit>>#genLongJumpIfFalse
    sqInt distance;
    sqInt target;

	distance = v3LongForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 2) + bytecodePC;
	return genJumpIfto(falseObject(), target);
}

static sqInt
genLongJumpIfTrue(void)
{
	// SimpleStackBasedCogit>>#genLongJumpIfTrue
    sqInt distance;
    sqInt target;

	distance = v3LongForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 2) + bytecodePC;
	return genJumpIfto(trueObject(), target);
}


/*	237		11101101	i i i i i i i i	Pop and Store Temporary Variable #iiiiiiii */

static sqInt
genLongStoreAndPopTemporaryVariableBytecode(void)
{
	// SimpleStackBasedCogit>>#genLongStoreAndPopTemporaryVariableBytecode
	return genStorePopTemporaryVariable(1, byte1);
}

static sqInt
genLongUnconditionalBackwardJump(void)
{
	// SimpleStackBasedCogit>>#genLongUnconditionalBackwardJump
    sqInt distance;
    sqInt targetpc;

	distance = v3LongBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	assert(distance < 0);
	targetpc = (distance + 2) + bytecodePC;
	return genJumpBackTo(targetpc);
}

static sqInt
genLongUnconditionalForwardJump(void)
{
	// SimpleStackBasedCogit>>#genLongUnconditionalForwardJump
    sqInt distance;
    sqInt targetpc;

	distance = v3LongBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	assert(distance >= 0);
	targetpc = (distance + 2) + bytecodePC;
	return genJumpTo(targetpc);
}

static sqInt
genMarshalledSendSupernumArgs(sqInt selector, sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#genMarshalledSendSuper:numArgs:
	if (isYoung(selector)) {
		hasYoungReferent = 1;
	}
	assert(needsFrame);
	if (numArgs > 2) {
/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, numArgs, SendNumArgsReg);
	}
	/* begin MoveCw:R: */
	genoperandoperand(MoveCwR, selector, ClassReg);
	CallSend(superSendTrampolines[((numArgs < (NumSendTrampolines - 1)) ? numArgs : (NumSendTrampolines - 1))]);
	usesMethodClass = 1;
	(optStatus.isReceiverResultRegLive = 0);
	return ssPushRegister(ReceiverResultReg);
}

static sqInt
genMarshalledSendnumArgs(sqInt selector, sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#genMarshalledSend:numArgs:
	if (isYoung(selector)) {
		hasYoungReferent = 1;
	}
	assert(needsFrame);
	if (numArgs > 2) {
/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, numArgs, SendNumArgsReg);
	}
	/* begin MoveCw:R: */
	genoperandoperand(MoveCwR, selector, ClassReg);
	CallSend(sendTrampolines[((numArgs < (NumSendTrampolines - 1)) ? numArgs : (NumSendTrampolines - 1))]);
	(optStatus.isReceiverResultRegLive = 0);
	return ssPushRegister(ReceiverResultReg);
}


/*	Generate the abort for a method. This abort performs either a call of
	ceSICMiss: to handle a single-in-line cache miss or a call of
	ceStackOverflow: to handle a
	stack overflow. It distinguishes the two by testing ResultReceiverReg. If
	the register is zero then this is a stack-overflow because a) the receiver
	has already
	been pushed and so can be set to zero before calling the abort, and b) the
	receiver must always contain an object (and hence be non-zero) on SIC
	miss.  */

static sqInt
genMethodAbortTrampolineFor(sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#genMethodAbortTrampolineFor:
    AbstractInstruction *jumpSICMiss;

	opcodeIndex = 0;
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 0, ReceiverResultReg);
	/* begin JumpNonZero: */
	jumpSICMiss = genoperand(JumpNonZero, ((sqInt)0));
	
compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(ceStackOverflow, 1, SendNumArgsReg, null, null, null, 0, 1, null);
	jmpTarget(jumpSICMiss, gLabel());
	genPushRegisterArgsForAbortMissNumArgs(backEnd, numArgs);
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceSICMiss, trampolineNamenumArgs("ceMethodAbort", (numArgs <= 1
		? numArgs
		: -1)), 1, ReceiverResultReg, null, null, null, 0, 1, null, 1);
}

static AbstractInstruction *
genMulRR(AbstractInstruction * self_in_genMulRR, sqInt regSource, sqInt regDest)
{
	// CogIA32Compiler>>#genMulR:R:
	genoperandoperand(IMULRR, regSource, regDest);
	return self_in_genMulRR;
}

static sqInt
genMustBeBooleanTrampolineForcalled(sqInt boolean, char *trampolineName)
{
	// SimpleStackBasedCogit>>#genMustBeBooleanTrampolineFor:called:

	/* If the objectRepresentation does want true & false to be mobile then we need to record these addresses. */

opcodeIndex = 0;
	assert(!(shouldAnnotateObjectReference(boolean)));
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, boolean, TempReg);
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceSendMustBeBoolean, trampolineName, 1, TempReg, null, null, null, 0, 1, null, 1);
}


/*	Generate a call to code that allocates a new Array of size.
	The Array should be initialized with nils iff initialized is true.
	The size arg is passed in SendNumArgsReg, the result
	must come back in ReceiverResultReg. */

static void
genNewArrayOfSizeinitialized(sqInt size, sqInt initialized)
{
	// CogObjectRepresentationForSqueakV3>>#genNewArrayOfSize:initialized:
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, size, SendNumArgsReg);
	CallRT(ceCreateNewArrayTrampoline);
}

static sqInt
genNonLocalReturnTrampoline(void)
{
	// Cogit>>#genNonLocalReturnTrampoline
    sqInt address;
    sqInt address1;


	/* write the return address to the coInterpreter instructionPointerAddress;
	   CISCs will have pushed it on the stack, so pop it first; RISCs will have it in
	   their link register so just write it directly. */

	opcodeIndex = 0;
	/* begin PopR: */
	genoperand(PopR, TempReg);
	/* begin MoveR:Aw: */
	address1 = instructionPointerAddress();
	genoperandoperand(MoveRAw, TempReg, address1);

	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceNonLocalReturn, "ceNonLocalReturnTrampoline", 1, ReceiverResultReg, null, null, null, 0, 0, null, 1);
}

static sqInt
genPassConstasArgument(AbstractInstruction * self_in_genPassConstasArgument, sqInt constant, sqInt zeroRelativeArgIndex)
{
	// CogIA32Compiler>>#genPassConst:asArgument:
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, constant, TempReg);
	/* begin PushR: */
	genoperand(PushR, TempReg);
	return 0;
}

static sqInt
genPassRegasArgument(AbstractInstruction * self_in_genPassRegasArgument, sqInt abstractRegister, sqInt zeroRelativeArgIndex)
{
	// CogIA32Compiler>>#genPassReg:asArgument:
	/* begin PushR: */
	genoperand(PushR, abstractRegister);
	return 0;
}


/*	Generate the abort for a PIC. This abort performs either a call of
	ceInterpretMethodFromPIC:receiver: to handle invoking an uncogged
	target or a call of ceMNUFromPICMNUMethod:receiver: to handle an
	MNU dispatch in a closed PIC. It distinguishes the two by testing
	ClassReg. If the register is zero then this is an MNU. */

static sqInt
genPICAbortTrampolineFor(sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#genPICAbortTrampolineFor:
	opcodeIndex = 0;
	genPushRegisterArgsForAbortMissNumArgs(backEnd, numArgs);
	return genInnerPICAbortTrampoline(trampolineNamenumArgs("cePICAbort", (numArgs <= 1
		? numArgs
		: -1)));
}

static sqInt
genPICMissTrampolineFor(sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#genPICMissTrampolineFor:
    sqInt startAddress;

	startAddress = methodZoneBase;

	/* N.B. a closed PIC jumps to the miss routine, not calls it, so there is only one retpc on the stack. */

opcodeIndex = 0;
	genPushRegisterArgsForNumArgs(backEnd, numArgs);
	genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceCPICMissreceiver, trampolineNamenumArgs("cePICMiss", (numArgs <= 1
		? numArgs
		: -1)), 2, ClassReg, ReceiverResultReg, null, null, 0, 1, null, 1);
	return startAddress;
}

static sqInt
genPopStackBytecode(void)
{
	// StackToRegisterMappingCogit>>#genPopStackBytecode
	annotateBytecodeIfAnnotated(ssTop());
	if (((ssTop())->spilled)) {
		/* begin AddCq:R: */
		genoperandoperand(AddCqR, BytesPerWord, SPReg);
	}
	ssPop(1);
	return 0;
}

static sqInt
genPrimitiveAdd(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveAdd
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	genRemoveSmallIntegerTagsInScratchReg(ClassReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, ReceiverResultReg, ClassReg);
	/* begin JumpOverflow: */
	jumpOvfl = genoperand(JumpOverflow, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOvfl, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}

static sqInt
genPrimitiveAsCharacter(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveAsCharacter
    sqInt na;
    sqInt r;

	na = argumentCountOf(methodObj);
	if (na <= 1) {
if (((r = genInnerPrimitiveAsCharacterinReg(0, (na == 0
	? ReceiverResultReg
	: Arg0Reg)))) < 0) {
			return r;
		}
	}
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveAsFloat(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveAsFloat
    AbstractInstruction *jumpFailAlloc;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, TempReg, DPFPReg0);
	jumpFailAlloc = genAllocFloatValueintoscratchRegscratchReg(DPFPReg0, SendNumArgsReg, ClassReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpFailAlloc, gLabel());
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveAt(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveAt
    sqInt r;

	assert((numRegArgs()) >= 1);
	if (((r = genInnerPrimitiveAt(0))) < 0) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveAtPut(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveAtPut
    sqInt r;

	if ((((r = genInnerPrimitiveAtPut(0))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveBitAnd(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveBitAnd
    AbstractInstruction *jumpNotSI;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);

	/* Whether the SmallInteger tags are zero or non-zero, oring them together will preserve them. */

jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin AndR:R: */
	genoperandoperand(AndRR, Arg0Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, gLabel());
	return 0;
}

static sqInt
genPrimitiveBitOr(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveBitOr
    AbstractInstruction *jumpNotSI;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);

	/* Whether the SmallInteger tags are zero or non-zero, oring them together will preserve them. */

jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin OrR:R: */
	genoperandoperand(OrRR, Arg0Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, gLabel());
	return 0;
}


/*	Receiver and arg in registers.
	Stack looks like
	return address
	
	rTemp := rArg0
	rClass := tTemp
	rTemp := rTemp & 1
	jz nonInt
	rClass >>= 1
	cmp 0,rClass
	jge neg
	cmp 31,rClass // numSmallIntegerBits, jge for sign
	jge tooBig
	rTemp := rReceiver
	rTemp <<= rClass
	rTemp >>= rClass (arithmetic)
	cmp rTemp,rReceiver
	jnz ovfl
	rReceiver := rReceiver - 1
	rReceiver := rReceiver <<= rClass
	rReceiver := rReceiver + 1
	ret
	neg:
	rClass := 0 - rClass
	cmp 31,rClass
	jge inRange
	rClass := 31
	inRange
	rReceiver := rReceiver >>= rClass.
	rReceiver := rReceiver | 1.
	ret
	ovfl
	tooBig
	nonInt:
	fail
 */

static sqInt
genPrimitiveBitShift(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveBitShift
    AbstractInstruction *jumpInRange;
    AbstractInstruction *jumpNegative;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;
    AbstractInstruction *jumpTooBig;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;

	assert((numRegArgs()) >= 1);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	genConvertSmallIntegerToIntegerInReg(ClassReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpNegative))) {
		/* begin CmpCq:R: */
		genoperandoperand(CmpCqR, 0, ClassReg);
	}
	/* begin JumpNegative: */
	jumpNegative = genoperand(JumpNegative, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant = numSmallIntegerBits();
	genoperandoperand(CmpCqR, quickConstant, ClassReg);
	/* begin JumpGreaterOrEqual: */
	jumpTooBig = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin LogicalShiftLeftR:R: */
	genoperandoperand(LogicalShiftLeftRR, ClassReg, TempReg);
	/* begin ArithmeticShiftRightR:R: */
	genoperandoperand(ArithmeticShiftRightRR, ClassReg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, ReceiverResultReg);
	/* begin JumpNonZero: */
	jumpOvfl = genoperand(JumpNonZero, ((sqInt)0));
	genRemoveSmallIntegerTagsInScratchReg(ReceiverResultReg);
	/* begin LogicalShiftLeftR:R: */
	genoperandoperand(LogicalShiftLeftRR, ClassReg, ReceiverResultReg);
	genAddSmallIntegerTagsTo(ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNegative, gNegateR(ClassReg));
	/* begin CmpCq:R: */
	quickConstant1 = numSmallIntegerBits();
	genoperandoperand(CmpCqR, quickConstant1, ClassReg);
	/* begin JumpLessOrEqual: */
	jumpInRange = genoperand(JumpLessOrEqual, ((sqInt)0));
	/* begin MoveCq:R: */
	quickConstant2 = numSmallIntegerBits();
	genoperandoperand(MoveCqR, quickConstant2, ClassReg);
	jmpTarget(jumpInRange, gArithmeticShiftRightRR(ClassReg, ReceiverResultReg));
	genSetSmallIntegerTagsIn(ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, jmpTarget(jumpTooBig, jmpTarget(jumpOvfl, gLabel())));
	return 0;
}

static sqInt
genPrimitiveBitXor(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveBitXor
    AbstractInstruction *jumpNotSI;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);

	/* Clear one or the other tag so that xoring will preserve them. */

jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	genRemoveSmallIntegerTagsInScratchReg(Arg0Reg);
	/* begin XorR:R: */
	genoperandoperand(XorRR, Arg0Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, gLabel());
	return 0;
}

static sqInt
genPrimitiveCharacterValue(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveCharacterValue
    sqInt r;

	if (((r = genInnerPrimitiveCharacterValue(0))) < 0) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}


/*	Depending on argument count the argument is either
	0 args: ReceiverResultReg
	1 args: Arg0Reg
	N args: top of stack (assuming 1 reg arg for now) */

static sqInt
genPrimitiveClass(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveClass
    sqInt reg;

	if (methodOrBlockNumArgs == 1) {
		reg = Arg0Reg;
	}
	else {
if (methodOrBlockNumArgs > 0) {
			/* begin MoveMw:r:R: */
			genoperandoperandoperand(MoveMwrR, BytesPerWord, SPReg, ReceiverResultReg);
		}
		reg = ReceiverResultReg;
	}
	if ((genGetClassObjectOfintoscratchReginstRegIsReceiver(reg, ReceiverResultReg, TempReg, methodOrBlockNumArgs == 0)) == BadRegisterSet) {
		genGetClassObjectOfintoscratchReginstRegIsReceiver(reg, ClassReg, TempReg, methodOrBlockNumArgs == 0);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	}
	/* begin RetN: */
	genoperand(RetN, 0);
	return 0;
}


/*	Check the argument count. Fail if wrong.
	Get the method from the outerContext and see if it is cogged. If so, jump
	to the
	block entry or the no-context-switch entry, as appropriate, and we're
	done. If not,
	invoke the interpreter primitive. */
/*	Check the argument count. Fail if wrong.
	Get the method from the outerContext and see if it is cogged. If so, jump
	to the
	block entry or the no-context-switch entry, as appropriate, and we're
	done. If not,
	invoke the interpreter primitive.
	Override to push the register args first. */

static sqInt
genPrimitiveClosureValue(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveClosureValue
    AbstractInstruction *jumpBCMethod;
    AbstractInstruction *jumpFail;
    sqInt offset;
    void (*primitiveRoutine)();
    sqInt result;

	genPushRegisterArgs();
	genLoadSlotsourceRegdestReg(ClosureNumArgsIndex, ReceiverResultReg, TempReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, ((methodOrBlockNumArgs << 1) | 1), TempReg);
	/* begin JumpNonZero: */
	jumpFail = genoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ReceiverResultReg, ClassReg);
	genLoadSlotsourceRegdestReg(MethodIndex, ClassReg, SendNumArgsReg);
	genLoadSlotsourceRegdestReg(HeaderIndex, SendNumArgsReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ClassReg);
	jumpBCMethod = genJumpSmallIntegerInScratchReg(TempReg);
	/* begin MoveM16:r:R: */
	offset = offsetof(CogMethod, blockEntryOffset);
	genoperandoperandoperand(MoveM16rR, offset, ClassReg, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, ClassReg, TempReg);
	primitiveRoutine = functionPointerForCompiledMethodprimitiveIndex(methodObj, primitiveIndex);
	if (primitiveRoutine == primitiveClosureValueNoContextSwitch) {
		if (blockNoContextSwitchOffset == null) {
			return NotFullyInitialized;
		}
		/* begin SubCq:R: */
		genoperandoperand(SubCqR, blockNoContextSwitchOffset, TempReg);
	}
	/* begin JumpR: */
	genoperand(JumpR, TempReg);
	jmpTarget(jumpBCMethod, gLabel());
	if (((result = compileInterpreterPrimitive(primitiveRoutine))) < 0) {
		return result;
	}
	jmpTarget(jumpFail, gLabel());
	return 0;
}

static sqInt
genPrimitiveDiv(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveDiv
    AbstractInstruction *convert;
    AbstractInstruction *jumpExact;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpSameSign;
    AbstractInstruction *jumpZero;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, Arg1Reg);

	/* We must shift away the tags, not just subtract them, so that the
	   overflow case doesn't actually overflow the machine instruction. */

	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		genoperandoperand(CmpCqR, 0, ClassReg);
	}
	/* begin JumpZero: */
	jumpZero = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 0, ClassReg);
	/* begin JumpZero: */
	jumpExact = genoperand(JumpZero, ((sqInt)0));
	/* begin XorR:R: */
	genoperandoperand(XorRR, ClassReg, Arg1Reg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		genoperandoperand(CmpCqR, 0, Arg1Reg);
	}
	/* begin JumpGreaterOrEqual: */
	jumpSameSign = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin SubCq:R: */
	genoperandoperand(SubCqR, 1, TempReg);
	jmpTarget(jumpSameSign, (convert = gLabel()));
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpExact, gCmpCqR(1 << ((numSmallIntegerBits()) - 1), TempReg));
	/* begin JumpLess: */
	genoperand(JumpLess, ((sqInt)convert));
	jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}

static sqInt
genPrimitiveDivide(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveDivide
    AbstractInstruction *jumpInexact;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOverflow;
    AbstractInstruction *jumpZero;
    sqInt quickConstant;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);

	/* We must shift away the tags, not just subtract them, so that the
	   overflow case doesn't actually overflow the machine instruction. */

	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	/* begin JumpZero: */
	jumpZero = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 0, ClassReg);
	/* begin JumpNonZero: */
	jumpInexact = genoperand(JumpNonZero, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant = 1 << ((numSmallIntegerBits()) - 1);
	genoperandoperand(CmpCqR, quickConstant, TempReg);
	/* begin JumpGreaterOrEqual: */
	jumpOverflow = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOverflow, jmpTarget(jumpInexact, jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()))));
	return 0;
}

static sqInt
genPrimitiveEqual(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveEqual
	return genSmallIntegerComparisonorDoubleComparison(JumpZero, gJumpFPEqual);
}

static sqInt
genPrimitiveFloatAdd(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatAdd
	return genDoubleArithmeticpreOpCheck(AddRdRd, null);
}

static sqInt
genPrimitiveFloatDivide(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatDivide
	return genDoubleArithmeticpreOpCheck(DivRdRd, genDoubleFailIfZeroArgRcvrarg);
}

static sqInt
genPrimitiveFloatEqual(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatEqual
	return genDoubleComparisoninvert(gJumpFPEqual, 0);
}

static sqInt
genPrimitiveFloatGreaterOrEqual(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatGreaterOrEqual
	return genDoubleComparisoninvert(gJumpFPGreaterOrEqual, 0);
}

static sqInt
genPrimitiveFloatGreaterThan(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatGreaterThan
	return genDoubleComparisoninvert(gJumpFPGreater, 0);
}

static sqInt
genPrimitiveFloatLessOrEqual(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatLessOrEqual
	return genDoubleComparisoninvert(gJumpFPGreaterOrEqual, 1);
}

static sqInt
genPrimitiveFloatLessThan(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatLessThan
	return genDoubleComparisoninvert(gJumpFPGreater, 1);
}

static sqInt
genPrimitiveFloatMultiply(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatMultiply
	return genDoubleArithmeticpreOpCheck(MulRdRd, null);
}

static sqInt
genPrimitiveFloatNotEqual(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatNotEqual
	return genDoubleComparisoninvert(gJumpFPNotEqual, 0);
}

static sqInt
genPrimitiveFloatSquareRoot(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveFloatSquareRoot
    AbstractInstruction *jumpFailAlloc;

	genGetDoubleValueOfinto(ReceiverResultReg, DPFPReg0);
	/* begin SqrtRd: */
	genoperand(SqrtRd, DPFPReg0);
	jumpFailAlloc = genAllocFloatValueintoscratchRegscratchReg(DPFPReg0, SendNumArgsReg, ClassReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpFailAlloc, gLabel());
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveFloatSubtract(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveFloatSubtract
	return genDoubleArithmeticpreOpCheck(SubRdRd, null);
}

static sqInt
genPrimitiveGreaterOrEqual(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveGreaterOrEqual
	return genSmallIntegerComparisonorDoubleComparison(JumpGreaterOrEqual, gJumpFPGreaterOrEqual);
}

static sqInt
genPrimitiveGreaterThan(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveGreaterThan
	return genSmallIntegerComparisonorDoubleComparison(JumpGreater, gJumpFPGreater);
}


/*	Receiver and arg in registers.
	Stack looks like
	return address */

static sqInt
genPrimitiveIdentical(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveIdentical
	return genInnerPrimitiveIdenticalorNotIf(0, 0);
}

static sqInt
genPrimitiveIdentityHash(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveIdentityHash
    sqInt r;

	if (((r = genInnerPrimitiveIdentityHash(0))) < 0) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveLessOrEqual(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveLessOrEqual
	return genSmallIntegerComparisonorDoubleComparison(JumpLessOrEqual, gJumpFPLessOrEqual);
}

static sqInt
genPrimitiveLessThan(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveLessThan
	return genSmallIntegerComparisonorDoubleComparison(JumpLess, gJumpFPLess);
}

static sqInt
genPrimitiveMod(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveMod
    AbstractInstruction *jumpExact;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpSameSign;
    AbstractInstruction *jumpZero;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	genRemoveSmallIntegerTagsInScratchReg(ClassReg);
	/* begin JumpZero: */
	jumpZero = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, Arg1Reg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genRemoveSmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 0, ClassReg);
	/* begin JumpZero: */
	jumpExact = genoperand(JumpZero, ((sqInt)0));
	/* begin XorR:R: */
	genoperandoperand(XorRR, ClassReg, Arg1Reg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		genoperandoperand(CmpCqR, 0, Arg1Reg);
	}
	/* begin JumpGreaterOrEqual: */
	jumpSameSign = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin XorR:R: */
	genoperandoperand(XorRR, ClassReg, Arg1Reg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, ClassReg);
	jmpTarget(jumpSameSign, jmpTarget(jumpExact, gLabel()));
	genSetSmallIntegerTagsIn(ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}

static sqInt
genPrimitiveMultiply(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveMultiply
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, Arg1Reg);
	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	genRemoveSmallIntegerTagsInScratchReg(Arg1Reg);
	gMulRR(Arg1Reg, ClassReg);
	/* begin JumpOverflow: */
	jumpOvfl = genoperand(JumpOverflow, ((sqInt)0));
	genSetSmallIntegerTagsIn(ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOvfl, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}

static sqInt
genPrimitiveNew(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveNew
    sqInt numArgs;
    sqInt r;

	if ((((r = genInnerPrimitiveNew(0))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}

	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveNewMethod(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveNewMethod
    sqInt r;

	if ((((r = genInnerPrimitiveNewMethod(2 * BytesPerWord))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveNewWithArg(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveNewWithArg
    sqInt numArgs;
    sqInt r;

	if ((((r = genInnerPrimitiveNewWithArg(0))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}

	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveNotEqual(void)
{
	// SimpleStackBasedCogit>>#genPrimitiveNotEqual
	return genSmallIntegerComparisonorDoubleComparison(JumpNonZero, gJumpFPNotEqual);
}


/*	Receiver and arg in registers.
	Stack looks like
	return address */

static sqInt
genPrimitiveNotIdentical(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveNotIdentical
	return genInnerPrimitiveIdenticalorNotIf(0, 1);
}

static sqInt
genPrimitiveQuo(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveQuo
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOverflow;
    AbstractInstruction *jumpZero;
    sqInt quickConstant;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);

	/* We must shift away the tags, not just subtract them, so that the
	   overflow case doesn't actually overflow the machine instruction. */

	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		genoperandoperand(CmpCqR, 0, ClassReg);
	}
	/* begin JumpZero: */
	jumpZero = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = 1 << ((numSmallIntegerBits()) - 1);
	genoperandoperand(CmpCqR, quickConstant, TempReg);
	/* begin JumpGreaterOrEqual: */
	jumpOverflow = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOverflow, jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel())));
	return 0;
}

static sqInt
genPrimitiveSize(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveSize
    sqInt r;

	if (((r = genInnerPrimitiveSize(0))) < 0) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveStringAt(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveStringAt
    sqInt r;

	assert((numRegArgs()) >= 1);
	if (((r = genInnerPrimitiveStringAt(0))) < 0) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveStringAtPut(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveStringAtPut
    sqInt r;

	if ((((r = genInnerPrimitiveStringAtPut(0))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

static sqInt
genPrimitiveSubtract(void)
{
	// StackToRegisterMappingCogit>>#genPrimitiveSubtract
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	jumpNotSI = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, Arg0Reg, TempReg);
	/* begin JumpOverflow: */
	jumpOvfl = genoperand(JumpOverflow, ((sqInt)0));
	genAddSmallIntegerTagsTo(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOvfl, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}


/*	Generate the substitute return code for an external or FFI primitive call.
	On success simply return, extracting numArgs from newMethod.
	On primitive failure call ceActivateFailingPrimitiveMethod: newMethod. */

static void
genPrimReturnEnterCogCodeEnilopmart(sqInt profiling)
{
	// SimpleStackBasedCogit>>#genPrimReturnEnterCogCodeEnilopmart:
    sqInt address;
    sqInt address1;
    sqInt address2;
    sqInt address3;
    sqInt address4;
    sqInt address5;
    sqInt address6;
    AbstractInstruction *continuePostSample;
    AbstractInstruction *jmpFail;
    AbstractInstruction *jmpSample;

	opcodeIndex = 0;
	if (profiling) {

		/* Test nextProfileTick for being non-zero and call checkProfileTick: if so.
		   N.B. nextProfileTick is 64-bits so 32-bit systems need to test both halves. */

		
		/* Test nextProfileTick for being non-zero and call checkProfileTick: if so.
		   N.B. nextProfileTick is 64-bits so 32-bit systems need to test both halves. */

		/* begin MoveAw:R: */
		address = nextProfileTickAddress();
		genoperandoperand(MoveAwR, address, TempReg);
		/* begin MoveAw:R: */
		address1 = (nextProfileTickAddress()) + BytesPerWord;
		genoperandoperand(MoveAwR, address1, ClassReg);
		/* begin OrR:R: */
		genoperandoperand(OrRR, TempReg, ClassReg);

		/* begin JumpNonZero: */
		jmpSample = genoperand(JumpNonZero, ((sqInt)0));
		/* begin Label */
		continuePostSample = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	}
	maybeCompileAllocFillerCheck();
	/* begin MoveAw:R: */
	address5 = primFailCodeAddress();
	genoperandoperand(MoveAwR, address5, TempReg);
	flag("ask concrete code gen if move sets condition codes?");
	/* begin CmpCq:R: */
	genoperandoperand(CmpCqR, 0, TempReg);
	/* begin JumpNonZero: */
	jmpFail = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveAw:R: */
	address4 = instructionPointerAddress();
	genoperandoperand(MoveAwR, address4, ClassReg);
	genLoadStackPointers(backEnd);
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, SPReg, ReceiverResultReg);
	/* begin MoveR:Mw:r: */
	genoperandoperandoperand(MoveRMwr, ClassReg, 0, SPReg);
	/* begin RetN: */
	genoperand(RetN, 0);

	jmpTarget(jmpFail, gMoveAwR(newMethodAddress(), SendNumArgsReg));
	/* begin MoveAw:R: */
	address6 = cStackPointerAddress();
	genoperandoperand(MoveAwR, address6, SPReg);
	if (cStackAlignment > BytesPerWord) {
		genAlignCStackSavingRegistersnumArgswordAlignment(backEnd, 0, 1, ((sqInt) cStackAlignment >> 2));
	}
	genPassRegasArgument(backEnd, SendNumArgsReg, 0);
	CallRT((unsigned long)ceActivateFailingPrimitiveMethod);
	if (profiling) {

		/* Call ceCheckProfileTick: to record sample and then continue.  newMethod
		   should be up-to-date.  Need to save and restore the link reg around this call. */

		jmpTarget(jmpSample, gLabel());
		
CallRT((unsigned long)ceCheckProfileTick);
		
/* begin Jump: */
		genoperand(Jump, ((sqInt)continuePostSample));
	}
}

static sqInt
genPushActiveContextBytecode(void)
{
	// StackToRegisterMappingCogit>>#genPushActiveContextBytecode
	assert(needsFrame);
	(optStatus.isReceiverResultRegLive = 0);
	ssAllocateCallReg(ReceiverResultReg);

	genGetActiveContextNumArgslargeinBlock(methodOrBlockNumArgs, methodNeedsLargeContext(methodObj), inBlock);
	return ssPushRegister(ReceiverResultReg);
}


/*	Block compilation. At this point in the method create the block. Note its
	start and defer generating code for it until after the method and any
	other preceeding
	blocks. The block's actual code will be compiled later. */
/*	143 10001111 llllkkkk jjjjjjjj iiiiiiii	Push Closure Num Copied llll Num
	Args kkkk BlockSize jjjjjjjjiiiiiiii */

static sqInt
genPushClosureCopyCopiedValuesBytecode(void)
{
	// StackToRegisterMappingCogit>>#genPushClosureCopyCopiedValuesBytecode
    sqInt i;
    sqInt numArgs;
    sqInt numCopied;
    sqInt reg;

	assert(needsFrame);
	addBlockStartAtnumArgsnumCopiedspan(bytecodePC + 4, (numArgs = byte1 & 15), (numCopied = ((usqInt) byte1) >> 4), (byte2 << 8) + byte3);
	
if (numCopied > 0) {
ssFlushTo(simStackPtr);
	}
	(optStatus.isReceiverResultRegLive = 0);
	ssAllocateCallRegand(SendNumArgsReg, ReceiverResultReg);

	genCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(bytecodePC + 5, numArgs, numCopied, methodOrBlockNumArgs, methodNeedsLargeContext(methodObj), inBlock);
	if (numCopied > 0) {
ssPop(numCopied);
	}
	return ssPushRegister(ReceiverResultReg);
}

static sqInt
genPushConstantFalseBytecode(void)
{
	// SimpleStackBasedCogit>>#genPushConstantFalseBytecode
	return genPushLiteral(falseObject());
}

static sqInt
genPushConstantNilBytecode(void)
{
	// SimpleStackBasedCogit>>#genPushConstantNilBytecode
	return genPushLiteral(nilObject());
}

static sqInt
genPushConstantTrueBytecode(void)
{
	// SimpleStackBasedCogit>>#genPushConstantTrueBytecode
	return genPushLiteral(trueObject());
}

static sqInt
genPushLiteralConstantBytecode(void)
{
	// SimpleStackBasedCogit>>#genPushLiteralConstantBytecode
	return genPushLiteralIndex(byte0 & 0x1F);
}


/*	<SmallInteger> */

static sqInt
genPushLiteralIndex(sqInt literalIndex)
{
	// SimpleStackBasedCogit>>#genPushLiteralIndex:
    sqInt literal;

	literal = getLiteral(literalIndex);
	return genPushLiteral(literal);
}

static sqInt
genPushLiteralVariableBytecode(void)
{
	// SimpleStackBasedCogit>>#genPushLiteralVariableBytecode
	return genPushLiteralVariable(byte0 & 0x1F);
}

static sqInt
genPushLiteralVariable(sqInt literalIndex)
{
	// StackToRegisterMappingCogit>>#genPushLiteralVariable:
    sqInt association;
    sqInt freeReg;

	freeReg = ssAllocatePreferredReg(ClassReg);

	/* N.B. Do _not_ use ReceiverResultReg to avoid overwriting receiver in assignment in frameless methods. */
	/* So far descriptors are not rich enough to describe the entire dereference so generate the register
	   load but don't push the result.  There is an order-of-evaluation issue if we defer the dereference. */

	association = getLiteral(literalIndex);
	annotateobjRef(gMoveCwR(association, TempReg), association);
	genEnsureObjInRegNotForwardedscratchReg(TempReg, freeReg);
	genLoadSlotsourceRegdestReg(ValueIndex, TempReg, freeReg);
	ssPushRegister(freeReg);
	return 0;
}

static sqInt
genPushLiteral(sqInt literal)
{
	// StackToRegisterMappingCogit>>#genPushLiteral:
	return ssPushConstant(literal);
}

static sqInt
genPushMaybeContextReceiverVariable(sqInt slotIndex)
{
	// StackToRegisterMappingCogit>>#genPushMaybeContextReceiverVariable:
    AbstractInstruction *jmpDone;
    AbstractInstruction *jmpSingle;

	assert(needsFrame);
	ssAllocateCallRegand(ReceiverResultReg, SendNumArgsReg);
	ensureReceiverResultRegContainsSelf();
	if ((registerMaskFor(ReceiverResultReg)) & callerSavedRegMask) {

		/* We have no way of reloading ReceiverResultReg since we need the inst var value as the result. */

(optStatus.isReceiverResultRegLive = 0);
	}
	if (slotIndex == InstructionPointerIndex) {
/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, slotIndex, SendNumArgsReg);
		CallRT(ceFetchContextInstVarTrampoline);
		return ssPushRegister(SendNumArgsReg);
	}
	genLoadSlotsourceRegdestReg(SenderIndex, ReceiverResultReg, TempReg);
	jmpSingle = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, slotIndex, SendNumArgsReg);
	CallRT(ceFetchContextInstVarTrampoline);
	/* begin Jump: */
	jmpDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpSingle, gLabel());
	genLoadSlotsourceRegdestReg(slotIndex, ReceiverResultReg, SendNumArgsReg);
	jmpTarget(jmpDone, gLabel());
	return ssPushRegister(SendNumArgsReg);
}

static sqInt
genPushNewArrayBytecode(void)
{
	// StackToRegisterMappingCogit>>#genPushNewArrayBytecode
    sqInt i;
    sqInt popValues;
    sqInt size;

	assert(needsFrame);
	(optStatus.isReceiverResultRegLive = 0);
	if ((popValues = byte1 > 0x7F)) {
		ssFlushTo(simStackPtr);
	}
	else {
ssAllocateCallRegand(SendNumArgsReg, ReceiverResultReg);
	}
	size = byte1 & 0x7F;
	if (!popValues) {
if (tryCollapseTempVectorInitializationOfSize(size)) {
			return 0;
		}
	}
	genNewArrayOfSizeinitialized(size, !popValues);
	if (popValues) {
for (i = (size - 1); i >= 0; i += -1) {
			/* begin PopR: */
			genoperand(PopR, TempReg);
			genStoreSourceRegslotIndexintoNewObjectInDestReg(TempReg, i, ReceiverResultReg);
		}
		ssPop(size);
	}
	return ssPushRegister(ReceiverResultReg);
}

static sqInt
genPushQuickIntegerConstantBytecode(void)
{
	// SimpleStackBasedCogit>>#genPushQuickIntegerConstantBytecode
	return genPushLiteral((((byte0 - 117) << 1) | 1));
}

static sqInt
genPushReceiverBytecode(void)
{
	// StackToRegisterMappingCogit>>#genPushReceiverBytecode
	if (((optStatus.isReceiverResultRegLive))
	 && (((optStatus.ssEntry)) == ((&simSelf)))) {
		return ssPushRegister(ReceiverResultReg);
	}
	return ssPushDesc(simSelf);
}

static sqInt
genPushReceiverVariableBytecode(void)
{
	// SimpleStackBasedCogit>>#genPushReceiverVariableBytecode
	return genPushReceiverVariable(byte0 & 15);
}

static sqInt
genPushReceiverVariable(sqInt index)
{
	// StackToRegisterMappingCogit>>#genPushReceiverVariable:
	ensureReceiverResultRegContainsSelf();
	return ssPushBaseoffset(ReceiverResultReg, slotOffsetOfInstVarIndex(index));
}


/*	Ensure that the register args are pushed before the retpc for methods with
	arity <= self numRegArgs.
 */
/*	This won't be as clumsy on a RISC. But putting the receiver and
	args above the return address means the CoInterpreter has a
	single machine-code frame format which saves us a lot of work. */

static void
genPushRegisterArgs(void)
{
	// StackToRegisterMappingCogit>>#genPushRegisterArgs
	if (!(regArgsHaveBeenPushed
		 || (methodOrBlockNumArgs > 1))) {
		genPushRegisterArgsForNumArgs(backEnd, methodOrBlockNumArgs);
		regArgsHaveBeenPushed = 1;
	}
}


/*	Ensure that the register args are pushed before the outer and
	inner retpcs at an entry miss for arity <= self numRegArgs. The
	outer retpc is that of a call at a send site. The inner is the call
	from a method or PIC abort/miss to the trampoline. */
/*	This won't be as clumsy on a RISC. But putting the receiver and
	args above the return address means the CoInterpreter has a
	single machine-code frame format which saves us a lot of work. */
/*	Iff there are register args convert
	base	->	outerRetpc		(send site retpc)
	sp		->	innerRetpc		(PIC abort/miss retpc)
	to
	base	->	receiver
	(arg0)
	(arg1)
	outerRetpc
	sp		->	innerRetpc		(PIC abort/miss retpc) */

static AbstractInstruction *
genPushRegisterArgsForAbortMissNumArgs(AbstractInstruction * self_in_genPushRegisterArgsForAbortMissNumArgs, sqInt numArgs)
{
	// CogIA32Compiler>>#genPushRegisterArgsForAbortMissNumArgs:
	if (numArgs <= 1) {
assert((numRegArgs()) <= 2);
		if (numArgs == 0) {
/* begin MoveMw:r:R: */
			genoperandoperandoperand(MoveMwrR, 0, SPReg, TempReg);
			/* begin PushR: */
			genoperand(PushR, TempReg);
			/* begin MoveMw:r:R: */
			genoperandoperandoperand(MoveMwrR, BytesPerWord * 2, SPReg, TempReg);
			/* begin MoveR:Mw:r: */
			genoperandoperandoperand(MoveRMwr, TempReg, BytesPerWord, SPReg);
			/* begin MoveR:Mw:r: */
			genoperandoperandoperand(MoveRMwr, ReceiverResultReg, 2 * BytesPerWord, SPReg);
			return self_in_genPushRegisterArgsForAbortMissNumArgs;
		}
		if (numArgs == 1) {
/* begin MoveMw:r:R: */
			genoperandoperandoperand(MoveMwrR, BytesPerWord, SPReg, TempReg);
			/* begin PushR: */
			genoperand(PushR, TempReg);
			/* begin MoveMw:r:R: */
			genoperandoperandoperand(MoveMwrR, BytesPerWord, SPReg, TempReg);
			/* begin PushR: */
			genoperand(PushR, TempReg);
			/* begin MoveR:Mw:r: */
			genoperandoperandoperand(MoveRMwr, ReceiverResultReg, 3 * BytesPerWord, SPReg);
			/* begin MoveR:Mw:r: */
			genoperandoperandoperand(MoveRMwr, Arg0Reg, 2 * BytesPerWord, SPReg);
			return self_in_genPushRegisterArgsForAbortMissNumArgs;
		}
		if (numArgs == 2) {
/* begin PushR: */
			genoperand(PushR, Arg1Reg);
			/* begin MoveMw:r:R: */
			genoperandoperandoperand(MoveMwrR, BytesPerWord * 2, SPReg, TempReg);
			/* begin PushR: */
			genoperand(PushR, TempReg);
			/* begin MoveMw:r:R: */
			genoperandoperandoperand(MoveMwrR, BytesPerWord * 2, SPReg, TempReg);
			/* begin PushR: */
			genoperand(PushR, TempReg);
			/* begin MoveR:Mw:r: */
			genoperandoperandoperand(MoveRMwr, ReceiverResultReg, 4 * BytesPerWord, SPReg);
			/* begin MoveR:Mw:r: */
			genoperandoperandoperand(MoveRMwr, Arg0Reg, 3 * BytesPerWord, SPReg);
			return self_in_genPushRegisterArgsForAbortMissNumArgs;
		}
	}
	return self_in_genPushRegisterArgsForAbortMissNumArgs;
}


/*	Ensure that the register args are pushed before the retpc for arity <=
	self numRegArgs.
 */
/*	This won't be as clumsy on a RISC. But putting the receiver and
	args above the return address means the CoInterpreter has a
	single machine-code frame format which saves us a lot of work. */

static AbstractInstruction *
genPushRegisterArgsForNumArgs(AbstractInstruction * self_in_genPushRegisterArgsForNumArgs, sqInt numArgs)
{
	// CogIA32Compiler>>#genPushRegisterArgsForNumArgs:
	if (numArgs <= 1) {
assert((numRegArgs()) <= 2);
		/* begin MoveMw:r:R: */
		genoperandoperandoperand(MoveMwrR, 0, SPReg, TempReg);
		/* begin MoveR:Mw:r: */
		genoperandoperandoperand(MoveRMwr, ReceiverResultReg, 0, SPReg);
		if (numArgs > 0) {
/* begin PushR: */
			genoperand(PushR, Arg0Reg);
			if (numArgs > 1) {
/* begin PushR: */
				genoperand(PushR, Arg1Reg);
			}
		}
		/* begin PushR: */
		genoperand(PushR, TempReg);

	}
	return self_in_genPushRegisterArgsForNumArgs;
}

static sqInt
genPushRemoteTempLongBytecode(void)
{
	// StackToRegisterMappingCogit>>#genPushRemoteTempLongBytecode
    sqInt offset;

	ssAllocateRequiredRegand(ClassReg, SendNumArgsReg);
	/* begin MoveMw:r:R: */
	offset = frameOffsetOfTemporary(byte2);
	genoperandoperandoperand(MoveMwrR, offset, FPReg, ClassReg);
	genLoadSlotsourceRegdestReg(byte1, ClassReg, SendNumArgsReg);
	return ssPushRegister(SendNumArgsReg);
}

static sqInt
genPushTemporaryVariableBytecode(void)
{
	// SimpleStackBasedCogit>>#genPushTemporaryVariableBytecode
	return genPushTemporaryVariable(byte0 & 15);
}

static sqInt
genPushTemporaryVariable(sqInt index)
{
	// StackToRegisterMappingCogit>>#genPushTemporaryVariable:
	return ssPushDesc(simStack[index]);
}


/*	because selected by CoInterpreter>>quickPrimitiveGeneratorFor: */

sqInt
genQuickReturnConst(void)
{
	// SimpleStackBasedCogit>>#genQuickReturnConst
    sqInt constant;

	constant = quickPrimitiveConstantFor(primitiveIndex);
	annotateobjRef(genoperandoperand((isImmediate(constant)
		? MoveCqR
		: MoveCwR), constant, ReceiverResultReg), constant);
	return genUpArrowReturn();
}


/*	because selected by CoInterpreter>>quickPrimitiveGeneratorFor: */

sqInt
genQuickReturnInstVar(void)
{
	// SimpleStackBasedCogit>>#genQuickReturnInstVar
    sqInt index;

	index = quickPrimitiveInstVarIndexFor(primitiveIndex);
	genLoadSlotsourceRegdestReg(index, ReceiverResultReg, ReceiverResultReg);
	return genUpArrowReturn();
}


/*	because selected by CoInterpreter>>quickPrimitiveGeneratorFor: */

sqInt
genQuickReturnSelf(void)
{
	// SimpleStackBasedCogit>>#genQuickReturnSelf
	return genUpArrowReturn();
}

static sqInt
genRemoveNArgsFromStack(AbstractInstruction * self_in_genRemoveNArgsFromStack, sqInt n)
{
	// CogIA32Compiler>>#genRemoveNArgsFromStack:
	/* begin AddCq:R: */
	genoperandoperand(AddCqR, n * 4, ESP);
	return 0;
}

static sqInt
genRemoveSmallIntegerTagsInScratchReg(sqInt scratchReg)
{
	// CogObjectRepresentationForSqueakV3>>#genRemoveSmallIntegerTagsInScratchReg:
	/* begin SubCq:R: */
	genoperandoperand(SubCqR, 1, scratchReg);
	return 0;
}

static sqInt
genRestoreRegs(AbstractInstruction * self_in_genRestoreRegs)
{
	// CogIA32Compiler>>#genRestoreRegs
	/* begin PopR: */
	genoperand(PopR, EAX);
	/* begin PopR: */
	genoperand(PopR, EBX);
	/* begin PopR: */
	genoperand(PopR, ECX);
	/* begin PopR: */
	genoperand(PopR, EDX);
	/* begin PopR: */
	genoperand(PopR, ESI);
	/* begin PopR: */
	genoperand(PopR, EDI);
	return 0;
}

static sqInt
genRestoreRegsExcept(AbstractInstruction * self_in_genRestoreRegsExcept, sqInt abstractReg)
{
	// CogIA32Compiler>>#genRestoreRegsExcept:
    sqInt realReg;

	realReg = concreteRegister(self_in_genRestoreRegsExcept, abstractReg);
	if (realReg == EAX) {
/* begin AddCq:R: */
		genoperandoperand(AddCqR, 4, ESP);
	}
	else {
/* begin PopR: */
		genoperand(PopR, EAX);
	}
	if (realReg == EBX) {
/* begin AddCq:R: */
		genoperandoperand(AddCqR, 4, ESP);
	}
	else {
/* begin PopR: */
		genoperand(PopR, EBX);
	}
	if (realReg == ECX) {
/* begin AddCq:R: */
		genoperandoperand(AddCqR, 4, ESP);
	}
	else {
/* begin PopR: */
		genoperand(PopR, ECX);
	}
	if (realReg == EDX) {
/* begin AddCq:R: */
		genoperandoperand(AddCqR, 4, ESP);
	}
	else {
/* begin PopR: */
		genoperand(PopR, EDX);
	}
	if (realReg == ESI) {
/* begin AddCq:R: */
		genoperandoperand(AddCqR, 4, ESP);
	}
	else {
/* begin PopR: */
		genoperand(PopR, ESI);
	}
	if (realReg == EDI) {
/* begin AddCq:R: */
		genoperandoperand(AddCqR, 4, ESP);
	}
	else {
/* begin PopR: */
		genoperand(PopR, EDI);
	}
	return 0;
}

static sqInt
genReturnFalse(void)
{
	// SimpleStackBasedCogit>>#genReturnFalse
	annotateobjRef(gMoveCwR(falseObject(), ReceiverResultReg), falseObject());
	return genUpArrowReturn();
}

static sqInt
genReturnNil(void)
{
	// SimpleStackBasedCogit>>#genReturnNil
	annotateobjRef(gMoveCwR(nilObject(), ReceiverResultReg), nilObject());
	return genUpArrowReturn();
}


/*	Frameless method activation looks like
	receiver
	args
	sp->	ret pc.
	Return pops receiver and arguments off the stack. Callee pushes the
	result.  */

static sqInt
genReturnReceiver(void)
{
	// SimpleStackBasedCogit>>#genReturnReceiver
	flag("currently caller pushes result");
	if (needsFrame) {
		/* begin MoveMw:r:R: */
		genoperandoperandoperand(MoveMwrR, FoxMFReceiver, FPReg, ReceiverResultReg);
	}
	return genUpArrowReturn();
}

static sqInt
genReturnTopFromBlock(void)
{
	// StackToRegisterMappingCogit>>#genReturnTopFromBlock
	assert(inBlock);
	popToReg(ssTop(), ReceiverResultReg);
	ssPop(1);
	if (needsFrame) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, FPReg, SPReg);
		/* begin PopR: */
		genoperand(PopR, FPReg);
	}
	
/* begin RetN: */
	genoperand(RetN, (methodOrBlockNumArgs + 1) * BytesPerWord);
	return 0;
}

static sqInt
genReturnTopFromMethod(void)
{
	// StackToRegisterMappingCogit>>#genReturnTopFromMethod
	popToReg(ssTop(), ReceiverResultReg);
	ssPop(1);
	return genUpArrowReturn();
}

static sqInt
genReturnTrue(void)
{
	// SimpleStackBasedCogit>>#genReturnTrue
	annotateobjRef(gMoveCwR(trueObject(), ReceiverResultReg), trueObject());
	return genUpArrowReturn();
}


/*	Generate a trampoline with one argument that will
	save and restore all registers around the call */

static sqInt
genSafeTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0)
{
	// Cogit>>#genSafeTrampolineFor:called:arg:
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 1, regOrConst0, null, null, null, 1, 1, null, 0);
}


/*	Generate a trampoline with two arguments that
	will save and restore all registers around the call */

static sqInt
genSafeTrampolineForcalledargarg(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1)
{
	// Cogit>>#genSafeTrampolineFor:called:arg:arg:
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 2, regOrConst0, regOrConst1, null, null, 1, 1, null, 0);
}


/*	Save the general purpose registers for a trampoline call. */

static sqInt
genSaveRegisters(AbstractInstruction * self_in_genSaveRegisters)
{
	// CogIA32Compiler>>#genSaveRegisters
	/* begin PushR: */
	genoperand(PushR, EDI);
	/* begin PushR: */
	genoperand(PushR, ESI);
	/* begin PushR: */
	genoperand(PushR, EDX);
	/* begin PushR: */
	genoperand(PushR, ECX);
	/* begin PushR: */
	genoperand(PushR, EBX);
	/* begin PushR: */
	genoperand(PushR, EAX);
	return 0;
}


/*	Save the frame and stack pointer registers to the framePointer
	and stackPointer variables. Used to save the machine code frame
	for use by the run-time when calling into the CoInterpreter run-time. */

static sqInt
genSaveStackPointers(AbstractInstruction * self_in_genSaveStackPointers)
{
	// CogIA32Compiler>>#genSaveStackPointers
    sqInt address;
    sqInt address1;

	/* begin MoveR:Aw: */
	address = framePointerAddress();
	genoperandoperand(MoveRAw, FPReg, address);
	/* begin MoveR:Aw: */
	address1 = stackPointerAddress();
	genoperandoperand(MoveRAw, SPReg, address1);
	return 0;
}


/*	Can use any of the first 64 literals for the selector and pass up to 3
	arguments. 
 */

static sqInt
genSecondExtendedSendBytecode(void)
{
	// SimpleStackBasedCogit>>#genSecondExtendedSendBytecode
	return genSendnumArgs(getLiteral(byte1 & 0x3F), ((usqInt) byte1) >> 6);
}

static sqInt
genSendLiteralSelector0ArgsBytecode(void)
{
	// SimpleStackBasedCogit>>#genSendLiteralSelector0ArgsBytecode
	return genSendnumArgs(getLiteral(byte0 & 15), 0);
}

static sqInt
genSendLiteralSelector1ArgBytecode(void)
{
	// SimpleStackBasedCogit>>#genSendLiteralSelector1ArgBytecode
	return genSendnumArgs(getLiteral(byte0 & 15), 1);
}

static sqInt
genSendLiteralSelector2ArgsBytecode(void)
{
	// SimpleStackBasedCogit>>#genSendLiteralSelector2ArgsBytecode
	return genSendnumArgs(getLiteral(byte0 & 15), 2);
}

static sqInt
genSendSupernumArgs(sqInt selector, sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#genSendSuper:numArgs:
	marshallSendArguments(numArgs);
	return genMarshalledSendSupernumArgs(selector, numArgs);
}


/*	Generate a trampoline with three arguments.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

static sqInt
genSendTrampolineFornumArgscalledargargarg(void *aRoutine, sqInt numArgs, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2)
{
	// StackToRegisterMappingCogit>>#genSendTrampolineFor:numArgs:called:arg:arg:arg:
    sqInt startAddress;

	startAddress = methodZoneBase;
	opcodeIndex = 0;
	genPushRegisterArgsForNumArgs(backEnd, numArgs);
	genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 3, regOrConst0, regOrConst1, regOrConst2, null, 0, 1, null, 1);
	return startAddress;
}


/*	Generate a trampoline with four arguments.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

static sqInt
genSendTrampolineFornumArgscalledargargargarg(void *aRoutine, sqInt numArgs, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3)
{
	// StackToRegisterMappingCogit>>#genSendTrampolineFor:numArgs:called:arg:arg:arg:arg:
    sqInt startAddress;

	startAddress = methodZoneBase;
	opcodeIndex = 0;
	genPushRegisterArgsForNumArgs(backEnd, numArgs);
	genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 4, regOrConst0, regOrConst1, regOrConst2, regOrConst3, 0, 1, null, 1);
	return startAddress;
}

static sqInt
genSendnumArgs(sqInt selector, sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#genSend:numArgs:
	marshallSendArguments(numArgs);
	return genMarshalledSendnumArgs(selector, numArgs);
}

static sqInt
genSetSmallIntegerTagsIn(sqInt scratchReg)
{
	// CogObjectRepresentationForSqueakV3>>#genSetSmallIntegerTagsIn:
	/* begin OrCq:R: */
	genoperandoperand(OrCqR, 1, scratchReg);
	return 0;
}

static sqInt
genShiftAwaySmallIntegerTagsInScratchReg(sqInt scratchReg)
{
	// CogObjectRepresentationForSqueakV3>>#genShiftAwaySmallIntegerTagsInScratchReg:
	/* begin ArithmeticShiftRightCq:R: */
	genoperandoperand(ArithmeticShiftRightCqR, 1, scratchReg);
	return 0;
}

static sqInt
genShortJumpIfFalse(void)
{
	// SimpleStackBasedCogit>>#genShortJumpIfFalse
    sqInt distance;
    sqInt target;

	distance = v3ShortForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 1) + bytecodePC;
	return genJumpIfto(falseObject(), target);
}

static sqInt
genShortUnconditionalJump(void)
{
	// SimpleStackBasedCogit>>#genShortUnconditionalJump
    sqInt distance;
    sqInt target;

	distance = v3ShortForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 1) + bytecodePC;
	return genJumpTo(target);
}


/*	Stack looks like
	return address */

static sqInt
genSmallIntegerComparisonorDoubleComparison(sqInt jumpOpcode, AbstractInstruction *(*jumpFPOpcodeGenerator)(void *))
{
	// StackToRegisterMappingCogit>>#genSmallIntegerComparison:orDoubleComparison:
    AbstractInstruction *jumpCond;
    AbstractInstruction *jumpDouble;
    AbstractInstruction *jumpFail;
    AbstractInstruction *jumpNonInt;
    AbstractInstruction *jumpTrue;
    sqInt quickConstant;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	jumpDouble = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ReceiverResultReg);
	jumpTrue = gen(jumpOpcode);
	annotateobjRef(gMoveCwR(falseObject(), ReceiverResultReg), falseObject());
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpTrue, annotateobjRef(gMoveCwR(trueObject(), ReceiverResultReg), trueObject()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpDouble, gLabel());
	
genGetCompactClassIndexNonImmOfinto(Arg0Reg, SendNumArgsReg);
	/* begin CmpCq:R: */
	quickConstant = classFloatCompactIndex();
	genoperandoperand(CmpCqR, quickConstant, SendNumArgsReg);
	/* begin JumpNonZero: */
	jumpFail = genoperand(JumpNonZero, ((sqInt)0));
	genConvertSmallIntegerToIntegerInReg(ReceiverResultReg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, ReceiverResultReg, DPFPReg0);
	genGetDoubleValueOfinto(Arg0Reg, DPFPReg1);
	/* begin CmpRd:Rd: */
	genoperandoperand(CmpRdRd, DPFPReg1, DPFPReg0);

	/* FP jumps are a little weird */

jumpCond = jumpFPOpcodeGenerator(0);
	annotateobjRef(gMoveCwR(falseObject(), ReceiverResultReg), falseObject());
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpCond, annotateobjRef(gMoveCwR(trueObject(), ReceiverResultReg), trueObject()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpFail, gLabel());

	return 0;
}

static sqInt
genSmalltalkToCStackSwitch(void)
{
	// Cogit>>#genSmalltalkToCStackSwitch
	genSaveStackPointers(backEnd);
	if (cFramePointerInUse) {
		genLoadCStackPointers(backEnd);
	}
	else {
genLoadCStackPointer(backEnd);
	}
	return 0;
}

static sqInt
genSpecialSelectorArithmetic(void)
{
	// StackToRegisterMappingCogit>>#genSpecialSelectorArithmetic
    char annotateInst;
    sqInt argInt;
    sqInt argIsConst;
    sqInt argIsInt;
    AbstractInstruction *instToAnnotate;
    AbstractInstruction *jumpContinue;
    AbstractInstruction *jumpNotSmallInts;
    BytecodeDescriptor *primDescriptor;
    sqInt rcvrInt;
    sqInt rcvrIsConst;
    sqInt rcvrIsInt;
    sqInt result;

	primDescriptor = generatorAt(byte0);
	argIsInt = ((argIsConst = (((ssTop())->type)) == SSConstant))
	 && ((((argInt = ((ssTop())->constant))) & 1));
	rcvrIsInt = ((rcvrIsConst = (((ssValue(1))->type)) == SSConstant))
	 && ((((rcvrInt = ((ssValue(1))->constant))) & 1));
	if (argIsInt
	 && (rcvrIsInt)) {
		rcvrInt = (rcvrInt >> 1);
		argInt = (argInt >> 1);
		
		switch ((primDescriptor->opcode)) {
		case AddRR:
			result = rcvrInt + argInt;
			break;
		case SubRR:
			result = rcvrInt - argInt;
			break;
		case AndRR:
			result = rcvrInt & argInt;
			break;
		case OrRR:
			result = rcvrInt | argInt;
			break;
		default:
			error("Case not found and no otherwise clause");
		}
		if (isIntegerValue(result)) {

			/* Must enter any annotatedConstants into the map */

annotateBytecodeIfAnnotated(ssValue(1));
			annotateBytecodeIfAnnotated(ssTop());
			return (ssPop(2),
			ssPushAnnotatedConstant(((result << 1) | 1)));
		}
		return genSpecialSelectorSend();
	}
	if ((rcvrIsConst
	 && (!rcvrIsInt))
	 || (argIsConst
	 && (!argIsInt))) {
		return genSpecialSelectorSend();
	}
	if (!(argIsInt
		 || (rcvrIsInt))) {
		return genSpecialSelectorSend();
	}
	if (argIsInt) {
ssFlushTo(simStackPtr - 2);
		popToReg(ssValue(1), ReceiverResultReg);
		annotateInst = ((ssTop())->annotateUse);
		ssPop(2);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	}
	else {
marshallSendArguments(1);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, Arg0Reg, TempReg);
		if (!rcvrIsInt) {
/* begin AndR:R: */
			genoperandoperand(AndRR, ReceiverResultReg, TempReg);

		}
	}
	jumpNotSmallInts = genJumpNotSmallIntegerInScratchReg(TempReg);
	
	switch ((primDescriptor->opcode)) {
	case AddRR:
		if (argIsInt) {
/* begin AddCq:R: */
			instToAnnotate = genoperandoperand(AddCqR, argInt - ConstZero, ReceiverResultReg);
			/* begin JumpNoOverflow: */
			jumpContinue = genoperand(JumpNoOverflow, ((sqInt)0));
			/* begin SubCq:R: */
			genoperandoperand(SubCqR, argInt - ConstZero, ReceiverResultReg);
		}
		else {
genRemoveSmallIntegerTagsInScratchReg(ReceiverResultReg);
			/* begin AddR:R: */
			genoperandoperand(AddRR, Arg0Reg, ReceiverResultReg);
			/* begin JumpNoOverflow: */
			jumpContinue = genoperand(JumpNoOverflow, ((sqInt)0));
			if (rcvrIsInt) {
/* begin MoveCq:R: */
				genoperandoperand(MoveCqR, rcvrInt, ReceiverResultReg);
			}
			else {
/* begin SubR:R: */
				genoperandoperand(SubRR, Arg0Reg, ReceiverResultReg);
				genSetSmallIntegerTagsIn(ReceiverResultReg);
			}
		}
		break;
	case SubRR:
		if (argIsInt) {
/* begin SubCq:R: */
			instToAnnotate = genoperandoperand(SubCqR, argInt - ConstZero, ReceiverResultReg);
			/* begin JumpNoOverflow: */
			jumpContinue = genoperand(JumpNoOverflow, ((sqInt)0));
			/* begin AddCq:R: */
			genoperandoperand(AddCqR, argInt - ConstZero, ReceiverResultReg);
		}
		else {
genRemoveSmallIntegerTagsInScratchReg(Arg0Reg);
			/* begin SubR:R: */
			genoperandoperand(SubRR, Arg0Reg, ReceiverResultReg);
			/* begin JumpNoOverflow: */
			jumpContinue = genoperand(JumpNoOverflow, ((sqInt)0));
			/* begin AddR:R: */
			genoperandoperand(AddRR, Arg0Reg, ReceiverResultReg);
			genSetSmallIntegerTagsIn(Arg0Reg);
		}
		break;
	case AndRR:
		if (argIsInt) {
/* begin AndCq:R: */
			instToAnnotate = genoperandoperand(AndCqR, argInt, ReceiverResultReg);
		}
		else {
/* begin AndR:R: */
			genoperandoperand(AndRR, Arg0Reg, ReceiverResultReg);
		}
		/* begin Jump: */
		jumpContinue = genoperand(Jump, ((sqInt)0));
		break;
	case OrRR:
		if (argIsInt) {
/* begin OrCq:R: */
			instToAnnotate = genoperandoperand(OrCqR, argInt, ReceiverResultReg);
		}
		else {
/* begin OrR:R: */
			genoperandoperand(OrRR, Arg0Reg, ReceiverResultReg);
		}
		/* begin Jump: */
		jumpContinue = genoperand(Jump, ((sqInt)0));
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	jmpTarget(jumpNotSmallInts, gLabel());
	if (argIsInt) {
if (annotateInst) {
/* begin annotateBytecode: */
			annotatewith(instToAnnotate, HasBytecodePC);
		}
		/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, argInt, Arg0Reg);
	}
	genMarshalledSendnumArgs(specialSelector(byte0 - (176)), 1);
	jmpTarget(jumpContinue, gLabel());
	return 0;
}

static sqInt
genSpecialSelectorClass(void)
{
	// StackToRegisterMappingCogit>>#genSpecialSelectorClass
    sqInt topReg;

	topReg = registerOrNil(ssTop());
	ssPop(1);
	if ((topReg == null)
	 || (topReg == ClassReg)) {
ssAllocateRequiredRegand((topReg = SendNumArgsReg), ClassReg);
	}
	else {
ssAllocateRequiredReg(ClassReg);
	}
	ssPush(1);
	popToReg(ssTop(), topReg);
	genGetClassObjectOfintoscratchReginstRegIsReceiver(topReg, ClassReg, TempReg, 0);
	return (ssPop(1),
	ssPushRegister(ClassReg));
}

static sqInt
genSpecialSelectorComparison(void)
{
	// StackToRegisterMappingCogit>>#genSpecialSelectorComparison
    AbstractInstruction *abstractInstruction;
    char annotateInst;
    sqInt argInt;
    sqInt argIsInt;
    BytecodeDescriptor *branchDescriptor;
    sqInt inlineCAB;
    AbstractInstruction *jumpNotSmallInts;
    void *jumpTarget;
    sqInt nExts;
    sqInt nextPC;
    sqInt postBranchPC;
    BytecodeDescriptor *primDescriptor;
    sqInt rcvrInt;
    sqInt rcvrIsInt;
    sqInt result;
    sqInt targetBytecodePC;

	ssFlushTo(simStackPtr - 2);
	primDescriptor = generatorAt(byte0);
	argIsInt = ((((ssTop())->type)) == SSConstant)
	 && ((((argInt = ((ssTop())->constant))) & 1));
	rcvrIsInt = ((((ssValue(1))->type)) == SSConstant)
	 && ((((rcvrInt = ((ssValue(1))->constant))) & 1));
	if (argIsInt
	 && (rcvrIsInt)) {
		;
		
		switch ((primDescriptor->opcode)) {
		case JumpLess:
			result = rcvrInt < argInt;
			break;
		case JumpLessOrEqual:
			result = rcvrInt <= argInt;
			break;
		case JumpGreater:
			result = rcvrInt > argInt;
			break;
		case JumpGreaterOrEqual:
			result = rcvrInt >= argInt;
			break;
		case JumpZero:
			result = rcvrInt == argInt;
			break;
		case JumpNonZero:
			result = rcvrInt != argInt;
			break;
		default:
			error("Case not found and no otherwise clause");
		}
		annotateBytecodeIfAnnotated(ssValue(1));
		annotateBytecodeIfAnnotated(ssTop());
		ssPop(2);
		return ssPushAnnotatedConstant((result
			? trueObject()
			: falseObject()));
	}
	nextPC = bytecodePC + ((primDescriptor->numBytes));
	nExts = 0;
	while (1) {
branchDescriptor = generatorAt((fetchByteofObject(nextPC, methodObj)) + (byte0 & 256));
		if (!((branchDescriptor->isExtension))) break;
		nExts += 1;
		nextPC += (branchDescriptor->numBytes);
	}

	/* Further, only interested in inlining = and ~= if there's a SmallInteger constant involved.
	   The relational operators successfully statically predict SmallIntegers; the equality operators do not. */

	inlineCAB = ((branchDescriptor->isBranchTrue))
	 || ((branchDescriptor->isBranchFalse));
	if (inlineCAB
	 && ((((primDescriptor->opcode)) == JumpZero)
	 || (((primDescriptor->opcode)) == JumpNonZero))) {
		inlineCAB = argIsInt
		 || (rcvrIsInt);
	}
	if (!inlineCAB) {
return genSpecialSelectorSend();
	}
	targetBytecodePC = (nextPC + ((branchDescriptor->numBytes))) + (((branchDescriptor->spanFunction))(branchDescriptor, nextPC, nExts, methodObj));
	postBranchPC = nextPC + ((branchDescriptor->numBytes));
	if (argIsInt) {
popToReg(ssValue(1), ReceiverResultReg);
		annotateInst = ((ssTop())->annotateUse);
		ssPop(2);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	}
	else {
marshallSendArguments(1);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, Arg0Reg, TempReg);
		if (!rcvrIsInt) {
/* begin AndR:R: */
			genoperandoperand(AndRR, ReceiverResultReg, TempReg);

		}
	}
	jumpNotSmallInts = genJumpNotSmallIntegerInScratchReg(TempReg);
	if (argIsInt) {
if (annotateInst) {
/* begin annotateBytecode: */
			/* begin CmpCq:R: */
			abstractInstruction = genoperandoperand(CmpCqR, argInt, ReceiverResultReg);
			annotatewith(abstractInstruction, HasBytecodePC);
		}
		else {
/* begin CmpCq:R: */
			genoperandoperand(CmpCqR, argInt, ReceiverResultReg);
		}
	}
	else {
/* begin CmpR:R: */
		genoperandoperand(CmpRR, Arg0Reg, ReceiverResultReg);
	}
	genoperand(((branchDescriptor->isBranchTrue)
		? (primDescriptor->opcode)
		: inverseBranchFor((primDescriptor->opcode))), ((usqInt)(ensureNonMergeFixupAt(targetBytecodePC - initialPC))));
	/* begin Jump: */
	jumpTarget = ensureNonMergeFixupAt(postBranchPC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget));
	jmpTarget(jumpNotSmallInts, gLabel());
	if (argIsInt) {
/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, argInt, Arg0Reg);
	}
	return genMarshalledSendnumArgs(specialSelector(byte0 - (176)), 1);
}

static sqInt
genSpecialSelectorEqualsEquals(void)
{
	// StackToRegisterMappingCogit>>#genSpecialSelectorEqualsEquals
    sqInt argReg;
    BytecodeDescriptor *branchDescriptor;
    AbstractInstruction *jumpEqual;
    AbstractInstruction *jumpNotEqual;
    void *jumpTarget;
    sqInt nExts;
    sqInt nextPC;
    sqInt postBranchPC;
    BytecodeDescriptor *primDescriptor;
    sqInt quickConstant;
    sqInt rcvrReg;
    sqInt result;
    sqInt targetBytecodePC;
    sqInt unforwardArg;
    sqInt unforwardRcvr;


	/* forwarders have been followed in cog:selector: */

primDescriptor = generatorAt(byte0);
	if (((((ssTop())->type)) == SSConstant)
	 && ((((ssValue(1))->type)) == SSConstant)) {
		assert(!((primDescriptor->isMapped)));
		result = ((((ssTop())->constant)) == (((ssValue(1))->constant))
			? trueObject()
			: falseObject());
		ssPop(2);
		return ssPushConstant(result);
	}
	nextPC = bytecodePC + ((primDescriptor->numBytes));
	nExts = 0;
	while (1) {
branchDescriptor = generatorAt((fetchByteofObject(nextPC, methodObj)) + (byte0 & 256));
		if (!((branchDescriptor->isExtension))) break;
		nExts += 1;
		nextPC += (branchDescriptor->numBytes);
	}
	if (((branchDescriptor->isBranchTrue))
	 || ((branchDescriptor->isBranchFalse))) {
		ssFlushTo(simStackPtr - 2);
	}
	unforwardRcvr = ((((ssValue(1))->type)) != SSConstant)
	 || (shouldAnnotateObjectReference(((ssValue(1))->constant)));

	/* Don't use ReceiverResultReg for receiver to keep ReceiverResultReg live.
	   Optimize e.g. rcvr == nil, the common case for ifNil: et al. */

	unforwardArg = ((((ssTop())->type)) != SSConstant)
	 || (shouldAnnotateObjectReference(((ssTop())->constant)));
	if (needsFrame) {
		if (unforwardArg) {
ssAllocateRequiredRegupThrough((argReg = Arg0Reg), simStackPtr - 1);
		}
		ssAllocateRequiredRegupThrough((rcvrReg = Arg1Reg), simStackPtr - 2);
	}
	else {
if (unforwardArg) {
argReg = ssAllocatePreferredReg(ClassReg);
		}
		rcvrReg = ssAllocatePreferredReg(SendNumArgsReg);
	}
	if (unforwardArg) {
popToReg(ssTop(), argReg);
		genEnsureOopInRegNotForwardedscratchReg(argReg, TempReg);
		popToReg(ssValue(1), rcvrReg);
		if (unforwardRcvr) {
genEnsureOopInRegNotForwardedscratchReg(rcvrReg, TempReg);
		}
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, argReg, rcvrReg);
	}
	else {
popToReg(ssValue(1), rcvrReg);
		if (unforwardRcvr) {
genEnsureOopInRegNotForwardedscratchReg(rcvrReg, TempReg);
		}
		/* begin CmpCq:R: */
		quickConstant = ((ssTop())->constant);
		genoperandoperand(CmpCqR, quickConstant, rcvrReg);
	}
	ssPop(2);
	if (!(((branchDescriptor->isBranchTrue))
		 || ((branchDescriptor->isBranchFalse)))) {
		/* begin JumpNonZero: */
		jumpNotEqual = genoperand(JumpNonZero, ((sqInt)0));
		annotateobjRef(gMoveCwR(trueObject(), rcvrReg), trueObject());
		/* begin Jump: */
		jumpEqual = genoperand(Jump, ((sqInt)0));
		jmpTarget(jumpNotEqual, annotateobjRef(gMoveCwR(falseObject(), rcvrReg), falseObject()));
		jmpTarget(jumpEqual, gLabel());
		ssPushRegister(rcvrReg);
		return 0;
	}
	targetBytecodePC = (nextPC + ((branchDescriptor->numBytes))) + (((branchDescriptor->spanFunction))(branchDescriptor, nextPC, nExts, methodObj));
	postBranchPC = nextPC + ((branchDescriptor->numBytes));
	if ((((fixupAt(nextPC - initialPC))->targetInstruction)) == 0) {

		/* The next instruction is dead.  we can skip it. */


		/* The next instruction is dead.  we can skip it. */

deadCode = 1;
		ensureFixupAt(targetBytecodePC - initialPC);
		ensureFixupAt(postBranchPC - initialPC);
	}
	else {
ssPushConstant(trueObject());
	}
	genoperand(((branchDescriptor->isBranchTrue)
		? JumpZero
		: JumpNonZero), ((usqInt)(ensureNonMergeFixupAt(targetBytecodePC - initialPC))));
	/* begin Jump: */
	jumpTarget = ensureNonMergeFixupAt(postBranchPC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget));
	return 0;
}

static sqInt
genSpecialSelectorSend(void)
{
	// SimpleStackBasedCogit>>#genSpecialSelectorSend
    sqInt index;
    sqInt numArgs;
    sqInt selector;

	index = byte0 - (176);
	selector = specialSelector(index);
	numArgs = specialSelectorNumArgs(index);
	return genSendnumArgs(selector, numArgs);
}

static sqInt
genStoreAndPopReceiverVariableBytecode(void)
{
	// SimpleStackBasedCogit>>#genStoreAndPopReceiverVariableBytecode
	return genStorePopReceiverVariable(1, byte0 & 7);
}

static sqInt
genStoreAndPopRemoteTempLongBytecode(void)
{
	// SimpleStackBasedCogit>>#genStoreAndPopRemoteTempLongBytecode
	return genStorePopRemoteTempAt(1, byte1, byte2);
}

static sqInt
genStoreAndPopTemporaryVariableBytecode(void)
{
	// SimpleStackBasedCogit>>#genStoreAndPopTemporaryVariableBytecode
	return genStorePopTemporaryVariable(1, byte0 & 7);
}

static sqInt
genStoreImmediateInSourceRegslotIndexdestReg(sqInt sourceReg, sqInt index, sqInt destReg)
{
	// CogObjectRepresentationForSqueakV3>>#genStoreImmediateInSourceReg:slotIndex:destReg:
	/* begin MoveR:Mw:r: */
	genoperandoperandoperand(MoveRMwr, sourceReg, (index * BytesPerWord) + BaseHeaderSize, destReg);
	return 0;
}

static sqInt
genStorePopLiteralVariable(sqInt popBoolean, sqInt litVarIndex)
{
	// StackToRegisterMappingCogit>>#genStorePop:LiteralVariable:
    sqInt association;
    sqInt constVal;
    sqInt topReg;
    sqInt valueReg;

	flag("with better register allocation this wouldn't need a frame.  e.g. use SendNumArgs instead of ReceiverResultReg");
	assert(needsFrame);
	(optStatus.isReceiverResultRegLive = 0);
	association = getLiteral(litVarIndex);

	/* Avoid store check for immediate values */

constVal = maybeConstant(ssTop());
	if (((((ssTop())->type)) == SSConstant)
	 && (!(shouldAnnotateObjectReference(constVal)))) {
		ssAllocateRequiredReg(ReceiverResultReg);
		annotateobjRef(gMoveCwR(association, ReceiverResultReg), association);
		genEnsureObjInRegNotForwardedscratchReg(ReceiverResultReg, TempReg);
		ssStorePoptoPreferredReg(popBoolean, TempReg);
		if (traceStores > 0) {
			CallRT(ceTraceStoreTrampoline);
		}
		return genStoreImmediateInSourceRegslotIndexdestReg(TempReg, ValueIndex, ReceiverResultReg);
	}
	if ((((topReg = registerOrNil(ssTop()))) == null)
	 || (topReg == ReceiverResultReg)) {
topReg = ClassReg;
	}
	ssPop(1);
	ssAllocateCallReg(topReg);
	ssPush(1);
	valueReg = ssStorePoptoPreferredReg(popBoolean, topReg);
	if (valueReg == ReceiverResultReg) {
/* begin MoveR:R: */
		genoperandoperand(MoveRR, valueReg, topReg);
	}
	ssAllocateCallReg(ReceiverResultReg);
	annotateobjRef(gMoveCwR(association, ReceiverResultReg), association);
	genEnsureObjInRegNotForwardedscratchReg(ReceiverResultReg, TempReg);
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, topReg, TempReg);
		CallRT(ceTraceStoreTrampoline);
	}
	return genStoreSourceRegslotIndexdestRegscratchReg(topReg, ValueIndex, ReceiverResultReg, TempReg);
}

static sqInt
genStorePopMaybeContextReceiverVariable(sqInt popBoolean, sqInt slotIndex)
{
	// StackToRegisterMappingCogit>>#genStorePop:MaybeContextReceiverVariable:
    AbstractInstruction *jmpDone;
    AbstractInstruction *jmpSingle;
    sqInt valueReg;

	assert(needsFrame);
	ssFlushUpThroughReceiverVariable(slotIndex);
	ensureReceiverResultRegContainsSelf();
	ssPop(1);
	ssAllocateCallRegand(ClassReg, SendNumArgsReg);
	ssPush(1);
	genLoadSlotsourceRegdestReg(SenderIndex, ReceiverResultReg, TempReg);
	valueReg = ssStorePoptoPreferredReg(popBoolean, ClassReg);
	if (valueReg != ClassReg) {
/* begin MoveR:R: */
		genoperandoperand(MoveRR, valueReg, ClassReg);
	}
	jmpSingle = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin MoveCq:R: */
	genoperandoperand(MoveCqR, slotIndex, SendNumArgsReg);
	CallRT(ceStoreContextInstVarTrampoline);
	/* begin Jump: */
	jmpDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpSingle, gLabel());
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ClassReg, TempReg);
		CallRT(ceTraceStoreTrampoline);
	}
	genStoreSourceRegslotIndexdestRegscratchReg(ClassReg, slotIndex, ReceiverResultReg, TempReg);
	jmpTarget(jmpDone, gLabel());
	return 0;
}

static sqInt
genStorePopReceiverVariable(sqInt popBoolean, sqInt slotIndex)
{
	// StackToRegisterMappingCogit>>#genStorePop:ReceiverVariable:
    sqInt constVal;
    sqInt topReg;
    sqInt valueReg;

	if (!needsFrame) {
		return genFramelessStorePopReceiverVariable(popBoolean, slotIndex);
	}
	ssFlushUpThroughReceiverVariable(slotIndex);
	constVal = maybeConstant(ssTop());
	if (((((ssTop())->type)) == SSConstant)
	 && (!(shouldAnnotateObjectReference(constVal)))) {
		ensureReceiverResultRegContainsSelf();
		ssStorePoptoPreferredReg(popBoolean, TempReg);
		if (traceStores > 0) {
			CallRT(ceTraceStoreTrampoline);
		}
		return genStoreImmediateInSourceRegslotIndexdestReg(TempReg, slotIndex, ReceiverResultReg);
	}
	if ((((topReg = registerOrNil(ssTop()))) == null)
	 || (topReg == ReceiverResultReg)) {
topReg = ClassReg;
	}
	ssPop(1);
	ssAllocateCallReg(topReg);
	ssPush(1);
	valueReg = ssStorePoptoPreferredReg(popBoolean, topReg);
	if (valueReg == ReceiverResultReg) {
/* begin MoveR:R: */
		genoperandoperand(MoveRR, valueReg, topReg);
	}
	ensureReceiverResultRegContainsSelf();
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, topReg, TempReg);
		CallRT(ceTraceStoreTrampoline);
	}
	return genStoreSourceRegslotIndexdestRegscratchReg(topReg, slotIndex, ReceiverResultReg, TempReg);
}

static sqInt
genStorePopRemoteTempAt(sqInt popBoolean, sqInt slotIndex, sqInt remoteTempIndex)
{
	// StackToRegisterMappingCogit>>#genStorePop:RemoteTemp:At:
    sqInt constVal;
    sqInt offset;
    sqInt offset1;
    sqInt topReg;
    char topSpilled;
    sqInt valueReg;

	assert(needsFrame);
	(optStatus.isReceiverResultRegLive = 0);
	constVal = maybeConstant(ssTop());
	if (((((ssTop())->type)) == SSConstant)
	 && (!(shouldAnnotateObjectReference(constVal)))) {
		ssAllocateRequiredReg(ReceiverResultReg);
		/* begin MoveMw:r:R: */
		offset = frameOffsetOfTemporary(remoteTempIndex);
		genoperandoperandoperand(MoveMwrR, offset, FPReg, ReceiverResultReg);
		ssStorePoptoPreferredReg(popBoolean, TempReg);
		if (traceStores > 0) {
			CallRT(ceTraceStoreTrampoline);
		}
		return genStoreImmediateInSourceRegslotIndexdestReg(TempReg, slotIndex, ReceiverResultReg);
	}
	if ((((topReg = registerOrNil(ssTop()))) == null)
	 || (topReg == ReceiverResultReg)) {
topReg = ClassReg;
	}
	ssPop(1);
	ssAllocateCallRegand(topReg, ReceiverResultReg);
	ssPush(1);
	topSpilled = ((ssTop())->spilled);
	valueReg = ssStorePoptoPreferredReg(popBoolean
	 || (topSpilled), topReg);
	if (valueReg == ReceiverResultReg) {
/* begin MoveR:R: */
		genoperandoperand(MoveRR, valueReg, topReg);
	}
	if (!popBoolean) {
if (!topSpilled) {
ssPop(1);
		}
		ssPushRegister(topReg);
	}
	/* begin MoveMw:r:R: */
	offset1 = frameOffsetOfTemporary(remoteTempIndex);
	genoperandoperandoperand(MoveMwrR, offset1, FPReg, ReceiverResultReg);
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, topReg, TempReg);
		CallRT(ceTraceStoreTrampoline);
	}
	return genStoreSourceRegslotIndexdestRegscratchReg(topReg, slotIndex, ReceiverResultReg, TempReg);
}

static sqInt
genStorePopTemporaryVariable(sqInt popBoolean, sqInt tempIndex)
{
	// StackToRegisterMappingCogit>>#genStorePop:TemporaryVariable:
    sqInt offset;
    sqInt reg;

	ssFlushUpThroughTemporaryVariable(tempIndex);
	reg = ssStorePoptoPreferredReg(popBoolean, TempReg);
	/* begin MoveR:Mw:r: */
	offset = frameOffsetOfTemporary(tempIndex);
	genoperandoperandoperand(MoveRMwr, reg, offset, FPReg);
	return 0;
}

static sqInt
genStoreRemoteTempLongBytecode(void)
{
	// SimpleStackBasedCogit>>#genStoreRemoteTempLongBytecode
	return genStorePopRemoteTempAt(0, byte1, byte2);
}

static sqInt
genStoreSourceRegslotIndexdestRegscratchReg(sqInt sourceReg, sqInt index, sqInt destReg, sqInt scratchReg)
{
	// CogObjectRepresentationForSqueakV3>>#genStoreSourceReg:slotIndex:destReg:scratchReg:
    sqInt address;
    AbstractInstruction *jmpAlreadyRoot;
    AbstractInstruction *jmpDestYoung;
    AbstractInstruction *jmpImmediate;
    AbstractInstruction *jmpSourceOld;
    sqInt mask;
    sqInt rootBitByteOffset;


	/* do the store */
	/* now the check.  Is value stored an integer?  If so we're done */

/* begin MoveR:Mw:r: */
	genoperandoperandoperand(MoveRMwr, sourceReg, (index * BytesPerWord) + BaseHeaderSize, destReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, sourceReg, scratchReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 1, scratchReg);
	/* begin JumpNonZero: */
	jmpImmediate = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveAw:R: */
	address = youngStartAddress();
	genoperandoperand(MoveAwR, address, scratchReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, scratchReg, destReg);
	/* begin JumpAboveOrEqual: */
	jmpDestYoung = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, scratchReg, sourceReg);
	/* begin JumpBelow: */
	jmpSourceOld = genoperand(JumpBelow, ((sqInt)0));
	rootBitByteOffset = RootBitDigitLength - 1;

	/* N.B. MoveMb:r:R: does not zero other bits */

mask = ((usqInt) RootBit) >> ((RootBitDigitLength - 1) * 8);
	/* begin MoveMb:r:R: */
	genoperandoperandoperand(MoveMbrR, rootBitByteOffset, destReg, scratchReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, mask, scratchReg);
	/* begin JumpNonZero: */
	jmpAlreadyRoot = genoperand(JumpNonZero, ((sqInt)0));
	assert(destReg == ReceiverResultReg);
	CallRTregistersToBeSavedMask(ceStoreCheckTrampoline, (registerMaskFor(sourceReg)) & (callerSavedRegMask()));
	jmpTarget(jmpImmediate, jmpTarget(jmpDestYoung, jmpTarget(jmpSourceOld, jmpTarget(jmpAlreadyRoot, gLabel()))));
	return 0;
}

static sqInt
genStoreSourceRegslotIndexintoNewObjectInDestReg(sqInt sourceReg, sqInt index, sqInt destReg)
{
	// CogObjectRepresentationForSqueakV3>>#genStoreSourceReg:slotIndex:intoNewObjectInDestReg:
	/* begin MoveR:Mw:r: */
	genoperandoperandoperand(MoveRMwr, sourceReg, (index * BytesPerWord) + BaseHeaderSize, destReg);
	return 0;
}

static AbstractInstruction *
genSubstituteReturnAddress(AbstractInstruction * self_in_genSubstituteReturnAddress, sqInt retpc)
{
	// CogIA32Compiler>>#genSubstituteReturnAddress:
	/* begin PushCw: */
	return genoperand(PushCw, retpc);
}


/*	Generate a trampoline with no arguments */

static sqInt
genTrampolineForcalled(void *aRoutine, char *aString)
{
	// Cogit>>#genTrampolineFor:called:
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 0, null, null, null, null, 0, 1, null, 0);
}


/*	Generate a trampoline with one argument.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

static sqInt
genTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0)
{
	// Cogit>>#genTrampolineFor:called:arg:
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 1, regOrConst0, null, null, null, 0, 1, null, 0);
}


/*	Generate a trampoline with two arguments that answers a result.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

static sqInt
genTrampolineForcalledargargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt resultReg)
{
	// Cogit>>#genTrampolineFor:called:arg:arg:arg:result:
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 3, regOrConst0, regOrConst1, regOrConst2, null, 0, 1, resultReg, 0);
}


/*	Generate a trampoline with two arguments that answers a result.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

static sqInt
genTrampolineForcalledargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt resultReg)
{
	// Cogit>>#genTrampolineFor:called:arg:arg:result:
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 2, regOrConst0, regOrConst1, null, null, 0, 1, resultReg, 0);
}


/*	Generate a trampoline with one argument that answers a result.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

static sqInt
genTrampolineForcalledargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt resultReg)
{
	// Cogit>>#genTrampolineFor:called:arg:result:
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 1, regOrConst0, null, null, null, 0, 1, resultReg, 0);
}


/*	Generate a trampoline with up to four arguments. Generate either a call or
	a jump to aRoutineOrNil
	as requested by callJumpBar. If generating a call and resultRegOrNil is
	non-zero pass the C result
	back in resultRegOrNil.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

static sqInt
genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(void *aRoutine, char *trampolineName, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNil, sqInt appendBoolean)
{
	// Cogit>>#genTrampolineFor:called:numArgs:arg:arg:arg:arg:saveRegs:pushLinkReg:resultReg:appendOpcodes:
    sqInt startAddress;

	startAddress = methodZoneBase;
	if (!appendBoolean) {
opcodeIndex = 0;
	}
	compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(aRoutine, numArgs, regOrConst0, regOrConst1, regOrConst2, regOrConst3, saveRegs, pushLinkReg, resultRegOrNil);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress(trampolineName, startAddress);
	recordRunTimeObjectReferences();
	return startAddress;
}


/*	Generate a method return from within a method or a block.
	Frameless method activation looks like
	receiver
	args
	sp->	ret pc.
	Return pops receiver and arguments off the stack. Callee pushes the
	result.  */

static sqInt
genUpArrowReturn(void)
{
	// StackToRegisterMappingCogit>>#genUpArrowReturn
    AbstractInstruction *abstractInstruction;
    sqInt offset;

	if (inBlock) {
		assert(needsFrame);
		/* begin annotateBytecode: */
		abstractInstruction = CallRT(ceNonLocalReturnTrampoline);
		annotatewith(abstractInstruction, HasBytecodePC);
		return 0;
	}
	if (needsFrame) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, FPReg, SPReg);
		/* begin PopR: */
		genoperand(PopR, FPReg);
		
/* begin RetN: */
		genoperand(RetN, (methodOrBlockNumArgs + 1) * BytesPerWord);
	}
	else {
;
		/* begin RetN: */
		offset = ((methodOrBlockNumArgs > 1)
		 || (regArgsHaveBeenPushed)
			? (methodOrBlockNumArgs + 1) * BytesPerWord
			: 0);
		genoperand(RetN, offset);
	}
	return 0;
}

static AbstractInstruction *
genWriteCResultIntoReg(AbstractInstruction * self_in_genWriteCResultIntoReg, sqInt abstractRegister)
{
	// CogAbstractInstruction>>#genWriteCResultIntoReg:
    sqInt cResultReg;

	cResultReg = cResultRegister(self_in_genWriteCResultIntoReg);
	if (abstractRegister != cResultReg) {
genoperandoperand(MoveRR, cResultReg, abstractRegister);
	}
	return self_in_genWriteCResultIntoReg;
}


/*	<Integer> */

static AbstractInstruction *
gen(sqInt opcode)
{
	// Cogit>>#gen:
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	
return abstractInstruction;
}


/*	<Integer> */
/*	<Integer|CogAbstractInstruction> */

static AbstractInstruction *
genoperand(sqInt opcode, sqInt operand)
{
	// Cogit>>#gen:operand:
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	((abstractInstruction->operands))[0] = operand;
	
return abstractInstruction;
}


/*	<Integer> */
/*	<Integer|CogAbstractInstruction> */
/*	<Integer|CogAbstractInstruction> */

static AbstractInstruction *
genoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo)
{
	// Cogit>>#gen:operand:operand:
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	((abstractInstruction->operands))[0] = operandOne;
	((abstractInstruction->operands))[1] = operandTwo;
	
return abstractInstruction;
}


/*	<Integer> */
/*	<Integer|CogAbstractInstruction> */
/*	<Integer|CogAbstractInstruction> */
/*	<Integer|CogAbstractInstruction> */

static AbstractInstruction *
genoperandoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo, sqInt operandThree)
{
	// Cogit>>#gen:operand:operand:operand:
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	((abstractInstruction->operands))[0] = operandOne;
	((abstractInstruction->operands))[1] = operandTwo;
	((abstractInstruction->operands))[2] = operandThree;
	
return abstractInstruction;
}


/*	subclasses override if they want, and will have SendNumArgsReg and
	ClassReg available in addition to ReceiverResultReg and TempReg if they
	do. 
 */

static sqInt
getActiveContextAllocatesInMachineCode(void)
{
	// CogObjectRepresentation>>#getActiveContextAllocatesInMachineCode
	return 0;
}


/*	Extract the inline cache tag for the object in sourceReg into destReg. The
	inline cache tag for a given object is the value loaded in inline caches
	to distinguish objects
	of different classes. In SqueakV3 the tag is the integer tag bit for
	SmallIntegers (1),
	the compact class index shifted by log: 2 word size for objects with
	compact classes
	(1 * 4 to: 31 * 4 by: 4), or the class. These ranges cannot overlap
	because the heap
	(and hence the lowest class object) is beyond the machine code zone. */

static AbstractInstruction *
getInlineCacheClassTagFrominto(sqInt sourceReg, sqInt destReg)
{
	// CogObjectRepresentationForSqueakV3>>#getInlineCacheClassTagFrom:into:
    AbstractInstruction *entryLabel;
    AbstractInstruction *jumpCompact;
    AbstractInstruction *jumpIsInt;
    sqInt offset;
    sqInt quickConstant;
    sqInt quickConstant1;

	/* begin AlignmentNops: */
	genoperand(AlignmentNops, ((BytesPerWord < 8) ? 8 : BytesPerWord));
	/* begin Label */
	entryLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, sourceReg, destReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, 1, destReg);
	/* begin JumpNonZero: */
	jumpIsInt = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	genoperandoperandoperand(MoveMwrR, 0, sourceReg, destReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = (compactClassFieldLSB()) - ShiftForWord;
	genoperandoperand(LogicalShiftRightCqR, quickConstant, destReg);
	/* begin AndCq:R: */
	quickConstant1 = ((1 << (compactClassFieldWidth())) - 1) << ShiftForWord;
	genoperandoperand(AndCqR, quickConstant1, destReg);
	/* begin JumpNonZero: */
	jumpCompact = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset = classFieldOffset();
	genoperandoperandoperand(MoveMwrR, offset, sourceReg, destReg);
	/* begin AndCq:R: */
	genoperandoperand(AndCqR, ((sqInt) AllButTypeMask), destReg);
	jmpTarget(jumpCompact, jmpTarget(jumpIsInt, gLabel()));
	return entryLabel;
}


/*	Get the target of a jump instruction. Jumps have the target in the first
	operand. 
 */

static AbstractInstruction *
getJmpTarget(AbstractInstruction * self_in_getJmpTarget)
{
	// CogAbstractInstruction>>#getJmpTarget
	return ((AbstractInstruction *) (((self_in_getJmpTarget->operands))[0]));
}

static sqInt
getLiteral(sqInt litIndex)
{
	// Cogit>>#getLiteral:
	if (maxLitIndex < litIndex) {
		maxLitIndex = litIndex;
	}
	return literalofMethod(litIndex, methodObj);
}


/*	We can generate dpfp support if the processor has SSE2 instructions. */

static sqInt
hasDoublePrecisionFloatingPointSupport(AbstractInstruction * self_in_hasDoublePrecisionFloatingPointSupport)
{
	// CogIA32Compiler>>#hasDoublePrecisionFloatingPointSupport
	return hasSSE2Instructions(self_in_hasDoublePrecisionFloatingPointSupport);
}

static sqInt
hasLinkRegister(AbstractInstruction * self_in_hasLinkRegister)
{
	// CogIA32Compiler>>#hasLinkRegister
	return 0;
}


/*	Answer whether the concrete machine code contains pc-dependent
	instructions, such as the IA32/x86's short and long relative jumps
	and the EMT64/x86-64's pc-relative addressing mode. Such
	instructions require an extra pass to generate them correctly. */

static sqInt
hasPCDependentInstructions(AbstractInstruction * self_in_hasPCDependentInstructions)
{
	// CogIA32Compiler>>#hasPCDependentInstructions
	return 1;
}


/*	Answer if we support SSE2 */

static sqInt
hasSSE2Instructions(AbstractInstruction * self_in_hasSSE2Instructions)
{
	// CogIA32Compiler>>#hasSSE2Instructions
	return ((ceCheckFeatures()) & (1 << 26)) != 0;
}


/*	Answer if we support SSE */

static sqInt
hasSSEInstructions(AbstractInstruction * self_in_hasSSEInstructions)
{
	// CogIA32Compiler>>#hasSSEInstructions
	return ((ceCheckFeatures()) & (1 << 25)) != 0;
}

static sqInt
incrementUsageOfTargetIfLinkedSendmcpcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
	// Cogit>>#incrementUsageOfTargetIfLinkedSend:mcpc:ignored:
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;

	if (annotation == IsSendCall) {
entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

/* begin targetMethodAndSendTableFor:into: */
			if ((entryPoint & entryPointMask) == checkedEntryAlignment) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = sendTrampolines;
			}
			else {
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;
			}

			
			/* It's a linked send. */

if (((targetMethod1->cmUsageCount)) < (((sqInt) CMMaxUsageCount >> 1))) {

				/* It's a linked send. */

(targetMethod1->cmUsageCount = ((targetMethod1->cmUsageCount)) + 1);
			}

		}
	}
	return 0;
}


/*	Answer a usage count that reflects likely long-term usage. */

static sqInt
initialClosedPICUsageCount(void)
{
	// Cogit>>#initialClosedPICUsageCount
	return 2;
}


/*	A hook for the StackToregisterMappingCogit to override.
	We just initialize the methodLabel here because backEnd is static. */

static void
initializeBackend(void)
{
	// Cogit>>#initializeBackend
	(methodLabel->machineCodeSize = 0);
	(methodLabel->opcode = Label);
	((methodLabel->operands))[0] = 0;
	((methodLabel->operands))[1] = 0;
	callerSavedRegMask = callerSavedRegisterMask(backEnd);
}

void
initializeCodeZoneFromupTo(sqInt startAddress, sqInt endAddress)
{
	// Cogit>>#initializeCodeZoneFrom:upTo:
	sqMakeMemoryExecutableFromTo(startAddress, endAddress);
	codeBase = (methodZoneBase = startAddress);
	minValidCallAddress = (((((codeBase < (interpretAddress())) ? codeBase : (interpretAddress()))) < (primitiveFailAddress())) ? (((codeBase < (interpretAddress())) ? codeBase : (interpretAddress()))) : (primitiveFailAddress()));
	initializeBackend();
	maybeGenerateCheckFeatures();
	maybeGenerateICacheFlush();
	generateVMOwnerLockFunctions();
	ceGetSP = ((unsigned long (*)(void)) (genGetLeafCallStackPointer()));
	generateStackPointerCapture();
	generateTrampolines();
	
checkPrimitiveTableEnablers();
	manageFromto(methodZoneBase, endAddress);
	computeEntryOffsets();
	generateClosedPICPrototype();
	generateOpenPICPrototype();
}


/*	Make sure there's a flagged fixup at the targetIndex (pc relative to first
	pc) in fixups.
	These are the targets of backward branches. A backward branch fixup's
	simStackPtr needs to be set when generating the code for the bytecode at
	the targetIndex.
	Initially a fixup's target is just a flag. Later on it is replaced with a
	proper instruction. */

static BytecodeFixup *
initializeFixupAt(sqInt targetIndex)
{
	// StackToRegisterMappingCogit>>#initializeFixupAt:
    BytecodeFixup *fixup;

	fixup = fixupAt(targetIndex);
	(fixup->targetInstruction = ((AbstractInstruction *) 2));
	(fixup->simStackPtr = -2);
	return fixup;
}


/*	Answer a usage count that reflects likely long-term usage.
	Answer 0 for non-primitives or quick primitives (inst var accessors),
	1 for methods with interpreter primitives, and 2 for compiled primitives. */

static sqInt
initialMethodUsageCount(void)
{
	// Cogit>>#initialMethodUsageCount
	if ((primitiveIndex == 0)
	 || (isQuickPrimitiveIndex(primitiveIndex))) {
		return 0;
	}
	if ((primitiveGeneratorOrNil()) == null) {
		return 1;
	}
	return 2;
}


/*	Answer a usage count that reflects likely long-term usage. */

static sqInt
initialOpenPICUsageCount(void)
{
	// Cogit>>#initialOpenPICUsageCount
	return 3;
}

static void
initSimStackForFramefulMethod(sqInt startpc)
{
	// StackToRegisterMappingCogit>>#initSimStackForFramefulMethod:
    CogSimStackEntry *desc;
    sqInt i;

	(optStatus.isReceiverResultRegLive = 0);
	(simSelf.type = SSBaseOffset);
	(simSelf.spilled = 1);
	(simSelf.annotateUse = 0);
	(simSelf.registerr = FPReg);
	(simSelf.offset = FoxMFReceiver);

	/* N.B. Includes num args */

simSpillBase = methodOrBlockNumTemps;

	/* args */

simStackPtr = simSpillBase - 1;
	for (i = 0; i < methodOrBlockNumArgs; i += 1) {
		desc = simStackAt(i);
		(desc->type = SSBaseOffset);
		(desc->spilled = 1);
		(desc->annotateUse = 0);
		(desc->registerr = FPReg);
		(desc->offset = FoxCallerSavedIP + ((methodOrBlockNumArgs - i) * BytesPerWord));
		(desc->bcptr = startpc);
	}
	for (i = methodOrBlockNumArgs; i <= simStackPtr; i += 1) {
		desc = simStackAt(i);
		(desc->type = SSBaseOffset);
		(desc->spilled = 1);
		(desc->annotateUse = 0);
		(desc->registerr = FPReg);
		(desc->offset = FoxMFReceiver - (((i - methodOrBlockNumArgs) + 1) * BytesPerWord));
		(desc->bcptr = startpc);
	}
}


/*	The register receiver (he closure itself) and args are pushed by the
	closure value primitive(s)
	and hence a frameless block has all arguments and copied values pushed to
	the stack. However,
	the method receiver (self) is put in the ReceiverResultRegister by the
	block entry. */

static void
initSimStackForFramelessBlock(sqInt startpc)
{
	// StackToRegisterMappingCogit>>#initSimStackForFramelessBlock:
    CogSimStackEntry *desc;
    sqInt i;

	(simSelf.type = SSRegister);
	(simSelf.spilled = 0);
	(simSelf.annotateUse = 0);
	(simSelf.registerr = ReceiverResultReg);
	(optStatus.isReceiverResultRegLive = 1);
	(optStatus.ssEntry = (&simSelf));
	assert(methodOrBlockNumTemps >= methodOrBlockNumArgs);
	assert((numRegArgs()) <= 2);
	for (i = 0; i < methodOrBlockNumTemps; i += 1) {
		desc = simStackAt(i);
		(desc->type = SSBaseOffset);
		(desc->spilled = 1);
		(desc->annotateUse = 0);
		(desc->registerr = SPReg);
		(desc->offset = (methodOrBlockNumTemps - i) * BytesPerWord);
		(desc->bcptr = startpc);
	}
	simSpillBase = (simStackPtr = methodOrBlockNumTemps - 1);
}

static void
initSimStackForFramelessMethod(sqInt startpc)
{
	// StackToRegisterMappingCogit>>#initSimStackForFramelessMethod:
    CogSimStackEntry *desc;
    sqInt i;

	(simSelf.type = SSRegister);
	(simSelf.spilled = 0);
	(simSelf.annotateUse = 0);
	(simSelf.registerr = ReceiverResultReg);
	(optStatus.isReceiverResultRegLive = 1);
	(optStatus.ssEntry = (&simSelf));
	assert((methodOrBlockNumTemps == methodOrBlockNumArgs)
	 || (isQuickPrimitiveIndex(primitiveIndex)));
	assert((numRegArgs()) <= 2);
	if (((methodOrBlockNumArgs >= 1) && (methodOrBlockNumArgs <= 1))) {
		desc = simStackAt(0);
		(desc->type = SSRegister);
		(desc->spilled = 0);
		(desc->annotateUse = 0);
		(desc->registerr = Arg0Reg);
		(desc->bcptr = startpc);
		if (methodOrBlockNumArgs > 1) {
			desc = simStackAt(1);
			(desc->type = SSRegister);
			(desc->spilled = 0);
			(desc->annotateUse = 0);
			(desc->registerr = Arg1Reg);
			(desc->bcptr = startpc);
		}
	}
	else {
for (i = 0; i < methodOrBlockNumArgs; i += 1) {
			desc = simStackAt(i);
			(desc->type = SSBaseOffset);
			(desc->registerr = SPReg);
			(desc->spilled = 1);
			(desc->annotateUse = 0);
			(desc->offset = (methodOrBlockNumArgs - i) * BytesPerWord);
			(desc->bcptr = startpc);
		}
	}
	simSpillBase = (simStackPtr = methodOrBlockNumArgs - 1);
}


/*	Answer the inline cache tag for the return address of a send. */

static sqInt
inlineCacheTagAt(AbstractInstruction * self_in_inlineCacheTagAt, sqInt callSiteReturnAddress)
{
	// CogIA32Compiler>>#inlineCacheTagAt:
	return literalBeforeFollowingAddress(self_in_inlineCacheTagAt, callSiteReturnAddress - 5);
}


/*	c.f. getInlineCacheClassTagFrom:into: */

static sqInt
inlineCacheTagForInstance(sqInt oop)
{
	// CogObjectRepresentationForSqueakV3>>#inlineCacheTagForInstance:
    sqInt cci;

	if ((oop & 1)) {
return ((0 << 1) | 1);
	}
	if (((cci = compactClassIndexOf(oop))) > 0) {
		return cci << ShiftForWord;
	}
	return (classHeader(oop)) & AllButTypeMask;
}

static sqInt
inlineCacheTagIsYoung(sqInt cacheTag)
{
	// CogObjectRepresentationForSqueakV3>>#inlineCacheTagIsYoung:
	return isYoung(cacheTag);
}

static sqInt
inlineCacheTagsMayBeObjects(void)
{
	// CogObjectRepresentationForSqueakV3>>#inlineCacheTagsMayBeObjects
	return 1;
}


/*	Answer the instruction size at pc. This is very far from a full decode.
	It only has to cope with the instructions generated in a block dispatch. */

static sqInt
instructionSizeAt(AbstractInstruction * self_in_instructionSizeAt, sqInt pc)
{
	// CogIA32Compiler>>#instructionSizeAt:
    sqInt op;

	op = byteAt(pc);
	
	switch (op) {
	case 15:
		return twoByteInstructionSizeAt(self_in_instructionSizeAt, pc);

	case 61:
	case 233:
		return 5;

	case 112:
	case 113:
	case 114:
	case 115:
	case 116:
	case 117:
	case 118:
	case 119:
	case 120:
	case 121:
	case 122:
	case 123:
	case 0x7C:
	case 125:
	case 0x7E:
	case 0x7F:
	case 137:
	case 235:
		return 2;

	case 131:
		return sizeImmediateGroup1at(self_in_instructionSizeAt, op, pc);

	case 139:
		return sizeHasModrmat(self_in_instructionSizeAt, op, pc);

	case 144:
		return 1;

	default:
		error("Case not found and no otherwise clause");
		return -1;
	}
}

sqInt
interpretOffset(void)
{
	// Cogit>>#interpretOffset
	return missOffset;
}

static sqInt
inverseBranchFor(sqInt opcode)
{
	// Cogit>>#inverseBranchFor:
	
	switch (opcode) {
	case JumpLongZero:
		return JumpLongNonZero;

	case JumpLongNonZero:
		return JumpLongZero;

	case JumpZero:
		return JumpNonZero;

	case JumpNonZero:
		return JumpZero;

	case JumpNegative:
		return JumpNonNegative;

	case JumpNonNegative:
		return JumpNegative;

	case JumpOverflow:
		return JumpNoOverflow;

	case JumpNoOverflow:
		return JumpOverflow;

	case JumpCarry:
		return JumpNoCarry;

	case JumpNoCarry:
		return JumpCarry;

	case JumpLess:
		return JumpGreaterOrEqual;

	case JumpGreaterOrEqual:
		return JumpLess;

	case JumpGreater:
		return JumpLessOrEqual;

	case JumpLessOrEqual:
		return JumpGreater;

	case JumpBelow:
		return JumpAboveOrEqual;

	case JumpAboveOrEqual:
		return JumpBelow;

	case JumpAbove:
		return JumpBelowOrEqual;

	case JumpBelowOrEqual:
		return JumpAbove;

	default:
		error("Case not found and no otherwise clause");
	}
	error("invalid opcode for inverse");
	return 0;
}

static sqInt
isAFixup(AbstractInstruction * self_in_isAFixup, void *fixupOrAddress)
{
	// CogAbstractInstruction>>#isAFixup:
	return addressIsInFixups(fixupOrAddress);
}

static sqInt
isAnInstruction(AbstractInstruction * self_in_isAnInstruction, AbstractInstruction *addressOrInstruction)
{
	// CogAbstractInstruction>>#isAnInstruction:
	return addressIsInInstructions(addressOrInstruction);
}


/*	Answer if the branch bytecode with the given descriptor is a backward
	branch. 
 */

static sqInt
isBackwardBranchatextsin(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	// Cogit>>#isBackwardBranch:at:exts:in:
	assert(((descriptor->spanFunction)) != null);
	return (((descriptor->spanFunction))(descriptor, pc, nExts, aMethodObj)) < 0;
}

static sqInt
isBigEndian(AbstractInstruction * self_in_isBigEndian)
{
	// CogIA32Compiler>>#isBigEndian
	return 0;
}

static sqInt
isBranch(BytecodeDescriptor * self_in_isBranch)
{
	// CogBytecodeDescriptor>>#isBranch
	return (((self_in_isBranch->spanFunction)) != null)
	 && (!((self_in_isBranch->isBlockCreation)));
}


/*	Assuming mcpc is a return pc answer if the instruction before it is a
	call. 
 */

static sqInt
isCallPreceedingReturnPC(AbstractInstruction * self_in_isCallPreceedingReturnPC, sqInt mcpc)
{
	// CogIA32Compiler>>#isCallPreceedingReturnPC:
	return (byteAt(mcpc - 5)) == 232;
}

static sqInt
isJump(AbstractInstruction * self_in_isJump)
{
	// CogAbstractInstruction>>#isJump
	return ((((self_in_isJump->opcode)) >= FirstJump) && (((self_in_isJump->opcode)) <= LastJump));
}

static sqInt
isJumpAt(AbstractInstruction * self_in_isJumpAt, sqInt pc)
{
	// CogIA32Compiler>>#isJumpAt:
    sqInt op;

	op = byteAt(pc);
	return (((op >= 112) && (op <= 0x7F)))
	 || ((op == 233)
	 || ((op == 235)
	 || ((op == 15)
	 && ((((byteAt(pc + 1)) >= 128) && ((byteAt(pc + 1)) <= 143))))));
}

static sqInt
isLongJump(AbstractInstruction * self_in_isLongJump)
{
	// CogAbstractInstruction>>#isLongJump
	return ((((self_in_isLongJump->opcode)) >= FirstJump) && (((self_in_isLongJump->opcode)) <= (FirstShortJump - 1)));
}


/*	Answer if the receiver is a pc-dependent instruction. */

static sqInt
isPCDependent(AbstractInstruction * self_in_isPCDependent)
{
	// CogIA32Compiler>>#isPCDependent
	return (isJump(self_in_isPCDependent))
	 || (((self_in_isPCDependent->opcode)) == AlignmentNops);
}

static sqInt
isPCMappedAnnotationalternateInstructionSet(sqInt annotation, sqInt isAlternateInstSet)
{
	// Cogit>>#isPCMappedAnnotation:alternateInstructionSet:
	return (annotation == IsSendCall)
			 || (annotation == HasBytecodePC);
}

sqInt
isPCWithinMethodZone(char *address)
{
	// Cogit>>#isPCWithinMethodZone:
	return (((((usqInt)address)) >= methodZoneBase) && ((((usqInt)address)) <= (freeStart())));
}

static sqInt
isQuick(AbstractInstruction * self_in_isQuick, unsigned long operand)
{
	// CogIA32Compiler>>#isQuick:
	return (((((sqInt) operand)) >= -128) && ((((sqInt) operand)) <= 0x7F));
}


/*	Answer if the instruction preceeding retpc is a call instruction. */

sqInt
isSendReturnPC(sqInt retpc)
{
	// Cogit>>#isSendReturnPC:
    sqInt target;

	if (!(isCallPreceedingReturnPC(backEnd, retpc))) {
		return 0;
	}
	target = callTargetFromReturnAddress(backEnd, retpc);
	return (((target >= firstSend) && (target <= lastSend)))
	 || (((target >= methodZoneBase) && (target <= (freeStart()))));
}

static sqInt
isSmallIntegerTagNonZero(void)
{
	// CogObjectRepresentationForSqueakV3>>#isSmallIntegerTagNonZero
	return 1;
}

static sqInt
isUnconditionalBranch(BytecodeDescriptor * self_in_isUnconditionalBranch)
{
	// CogBytecodeDescriptor>>#isUnconditionalBranch
	return (isBranch(self_in_isUnconditionalBranch))
	 && (!(((self_in_isUnconditionalBranch->isBranchTrue))
 || ((self_in_isUnconditionalBranch->isBranchFalse))));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

static AbstractInstruction *
gJumpFPEqual(void *jumpTarget)
{
	// Cogit>>#JumpFPEqual:
    AbstractInstruction *jumpToTarget;
    AbstractInstruction *jumpUnordered;

	/* begin genJumpFPEqual: */
	jumpUnordered = gen(JumpFPUnordered);
	jumpToTarget = genoperand(JumpFPEqual, ((sqInt)jumpTarget));
	jmpTarget(jumpUnordered, gLabel());
	return jumpToTarget;
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

static AbstractInstruction *
gJumpFPGreaterOrEqual(void *jumpTarget)
{
	// Cogit>>#JumpFPGreaterOrEqual:
	/* begin genJumpFPGreaterOrEqual: */
	return genoperand(JumpFPGreaterOrEqual, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

static AbstractInstruction *
gJumpFPGreater(void *jumpTarget)
{
	// Cogit>>#JumpFPGreater:
	/* begin genJumpFPGreater: */
	return genoperand(JumpFPGreater, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

static AbstractInstruction *
gJumpFPLessOrEqual(void *jumpTarget)
{
	// Cogit>>#JumpFPLessOrEqual:
	/* begin genJumpFPLessOrEqual: */
	return genoperand(JumpFPLessOrEqual, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

static AbstractInstruction *
gJumpFPLess(void *jumpTarget)
{
	// Cogit>>#JumpFPLess:
	/* begin genJumpFPLess: */
	return genoperand(JumpFPLess, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

static AbstractInstruction *
gJumpFPNotEqual(void *jumpTarget)
{
	// Cogit>>#JumpFPNotEqual:
    AbstractInstruction *jumpToTarget;
    AbstractInstruction *jumpUnordered;

	/* begin genJumpFPNotEqual: */
	jumpToTarget = genoperand(JumpFPNotEqual, ((sqInt)jumpTarget));
	jumpUnordered = genoperand(JumpFPUnordered, ((sqInt)jumpTarget));
	addDependent(jumpToTarget, jumpUnordered);
	return jumpToTarget;
}


/*	Big assumption here that calls and jumps look the same as regards their
	displacement. This works on x86 and I think on ARM. */

static AbstractInstruction *
JumpRT(sqInt callTarget)
{
	// Cogit>>#JumpRT:
    AbstractInstruction *abstractInstruction;

	/* begin annotateCall: */
	/* begin JumpLong: */
	abstractInstruction = genoperand(JumpLong, callTarget);
	return annotatewith(abstractInstruction, IsRelativeCall);
}


/*	Set the target of a jump instruction. These all have the target in the
	first operand. */
/*	Set the target of a jump instruction. These all have the target in the
	first operand.
	Override to cope with JumpFPNotEqual where because if IEEE NaN conformance
	and the behaviour of COMISD/UCOMISD we generate two jumps to the same
	target.  */

static AbstractInstruction *
jmpTarget(AbstractInstruction * self_in_jmpTarget, AbstractInstruction *anAbstractInstruction)
{
	// CogIA32Compiler>>#jmpTarget:
    AbstractInstruction *aDependent;

	aDependent = (self_in_jmpTarget->dependent);
	while (aDependent != null) {
jmpTarget(aDependent, anAbstractInstruction);
		aDependent = (aDependent->dependent);
	}
	null;
	((self_in_jmpTarget->operands))[0] = (((usqInt)anAbstractInstruction));
	return anAbstractInstruction;
}

static sqInt
jumpLongByteSize(AbstractInstruction * self_in_jumpLongByteSize)
{
	// CogIA32Compiler>>#jumpLongByteSize
	return 5;
}

static sqInt
jumpLongConditionalByteSize(AbstractInstruction * self_in_jumpLongConditionalByteSize)
{
	// CogIA32Compiler>>#jumpLongConditionalByteSize
	return 6;
}


/*	Answer the target address for the long jump immediately preceeding mcpc */

static sqInt
jumpLongTargetBeforeFollowingAddress(AbstractInstruction * self_in_jumpLongTargetBeforeFollowingAddress, sqInt mcpc)
{
	// CogIA32Compiler>>#jumpLongTargetBeforeFollowingAddress:
	return callTargetFromReturnAddress(self_in_jumpLongTargetBeforeFollowingAddress, mcpc);
}

static sqInt
jumpShortByteSize(AbstractInstruction * self_in_jumpShortByteSize)
{
	// CogIA32Compiler>>#jumpShortByteSize
	return 2;
}


/*	Since it's an extraction from other methods. */

static AbstractInstruction *
jumpTargetAddress(AbstractInstruction * self_in_jumpTargetAddress)
{
	// CogAbstractInstruction>>#jumpTargetAddress
    AbstractInstruction *jumpTarget;

	jumpTarget = ((AbstractInstruction *) (((self_in_jumpTargetAddress->operands))[0]));
	assertSaneJumpTarget(jumpTarget);
	if (isAnInstruction(self_in_jumpTargetAddress, jumpTarget)) {
		jumpTarget = ((AbstractInstruction *) ((jumpTarget->address)));
	}
	assert(jumpTarget != 0);
	return jumpTarget;
}

static sqInt
jumpTargetPCAt(AbstractInstruction * self_in_jumpTargetPCAt, sqInt pc)
{
	// CogIA32Compiler>>#jumpTargetPCAt:
    sqInt byte;
    sqInt offset;
    sqInt size;

	size = instructionSizeAt(self_in_jumpTargetPCAt, pc);
	if (size == 2) {
byte = byteAt(pc + 1);
		offset = ((byte & 128) == 0
			? byte
			: byte - 256);
	}
	else {
byte = byteAt((pc + size) - 1);
		offset = ((byte & 128) == 0
			? byte
			: byte - 256);
		offset = (offset << 8) + (byteAt((pc + size) - 2));
		offset = (offset << 8) + (byteAt((pc + size) - 3));
		offset = (offset << 8) + (byteAt((pc + size) - 4));
	}
	return (pc + size) + offset;
}


/*	Answer that all entries in youngReferrers are in-use and have the
	cmRefersToYoung flag set.
	Used to check that the youngreferrers pruning routines work correctly. */

static sqInt
kosherYoungReferrers(void)
{
	// CogMethodZone>>#kosherYoungReferrers
    CogMethod *cogMethod;
    usqInt pointer;

	if ((youngReferrers > limitAddress)
	 || (youngReferrers < mzFreeStart)) {
		return 0;
	}
	pointer = youngReferrers;
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (!((((cogMethod->cmType)) != CMFree)
			 && ((cogMethod->cmRefersToYoung)))) {
			return 0;
		}
		pointer += BytesPerWord;
	}
	return 1;
}

static AbstractInstruction *
gLabel(void)
{
	// Cogit>>#Label
	return genoperandoperand(Label, (labelCounter += 1), bytecodePC);
}

static AbstractInstruction *
gLogicalShiftRightCqR(sqInt quickConstant, sqInt reg)
{
	// Cogit>>#LogicalShiftRightCq:R:
	return genoperandoperand(LogicalShiftRightCqR, quickConstant, reg);
}


/*	To arrange that the block method field pushed in a block entry has
	its MFMethodFlagIsBlockFlag bit set we provide labels with an offset.
	The offset for the fakeHeader reference is MFMethodFlagIsBlockFlag.
	See compileBlockFrameBuild: */

static sqInt
labelOffset(AbstractInstruction * self_in_labelOffset)
{
	// CogAbstractInstruction>>#labelOffset
	return ((self_in_labelOffset->operands))[1];
}

static AbstractInstruction *
lastOpcode(void)
{
	// Cogit>>#lastOpcode
	assert(opcodeIndex > 0);
	return abstractInstructionAt(opcodeIndex - 1);
}


/*	Answer the delta from the stack pointer after a call to the stack pointer
	immediately prior to the call. This is used to compute the stack pointer
	immediately prior to call from within a leaf routine, which in turn is
	used to capture the c stack pointer to use in trampolines back into the C
	run-time.  */

static sqInt
leafCallStackPointerDelta(AbstractInstruction * self_in_leafCallStackPointerDelta)
{
	// CogIA32Compiler>>#leafCallStackPointerDelta
	return 4;
}

void
linkSendAtintooffsetreceiver(sqInt callSiteReturnAddress, CogMethod *sendingMethod, CogMethod *targetMethod, sqInt theEntryOffset, sqInt receiver)
{
	// Cogit>>#linkSendAt:in:to:offset:receiver:
    sqInt address;
    sqInt extent;
    sqInt inlineCacheTag;

	assert((theEntryOffset == cmEntryOffset)
	 || (theEntryOffset == cmNoCheckEntryOffset));

	assert(((callSiteReturnAddress >= methodZoneBase) && (callSiteReturnAddress <= (freeStart()))));
	inlineCacheTag = (theEntryOffset == cmNoCheckEntryOffset
		? (targetMethod->selector)
		: inlineCacheTagForInstance(receiver));
	if ((!((sendingMethod->cmRefersToYoung)))
	 && (inlineCacheTagIsYoung(inlineCacheTag))) {
		assert((occurrencesInYoungReferrers(sendingMethod)) == 0);
		(sendingMethod->cmRefersToYoung = 1);
		addToYoungReferrers(sendingMethod);
	}
	address = (((sqInt)targetMethod)) + theEntryOffset;
	extent = rewriteInlineCacheAttagtarget(backEnd, callSiteReturnAddress, inlineCacheTag, address);
	flushICacheFromto(processor, (callSiteReturnAddress - 1) - extent, callSiteReturnAddress - 1);
}


/*	Answer the literal embedded in the instruction immediately preceeding
	followingAddress. 
 */

static sqInt
literalBeforeFollowingAddress(AbstractInstruction * self_in_literalBeforeFollowingAddress, sqInt followingAddress)
{
	// CogIA32Compiler>>#literalBeforeFollowingAddress:
	return ((((byteAt(followingAddress - 1)) << 24) + ((byteAt(followingAddress - 2)) << 16)) + ((byteAt(followingAddress - 3)) << 8)) + (byteAt(followingAddress - 4));
}

static sqInt
liveRegisters(void)
{
	// StackToRegisterMappingCogit>>#liveRegisters
    sqInt i;
    sqInt regsSet;

	if (needsFrame) {
		regsSet = 0;
	}
	else {
regsSet = registerMaskFor(ReceiverResultReg);
		if ((methodOrBlockNumArgs <= 1)
		 && (methodOrBlockNumArgs > 0)) {
			regsSet = regsSet | (registerMaskFor(Arg0Reg));
			
		}
	}
	for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= simStackPtr; i += 1) {
		regsSet = regsSet | (registerMask(simStackAt(i)));
	}
	return regsSet;
}


/*	Answer the byte size of a MoveCwR opcode's corresponding machine code */

static sqInt
loadLiteralByteSize(AbstractInstruction * self_in_loadLiteralByteSize)
{
	// CogIA32Compiler>>#loadLiteralByteSize
	return 5;
}

static void
loadSubsequentBytesForDescriptorat(BytecodeDescriptor *descriptor, sqInt pc)
{
	// Cogit>>#loadSubsequentBytesForDescriptor:at:
	if (((descriptor->numBytes)) > 1) {
		byte1 = fetchByteofObject(pc + 1, methodObj);
		if (((descriptor->numBytes)) > 2) {
			byte2 = fetchByteofObject(pc + 2, methodObj);
			if (((descriptor->numBytes)) > 3) {
				byte3 = fetchByteofObject(pc + 3, methodObj);
				if (((descriptor->numBytes)) > 4) {
					notYetImplemented();
				}
			}
		}
	}
}


/*	Since it's an extraction from other methods. */
/*	This needs to be digfferent from jumpTargetAddress because long jumps can
	be to absolute addresses and hence we can't assert that the jump target is
	sane. 
 */

static AbstractInstruction *
longJumpTargetAddress(AbstractInstruction * self_in_longJumpTargetAddress)
{
	// CogAbstractInstruction>>#longJumpTargetAddress
    AbstractInstruction *jumpTarget;

	jumpTarget = ((AbstractInstruction *) (((self_in_longJumpTargetAddress->operands))[0]));
	if (isAnInstruction(self_in_longJumpTargetAddress, jumpTarget)) {
		jumpTarget = ((AbstractInstruction *) ((jumpTarget->address)));
	}
	assert(jumpTarget != 0);
	return jumpTarget;
}

static AbstractInstruction *
gMoveAwR(sqInt address, sqInt reg)
{
	// Cogit>>#MoveAw:R:
	return genoperandoperand(MoveAwR, address, reg);
}

static AbstractInstruction *
gMoveCwR(sqInt wordConstant, sqInt reg)
{
	// Cogit>>#MoveCw:R:
	return genoperandoperand(MoveCwR, wordConstant, reg);
}

static AbstractInstruction *
gMoveMwrR(sqInt offset, sqInt baseReg, sqInt destReg)
{
	// Cogit>>#MoveMw:r:R:
	return genoperandoperandoperand(MoveMwrR, offset, baseReg, destReg);
}

static AbstractInstruction *
gMoveRMwr(sqInt sourceReg, sqInt offset, sqInt baseReg)
{
	// Cogit>>#MoveR:Mw:r:
	return genoperandoperandoperand(MoveRMwr, sourceReg, offset, baseReg);
}


/*	Multiplication is a little weird on some processors. Defer to the backEnd
	to allow it to generate any special code it may need to. */

static AbstractInstruction *
gMulRR(sqInt reg1, sqInt reg2)
{
	// Cogit>>#MulR:R:
	genMulRR(backEnd, reg1, reg2);
	return abstractInstructionAt(opcodeIndex - 1);
}


/*	Answer the maximum number of bytes of machine code generated for any
	abstract instruction.
	e.g. lock movsd 0x400(%esp),%xmm4 => f0 f2 0f 10 a4 24 00 04 00 00 */

static sqInt
machineCodeBytes(AbstractInstruction * self_in_machineCodeBytes)
{
	// CogIA32Compiler>>#machineCodeBytes
	return 10;
}

static void
manageFromto(sqInt theStartAddress, sqInt theLimitAddress)
{
	// CogMethodZone>>#manageFrom:to:
	mzFreeStart = (baseAddress = theStartAddress);
	youngReferrers = (limitAddress = theLimitAddress);
	openPICList = null;
	
methodBytesFreedSinceLastCompaction = 0;
	methodCount = 0;
}


/*	Answer the address of the null byte at the end of the method map. */

static sqInt
mapEndFor(CogMethod *cogMethod)
{
	// Cogit>>#mapEndFor:
    sqInt end;

	end = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while ((byteAt(end)) != MapEnd) {
		end -= 1;
		assert(end > ((((sqInt)cogMethod)) + cmNoCheckEntryOffset));
	}
	return end;
}


/*	Unlinking/GC/Disassembly support */

static sqInt
mapForperformUntilarg(CogMethod *cogMethod, int (*functionSymbol)(sqInt annotation, char *mcpc, sqInt arg), sqInt arg)
{
	// Cogit>>#mapFor:performUntil:arg:
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
			result = functionSymbol((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), arg);
			if (result != 0) {
return result;
			}
		}
		else {
mcpc += (mapByte >= DisplacementX2N
				? (mapByte - DisplacementX2N) << AnnotationShift
				: mapByte);
		}
		map -= 1;
	}
	return 0;
}


/*	Remap all object references in the closed PIC. Answer if any references
	are young.
	Set codeModified if any modifications are made. */

static sqInt
mapObjectReferencesInClosedPIC(CogMethod *cPIC)
{
	// Cogit>>#mapObjectReferencesInClosedPIC:
    sqInt i;
    sqInt pc;
    sqInt refersToYoung;

	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	refersToYoung = updateMaybeObjRefAt(pc - (jumpLongByteSize(backEnd)));
	pc += cPICCaseSize;
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		if (updateMaybeObjRefAt((pc - (jumpLongConditionalByteSize(backEnd))) - (loadLiteralByteSize(backEnd)))) {
			refersToYoung = 1;
		}
		if (updateMaybeObjRefAt(pc - (jumpLongConditionalByteSize(backEnd)))) {
			refersToYoung = 1;
		}
		pc += cPICCaseSize;
	}
	return refersToYoung;
}


/*	Update all references to objects in the generated runtime. */

static void
mapObjectReferencesInGeneratedRuntime(void)
{
	// Cogit>>#mapObjectReferencesInGeneratedRuntime
    sqInt i;
    sqInt literal;
    sqInt mappedLiteral;
    sqInt mcpc;

	for (i = 0; i < runtimeObjectRefIndex; i += 1) {
		mcpc = objectReferencesInRuntime[i];
		literal = literalBeforeFollowingAddress(backEnd, ((sqInt)mcpc));
		mappedLiteral = remapObject(literal);
		if (mappedLiteral != literal) {
storeLiteralbeforeFollowingAddress(backEnd, mappedLiteral, mcpc);
			codeModified = 1;
		}
	}
}


/*	Update all references to objects in machine code for a become.
	Unlike incrementalGC or fullGC a method that does not refer to young may
	refer to young as a result of the become operation. Unlike incrementalGC
	or fullGC the reference from a Cog method to its methodObject *must not*
	change since the two are two halves of the same object. */

static void
mapObjectReferencesInMachineCodeForBecome(void)
{
	// Cogit>>#mapObjectReferencesInMachineCodeForBecome
    CogMethod *cogMethod;
    sqInt freedPIC;
    sqInt hasYoungObj;
    sqInt hasYoungObjPtr;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt remappedMethod;
    sqInt result;
    sqInt val;

	hasYoungObj = 0;
	hasYoungObjPtr = ((sqInt)((&hasYoungObj)));
	codeModified = (freedPIC = 0);
	mapObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		assert(!hasYoungObj);
		if (((cogMethod->cmType)) != CMFree) {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			(cogMethod->selector = remapOop((cogMethod->selector)));
			if (((cogMethod->cmType)) == CMClosedPIC) {
				if ((isYoung((cogMethod->selector)))
				 || (mapObjectReferencesInClosedPIC(cogMethod))) {
					freedPIC = 1;
					freeMethod(cogMethod);
				}
			}
			else {
if (isYoung((cogMethod->selector))) {
					hasYoungObj = 1;
				}
				if (((cogMethod->cmType)) == CMMethod) {
					assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
					remappedMethod = remapOop((cogMethod->methodObject));
					if (remappedMethod != ((cogMethod->methodObject))) {
						if (methodHasCogMethod(remappedMethod)) {
							error("attempt to become two cogged methods");
						}
						if (!(withoutForwardingOnandwithsendToCogit((cogMethod->methodObject), remappedMethod, (cogMethod->cmUsesPenultimateLit), methodhasSameCodeAscheckPenultimate))) {
							error("attempt to become cogged method into different method");
						}
						if ((rawHeaderOf((cogMethod->methodObject))) == (((sqInt)cogMethod))) {
							rawHeaderOfput((cogMethod->methodObject), (cogMethod->methodHeader));
							(cogMethod->methodHeader = rawHeaderOf(remappedMethod));
							(cogMethod->methodObject = remappedMethod);
							rawHeaderOfput(remappedMethod, ((sqInt)cogMethod));
						}
						else {
assert((noAssertMethodClassAssociationOf((cogMethod->methodObject))) == (nilObject()));
							(cogMethod->methodHeader = rawHeaderOf(remappedMethod));
							(cogMethod->methodObject = remappedMethod);
						}
					}
					if (isYoung((cogMethod->methodObject))) {
						hasYoungObj = 1;
					}
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
						result = remapIfObjectRefpchasYoung((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), hasYoungObjPtr);
						if (result != 0) {
result;
							goto l1;
						}
					}
					else {
mcpc += (mapByte >= DisplacementX2N
							? (mapByte - DisplacementX2N) << AnnotationShift
							: mapByte);
					}
					map -= 1;
				}
				0;
			l1:	/* end mapFor:performUntil:arg: */;
				if (hasYoungObj) {
if (!((cogMethod->cmRefersToYoung))) {
						(cogMethod->cmRefersToYoung = 1);
						addToYoungReferrers(cogMethod);
					}
					hasYoungObj = 0;
				}
				else {
(cogMethod->cmRefersToYoung = 0);
				}
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	pruneYoungReferrers();
	if (freedPIC) {
unlinkSendsToFree();
		codeModified = 1;
	}
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

flushICacheFromto(processor, codeBase, ((sqInt)(limitZony())));
	}
}


/*	Update all references to objects in machine code for a full gc. Since
	the current (New)ObjectMemory GC makes everything old in a full GC
	a method not referring to young will not refer to young afterwards */

static void
mapObjectReferencesInMachineCodeForFullGC(void)
{
	// Cogit>>#mapObjectReferencesInMachineCodeForFullGC
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	codeModified = 0;
	mapObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			(cogMethod->selector = remapOop((cogMethod->selector)));
			if (((cogMethod->cmType)) == CMClosedPIC) {
				assert(!((cogMethod->cmRefersToYoung)));
				mapObjectReferencesInClosedPIC(cogMethod);
			}
			else {
if (((cogMethod->cmType)) == CMMethod) {
					assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
					(cogMethod->methodObject = remapOop((cogMethod->methodObject)));
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
						result = remapIfObjectRefpchasYoung((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), 0);
						if (result != 0) {
result;
							goto l1;
						}
					}
					else {
mcpc += (mapByte >= DisplacementX2N
							? (mapByte - DisplacementX2N) << AnnotationShift
							: mapByte);
					}
					map -= 1;
				}
				0;
			l1:	/* end mapFor:performUntil:arg: */;
				if (((cogMethod->cmRefersToYoung))
				 && (allYoungObjectsAgeInFullGC())) {
					(cogMethod->cmRefersToYoung = 0);
				}
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	pruneYoungReferrers();
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

flushICacheFromto(processor, codeBase, ((sqInt)(limitZony())));
	}
}


/*	Update all references to objects in machine code for either a Spur
	scavenging gc
	or a Squeak V3 incremental GC. Avoid scanning all code by using the
	youngReferrers list. In a young gc a method referring to young may no
	longer refer to young, but a
	method not referring to young cannot and will not refer to young
	afterwards.  */

static void
mapObjectReferencesInMachineCodeForYoungGC(void)
{
	// Cogit>>#mapObjectReferencesInMachineCodeForYoungGC
    CogMethod *cogMethod;
    sqInt hasYoungObj;
    sqInt hasYoungObjPtr;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    usqInt pointer;
    sqInt result;
    sqInt val;

	hasYoungObj = 0;
	hasYoungObjPtr = ((sqInt)((&hasYoungObj)));
	codeModified = 0;
	pointer = youngReferrers();
	while (pointer < limitAddress) {
		assert(!hasYoungObj);
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (((cogMethod->cmType)) == CMFree) {
			assert(!((cogMethod->cmRefersToYoung)));
		}
		else {
assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			if ((cogMethod->cmRefersToYoung)) {
				assert((((cogMethod->cmType)) == CMMethod)
				 || (((cogMethod->cmType)) == CMOpenPIC));
				(cogMethod->selector = remapOop((cogMethod->selector)));
				if (isYoung((cogMethod->selector))) {
					hasYoungObj = 1;
				}
				if (((cogMethod->cmType)) == CMMethod) {
					assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
					(cogMethod->methodObject = remapOop((cogMethod->methodObject)));
					if (isYoung((cogMethod->methodObject))) {
						hasYoungObj = 1;
					}
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
						result = remapIfObjectRefpchasYoung((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), hasYoungObjPtr);
						if (result != 0) {
result;
							goto l1;
						}
					}
					else {
mcpc += (mapByte >= DisplacementX2N
							? (mapByte - DisplacementX2N) << AnnotationShift
							: mapByte);
					}
					map -= 1;
				}
				0;
			l1:	/* end mapFor:performUntil:arg: */;
				if (hasYoungObj) {
hasYoungObj = 0;
				}
				else {
(cogMethod->cmRefersToYoung = 0);
				}
			}
		}
		pointer += BytesPerWord;
	}
	pruneYoungReferrers();
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

flushICacheFromto(processor, methodZoneBase, ((sqInt)(limitZony())));
	}
}


/*	Update all references to objects in machine code. */

void
mapObjectReferencesInMachineCode(sqInt gcMode)
{
	// Cogit>>#mapObjectReferencesInMachineCode:
	
	switch (gcMode) {
	case GCModeScavenge:
	case GCModeIncr:
		mapObjectReferencesInMachineCodeForYoungGC();
		break;
	case GCModeFull:
		mapObjectReferencesInMachineCodeForFullGC();
		break;
	case GCModeBecome:
		mapObjectReferencesInMachineCodeForBecome();
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	if (!(asserta((freeStart()) <= (youngReferrers())))) {
		error("youngReferrers list overflowed");
	}
}

static void
markAndTraceLiteralIfYoung(sqInt literal)
{
	// CogObjectRepresentationForSqueakV3>>#markAndTraceLiteralIfYoung:
	if ((couldBeObject(literal))
	 && (isYoungObject(literal))) {
		assert(addressCouldBeObj(literal));
		markAndTrace(literal);
	}
}

static void
markAndTraceLiteral(sqInt literal)
{
	// CogObjectRepresentationForSqueakV3>>#markAndTraceLiteral:
	if (couldBeObject(literal)) {
		assert(addressCouldBeObj(literal));
		markAndTrace(literal);
	}
}


/*	Free any methods that refer to unmarked objects, unlinking sends to freed
	methods. 
 */

static void
markAndTraceMachineCodeForNewSpaceGC(void)
{
	// Cogit>>#markAndTraceMachineCodeForNewSpaceGC
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    usqInt pointer;
    sqInt result;

	if (leakCheckNewSpaceGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	codeModified = 0;
	pointer = youngReferrers();
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if ((cogMethod->cmRefersToYoung)) {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			assert((((cogMethod->cmType)) == CMMethod)
			 || (((cogMethod->cmType)) == CMOpenPIC));
			if (isYoung((cogMethod->selector))) {
				markAndTrace((cogMethod->selector));
			}
			if (((cogMethod->cmType)) == CMMethod) {
				if (isYoung((cogMethod->methodObject))) {
					markAndTrace((cogMethod->methodObject));
				}
				/* begin markYoungObjectsIn: */
				assert((((cogMethod->cmType)) == CMMethod)
				 || (((cogMethod->cmType)) == CMOpenPIC));
				if (isYoung((cogMethod->selector))) {
					markAndTrace((cogMethod->selector));
				}
				if ((((cogMethod->cmType)) == CMMethod)
				 && (isYoung((cogMethod->methodObject)))) {
					markAndTrace((cogMethod->methodObject));
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
						result = markYoungObjectspcmethod((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), (((sqInt)cogMethod)));
						if (result != 0) {
result;
							goto l1;
						}
					}
					else {
mcpc += (mapByte >= DisplacementX2N
							? (mapByte - DisplacementX2N) << AnnotationShift
							: mapByte);
					}
					map -= 1;
				}
				0;
			l1:	/* end mapFor:performUntil:arg: */;
			}
		}
		pointer += BytesPerWord;
	}
	if (leakCheckIncrementalGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

flushICacheFromto(processor, methodZoneBase, ((sqInt)(limitZony())));
	}
}


/*	Mark objects in machine-code of marked methods (or open PICs with marked
	selectors). 
 */

void
markAndTraceMachineCodeOfMarkedMethods(void)
{
	// Cogit>>#markAndTraceMachineCodeOfMarkedMethods
    CogMethod *cogMethod;
    sqInt map;
    sqInt map1;
    sqInt mapByte;
    sqInt mapByte1;
    sqInt mcpc;
    sqInt mcpc1;
    sqInt result;
    sqInt result1;

	if (leakCheckFullGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	codeModified = 0;
	markAndTraceObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMMethod)
		 && (isMarked((cogMethod->methodObject)))) {
			/* begin markAndTraceLiteralsIn: */
			assert(((((cogMethod->cmType)) == CMMethod)
			 && (isMarked((cogMethod->methodObject))))
			 || ((((cogMethod->cmType)) == CMOpenPIC)
			 && ((isImmediate((cogMethod->selector)))
			 || (isMarked((cogMethod->selector))))));
			markAndTraceLiteral((cogMethod->selector));
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
					result = markLiteralspcmethod((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), (((sqInt)cogMethod)));
					if (result != 0) {
result;
						goto l1;
					}
				}
				else {
mcpc += (mapByte >= DisplacementX2N
						? (mapByte - DisplacementX2N) << AnnotationShift
						: mapByte);
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		if ((((cogMethod->cmType)) == CMOpenPIC)
		 && ((isImmediate((cogMethod->selector)))
		 || (isMarked((cogMethod->selector))))) {
			/* begin markAndTraceLiteralsIn: */
			assert(((((cogMethod->cmType)) == CMMethod)
			 && (isMarked((cogMethod->methodObject))))
			 || ((((cogMethod->cmType)) == CMOpenPIC)
			 && ((isImmediate((cogMethod->selector)))
			 || (isMarked((cogMethod->selector))))));
			markAndTraceLiteral((cogMethod->selector));
			/* begin mapFor:performUntil:arg: */
			mcpc1 = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map1 = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte1 = byteAt(map1))) != MapEnd) {
				if (mapByte1 >= FirstAnnotation) {
mcpc1 += mapByte1 & DisplacementMask;
					result1 = markLiteralspcmethod((((usqInt) mapByte1) >> AnnotationShift), (((char *) mcpc1)), (((sqInt)cogMethod)));
					if (result1 != 0) {
result1;
						goto l2;
					}
				}
				else {
mcpc1 += (mapByte1 >= DisplacementX2N
						? (mapByte1 - DisplacementX2N) << AnnotationShift
						: mapByte1);
				}
				map1 -= 1;
			}
			0;
		l2:	/* end mapFor:performUntil:arg: */;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (leakCheckFullGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

flushICacheFromto(processor, methodZoneBase, ((sqInt)(limitZony())));
	}
}


/*	Mark and trace any object references in the generated run-time. */

static void
markAndTraceObjectReferencesInGeneratedRuntime(void)
{
	// Cogit>>#markAndTraceObjectReferencesInGeneratedRuntime
    sqInt i;
    sqInt literal;
    sqInt mcpc;

	for (i = 0; i < runtimeObjectRefIndex; i += 1) {
		mcpc = objectReferencesInRuntime[i];
		literal = literalBeforeFollowingAddress(backEnd, ((sqInt)mcpc));
		markAndTraceLiteral(literal);
	}
}

void
markAndTraceObjectsOrFreeMachineCode(sqInt inFullGC)
{
	// Cogit>>#markAndTraceObjectsOrFreeMachineCode:
	if (inFullGC) {
markAndTraceOrFreeMachineCodeForFullGC();
	}
	else {
markAndTraceMachineCodeForNewSpaceGC();
	}
}


/*	Mark and trace objects in the argument and free if it is appropriate.
	Answer if the method has been freed. firstVisit is a hint used to avoid
	scanning methods we've already seen. False positives are fine.
	For a CMMethod this
	frees if the bytecode method isnt marked,
	marks and traces object literals and selectors,
	unlinks sends to targets that should be freed.
	For a CMClosedPIC this
	frees if it refers to anything that should be freed or isn't marked.
	For a CMOpenPIC this
	frees if the selector isn't marked. */
/*	this recurses at most one level down */

static sqInt
markAndTraceOrFreeCogMethodfirstVisit(CogMethod *cogMethod, sqInt firstVisit)
{
	// Cogit>>#markAndTraceOrFreeCogMethod:firstVisit:
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	if (((cogMethod->cmType)) == CMFree) {
		return 1;
	}
	assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
	if (((cogMethod->cmType)) == CMMethod) {
		if (!(isMarked((cogMethod->methodObject)))) {
			freeMethod(cogMethod);
			return 1;
		}
		if (firstVisit) {
/* begin markLiteralsAndUnlinkUnmarkedSendsIn: */
			assert(((cogMethod->cmType)) == CMMethod);
			assert(isMarked((cogMethod->methodObject)));
			markAndTraceLiteral((cogMethod->selector));
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
					result = markLiteralsAndUnlinkIfUnmarkedSendpcmethod((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), (((sqInt)cogMethod)));
					if (result != 0) {
result;
						goto l1;
					}
				}
				else {
mcpc += (mapByte >= DisplacementX2N
						? (mapByte - DisplacementX2N) << AnnotationShift
						: mapByte);
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		return 0;
	}
	if (((cogMethod->cmType)) == CMClosedPIC) {
		if (!(closedPICRefersToUnmarkedObject(cogMethod))) {
			return 0;
		}
		freeMethod(cogMethod);
		return 1;
	}
	if (((cogMethod->cmType)) == CMOpenPIC) {
		if (isMarked((cogMethod->selector))) {
			return 0;
		}
		freeMethod(cogMethod);
		return 1;
	}
	assert((((cogMethod->cmType)) == CMMethod)
	 || ((((cogMethod->cmType)) == CMClosedPIC)
	 || (((cogMethod->cmType)) == CMOpenPIC)));
	return 0;
}


/*	Free any methods that refer to unmarked objects, unlinking sends to freed
	methods. 
 */

static void
markAndTraceOrFreeMachineCodeForFullGC(void)
{
	// Cogit>>#markAndTraceOrFreeMachineCodeForFullGC
    CogMethod *cogMethod;

	if (leakCheckFullGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	codeModified = 0;
	markAndTraceObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		markAndTraceOrFreeCogMethodfirstVisit(cogMethod, 1);
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (leakCheckFullGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

flushICacheFromto(processor, methodZoneBase, ((sqInt)(limitZony())));
	}
}


/*	Mark and trace literals. Unlink sends that have unmarked cache tags or
	targets. 
 */

static sqInt
markLiteralsAndUnlinkIfUnmarkedSendpcmethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
	// Cogit>>#markLiteralsAndUnlinkIfUnmarkedSend:pc:method:
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt cacheTagMarked;
    sqInt class;
    sqInt classpc;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt mixin;
    sqInt mixinpc;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation == IsObjectReference) {
literal = literalBeforeFollowingAddress(backEnd, ((sqInt)mcpc));
		markAndTraceLiteral(literal);
	}
	if (annotation == IsSendCall) {
/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */

		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (inlineCacheTagsMayBeObjects())
		 || ((entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC))));
		cacheTagMarked = tagCouldBeObj1
		 && (cacheTagIsMarked(cacheTag1));
		if (entryPoint1 > methodZoneBase) {

			/* It's a linked send. */

/* begin targetMethodAndSendTableFor:into: */
			if ((entryPoint1 & entryPointMask) == checkedEntryAlignment) {
				targetMethod1 = ((CogMethod *) (entryPoint1 - cmEntryOffset));
				sendTable1 = sendTrampolines;
			}
			else {
				targetMethod1 = ((CogMethod *) (entryPoint1 - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;
			}

			
			/* It's a linked send. */

if ((!cacheTagMarked)
			 || (markAndTraceOrFreeCogMethodfirstVisit(targetMethod1, (((usqInt)targetMethod1)) > (((usqInt)mcpc))))) {

				/* Either the cacheTag is unmarked (e.g. new class) or the target
				   has been freed (because it is unmarked), so unlink the send. */


				/* Either the cacheTag is unmarked (e.g. new class) or the target
				   has been freed (because it is unmarked), so unlink the send. */

				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
				codeModified = 1;
				markAndTraceLiteral((targetMethod1->selector));
			}

		}
		else {
markAndTraceLiteral(cacheTag1);
			
		}

	}
	return 0;
}


/*	Mark and trace literals.
	Additionally in Newspeak, void push implicits that have unmarked classes. */

static sqInt
markLiteralspcmethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
	// Cogit>>#markLiterals:pc:method:
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt class;
    sqInt classpc;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt mixin;
    sqInt mixinpc;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;

	if (annotation == IsObjectReference) {
literal = literalBeforeFollowingAddress(backEnd, ((sqInt)mcpc));
		markAndTraceLiteral(literal);
	}
	if (annotation == IsSendCall) {
/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */

		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (inlineCacheTagsMayBeObjects())
		 || ((entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC))));
		if (tagCouldBeObj1) {
markAndTraceLiteral(cacheTag1);
		}
		

	}
	return 0;
}

void
markMethodAndReferents(CogBlockMethod *aCogMethod)
{
	// Cogit>>#markMethodAndReferents:
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	assert((((aCogMethod->cmType)) == CMMethod)
	 || (((aCogMethod->cmType)) == CMBlock));
	cogMethod = (((aCogMethod->cmType)) == CMMethod
		? ((CogMethod *) aCogMethod)
		: cmHomeMethod(aCogMethod));
	(cogMethod->cmUsageCount = CMMaxUsageCount);
	/* begin mapFor:performUntil:arg: */
	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
			result = incrementUsageOfTargetIfLinkedSendmcpcignored((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), 0);
			if (result != 0) {
result;
				goto l1;
			}
		}
		else {
mcpc += (mapByte >= DisplacementX2N
				? (mapByte - DisplacementX2N) << AnnotationShift
				: mapByte);
		}
		map -= 1;
	}
	0;
l1:	/* end mapFor:performUntil:arg: */;
}


/*	Mark and trace young literals. */

static sqInt
markYoungObjectspcmethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
	// Cogit>>#markYoungObjects:pc:method:
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt class;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt mixin;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;

	if (annotation == IsObjectReference) {
literal = literalBeforeFollowingAddress(backEnd, ((sqInt)mcpc));
		markAndTraceLiteralIfYoung(literal);
	}
	if (annotation == IsSendCall) {
/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */

		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (inlineCacheTagsMayBeObjects())
		 || ((entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC))));
		if (tagCouldBeObj1) {
markAndTraceLiteralIfYoung(cacheTag1);
		}
		

	}
	return 0;
}


/*	Spill everything on the simulated stack that needs spilling (that below
	receiver and arguments).
	Marshall receiver and arguments to stack and/or registers depending on arg
	count. If the args don't fit in registers push receiver and args (spill
	everything), but still assign
	the receiver to ReceiverResultReg. */

static void
marshallSendArguments(sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#marshallSendArguments:
    sqInt anyRefs;
    CogSimStackEntry * cascade0;
    sqInt numSpilled;

	ssFlushTo((simStackPtr - numArgs) - 1);
	if (numArgs > 1) {

		/* If there are no spills and no references to ReceiverResultReg
		   the fetch of ReceiverResultReg from the stack can be avoided
		   by assigning directly to ReceiverResultReg and pushing it. */


		/* If there are no spills and no references to ReceiverResultReg
		   the fetch of ReceiverResultReg from the stack can be avoided
		   by assigning directly to ReceiverResultReg and pushing it. */

		numSpilled = numberOfSpillsInTopNItems(numArgs + 1);
		anyRefs = anyReferencesToRegisterinTopNItems(ReceiverResultReg, numArgs + 1);
		if ((numSpilled > 0)
		 || (anyRefs)) {
ssFlushTo(simStackPtr);
			storeToReg(simStackAt(simStackPtr - numArgs), ReceiverResultReg);
		}
		else {
cascade0 = simStackAt(simStackPtr - numArgs);
			storeToReg(cascade0, ReceiverResultReg);
			(cascade0->type = SSRegister);
			(cascade0->registerr = ReceiverResultReg);
			ssFlushTo(simStackPtr);
		}
	}
	else {

		/* Move the args to the register arguments, being careful to do
		   so last to first so e.g. previous contents don't get overwritten.
		   Also check for any arg registers in use by other args. */

		if (numArgs > 0) {

			/* Move the args to the register arguments, being careful to do
			   so last to first so e.g. previous contents don't get overwritten.
			   Also check for any arg registers in use by other args. */

			ssAllocateRequiredRegupThrough(Arg0Reg, simStackPtr - 1);

		}
		
if (numArgs > 0) {
popToReg(simStackAt((simStackPtr - numArgs) + 1), Arg0Reg);
		}
		popToReg(simStackAt(simStackPtr - numArgs), ReceiverResultReg);
	}
	ssPop(numArgs + 1);
}

usqInt
maxCogMethodAddress(void)
{
	// Cogit>>#maxCogMethodAddress
	return ((usqInt)(limitZony()));
}


/*	If allocCheckFiller is true, words in newSpace from freeStart to
	scavengeThreshold are filled with their address, and after each call of a
	plugin primitive, the VM checks
	that freeStart points to a word containing the value of freeStart. This is
	a simple
	check for primitives overwriting the ends of an object. */

static void
maybeCompileAllocFillerCheck(void)
{
	// SimpleStackBasedCogit>>#maybeCompileAllocFillerCheck
    sqInt address;
    sqInt address1;
    AbstractInstruction *jmpOk;

	if (getCheckAllocFiller()) {
		/* begin MoveAw:R: */
		address = freeStartAddress();
		genoperandoperand(MoveAwR, address, ClassReg);
		/* begin MoveMw:r:R: */
		genoperandoperandoperand(MoveMwrR, 0, ClassReg, TempReg);
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, ClassReg, TempReg);
		/* begin JumpZero: */
		jmpOk = genoperand(JumpZero, ((sqInt)0));
		/* begin MoveCq:R: */
		genoperandoperand(MoveCqR, PrimErrWritePastObject, TempReg);
		/* begin MoveR:Aw: */
		address1 = primFailCodeAddress();
		genoperandoperand(MoveRAw, TempReg, address1);
		jmpTarget(jmpOk, gLabel());
	}
}


/*	Check that the header fields are consistent with the type.
	Answer 0 if it is ok, otherwise answer a code for the error. */

static sqInt
maybeFreeCogMethodDoesntLookKosher(CogMethod *cogMethod)
{
	// Cogit>>#maybeFreeCogMethodDoesntLookKosher:
    sqInt result;

	result = cogMethodDoesntLookKosher(cogMethod);
	return (result == 2
		? 0
		: result);
}

static sqInt
maybeGenerateCheckFeatures(void)
{
	// Cogit>>#maybeGenerateCheckFeatures
    sqInt startAddress;

	
allocateOpcodesbytecodes(numCheckFeaturesOpcodes(backEnd), 0);
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	generateCheckFeatures(backEnd);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceCheckFeaturesFunction", startAddress);
	ceCheckFeaturesFunction = ((unsigned long (*)(void)) startAddress);
}

static sqInt
maybeGenerateICacheFlush(void)
{
	// Cogit>>#maybeGenerateICacheFlush
    static void (*ceFlushICache)(unsigned long from, unsigned long to);
    sqInt startAddress;

	return null;

	allocateOpcodesbytecodes(numICacheFlushOpcodes(backEnd), 0);
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	generateICacheFlush(backEnd);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceFlushICache", startAddress);
	ceFlushICache = ((void (*)(unsigned long,unsigned long)) startAddress);
}


/*	Answer the absolute machine code pc matching the zero-relative
	bytecode pc of a backward branch in cogMethod, given the start
	of the bytecodes for cogMethod's block or method object. */

usqInt
mcPCForBackwardBranchstartBcpcin(sqInt bcpc, sqInt startbcpc, CogBlockMethod *cogMethod)
{
	// Cogit>>#mcPCForBackwardBranch:startBcpc:in:
    sqInt aMethodObj;
    sqInt annotation;
    sqInt bcpc1;
    sqInt bsOffset;
    sqInt byte;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt endbcpc;
    CogMethod *homeMethod;
    sqInt isBackwardBranch;
    sqInt isInBlock;
    sqInt latestContinuation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt methodHeader;
    sqInt methodHeader1;
    sqInt nExts;
    sqInt nextBcpc;
    sqInt result;
    sqInt targetPC;

	/* begin mapFor:bcpc:performUntil:arg: */
	assert(((cogMethod->stackCheckOffset)) > 0);
	if (((cogMethod->cmType)) == CMMethod) {
		isInBlock = 0;
		homeMethod = ((CogMethod *) cogMethod);
		assert(startbcpc == (startPCOfMethodHeader((homeMethod->methodHeader))));
		map = ((((usqInt)homeMethod)) + ((homeMethod->blockSize))) - 1;
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == IsAbsPCReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsObjectReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsRelativeCall)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N))));
		latestContinuation = startbcpc;
		aMethodObj = (homeMethod->methodObject);
		endbcpc = (byteLengthOf(aMethodObj)) - 1;
		/* begin bytecodeSetOffsetForHeader: */
		methodHeader = (homeMethod->methodHeader);
		bsOffset = 0;
	}
	else {
isInBlock = 1;
		homeMethod = cmHomeMethod(cogMethod);
		map = findMapLocationForMcpcinMethod((((usqInt)cogMethod)) + (sizeof(CogBlockMethod)), homeMethod);
		assert(map != 0);
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == HasBytecodePC)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N));
		while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
			map -= 1;
		}

		/* skip fiducial; i.e. the map entry for the pc immediately following the method header. */

map -= 1;
		aMethodObj = (homeMethod->methodObject);
		bcpc1 = startbcpc - (blockCreationBytecodeSizeForHeader((homeMethod->methodHeader)));
		/* begin bytecodeSetOffsetForHeader: */
		methodHeader1 = (homeMethod->methodHeader);
		bsOffset = 0;
		byte = (fetchByteofObject(bcpc1, aMethodObj)) + bsOffset;
		descriptor = generatorAt(byte);
		endbcpc = (bcpc1 + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc1, -1, aMethodObj)
	: 0));
	}
	bcpc1 = startbcpc;
	mcpc = (((usqInt)cogMethod)) + ((cogMethod->stackCheckOffset));

	/* The stack check maps to the start of the first bytecode,
	   the first bytecode being effectively after frame build. */

	nExts = 0;
	result = 0;
	if (result != 0) {
return ((sqInt) result);
	}
	while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
		map -= 1;
	}
	map -= 1;
	while (((mapByte = byteAt(map))) != MapEnd) {

		/* defensive; we exit on bcpc */

if (mapByte >= FirstAnnotation) {

			/* defensive; we exit on bcpc */


			/* defensive; we exit on bcpc */

annotation = ((usqInt) mapByte) >> AnnotationShift;
			mcpc += mapByte & DisplacementMask;
			if ((annotation == IsSendCall)
							 || (annotation == HasBytecodePC)) {
while (1) {
byte = (fetchByteofObject(bcpc1, aMethodObj)) + bsOffset;
					descriptor = generatorAt(byte);
					if (isInBlock) {
if (bcpc1 >= endbcpc) {
return ((sqInt) 0);
						}
					}
					else {
if (((descriptor->isReturn))
						 && (bcpc1 >= latestContinuation)) {
							return ((sqInt) 0);
						}
						if ((isBranch(descriptor))
						 || ((descriptor->isBlockCreation))) {
							/* begin latestContinuationPCFor:at:exts:in: */
							distance = ((descriptor->spanFunction))(descriptor, bcpc1, nExts, aMethodObj);
							targetPC = (bcpc1 + ((descriptor->numBytes))) + (((distance < 0) ? 0 : distance));
							latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
						}
					}
					nextBcpc = (bcpc1 + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc1, nExts, aMethodObj)
	: 0));
					if (((descriptor->isMapped))
					 || (isInBlock
					 && ((descriptor->isMappedInBlock)))) break;
					bcpc1 = nextBcpc;
					nExts = ((descriptor->isExtension)
						? nExts + 1
						: 0);
				}
				isBackwardBranch = (isBranch(descriptor))
				 && (isBackwardBranchatextsin(descriptor, bcpc1, nExts, aMethodObj));
				result = (isBackwardBranch
				 && ((((sqInt)(((void *)bcpc)))) == bcpc1)
					? ((sqInt)(((char *) mcpc)))
					: 0);
				if (result != 0) {
return ((sqInt) result);
				}
				bcpc1 = nextBcpc;
				nExts = ((descriptor->isExtension)
					? nExts + 1
					: 0);
			}
			/* begin maybeRememberPrevMap:absPCMcpc: */
		}
		else {
mcpc += (mapByte >= DisplacementX2N
				? (mapByte - DisplacementX2N) << AnnotationShift
				: mapByte);
		}
		map -= 1;
	}
	return ((sqInt) 0);
}


/*	Discard type information because of a control-flow merge. */

static CogSimStackEntry *
mergeAtfrom(CogSimStackEntry * self_in_mergeAtfrom, sqInt baseOffset, sqInt baseRegister)
{
	// CogSimStackEntry>>#mergeAt:from:
	assert((self_in_mergeAtfrom->spilled));
	if (((self_in_mergeAtfrom->type)) == SSSpill) {
		assert((((self_in_mergeAtfrom->offset)) == baseOffset)
		 && (((self_in_mergeAtfrom->registerr)) == baseRegister));
	}
	else {
(self_in_mergeAtfrom->type) = SSSpill;
		(self_in_mergeAtfrom->offset) = baseOffset;
		(self_in_mergeAtfrom->registerr) = baseRegister;
	}
	return self_in_mergeAtfrom;
}


/*	Merge control flow at a fixup. The fixup holds the simStackPtr at the jump
	to this target.
	See stackToRegisterMapping on the class side for a full description. */

static void
mergeafterContinuation(BytecodeFixup *fixup, sqInt mergeWithContinuation)
{
	// StackToRegisterMappingCogit>>#merge:afterContinuation:
    sqInt i;

	traceMerge(fixup);
	(optStatus.isReceiverResultRegLive = 0);
	if (!mergeWithContinuation) {
assert((((usqInt)((fixup->targetInstruction)))) >= 2);
		simStackPtr = (fixup->simStackPtr);
	}
	if ((((usqInt)((fixup->targetInstruction)))) <= 2) {

		/* This is either a forward or backward branch target.
		   The stack must be flushed. */

		ssFlushTo(simStackPtr);
		if (((fixup->simStackPtr)) <= -2) {

			/* This is the target of a backward branch.  It doesn't have a simStackPtr yet. */

(fixup->simStackPtr = simStackPtr);
		}
		(fixup->targetInstruction = gLabel());
	}
	assert(simStackPtr >= ((fixup->simStackPtr)));
	
simStackPtr = (fixup->simStackPtr);

	/* For now throw away all type information for values on the stack, but sometime consider
	   the more sophisticated merge described in the class side stackToRegisterMapping. */

	simSpillBase = methodOrBlockNumTemps;
	for (i = methodOrBlockNumTemps; i <= simStackPtr; i += 1) {
		mergeAtfrom(simStackAt(i), FoxMFReceiver - (((i - methodOrBlockNumArgs) + 1) * BytesPerOop), FPReg);
	}
}

static sqInt
methodAbortTrampolineFor(sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#methodAbortTrampolineFor:
	return methodAbortTrampolines[((numArgs < (1 + 1)) ? numArgs : (1 + 1))];
}

CogMethod *
methodFor(void *address)
{
	// CogMethodZone>>#methodFor:
    CogMethod *cogMethod;
    CogMethod *nextMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while ((cogMethod < (limitZony()))
	 && ((((usqInt)cogMethod)) <= (((usqInt)address)))) {
		nextMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		if (nextMethod == cogMethod) {
return 0;
		}
		if (((((usqInt)address)) >= (((usqInt)cogMethod)))
		 && ((((usqInt)address)) < (((usqInt)nextMethod)))) {
			return cogMethod;
		}
		cogMethod = nextMethod;
	}
	return 0;
}


/*	For the purposes of become: see if the two methods are similar, i.e. can
	be safely becommed.
	This is pretty strict. All literals and bytecodes must be identical. Only
	trailer bytes and header
	flags can differ. */

static sqInt
methodhasSameCodeAscheckPenultimate(sqInt methodA, sqInt methodB, sqInt comparePenultimateLiteral)
{
	// Cogit>>#method:hasSameCodeAs:checkPenultimate:
    sqInt bi;
    sqInt endPCA;
    sqInt headerA;
    sqInt headerB;
    sqInt li;
    sqInt numLitsA;

	headerA = headerOf(methodA);
	headerB = headerOf(methodB);
	numLitsA = literalCountOfHeader(headerA);
	endPCA = endPCOf(methodA);
	if (((argumentCountOfMethodHeader(headerA)) != (argumentCountOfMethodHeader(headerB)))
	 || (((temporaryCountOfMethodHeader(headerA)) != (temporaryCountOfMethodHeader(headerB)))
	 || (((primitiveIndexOfMethodheader(methodA, headerA)) != (primitiveIndexOfMethodheader(methodB, headerB)))
	 || ((numLitsA != (literalCountOfHeader(headerB)))
	 || (endPCA > (byteLengthOf(methodB))))))) {
		return 0;
	}
	for (li = 1; li < numLitsA; li += 1) {
if ((fetchPointerofObject(li, methodA)) != (fetchPointerofObject(li, methodB))) {
			if ((li < (numLitsA - 1))
			 || (comparePenultimateLiteral)) {
return 0;
			}
		}
	}
	for (bi = (startPCOfMethod(methodA)); bi <= endPCA; bi += 1) {
		if ((fetchByteofObject(bi, methodA)) != (fetchByteofObject(bi, methodB))) {
			return 0;
		}
	}
	return 1;
}

sqInt
minCogMethodAddress(void)
{
	// Cogit>>#minCogMethodAddress
	return methodZoneBase;
}

sqInt
mnuOffset(void)
{
	// Cogit>>#mnuOffset
	return missOffset;
}

static sqInt
modRMRO(AbstractInstruction * self_in_modRMRO, sqInt mod, sqInt regMode, sqInt regOpcode)
{
	// CogIA32Compiler>>#mod:RM:RO:
	return ((mod << 6) + (regOpcode << 3)) + regMode;
}

static AbstractInstruction *
gNegateR(sqInt reg)
{
	// Cogit>>#NegateR:
	return genoperand(NegateR, reg);
}

static sqInt
needsFrameIfInBlock(sqInt stackDelta)
{
	// Cogit>>#needsFrameIfInBlock:
	return inBlock;
}

static sqInt
needsFrameIfMod16GENumArgs(sqInt stackDelta)
{
	// StackToRegisterMappingCogit>>#needsFrameIfMod16GENumArgs:
	return (byte0 % 16) >= methodOrBlockNumArgs;
}


/*	As of August 2013, the code generator can't deal with spills in frameless
	methods (the
	issue is to do with the stack offset to get at an argument, which is
	changed when there's a spill).
	In e.g. TextColor>>#dominates: other ^other class == self class the second
	send of class
	needs also rto allocate a register that the first one used, but the first
	one's register can't be
	spilled. So avoid this by only allowing class to be sent if the stack
	contains a single element. */

static sqInt
needsFrameIfStackGreaterThanOne(sqInt stackDelta)
{
	// StackToRegisterMappingCogit>>#needsFrameIfStackGreaterThanOne:
	return stackDelta > 1;
}

static sqInt
needsFrameNever(sqInt stackDelta)
{
	// Cogit>>#needsFrameNever:
	return 0;
}

static sqInt
noAssertMethodClassAssociationOf(sqInt methodPointer)
{
	// Cogit>>#noAssertMethodClassAssociationOf:
	return literalofMethod((literalCountOfHeader(noAssertHeaderOf(methodPointer))) - 1, methodPointer);
}


/*	Check that no metod is maximally marked. A maximal mark is an indication
	the method has been scanned to increase the usage count of its referent
	methods.  */

static sqInt
noCogMethodsMaximallyMarked(void)
{
	// Cogit>>#noCogMethodsMaximallyMarked
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (((cogMethod->cmUsageCount)) == CMMaxUsageCount)) {
			return 0;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return 1;
}

static AbstractInstruction *
nopsFromto(AbstractInstruction * self_in_nopsFromto, sqInt startAddr, sqInt endAddr)
{
	// CogIA32Compiler>>#nopsFrom:to:
    sqInt p;

	for (p = startAddr; p <= endAddr; p += 1) {
byteAtput(p, 144);
	}
	return self_in_nopsFromto;
}


/*	Answerr if all targets in the PIC are in-use methods. */

static sqInt
noTargetsFreeInClosedPIC(CogMethod *cPIC)
{
	// Cogit>>#noTargetsFreeInClosedPIC:
    sqInt entryPoint;
    sqInt i;
    sqInt pc;
    CogMethod *targetMethod;

	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {

		/* Find target from jump.  Ignore jumps to the interpret and MNU calls within this PIC */

entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd, pc);
		if ((entryPoint < (((sqInt)cPIC)))
		 || (entryPoint > ((((sqInt)cPIC)) + ((cPIC->blockSize))))) {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			if (((targetMethod->cmType)) != CMMethod) {
				return 0;
			}
		}
		if (i < ((cPIC->cPICNumCases))) {
			pc += cPICCaseSize;
		}
	}
	return 1;
}

static sqInt
numberOfSpillsInTopNItems(sqInt n)
{
	// StackToRegisterMappingCogit>>#numberOfSpillsInTopNItems:
    sqInt i;

	for (i = simStackPtr; i >= ((simStackPtr - n) + 1); i += -1) {
		if ((((simStackAt(i))->type)) == SSSpill) {
			return n - (simStackPtr - i);
		}
	}
	return 0;
}


/*	Answer the number of opcodes required to compile the CPUID call to extract
	the extended features information.
 */

static sqInt
numCheckFeaturesOpcodes(AbstractInstruction * self_in_numCheckFeaturesOpcodes)
{
	// CogIA32Compiler>>#numCheckFeaturesOpcodes
	return 11;
}


/*	If the processor has the ablity to generate code to flush the icache
	answer the number of opcodes required to compile an accessor for the
	feature. 
 */

static sqInt
numICacheFlushOpcodes(AbstractInstruction * self_in_numICacheFlushOpcodes)
{
	// CogAbstractInstruction>>#numICacheFlushOpcodes
	return 0;
}


/*	push $ebx
	movl #0, %eax
	movl 1, $ebx
	mfence
	lock cmpxchg %eax, &vmOwnerLock; # N.B. 2 instructions
	pop $ebx
	jnz locked
	sfence
	movl 1, $eax
	ret
	locked:								; N.B. Requires an instruction
	movl 0, $eax
	ret */

static sqInt
numLowLevelLockOpcodes(AbstractInstruction * self_in_numLowLevelLockOpcodes)
{
	// CogIA32Compiler>>#numLowLevelLockOpcodes
	return 14;
}

static sqInt
numMethods(void)
{
	// CogMethodZone>>#numMethods
	return methodCount;
}

sqInt
numMethodsOfType(sqInt cogMethodType)
{
	// CogMethodZone>>#numMethodsOfType:
    CogMethod *cogMethod;
    sqInt n;

	n = 0;
	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == cogMethodType) {
			n += 1;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return n;
}


/*	Define how many register arguments a StackToRegisterMappingCogit can
	and should use with the receiver. The value must be 0, 1 or 2. Note that a
	SimpleStackBasedCogit always has 0 register args (although the receiver is
	passed in a register). CogObjectRepresentationForSqueakV3 only implements
	at most 1-arg primitives, because the complexity of the object
	representation makes it difficult to implement at:put:, the most
	performance-critical 2-argument
	primitive.. The method must be inlined in CoInterpreter, and dead code
	eliminated so that the register-popping enilopmarts such as
	enterRegisterArgCogMethod:- at:receiver: do not have to be implemented in
	SimpleStackBasedCogit.  */

sqInt
numRegArgs(void)
{
	// CogObjectRepresentationForSqueakV3>>#numRegArgs
	return 1;
}

static sqInt
numSmallIntegerBits(void)
{
	// CogObjectRepresentationForSqueakV3>>#numSmallIntegerBits
	return 0x1F;
}

static sqInt
occurrencesInYoungReferrers(CogMethod *cogMethod)
{
	// CogMethodZone>>#occurrencesInYoungReferrers:
    sqInt count;
    usqInt pointer;

	assert(youngReferrers <= limitAddress);
	count = 0;
	pointer = youngReferrers;
	while (pointer < limitAddress) {
		if ((((sqInt)cogMethod)) == (longAt(pointer))) {
			count += 1;
		}
		pointer += BytesPerWord;
	}
	return count;
}


/*	Compare two oop values, treating them as object memory locations.
	Use #cCoerce:to: to ensure comparison of unsigned magnitudes. This
	method will be inlined during C translation. */

static sqInt
oopisGreaterThanOrEqualTo(sqInt anOop, sqInt otherOop)
{
	// VMClass>>#oop:isGreaterThanOrEqualTo:
	return (((usqInt) anOop)) >= (((usqInt) otherOop));
}


/*	Compare two oop values, treating them as object memory locations.
	Use #cCoerce:to: to ensure comparison of unsigned magnitudes. This
	method will be inlined during C translation. */

static sqInt
oopisGreaterThan(sqInt anOop, sqInt otherOop)
{
	// VMClass>>#oop:isGreaterThan:
	return (((usqInt) anOop)) > (((usqInt) otherOop));
}


/*	Compare two oop values, treating them as object memory locations.
	Use #cCoerce:to: to ensure comparison of unsigned magnitudes. This
	method will be inlined during C translation. */

static sqInt
oopisLessThan(sqInt anOop, sqInt otherOop)
{
	// VMClass>>#oop:isLessThan:
	return (((usqInt) anOop)) < (((usqInt) otherOop));
}

static CogMethod *
openPICWithSelector(sqInt aSelector)
{
	// CogMethodZone>>#openPICWithSelector:
    CogMethod *openPIC;

	openPIC = openPICList;
	do {
if ((openPIC == null)
		 || (((openPIC->selector)) == aSelector)) {
			return openPIC;
		}
		openPIC = ((CogMethod *) ((openPIC->nextOpenPIC)));
	} while(1);
}


/*	Store the generated machine code, answering the last address */

static sqInt
outputInstructionsAt(sqInt startAddress)
{
	// Cogit>>#outputInstructionsAt:
    sqInt absoluteAddress;
    AbstractInstruction *abstractInstruction;
    sqInt i;
    sqInt j;

	absoluteAddress = startAddress;
	for (i = 0; i < opcodeIndex; i += 1) {
		abstractInstruction = abstractInstructionAt(i);
		assert(((abstractInstruction->address)) == absoluteAddress);
		for (j = 0; j < ((abstractInstruction->machineCodeSize)); j += 1) {
			byteAtput(absoluteAddress, ((abstractInstruction->machineCode))[j]);
			absoluteAddress += 1;
		}
	}
	return absoluteAddress;
}


/*	Output instructions generated for one of the generated run-time routines,
	a trampoline, etc
 */

static sqInt
outputInstructionsForGeneratedRuntimeAt(sqInt startAddress)
{
	// Cogit>>#outputInstructionsForGeneratedRuntimeAt:
    sqInt endAddress;
    sqInt size;

	computeMaximumSizes();
	size = generateInstructionsAt(startAddress);
	endAddress = outputInstructionsAt(startAddress);
	assert((startAddress + size) == endAddress);
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	nopsFromto(backEnd, endAddress, methodZoneBase - 1);
	
return startAddress;
}

static AbstractInstruction *
gPushCw(sqInt wordConstant)
{
	// Cogit>>#PushCw:
	return genoperand(PushCw, wordConstant);
}

static AbstractInstruction *
padIfPossibleWithNopsFromto(AbstractInstruction * self_in_padIfPossibleWithNopsFromto, sqInt startAddr, sqInt endAddr)
{
	// CogIA32Compiler>>#padIfPossibleWithNopsFrom:to:
	nopsFromto(self_in_padIfPossibleWithNopsFromto, startAddr, endAddr);
	return self_in_padIfPossibleWithNopsFromto;
}


/*	Code entry closed PIC full or miss to an instance of a young class or to a
	young target method.
	Attempt to patch the send site to an open PIC. Answer if the attempt
	succeeded; in fact it will
	only return if the attempt failed.
	The stack looks like:
	receiver
	args
	sp=>	sender return address */

sqInt
patchToOpenPICFornumArgsreceiver(sqInt selector, sqInt numArgs, sqInt receiver)
{
	// Cogit>>#patchToOpenPICFor:numArgs:receiver:
    sqInt extent;
    CogMethod *oPIC;
    sqInt outerReturn;


	/* See if an Open PIC is already available. */

outerReturn = stackTop();
	oPIC = openPICWithSelector(selector);
	if (oPIC == null) {

		/* otherwise attempt to create an Open PIC. */


		/* otherwise attempt to create an Open PIC. */

oPIC = cogOpenPICSelectornumArgs(selector, numArgs);
		if ((((((sqInt)oPIC)) >= MaxNegativeErrorCode) && ((((sqInt)oPIC)) <= -1))) {

			/* For some reason the PIC couldn't be generated, most likely a lack of code memory. */

if ((((sqInt)oPIC)) == InsufficientCodeSpace) {

				/* For some reason the PIC couldn't be generated, most likely a lack of code memory. */

callForCogCompiledCodeCompaction();
			}
			return 0;
		}
	}
	extent = rewriteInlineCacheAttagtarget(backEnd, outerReturn, selector, (((sqInt)oPIC)) + cmEntryOffset);
	flushICacheFromto(processor, (outerReturn - 1) - extent, outerReturn - 1);
	flushICacheFromto(processor, ((sqInt)oPIC), (((sqInt)oPIC)) + openPICSize);
	executeCogMethodfromLinkedSendWithReceiver(oPIC, receiver);
	return 1;
}

sqInt
pcisWithinMethod(char *address, CogMethod *cogMethod)
{
	// Cogit>>#pc:isWithinMethod:
	return (((((sqInt)address)) >= ((((sqInt)cogMethod)) + (sizeof(CogMethod)))) && ((((sqInt)address)) <= ((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
}

static sqInt
picAbortTrampolineFor(sqInt numArgs)
{
	// StackToRegisterMappingCogit>>#picAbortTrampolineFor:
	return picAbortTrampolines[((numArgs < (1 + 1)) ? numArgs : (1 + 1))];
}


/*	Some metods have been freed. Compute how much each survivor needs to
	move during the ensuing compaction and record it in the objectHeader
	field.  */

static void
planCompaction(void)
{
	// CogMethodZone>>#planCompaction
    CogMethod *cogMethod;
    sqInt delta;

	delta = 0;
	cogMethod = ((CogMethod *) baseAddress);
	while ((((usqInt)cogMethod)) < mzFreeStart) {
		if (((cogMethod->cmType)) == CMFree) {
			delta -= (cogMethod->blockSize);
		}
		else {
assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			(cogMethod->objectHeader = delta);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

static CogSimStackEntry *
popToReg(CogSimStackEntry * self_in_popToReg, sqInt reg)
{
	// CogSimStackEntry>>#popToReg:
    sqInt baseReg;
    AbstractInstruction *inst;
    sqInt offset;
    sqInt quickConstant;
    sqInt reg1;

	if ((self_in_popToReg->spilled)) {
		/* begin PopR: */
		inst = genoperand(PopR, reg);
	}
	else {

		switch ((self_in_popToReg->type)) {
		case SSBaseOffset:
			/* begin MoveMw:r:R: */
			offset = (self_in_popToReg->offset);
			baseReg = (self_in_popToReg->registerr);
			inst = genoperandoperandoperand(MoveMwrR, offset, baseReg, reg);
			break;
		case SSConstant:
			inst = (shouldAnnotateObjectReference((self_in_popToReg->constant))
				? annotateobjRef(gMoveCwR((self_in_popToReg->constant), reg), (self_in_popToReg->constant))
				: (/* begin MoveCq:R: */
					(quickConstant = (self_in_popToReg->constant)),
					genoperandoperand(MoveCqR, quickConstant, reg)));
			break;
		case SSRegister:
			inst = (reg != ((self_in_popToReg->registerr))
				? (/* begin MoveR:R: */
					(reg1 = (self_in_popToReg->registerr)),
					genoperandoperand(MoveRR, reg1, reg))
				: (/* begin Label */
					genoperandoperand(Label, (labelCounter += 1), bytecodePC)));
			break;
		default:
			error("Case not found and no otherwise clause");
		}
	}
	if ((self_in_popToReg->annotateUse)) {
		/* begin annotateBytecode: */
		annotatewith(inst, HasBytecodePC);
		(self_in_popToReg->annotateUse) = 0;
	}
	return self_in_popToReg;
}

static sqInt
prevInstIsPCAnnotated(void)
{
	// StackToRegisterMappingCogit>>#prevInstIsPCAnnotated
    InstructionAnnotation *annotation;
    sqInt prevIndex;
    AbstractInstruction *prevInst;

	if (!(annotationIndex > 0)) {
		return 0;
	}
	annotation = (&(annotations[annotationIndex - 1]));
	if (!(isPCMappedAnnotationalternateInstructionSet((annotation->annotation), bytecodeSetOffset > 0))) {
		return 0;
	}
	prevIndex = opcodeIndex - 1;
	while (1) {
if (prevIndex <= 0) {
return 0;
		}
		prevInst = abstractInstructionAt(prevIndex);
		if (((annotation->instruction)) == prevInst) {
			return 1;
		}
		if (!(((prevInst->opcode)) == Label)) break;
		prevIndex -= 1;
	}
	return 0;
}


/*	If there is a generator for the current primitive then answer it;
	otherwise answer nil. */

static PrimitiveDescriptor *
primitiveGeneratorOrNil(void)
{
	// Cogit>>#primitiveGeneratorOrNil
    PrimitiveDescriptor *primitiveDescriptor;

	if (isQuickPrimitiveIndex(primitiveIndex)) {

		/* an unused one */

primitiveDescriptor = (&(primitiveGeneratorTable[0]));
		(primitiveDescriptor->primitiveGenerator = quickPrimitiveGeneratorFor(primitiveIndex));
		return primitiveDescriptor;
	}
	if (((primitiveIndex >= 1) && (primitiveIndex <= MaxCompiledPrimitiveIndex))) {
		return (&(primitiveGeneratorTable[primitiveIndex]));
	}
	return null;
}

void
printCogMethodFor(void *address)
{
	// Cogit>>#printCogMethodFor:
    CogMethod *cogMethod;

	cogMethod = methodFor(address);
	if (cogMethod == 0) {
print("not a method");
		cr();
	}
	else {
printCogMethod(cogMethod);
	}
}

void
printCogMethods(void)
{
	// CogMethodZone>>#printCogMethods
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		printCogMethod(cogMethod);
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

void
printCogMethodsOfType(sqInt cmType)
{
	// CogMethodZone>>#printCogMethodsOfType:
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == cmType) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

void
printCogMethodsWithMethod(sqInt methodOop)
{
	// CogMethodZone>>#printCogMethodsWithMethod:
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (((cogMethod->methodObject)) == methodOop)) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

void
printCogMethodsWithPrimitive(sqInt primIdx)
{
	// CogMethodZone>>#printCogMethodsWithPrimitive:
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (primIdx == (primitiveIndexOfMethodheader((cogMethod->methodObject), (cogMethod->methodHeader))))) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

void
printCogMethodsWithSelector(sqInt selectorOop)
{
	// CogMethodZone>>#printCogMethodsWithSelector:
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (((cogMethod->selector)) == selectorOop)) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

void
printCogYoungReferrers(void)
{
	// CogMethodZone>>#printCogYoungReferrers
    CogMethod *cogMethod;
    sqInt pointer;

	pointer = youngReferrers;
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (!((cogMethod->cmRefersToYoung))) {
			print("* ");
		}
		printCogMethod(cogMethod);
		pointer += BytesPerWord;
	}
}

void
printOpenPICList(void)
{
	// CogMethodZone>>#printOpenPICList
    CogMethod *openPIC;

	openPIC = openPICList;
	while (!(openPIC == null)) {
		printCogMethod(openPIC);
		openPIC = ((CogMethod *) ((openPIC->nextOpenPIC)));
	}
}

void
printTrampolineTable(void)
{
	// Cogit>>#printTrampolineTable
    sqInt i;

	for (i = 0; i < trampolineTableIndex; i += 2) {
		printHex(((sqInt)(trampolineAddresses[i + 1])));
		print(": ");
		print(((char *) (trampolineAddresses[i])));
		cr();
	}
}

static sqInt
processorHasDivQuoRem(sqInt ignoredPrimIndex)
{
	// Cogit>>#processorHasDivQuoRem:
	return canDivQuoRem(backEnd);
}

static sqInt
processorHasDoublePrecisionFloatingPointSupport(sqInt ignoredPrimIndex)
{
	// Cogit>>#processorHasDoublePrecisionFloatingPointSupport:
	return hasDoublePrecisionFloatingPointSupport(backEnd);
}

static sqInt
processorHasMultiply(sqInt ignoredPrimIndex)
{
	// Cogit>>#processorHasMultiply:
	return canMulRR(backEnd);
}

static sqInt
pruneYoungReferrers(void)
{
	// CogMethodZone>>#pruneYoungReferrers
    usqInt dest;
    usqInt next;
    usqInt source;

	assert(youngReferrers <= limitAddress);
	if (youngReferrers == limitAddress) {
		return null;
	}
	dest = limitAddress;
	while (1) {
next = dest - BytesPerWord;
		if (!((next >= youngReferrers)
		 && (((((CogMethod *) (longAt(next))))->cmRefersToYoung)))) break;
		dest = next;
	}
	assert(dest >= youngReferrers);
	source = dest - BytesPerWord;
	while (source >= youngReferrers) {
		if (((((CogMethod *) (longAt(source))))->cmRefersToYoung)) {
			assert(source < (dest - BytesPerWord));
			longAtput((dest -= BytesPerWord), longAt(source));
		}
		source -= BytesPerWord;
	}
	youngReferrers = dest;
	assert(kosherYoungReferrers());
}

void
recordCallOffsetInof(CogMethod *cogMethod, void *callLabelArg)
{
	// SimpleStackBasedCogit>>#recordCallOffsetIn:of:
    AbstractInstruction *callLabel;
    sqInt offset;
    sqInt *offsetTable;


	/* this function is exported but AbstractInstruction isn't; hence pun through void * */

callLabel = callLabelArg;
	offsetTable = (isCallPreceedingReturnPC(backEnd, ((usqInt)((callLabel->address))))
		? externalPrimCallOffsets
		: externalPrimJumpOffsets);
	offset = ((callLabel->address)) - (((sqInt)cogMethod));
	if ((offsetTable[(cogMethod->cmNumArgs)]) == null) {
		offsetTable[(cogMethod->cmNumArgs)] = offset;
	}
	else {
assert((offsetTable[(cogMethod->cmNumArgs)]) == offset);
	}
}

static void
recordGeneratedRunTimeaddress(char *aString, sqInt address)
{
	// Cogit>>#recordGeneratedRunTime:address:
	trampolineAddresses[trampolineTableIndex] = aString;
	trampolineAddresses[trampolineTableIndex + 1] = (((char *) address));
	trampolineTableIndex += 2;
}


/*	This one for C support code. */

sqInt
recordPrimTraceFunc(void)
{
	// Cogit>>#recordPrimTraceFunc
	return recordPrimTrace();
}

static void
recordRunTimeObjectReferences(void)
{
	// Cogit>>#recordRunTimeObjectReferences
    InstructionAnnotation *annotation;
    sqInt i;

	for (i = 0; i < annotationIndex; i += 1) {
		annotation = (&(annotations[i]));
		if (((annotation->annotation)) == IsObjectReference) {
			assert(runtimeObjectRefIndex < NumObjRefsInRuntime);
			assert(!hasYoungReferent);
			if (hasYoungReferent) {
				error("attempt to generate run-time routine containing young object reference.  Cannot initialize Cogit run-time.");
			}
			objectReferencesInRuntime[runtimeObjectRefIndex] = (((sqInt)(((((annotation->instruction))->address)) + ((((annotation->instruction))->machineCodeSize)))));
			runtimeObjectRefIndex += 1;
		}
	}
	annotationIndex = 0;
}


/*	Answer a bit mask for the receiver's register, if any. */

static sqInt
registerMask(CogSimStackEntry * self_in_registerMask)
{
	// CogSimStackEntry>>#registerMask
	return ((((self_in_registerMask->type)) == SSBaseOffset)
	 || (((self_in_registerMask->type)) == SSRegister)
		? registerMaskFor((self_in_registerMask->registerr))
		: 0);
}


/*	Answer a bit mask identifying the symbolic register.
	Registers are negative numbers. */

static sqInt
registerMaskFor(sqInt reg)
{
	// Cogit>>#registerMaskFor:
	return 1 << (1 - reg);
}


/*	Answer a bit mask identifying the symbolic registers.
	Registers are negative numbers. */

static sqInt
registerMaskForand(sqInt reg1, sqInt reg2)
{
	// Cogit>>#registerMaskFor:and:
	return (1 << (1 - reg1)) | (1 << (1 - reg2));
}


/*	Answer a bit mask identifying the symbolic registers.
	Registers are negative numbers. */

static sqInt
registerMaskForandand(sqInt reg1, sqInt reg2, sqInt reg3)
{
	// Cogit>>#registerMaskFor:and:and:
	return ((1 << (1 - reg1)) | (1 << (1 - reg2))) | (1 << (1 - reg3));
}

static sqInt
registerOrNil(CogSimStackEntry * self_in_registerOrNil)
{
	// CogSimStackEntry>>#registerOrNil
	return (((self_in_registerOrNil->type)) == SSRegister
		? (self_in_registerOrNil->registerr)
		: 0);
}


/*	When a block must be recompiled due to overestimating the
	numInitialNils fixups must be restored, which means rescannning
	since backward branches need their targets initialized. */

static void
reinitializeFixupsFromthrough(sqInt start, sqInt end)
{
	// StackToRegisterMappingCogit>>#reinitializeFixupsFrom:through:
    BytecodeFixup * cascade0;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt nExts;
    sqInt pc;
    sqInt targetPC;

	pc = start;
	nExts = 0;
	while (pc <= end) {
cascade0 = fixupAt(pc - initialPC);
		(cascade0->targetInstruction = 0);
		(cascade0->simStackPtr = null);
		byte0 = (fetchByteofObject(pc, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		if ((isBranch(descriptor))
		 && (isBackwardBranchatextsin(descriptor, pc, nExts, methodObj))) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			initializeFixupAt(targetPC - initialPC);
		}
		if ((descriptor->isBlockCreation)) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			pc = (pc + ((descriptor->numBytes))) + distance;
		}
		else {
pc += (descriptor->numBytes);
		}
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
	}
}

static sqInt
relocateAndPruneYoungReferrers(void)
{
	// CogMethodZone>>#relocateAndPruneYoungReferrers
    CogMethod *cogMethod;
    usqInt dest;
    usqInt next;
    usqInt source;

	assert(youngReferrers <= limitAddress);
	if (youngReferrers == limitAddress) {
		return null;
	}
	dest = limitAddress;
	while (1) {
next = dest - BytesPerWord;
		if (!((next >= youngReferrers)
		 && (((((cogMethod = ((CogMethod *) (longAt(next))))->cmType)) != CMFree)
		 && ((cogMethod->cmRefersToYoung))))) break;
		if (((cogMethod->objectHeader)) != 0) {
			longAtput(next, (((sqInt)cogMethod)) + ((cogMethod->objectHeader)));
		}
		dest = next;
	}
	assert(dest >= youngReferrers);
	source = dest - BytesPerWord;
	while (source >= youngReferrers) {
		cogMethod = ((CogMethod *) (longAt(source)));
		if ((((cogMethod->cmType)) != CMFree)
		 && ((cogMethod->cmRefersToYoung))) {
			assert(source < (dest - BytesPerWord));
			if (((cogMethod->objectHeader)) != 0) {
				cogMethod = ((CogMethod *) ((((sqInt)cogMethod)) + (((sqInt)((cogMethod->objectHeader))))));
			}
			longAtput((dest -= BytesPerWord), ((sqInt)cogMethod));
		}
		source -= BytesPerWord;
	}
	youngReferrers = dest;
}

static AbstractInstruction *
relocateCallBeforeReturnPCby(AbstractInstruction * self_in_relocateCallBeforeReturnPCby, sqInt retpc, sqInt delta)
{
	// CogIA32Compiler>>#relocateCallBeforeReturnPC:by:
    sqInt distance;

	if (delta != 0) {
distance = ((((byteAt(retpc - 1)) << 24) + ((byteAt(retpc - 2)) << 16)) + ((byteAt(retpc - 3)) << 8)) + (byteAt(retpc - 4));
		distance += delta;
		byteAtput(retpc - 1, (((usqInt) distance) >> 24) & 0xFF);
		byteAtput(retpc - 2, (((usqInt) distance) >> 16) & 0xFF);
		byteAtput(retpc - 3, (((usqInt) distance) >> 8) & 0xFF);
		byteAtput(retpc - 4, distance & 0xFF);
	}
	return self_in_relocateCallBeforeReturnPCby;
}

static void
relocateCallsAndSelfReferencesInMethod(CogMethod *cogMethod)
{
	// Cogit>>#relocateCallsAndSelfReferencesInMethod:
    sqInt delta;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	delta = (cogMethod->objectHeader);
	assert((((cogMethod->cmType)) == CMMethod)
	 || (((cogMethod->cmType)) == CMOpenPIC));
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)cogMethod)) + missOffset)) == ((((cogMethod->cmType)) == CMMethod
	? methodAbortTrampolineFor((cogMethod->cmNumArgs))
	: picAbortTrampolineFor((cogMethod->cmNumArgs)))));
	relocateCallBeforeReturnPCby(backEnd, (((sqInt)cogMethod)) + missOffset, -delta);
	/* begin mapFor:performUntil:arg: */
	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
			result = relocateIfCallOrMethodReferencemcpcdelta((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), delta);
			if (result != 0) {
result;
				goto l1;
			}
		}
		else {
mcpc += (mapByte >= DisplacementX2N
				? (mapByte - DisplacementX2N) << AnnotationShift
				: mapByte);
		}
		map -= 1;
	}
	0;
l1:	/* end mapFor:performUntil:arg: */;
}

static void
relocateCallsInClosedPIC(CogMethod *cPIC)
{
	// Cogit>>#relocateCallsInClosedPIC:
    sqInt delta;
    sqInt entryPoint;
    sqInt i;
    sqInt pc;
    CogMethod *targetMethod;

	delta = (cPIC->objectHeader);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)cPIC)) + missOffset)) == (picAbortTrampolineFor((cPIC->cmNumArgs))));
	relocateCallBeforeReturnPCby(backEnd, (((sqInt)cPIC)) + missOffset, -delta);
	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {

		/* Find target from jump.  Ignore jumps to the interpret and MNU calls within this PIC */

entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd, pc);
		if ((entryPoint < (((sqInt)cPIC)))
		 || (entryPoint > ((((sqInt)cPIC)) + ((cPIC->blockSize))))) {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			assert(((targetMethod->cmType)) == CMMethod);
			relocateJumpBeforeFollowingAddressby(backEnd, pc, -(delta - ((targetMethod->objectHeader))));
		}
		pc += cPICCaseSize;
	}
	assert(((cPIC->cPICNumCases)) > 0);

	/* Finally relocate the load of the PIC and the jump to the overflow routine ceCPICMiss:receiver: */

pc -= cPICCaseSize;
	relocateMethodReferenceBeforeAddressby(backEnd, pc + (loadLiteralByteSize(backEnd)), delta);
	relocateJumpBeforeFollowingAddressby(backEnd, pc + cPICEndSize, -delta);
}

static sqInt
relocateIfCallOrMethodReferencemcpcdelta(sqInt annotation, char *mcpc, sqInt delta)
{
	// Cogit>>#relocateIfCallOrMethodReference:mcpc:delta:
    sqInt entryPoint;
    sqInt off;
    sqInt offset;
    sqInt *sendTable;
    sqInt table;
    CogMethod *targetMethod;
    sqInt unlinkedRoutine;

	if (annotation == IsSendCall) {
entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint <= methodZoneBase) {

			/* send is not linked; just relocate */

relocateCallBeforeReturnPCby(backEnd, ((sqInt)mcpc), -delta);
			return 0;
		}
		/* begin offsetAndSendTableFor:annotation:into: */
		if ((entryPoint & entryPointMask) == checkedEntryAlignment) {
			offset = cmEntryOffset;
			sendTable = sendTrampolines;

		}
		else {
			offset = cmNoCheckEntryOffset;
			sendTable = superSendTrampolines;

		}

		targetMethod = ((CogMethod *) (entryPoint - offset));
		if (((targetMethod->cmType)) == CMMethod) {

			/* send target not freed; just relocate. */

relocateCallBeforeReturnPCby(backEnd, ((sqInt)mcpc), -(delta - ((targetMethod->objectHeader))));
			return 0;
		}
		unlinkedRoutine = sendTable[((((targetMethod->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod->cmNumArgs)) : (NumSendTrampolines - 1))];
		unlinkedRoutine -= delta;
		rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod->selector), unlinkedRoutine);
		return 0;
	}
	if (annotation == IsRelativeCall) {
relocateCallBeforeReturnPCby(backEnd, ((sqInt)mcpc), -delta);
		return 0;
	}
	if (annotation == IsAbsPCReference) {
relocateMethodReferenceBeforeAddressby(backEnd, ((sqInt)mcpc), delta);
	}
	return 0;
}

static AbstractInstruction *
relocateJumpBeforeFollowingAddressby(AbstractInstruction * self_in_relocateJumpBeforeFollowingAddressby, sqInt pc, sqInt delta)
{
	// CogIA32Compiler>>#relocateJumpBeforeFollowingAddress:by:
	relocateCallBeforeReturnPCby(self_in_relocateJumpBeforeFollowingAddressby, pc, delta);
	return self_in_relocateJumpBeforeFollowingAddressby;
}

static AbstractInstruction *
relocateMethodReferenceBeforeAddressby(AbstractInstruction * self_in_relocateMethodReferenceBeforeAddressby, sqInt pc, sqInt delta)
{
	// CogIA32Compiler>>#relocateMethodReferenceBeforeAddress:by:
	relocateCallBeforeReturnPCby(self_in_relocateMethodReferenceBeforeAddressby, pc, delta);
	return self_in_relocateMethodReferenceBeforeAddressby;
}


/*	All surviving methods have had the amount they are going to relocate by
	stored in their objectHeader fields. Relocate all relative calls so that
	after the compaction of both the method containing each call and the call
	target the calls invoke the same target. */

static sqInt
relocateMethodsPreCompaction(void)
{
	// Cogit>>#relocateMethodsPreCompaction
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			if (((cogMethod->cmType)) == CMClosedPIC) {
				relocateCallsInClosedPIC(cogMethod);
			}
			else {
relocateCallsAndSelfReferencesInMethod(cogMethod);
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	relocateAndPruneYoungReferrers();
	return 1;
}

static sqInt
remapIfObjectRefpchasYoung(sqInt annotation, char *mcpc, sqInt hasYoungPtr)
{
	// Cogit>>#remapIfObjectRef:pc:hasYoung:
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt ignored;
    sqInt literal;
    sqInt mappedCacheTag;
    sqInt mappedLiteral;
    sqInt mappedOop;
    sqInt oop;
    sqInt pc;
    sqInt *sendTable;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;
    CogMethod *targetMethod;
    CogMethod *targetMethod1;

	if (annotation == IsObjectReference) {
literal = literalBeforeFollowingAddress(backEnd, ((sqInt)mcpc));
		if (couldBeObject(literal)) {
			mappedLiteral = remapObject(literal);
			if (literal != mappedLiteral) {
storeLiteralbeforeFollowingAddress(backEnd, mappedLiteral, ((sqInt)mcpc));
				codeModified = 1;
			}
			if ((hasYoungPtr != 0)
			 && (isYoung(mappedLiteral))) {
				(((sqInt *) hasYoungPtr))[0] = 1;
			}
		}
	}
	if (annotation == IsSendCall) {
/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */

		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (inlineCacheTagsMayBeObjects())
		 || ((entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC))));
		if (tagCouldBeObj1
		 && (couldBeObject(cacheTag1))) {
			mappedCacheTag = remapObject(cacheTag1);
			if (cacheTag1 != mappedCacheTag) {
rewriteInlineCacheTagat(backEnd, mappedCacheTag, ((sqInt)mcpc));
				codeModified = 1;
			}
			if ((hasYoungPtr != 0)
			 && (isYoung(mappedCacheTag))) {
				(((sqInt *) hasYoungPtr))[0] = 1;
			}
		}
		if (0) {
pc = (((sqInt)mcpc)) + (jumpShortByteSize(backEnd));
			if (((oop = unalignedLongAt(backEnd, pc))) != 0) {
				mappedOop = remapOop(oop);
				if (mappedOop != oop) {
unalignedLongAtput(backEnd, pc, mappedOop);
				}
				if ((hasYoungPtr != 0)
				 && (isYoung(mappedOop))) {
					(((sqInt *) hasYoungPtr))[0] = 1;
				}
				pc = ((((sqInt)mcpc)) + (jumpShortByteSize(backEnd))) + BytesPerOop;
				if (((oop = unalignedLongAt(backEnd, pc))) != 0) {
					mappedOop = remapOop(oop);
					if (mappedOop != oop) {
unalignedLongAtput(backEnd, pc, mappedOop);
					}
					if ((hasYoungPtr != 0)
					 && (isYoung(mappedOop))) {
						(((sqInt *) hasYoungPtr))[0] = 1;
					}
				}
			}
		}
		else {
if (hasYoungPtr != 0) {

				/* Since the unlinking routines may rewrite the cacheTag to the send's selector, and
				   since they don't have the cogMethod to hand and can't add it to youngReferrers,
				   the method must remain in youngReferrers if the targetMethod's selector is young. */
				/* It's a linked send. */

if (entryPoint1 > methodZoneBase) {

					/* Since the unlinking routines may rewrite the cacheTag to the send's selector, and
					   since they don't have the cogMethod to hand and can't add it to youngReferrers,
					   the method must remain in youngReferrers if the targetMethod's selector is young. */
					/* It's a linked send. */

/* begin targetMethodAndSendTableFor:into: */
					if ((entryPoint1 & entryPointMask) == checkedEntryAlignment) {
						targetMethod1 = ((CogMethod *) (entryPoint1 - cmEntryOffset));
						sendTable = sendTrampolines;
					}
					else {
						targetMethod1 = ((CogMethod *) (entryPoint1 - cmNoCheckEntryOffset));
						sendTable = superSendTrampolines;
					}

					
					/* Since the unlinking routines may rewrite the cacheTag to the send's selector, and
					   since they don't have the cogMethod to hand and can't add it to youngReferrers,
					   the method must remain in youngReferrers if the targetMethod's selector is young. */
					/* It's a linked send. */

if (isYoung((targetMethod1->selector))) {

						/* Since the unlinking routines may rewrite the cacheTag to the send's selector, and
						   since they don't have the cogMethod to hand and can't add it to youngReferrers,
						   the method must remain in youngReferrers if the targetMethod's selector is young. */
						/* It's a linked send. */

(((sqInt *) hasYoungPtr))[0] = 1;
					}

				}
			}
		}

	}
	return 0;
}

static sqInt
remapObject(sqInt oop)
{
	// CogObjectRepresentationForSqueakV3>>#remapObject:
	return remap(oop);
}

static sqInt
remapOop(sqInt oop)
{
	// CogObjectRepresentationForSqueakV3>>#remapOop:
	return ((oop & 1)
		? oop
		: remap(oop));
}

static sqInt
removeFromOpenPICList(CogMethod *anOpenPIC)
{
	// CogMethodZone>>#removeFromOpenPICList:
    CogMethod *prevPIC;

	assert(((anOpenPIC->cmType)) == CMOpenPIC);
	if (anOpenPIC == openPICList) {

		/* N.B. Use self rather than coInterpreter to avoid attempting to cast nil.
		   Conversion to CogMethod done in the nextOpenPIC accessor. */


		/* N.B. Use self rather than coInterpreter to avoid attempting to cast nil.
		   Conversion to CogMethod done in the nextOpenPIC accessor. */

		openPICList = ((CogMethod *) ((anOpenPIC->nextOpenPIC)));
		return null;
	}
	prevPIC = openPICList;
	do {
assert((prevPIC != null)
		 && (((prevPIC->cmType)) == CMOpenPIC));
		if (((prevPIC->nextOpenPIC)) == (((sqInt)anOpenPIC))) {
			(prevPIC->nextOpenPIC = (anOpenPIC->nextOpenPIC));
			return null;
		}
		prevPIC = ((CogMethod *) ((prevPIC->nextOpenPIC)));
	} while(1);
}

static AbstractInstruction *
resolveJumpTarget(AbstractInstruction * self_in_resolveJumpTarget)
{
	// CogAbstractInstruction>>#resolveJumpTarget
    BytecodeFixup *fixup;

	assert(isJump(self_in_resolveJumpTarget));
	fixup = ((BytecodeFixup *) (((self_in_resolveJumpTarget->operands))[0]));
	null;
	if (isAFixup(self_in_resolveJumpTarget, fixup)) {
		assert(addressIsInInstructions((fixup->targetInstruction)));
		jmpTarget(self_in_resolveJumpTarget, (fixup->targetInstruction));
	}
	return self_in_resolveJumpTarget;
}


/*	We must ensure the ReceiverResultReg is live across the store check so
	that we can store into receiver inst vars in a frameless method since self
	exists only in ReceiverResultReg in a frameless method. So if
	ReceiverResultReg is
	caller-saved we use the fact that ceStoreCheck: answers its argument to
	reload ReceiverResultReg cheaply. Otherwise we don't care about the result
	and use the cResultRegister, effectively a no-op (see
	compileTrampoline...)  */

static sqInt
returnRegForStoreCheck(void)
{
	// StackToRegisterMappingCogit>>#returnRegForStoreCheck
	return ((registerMaskFor(ReceiverResultReg)) & callerSavedRegMask
		? ReceiverResultReg
		: cResultRegister(backEnd));
}


/*	Rewrite a call instruction to call a different target. This variant is
	used to link PICs
	in ceSendMiss et al, and to rewrite cached primitive calls. Answer the
	extent of
	the code change which is used to compute the range of the icache to flush. */
/*	self cCode: ''
	inSmalltalk: [cogit disassembleFrom: callSiteReturnAddress - 10 to:
	callSiteReturnAddress - 1]. */

static sqInt
rewriteCallAttarget(AbstractInstruction * self_in_rewriteCallAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress)
{
	// CogIA32Compiler>>#rewriteCallAt:target:
    usqInt callDistance;

	if (!(callTargetAddress >= (minCallAddress()))) {
		error("linking callsite to invalid address");
	}

	callDistance = ((usqInt) (callTargetAddress - callSiteReturnAddress));
	byteAtput(callSiteReturnAddress - 1, (((usqInt) callDistance) >> 24) & 0xFF);
	byteAtput(callSiteReturnAddress - 2, (((usqInt) callDistance) >> 16) & 0xFF);
	byteAtput(callSiteReturnAddress - 3, (((usqInt) callDistance) >> 8) & 0xFF);
	byteAtput(callSiteReturnAddress - 4, callDistance & 0xFF);
	assert((((usqInt) (callTargetFromReturnAddress(self_in_rewriteCallAttarget, callSiteReturnAddress)))) == callTargetAddress);
	return 5;
}


/*	Rewrite an inline cache to call a different target for a new tag. This
	variant is used
	to link unlinked sends in ceSend:to:numArgs: et al. Answer the extent of
	the code
	change which is used to compute the range of the icache to flush. */
/*	self cCode: ''
	inSmalltalk: [cogit disassembleFrom: callSiteReturnAddress - 10 to:
	callSiteReturnAddress - 1]. */

static sqInt
rewriteInlineCacheAttagtarget(AbstractInstruction * self_in_rewriteInlineCacheAttagtarget, usqInt callSiteReturnAddress, sqInt cacheTag, usqInt callTargetAddress)
{
	// CogIA32Compiler>>#rewriteInlineCacheAt:tag:target:
    usqInt callDistance;

	if (!(callTargetAddress >= (minCallAddress()))) {
		error("linking callsite to invalid address");
	}

	callDistance = ((usqInt) (callTargetAddress - callSiteReturnAddress));
	byteAtput(callSiteReturnAddress - 1, (((usqInt) callDistance) >> 24) & 0xFF);
	byteAtput(callSiteReturnAddress - 2, (((usqInt) callDistance) >> 16) & 0xFF);
	byteAtput(callSiteReturnAddress - 3, (((usqInt) callDistance) >> 8) & 0xFF);
	byteAtput(callSiteReturnAddress - 4, callDistance & 0xFF);
	byteAtput(callSiteReturnAddress - 6, (((usqInt) cacheTag) >> 24) & 0xFF);
	byteAtput(callSiteReturnAddress - 7, (((usqInt) cacheTag) >> 16) & 0xFF);
	byteAtput(callSiteReturnAddress - 8, (((usqInt) cacheTag) >> 8) & 0xFF);
	byteAtput(callSiteReturnAddress - 9, cacheTag & 0xFF);
	assert((((usqInt) (callTargetFromReturnAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress)))) == callTargetAddress);
	return 10;
}


/*	Rewrite an inline cache with a new tag. This variant is used
	by the garbage collector. */

static AbstractInstruction *
rewriteInlineCacheTagat(AbstractInstruction * self_in_rewriteInlineCacheTagat, sqInt cacheTag, sqInt callSiteReturnAddress)
{
	// CogIA32Compiler>>#rewriteInlineCacheTag:at:
	byteAtput(callSiteReturnAddress - 6, (((usqInt) cacheTag) >> 24) & 0xFF);
	byteAtput(callSiteReturnAddress - 7, (((usqInt) cacheTag) >> 16) & 0xFF);
	byteAtput(callSiteReturnAddress - 8, (((usqInt) cacheTag) >> 8) & 0xFF);
	byteAtput(callSiteReturnAddress - 9, cacheTag & 0xFF);
	return self_in_rewriteInlineCacheTagat;
}


/*	Rewrite a long jump instruction to jump to a different target. This
	variant is used to rewrite cached primitive calls. Answer the extent of
	the code change which is used to compute the range of the icache to flush. */

static sqInt
rewriteJumpLongAttarget(AbstractInstruction * self_in_rewriteJumpLongAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress)
{
	// CogIA32Compiler>>#rewriteJumpLongAt:target:
	return rewriteCallAttarget(self_in_rewriteJumpLongAttarget, callSiteReturnAddress, callTargetAddress);
}

void
rewritePrimInvocationInto(CogMethod *cogMethod, void (*primFunctionPointer)(void))
{
	// SimpleStackBasedCogit>>#rewritePrimInvocationIn:to:
    sqInt address;
    sqInt extent;
    sqInt flags;
    sqInt primIndex;

	assert(((cogMethod->cmType)) == CMMethod);
	primIndex = primitiveIndexOfMethodheader((cogMethod->methodObject), (cogMethod->methodHeader));

	/* See compileInterpreterPrimitive: */

flags = primitivePropertyFlags(primIndex);
	if ((flags & PrimCallMayCallBack) != 0) {
		address = (((usqInt)cogMethod)) + (externalPrimJumpOffsets[(cogMethod->cmNumArgs)]);
		extent = rewriteJumpLongAttarget(backEnd, address, ((usqInt)primFunctionPointer));
	}
	else {
address = (((usqInt)cogMethod)) + (externalPrimCallOffsets[(cogMethod->cmNumArgs)]);
		extent = rewriteCallAttarget(backEnd, address, ((usqInt)primFunctionPointer));
	}
	flushICacheFromto(processor, address, address + extent);
}


/*	The youngReferrers list holds methods that may contain a reference to a
	young object and hence need to be visited during young-space garbage
	collection. The
	list saves walking through all of code space to do so, as in typical
	circumstances there are no methods that refer to young objects.However,
	events like become:
	can potentially cause every method to refer to a new object (becomming
	true for
	example). So there needs to be room on the list for as many methods as
	exist.  */

static sqInt
roomOnYoungReferrersList(void)
{
	// CogMethodZone>>#roomOnYoungReferrersList
	assert((youngReferrers <= limitAddress)
	 && (youngReferrers >= (limitAddress - (methodCount * BytesPerWord))));
	return (limitAddress - (methodCount * BytesPerWord)) >= mzFreeStart;
}

static AbstractInstruction *
gSubCqR(sqInt quickConstant, sqInt reg)
{
	// Cogit>>#SubCq:R:
	return genoperandoperand(SubCqR, quickConstant, reg);
}

static AbstractInstruction *
gSubCwR(sqInt wordConstant, sqInt reg)
{
	// Cogit>>#SubCw:R:
	return genoperandoperand(SubCwR, wordConstant, reg);
}


/*	Scan the block to determine if the block needs a frame or not */

static void
scanBlock(BlockStart *blockStart)
{
	// StackToRegisterMappingCogit>>#scanBlock:
    BytecodeDescriptor *descriptor;
    sqInt end;
    sqInt framelessStackDelta;
    sqInt (* const isPushNilFunction)(struct _BytecodeDescriptor *,sqInt,sqInt,sqInt) = v3IsPushNil;
    sqInt nExts;
    sqInt pc;
    sqInt pushingNils;

	needsFrame = 0;
	prevBCDescriptor = null;
	methodOrBlockNumArgs = (blockStart->numArgs);
	inBlock = 1;
	pc = (blockStart->startpc);
	end = ((blockStart->startpc)) + ((blockStart->span));
	framelessStackDelta = (nExts = 0);
	pushingNils = 1;
	while (pc < end) {
byte0 = (fetchByteofObject(pc, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		if (!needsFrame) {
			if ((((descriptor->needsFrameFunction)) == null)
			 || (((descriptor->needsFrameFunction))(framelessStackDelta))) {
				needsFrame = 1;
			}
			else {
framelessStackDelta += (descriptor->stackDelta);
			}
		}
		if (pushingNils
		 && (!((descriptor->isExtension)))) {

			/* Count the initial number of pushed nils acting as temp initializers.  We can't tell
			   whether an initial pushNil is an operand reference or a temp initializer, except
			   when the pushNil is a jump target (has a fixup) in which case it is definitely an
			   operand reference.  So rarely we may end up over-estimating.  We will correct
			   by checking the stack depth at the end of the block in compileBlockBodies. */

			if ((pushingNils = (isPushNilFunction(descriptor, pc, nExts, methodObj))
			 && ((((fixupAt(pc - initialPC))->targetInstruction)) == 0))) {
				assert(((descriptor->numBytes)) == 1);
				(blockStart->numInitialNils = ((blockStart->numInitialNils)) + 1);
			}
		}
		pc = (pc + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj)
	: 0));
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
		prevBCDescriptor = descriptor;
	}
	if (!needsFrame) {
		assert((framelessStackDelta >= 0)
		 && (((blockStart->numInitialNils)) >= framelessStackDelta));
		(blockStart->numInitialNils = ((blockStart->numInitialNils)) - framelessStackDelta);
	}
}


/*	Answer the number of clean blocks found in the literal frame */

static sqInt
scanForCleanBlocks(void)
{
	// Cogit>>#scanForCleanBlocks
    sqInt i;
    sqInt iLimiT;
    sqInt lit;
    sqInt numCleanBlocks;
    sqInt startPCOrNil;

	numCleanBlocks = 0;
	for (i = 1, iLimiT = (literalCountOf(methodObj)); i <= iLimiT; i += 1) {
		lit = fetchPointerofObject(i, methodObj);
		startPCOrNil = startPCOrNilOfLiteralin(lit, methodObj);
		if (!(startPCOrNil == null)) {
			numCleanBlocks += 1;
		}
	}
	return numCleanBlocks;
}


/*	Scan the method (and all embedded blocks) to determine
	- what the last bytecode is; extra bytes at the end of a method are used
	to encode things like source pointers or temp names
	- if the method needs a frame or not
	- what are the targets of any backward branches.
	- how many blocks it creates
	Answer the block count or on error a negative error code */

static sqInt
scanMethod(void)
{
	// StackToRegisterMappingCogit>>#scanMethod
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt framelessStackDelta;
    sqInt latestContinuation;
    sqInt nExts;
    sqInt numBlocks;
    sqInt pc;
    sqInt targetPC;

	needsFrame = 0;
	inBlock = 0;
	prevBCDescriptor = null;
	if ((primitiveIndex > 0)
	 && (isQuickPrimitiveIndex(primitiveIndex))) {
		return 0;
	}
	pc = (latestContinuation = initialPC);
	numBlocks = (framelessStackDelta = (nExts = 0));
	while (pc <= endPC) {
		byte0 = (fetchByteofObject(pc, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		if (((descriptor->isReturn))
		 && (pc >= latestContinuation)) {
			endPC = pc;
		}
		if (!needsFrame) {
			if ((((descriptor->needsFrameFunction)) == null)
			 || (((descriptor->needsFrameFunction))(framelessStackDelta))) {
				needsFrame = 1;
			}
			else {
framelessStackDelta += (descriptor->stackDelta);
			}
		}
		if (isBranch(descriptor)) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			if (isBackwardBranchatextsin(descriptor, pc, nExts, methodObj)) {
				initializeFixupAt(targetPC - initialPC);
			}
			else {
latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
			}
		}
		if ((descriptor->isBlockCreation)) {
			numBlocks += 1;
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
		}
		pc += (descriptor->numBytes);
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
		prevBCDescriptor = descriptor;
	}
	return numBlocks;
}

void
setBreakMethod(sqInt anObj)
{
	// Cogit>>#setBreakMethod:
	breakMethod = anObj;
}


/*	Hack: To arrange that the block method field pushed in a block entry has
	its MFMethodFlagIsBlockFlag bit set we provide labels with an offset. The
	offset for the fakeHeader reference is MFMethodFlagIsBlockFlag. See
	compileBlockFrameBuild: */

static sqInt
setLabelOffset(AbstractInstruction * self_in_setLabelOffset, sqInt aValue)
{
	// CogAbstractInstruction>>#setLabelOffset:
	return ((self_in_setLabelOffset->operands))[1] = aValue;
}

void
setPostCompileHook(void (*aFunction)(CogMethod *, void *))
{
	// Cogit>>#setPostCompileHook:
	postCompileHook = aFunction;
}


/*	If a method is compiled to machine code via a block entry it won't have a
	selector. A subsequent send can find the method and hence fill in the
	selector. 
 */
/*	self disassembleMethod: cogMethod */

void
setSelectorOfto(CogMethod *cogMethod, sqInt aSelectorOop)
{
	// Cogit>>#setSelectorOf:to:
	compilationBreakpoint(aSelectorOop, lengthOf(aSelectorOop));
	assert(((cogMethod->cmType)) == CMMethod);
	(cogMethod->selector = aSelectorOop);
	if ((!((cogMethod->cmRefersToYoung)))
	 && (isYoung(aSelectorOop))) {
		assert((occurrencesInYoungReferrers(cogMethod)) == 0);
		(cogMethod->cmRefersToYoung = 1);
		addToYoungReferrers(cogMethod);
	}
}


/*	to save Slang from having to be a real compiler (it can't inline switches
	that return)
 */
/*	Answer if the receiver's opcode sets the condition codes correctly for the
	given conditional jump opcode.
 */

static sqInt
setsConditionCodesFor(AbstractInstruction * self_in_setsConditionCodesFor, sqInt aConditionalJumpOpcode)
{
	// CogIA32Compiler>>#setsConditionCodesFor:
	
	switch ((self_in_setsConditionCodesFor->opcode)) {
	case ArithmeticShiftRightCqR:
	case ArithmeticShiftRightRR:
	case LogicalShiftLeftCqR:
	case LogicalShiftLeftRR:
		return shiftSetsConditionCodesFor(self_in_setsConditionCodesFor, aConditionalJumpOpcode);

	case XorRR:
		return 1;

	default:
		haltmsg("unhandled opcode in setsConditionCodesFor:");
		return 0;

	}
}


/*	OF flag only guaranteed to be set for 1-bit shifts. See [1] p 490 */

static sqInt
shiftSetsConditionCodesFor(AbstractInstruction * self_in_shiftSetsConditionCodesFor, sqInt aConditionalJumpOpcode)
{
	// CogIA32Compiler>>#shiftSetsConditionCodesFor:
	return ((((self_in_shiftSetsConditionCodesFor->opcode)) == ArithmeticShiftRightCqR)
	 || (((self_in_shiftSetsConditionCodesFor->opcode)) == LogicalShiftLeftCqR))
	 && ((((self_in_shiftSetsConditionCodesFor->operands))[0]) == 1);
}


/*	self assert: ((objectMemory isIntegerObject: anOop)
	or: [objectMemory addressCouldBeObj: anOop]). */

static sqInt
shouldAnnotateObjectReference(sqInt anOop)
{
	// CogObjectRepresentationForSqueakV3>>#shouldAnnotateObjectReference:
	return (isNonIntegerObject(anOop))
	 && (oopisGreaterThan(anOop, trueObject()));
}

static sqInt
sizeHasModrmat(AbstractInstruction * self_in_sizeHasModrmat, sqInt op, sqInt pc)
{
	// CogIA32Compiler>>#sizeHasModrm:at:
    sqInt mod;
    sqInt modrm;
    sqInt rm;
    sqInt ro;

	modrm = byteAt(pc + 1);
	mod = ((usqInt) modrm) >> 6;
	ro = (((usqInt) modrm) >> 3) & 7;
	rm = modrm & 7;
	if (mod == 3) {
return 2;
	}
	if (rm != 4) {

		/* no SIB byte */


		switch (mod) {
		case 0:
			return (rm == 5
				? 6
				: 3);

		case 1:
			return 3;

		case 2:
			return 6;

		default:
			error("Case not found and no otherwise clause");
			return -1;
		}
	}
	haltmsg("fall through in sizeHasModrm:at:");
	return 0;
}


/*	see [1] p A-7, p A-13 */

static sqInt
sizeImmediateGroup1at(AbstractInstruction * self_in_sizeImmediateGroup1at, sqInt op, sqInt pc)
{
	// CogIA32Compiler>>#sizeImmediateGroup1:at:
    sqInt mod;
    sqInt modrm;
    sqInt rm;
    sqInt ro;

	modrm = byteAt(pc + 1);
	mod = ((usqInt) modrm) >> 6;
	ro = (((usqInt) modrm) >> 3) & 7;
	rm = modrm & 7;
	
	switch (ro) {
	case 7:
		return (op == 129
			? 6
			: 3);

	default:
		error("Case not found and no otherwise clause");
		return -1;
	}
}


/*	Size a jump and set its address. The target may be another instruction
	or an absolute address. On entry the address inst var holds our virtual
	address. On exit address is set to eventualAbsoluteAddress, which is
	where this instruction will be output. The span of a jump to a following
	instruction is therefore between that instruction's address and this
	instruction's address ((which are both still their virtual addresses), but
	the span of a jump to a preceeding instruction or to an absolute address
	is between that instruction's address (which by now is its eventual
	absolute address) or absolute address and eventualAbsoluteAddress. */

static sqInt
sizePCDependentInstructionAt(AbstractInstruction * self_in_sizePCDependentInstructionAt, sqInt eventualAbsoluteAddress)
{
	// CogIA32Compiler>>#sizePCDependentInstructionAt:
    AbstractInstruction *abstractInstruction;
    sqInt alignment;
    sqInt maximumSpan;
    sqInt target;

	if (((self_in_sizePCDependentInstructionAt->opcode)) == AlignmentNops) {
		(self_in_sizePCDependentInstructionAt->address) = eventualAbsoluteAddress;
		alignment = ((self_in_sizePCDependentInstructionAt->operands))[0];
		return ((self_in_sizePCDependentInstructionAt->machineCodeSize) = ((eventualAbsoluteAddress + (alignment - 1)) & (-alignment)) - eventualAbsoluteAddress);
	}
	assert(isJump(self_in_sizePCDependentInstructionAt));
	target = ((self_in_sizePCDependentInstructionAt->operands))[0];
	abstractInstruction = ((AbstractInstruction *) target);
	if (isAnInstruction(self_in_sizePCDependentInstructionAt, abstractInstruction)) {
		maximumSpan = ((abstractInstruction->address)) - (((abstractInstructionfollows(self_in_sizePCDependentInstructionAt, abstractInstruction)
	? eventualAbsoluteAddress
	: (self_in_sizePCDependentInstructionAt->address))) + 2);
	}
	else {
maximumSpan = target - (eventualAbsoluteAddress + 2);
	}
	(self_in_sizePCDependentInstructionAt->address) = eventualAbsoluteAddress;
	return ((self_in_sizePCDependentInstructionAt->machineCodeSize) = (((self_in_sizePCDependentInstructionAt->opcode)) >= FirstShortJump
		? (isQuick(self_in_sizePCDependentInstructionAt, maximumSpan)
				? 2
				: (((self_in_sizePCDependentInstructionAt->opcode)) == Jump
						? 5
						: 6))
		: (((self_in_sizePCDependentInstructionAt->opcode)) == JumpLong
				? 5
				: 6)));
}

static sqInt
slotOffsetOfInstVarIndex(sqInt index)
{
	// CogObjectRepresentationForSqueakV3>>#slotOffsetOfInstVarIndex:
	return (index * BytesPerWord) + BaseHeaderSize;
}

static sqInt
smallIntegerIsOnlyImmediateType(void)
{
	// CogObjectRepresentationForSqueakV3>>#smallIntegerIsOnlyImmediateType
	return 1;
}

static sqInt
spanForCleanBlockStartingAt(sqInt startPC)
{
	// Cogit>>#spanForCleanBlockStartingAt:
    BytecodeDescriptor *descriptor;
    sqInt end;
    sqInt pc;

	pc = startPC;
	end = byteLengthOf(methodObj);
	while (pc <= end) {
descriptor = generatorAt((fetchByteofObject(pc, methodObj)) + bytecodeSetOffset);
		pc += (descriptor->numBytes);
		if ((descriptor->isReturn)) {
			return pc - startPC;
		}
	}
	error("couldn't locate end of clean block");
	return 0;
}


/*	Allocate a register needed in a run-time call (i.e. flush uses of the
	register to the real stack). Since the run-time can smash any and
	all caller-saved registers also flush all caller-saved registers. */

static void
ssAllocateCallReg(sqInt requiredReg)
{
	// StackToRegisterMappingCogit>>#ssAllocateCallReg:
	ssAllocateRequiredRegMaskupThrough(callerSavedRegMask | (registerMaskFor(requiredReg)), simStackPtr);
}

static void
ssAllocateCallRegand(sqInt requiredReg1, sqInt requiredReg2)
{
	// StackToRegisterMappingCogit>>#ssAllocateCallReg:and:
	ssAllocateRequiredRegMaskupThrough(callerSavedRegMask | ((registerMaskFor(requiredReg1)) | (registerMaskFor(requiredReg2))), simStackPtr);
}

static void
ssAllocateCallRegandand(sqInt requiredReg1, sqInt requiredReg2, sqInt requiredReg3)
{
	// StackToRegisterMappingCogit>>#ssAllocateCallReg:and:and:
	ssAllocateRequiredRegMaskupThrough(callerSavedRegMask | ((registerMaskFor(requiredReg1)) | ((registerMaskFor(requiredReg2)) | (registerMaskFor(requiredReg3)))), simStackPtr);
}

static sqInt
ssAllocatePreferredReg(sqInt preferredReg)
{
	// StackToRegisterMappingCogit>>#ssAllocatePreferredReg:
    sqInt i;
    sqInt lastPreferred;
    sqInt liveRegs;
    sqInt preferredMask;
    sqInt reg;


	/* compute live regs while noting the last occurrence of preferredReg.
	   If there are none free we must spill from simSpillBase to last occurrence. */

	lastPreferred = -1;
	preferredMask = registerMaskFor(preferredReg);
	liveRegs = registerMaskForandand(TempReg, FPReg, SPReg);
	for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= simStackPtr; i += 1) {
		liveRegs = liveRegs | (registerMask(simStackAt(i)));
		if ((liveRegs & preferredMask) != 0) {
			lastPreferred = i;
		}
	}
	if ((liveRegs & (registerMaskFor(preferredReg))) == 0) {
		return preferredReg;
	}
	for (reg = GPRegMin; reg <= GPRegMax; reg += 1) {
if ((liveRegs & (registerMaskFor(reg))) == 0) {
			return reg;
		}
	}
	ssFlushTo(lastPreferred);
	assert(((liveRegisters()) & preferredMask) == 0);
	return preferredReg;
}

static void
ssAllocateRequiredRegMaskupThrough(sqInt requiredRegsMask, sqInt stackPtr)
{
	// StackToRegisterMappingCogit>>#ssAllocateRequiredRegMask:upThrough:
    sqInt i;
    sqInt lastRequired;
    sqInt liveRegs;


	/* compute live regs while noting the last occurrence of required regs.
	   If these are not free we must spill from simSpillBase to last occurrence.
	   Note we are conservative here; we could allocate FPReg in frameless methods. */

	lastRequired = -1;
	liveRegs = registerMaskForand(FPReg, SPReg);
	for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= stackPtr; i += 1) {
		liveRegs = liveRegs | (registerMask(simStackAt(i)));
		if (((registerMask(simStackAt(i))) & requiredRegsMask) != 0) {
			lastRequired = i;
		}
	}
	if (!((liveRegs & requiredRegsMask) == 0)) {

		/* Some live, must spill */

ssFlushTo(lastRequired);
		assert(((liveRegisters()) & requiredRegsMask) == 0);
	}
}

static void
ssAllocateRequiredReg(sqInt requiredReg)
{
	// StackToRegisterMappingCogit>>#ssAllocateRequiredReg:
	ssAllocateRequiredRegMaskupThrough(registerMaskFor(requiredReg), simStackPtr);
}

static void
ssAllocateRequiredRegand(sqInt requiredReg1, sqInt requiredReg2)
{
	// StackToRegisterMappingCogit>>#ssAllocateRequiredReg:and:
	ssAllocateRequiredRegMaskupThrough((registerMaskFor(requiredReg1)) | (registerMaskFor(requiredReg2)), simStackPtr);
}

static void
ssAllocateRequiredRegupThrough(sqInt requiredReg, sqInt stackPtr)
{
	// StackToRegisterMappingCogit>>#ssAllocateRequiredReg:upThrough:
	ssAllocateRequiredRegMaskupThrough(registerMaskFor(requiredReg), stackPtr);
}

static void
ssFlushTo(sqInt index)
{
	// StackToRegisterMappingCogit>>#ssFlushTo:
    sqInt i;

	for (i = methodOrBlockNumTemps; i < simSpillBase; i += 1) {
		assert(((simStackAt(i))->spilled));
	}
	if (simSpillBase <= index) {
		for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= index; i += 1) {
			assert(needsFrame);
			ensureSpilledAtfrom(simStackAt(i), frameOffsetOfTemporary(i), FPReg);
		}
		simSpillBase = index + 1;
	}
}


/*	Any occurrences on the stack of the value being stored (which is the top
	of stack)
	must be flushed, and hence any values colder than them stack. */

static void
ssFlushUpThroughReceiverVariable(sqInt slotIndex)
{
	// StackToRegisterMappingCogit>>#ssFlushUpThroughReceiverVariable:
    CogSimStackEntry *desc;
    sqInt index;

	for (index = (simStackPtr - 1); index >= (((simSpillBase < 0) ? 0 : simSpillBase)); index += -1) {
		desc = simStackAt(index);
		if ((((desc->type)) == SSBaseOffset)
		 && ((((desc->registerr)) == ReceiverResultReg)
		 && (((desc->offset)) == (slotOffsetOfInstVarIndex(slotIndex))))) {
			ssFlushTo(index);
			return;
		}
	}
}


/*	Any occurrences on the stack of the value being stored (which is the top
	of stack)
	must be flushed, and hence any values colder than them stack. */

static void
ssFlushUpThroughTemporaryVariable(sqInt tempIndex)
{
	// StackToRegisterMappingCogit>>#ssFlushUpThroughTemporaryVariable:
    CogSimStackEntry *desc;
    sqInt index;

	for (index = (simStackPtr - 1); index >= simSpillBase; index += -1) {
		desc = simStackAt(index);
		if ((((desc->type)) == SSBaseOffset)
		 && ((((desc->registerr)) == FPReg)
		 && (((desc->offset)) == (frameOffsetOfTemporary(tempIndex))))) {
			ssFlushTo(index);
			return;
		}
	}
}

static void
ssPop(sqInt n)
{
	// StackToRegisterMappingCogit>>#ssPop:
	assert(((simStackPtr - n) >= (methodOrBlockNumTemps - 1))
	 || ((!needsFrame)
	 && ((simStackPtr - n) >= -1)));
	simStackPtr -= n;
}

static sqInt
ssPushAnnotatedConstant(sqInt literal)
{
	// StackToRegisterMappingCogit>>#ssPushAnnotatedConstant:
    CogSimStackEntry * cascade0;

	ssPush(1);
	if (simSpillBase > simStackPtr) {
		simSpillBase = ((simStackPtr < 0) ? 0 : simStackPtr);
	}
	cascade0 = ssTop();
	(cascade0->type = SSConstant);
	(cascade0->annotateUse = 1);
	(cascade0->spilled = 0);
	(cascade0->constant = literal);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

static sqInt
ssPushBaseoffset(sqInt reg, sqInt offset)
{
	// StackToRegisterMappingCogit>>#ssPushBase:offset:
    CogSimStackEntry * cascade0;

	ssPush(1);
	if (simSpillBase > simStackPtr) {
		simSpillBase = ((simStackPtr < 0) ? 0 : simStackPtr);
	}
	cascade0 = ssTop();
	(cascade0->type = SSBaseOffset);
	(cascade0->spilled = 0);
	(cascade0->annotateUse = 0);
	(cascade0->registerr = reg);
	(cascade0->offset = offset);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

static sqInt
ssPushConstant(sqInt literal)
{
	// StackToRegisterMappingCogit>>#ssPushConstant:
    CogSimStackEntry * cascade0;

	ssPush(1);
	if (simSpillBase > simStackPtr) {
		simSpillBase = ((simStackPtr < 0) ? 0 : simStackPtr);
	}
	cascade0 = ssTop();
	(cascade0->type = SSConstant);
	(cascade0->spilled = 0);
	(cascade0->annotateUse = 0);
	(cascade0->constant = literal);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

static sqInt
ssPushDesc(CogSimStackEntry simStackEntry)
{
	// StackToRegisterMappingCogit>>#ssPushDesc:
	if (((simStackEntry.type)) == SSSpill) {
		(simStackEntry.type = SSBaseOffset);
	}
	(simStackEntry.spilled = 0);
	(simStackEntry.annotateUse = 0);
	(simStackEntry.bcptr = bytecodePC);
	simStack[(simStackPtr += 1)] = simStackEntry;
	if (simSpillBase > simStackPtr) {
		simSpillBase = ((simStackPtr < 0) ? 0 : simStackPtr);
	}
	return 0;
}

static sqInt
ssPushRegister(sqInt reg)
{
	// StackToRegisterMappingCogit>>#ssPushRegister:
    CogSimStackEntry * cascade0;

	ssPush(1);
	if (simSpillBase > simStackPtr) {
		simSpillBase = ((simStackPtr < 0) ? 0 : simStackPtr);
	}
	cascade0 = ssTop();
	(cascade0->type = SSRegister);
	(cascade0->spilled = 0);
	(cascade0->annotateUse = 0);
	(cascade0->registerr = reg);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

static void
ssPush(sqInt n)
{
	// StackToRegisterMappingCogit>>#ssPush:
	simStackPtr += n;
}


/*	Store or pop the top simulated stack entry to a register.
	Pop to preferredReg if the entry is not itself a register.
	Answer the actual register the result ends up in. */

static sqInt
ssStorePoptoPreferredReg(sqInt popBoolean, sqInt preferredReg)
{
	// StackToRegisterMappingCogit>>#ssStorePop:toPreferredReg:
    sqInt actualReg;

	actualReg = preferredReg;
	if (popBoolean) {
if (((((ssTop())->type)) == SSRegister)
		 && (!(((ssTop())->spilled)))) {
			assert(!(((ssTop())->annotateUse)));
			actualReg = ((ssTop())->registerr);
		}
		else {
popToReg(ssTop(), preferredReg);
		}
		ssPop(1);
	}
	else {
if ((((ssTop())->type)) == SSRegister) {
			assert(!(((ssTop())->annotateUse)));
			actualReg = ((ssTop())->registerr);
		}
		else {
storeToReg(ssTop(), preferredReg);
		}
	}
	return actualReg;
}

static CogSimStackEntry *
ssTop(void)
{
	// StackToRegisterMappingCogit>>#ssTop
	return simStackAt(simStackPtr);
}

static CogSimStackEntry
ssTopDescriptor(void)
{
	// StackToRegisterMappingCogit>>#ssTopDescriptor
	return simStack[simStackPtr];
}

static CogSimStackEntry *
ssValue(sqInt n)
{
	// StackToRegisterMappingCogit>>#ssValue:
	return simStackAt(simStackPtr - n);
}

static sqInt
stackBytesForNumArgs(AbstractInstruction * self_in_stackBytesForNumArgs, sqInt numArgs)
{
	// CogIA32Compiler>>#stackBytesForNumArgs:
	return numArgs * 4;
}


/*	Return a minimum amount of headroom for each stack page (in bytes). In a
	JIT the stack has to have room for interrupt handlers which will run on
	the stack.
	See [1] pp 6-13 to 6-14. On an interrupt or exception the maximum state
	that an IA32 CPU will push is SS, ESP, EFLAGS, CS, EIP and an error code.
	It may then
	call an interrupt procedure. Leave some room above the minimum state. */

static sqInt
stackPageInterruptHeadroomBytes(AbstractInstruction * self_in_stackPageInterruptHeadroomBytes)
{
	// CogIA32Compiler>>#stackPageInterruptHeadroomBytes
	return 256;
}


/*	Rewrite the literal in the instruction immediately preceeding
	followingAddress. 
 */

static AbstractInstruction *
storeLiteralbeforeFollowingAddress(AbstractInstruction * self_in_storeLiteralbeforeFollowingAddress, sqInt literal, sqInt followingAddress)
{
	// CogIA32Compiler>>#storeLiteral:beforeFollowingAddress:
	byteAtput(followingAddress - 1, (((usqInt) literal) >> 24) & 0xFF);
	byteAtput(followingAddress - 2, (((usqInt) literal) >> 16) & 0xFF);
	byteAtput(followingAddress - 3, (((usqInt) literal) >> 8) & 0xFF);
	byteAtput(followingAddress - 4, literal & 0xFF);
	return self_in_storeLiteralbeforeFollowingAddress;
}

static CogSimStackEntry *
storeToReg(CogSimStackEntry * self_in_storeToReg, sqInt reg)
{
	// CogSimStackEntry>>#storeToReg:
    sqInt baseReg;
    AbstractInstruction *inst;
    sqInt offset;
    sqInt quickConstant;
    sqInt reg1;

	
	switch ((self_in_storeToReg->type)) {
	case SSBaseOffset:
	case SSSpill:
		/* begin MoveMw:r:R: */
		offset = (self_in_storeToReg->offset);
		baseReg = (self_in_storeToReg->registerr);
		inst = genoperandoperandoperand(MoveMwrR, offset, baseReg, reg);
		break;
	case SSConstant:
		inst = (shouldAnnotateObjectReference((self_in_storeToReg->constant))
			? annotateobjRef(gMoveCwR((self_in_storeToReg->constant), reg), (self_in_storeToReg->constant))
			: (/* begin MoveCq:R: */
				(quickConstant = (self_in_storeToReg->constant)),
				genoperandoperand(MoveCqR, quickConstant, reg)));
		break;
	case SSRegister:
		inst = (reg != ((self_in_storeToReg->registerr))
			? (/* begin MoveR:R: */
				(reg1 = (self_in_storeToReg->registerr)),
				genoperandoperand(MoveRR, reg1, reg))
			: (/* begin Label */
				genoperandoperand(Label, (labelCounter += 1), bytecodePC)));
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	if ((self_in_storeToReg->annotateUse)) {
		/* begin annotateBytecode: */
		annotatewith(inst, HasBytecodePC);
		(self_in_storeToReg->annotateUse) = 0;
	}
	return self_in_storeToReg;
}

static sqInt
sib(AbstractInstruction * self_in_sib, sqInt scale, sqInt indexReg, sqInt baseReg)
{
	// CogIA32Compiler>>#s:i:b:
	return ((scale << 6) + (indexReg << 3)) + baseReg;
}

sqInt
traceLinkedSendOffset(void)
{
	// Cogit>>#traceLinkedSendOffset
	return cmNoCheckEntryOffset + (callInstructionByteSize(backEnd));
}


/*	Malloc a string with the contents for the trampoline table */

static char *
trampolineNamenumArgs(char *routinePrefix, sqInt numArgs)
{
	// Cogit>>#trampolineName:numArgs:
    char *theString;

	
theString = malloc((strlen(routinePrefix)) + 6);
	sprintf(theString, "%s%cArgs", routinePrefix, (numArgs >= 0
		? '0' + numArgs
		: 'N'));
	return theString;
}


/*	If the sequence of bytecodes is
	push: (Array new: 1)
	popIntoTemp: tempIndex
	pushConstant: const or pushTemp: n
	popIntoTemp: 0 inVectorAt: tempIndex
	collapse this into
	tempAt: tempIndex put: {const or temp}
	and answer true, otherwise answer false.
	One might think that we should look for a sequence of more than
	one pushes and pops but this is extremely rare.
	Exclude pushRcvr: n to avoid potential complications with context inst
	vars.  */

static sqInt
tryCollapseTempVectorInitializationOfSize(sqInt slots)
{
	// StackToRegisterMappingCogit>>#tryCollapseTempVectorInitializationOfSize:
    BytecodeDescriptor *pushArrayDesc;
    BytecodeDescriptor *pushValueDesc;
    sqInt reg;
    sqInt remoteTempIndex;
    BytecodeDescriptor *storeArrayDesc;
    BytecodeDescriptor *storeValueDesc;
    sqInt tempIndex;

	if (slots != 1) {
return 0;
	}
	pushArrayDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject(bytecodePC, methodObj)));
	assert(((pushArrayDesc->generator)) == genPushNewArrayBytecode);
	storeArrayDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject(bytecodePC + ((pushArrayDesc->numBytes)), methodObj)));
	if (((storeArrayDesc->generator)) == genStoreAndPopTemporaryVariableBytecode) {
		tempIndex = (fetchByteofObject(bytecodePC + ((pushArrayDesc->numBytes)), methodObj)) & 7;
	}
	else {
if (!(((storeArrayDesc->generator)) == genLongStoreAndPopTemporaryVariableBytecode)) {
			return 0;
		}
		tempIndex = fetchByteofObject((bytecodePC + ((pushArrayDesc->numBytes))) + 1, methodObj);
	}
	pushValueDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject((bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes)), methodObj)));
	if (!((((pushValueDesc->generator)) == genPushLiteralConstantBytecode)
		 || ((((pushValueDesc->generator)) == genPushQuickIntegerConstantBytecode)
		 || (((pushValueDesc->generator)) == genPushTemporaryVariableBytecode)))) {
		return 0;
	}
	storeValueDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject(((bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes))) + ((pushValueDesc->numBytes)), methodObj)));
	remoteTempIndex = fetchByteofObject((((bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes))) + ((pushValueDesc->numBytes))) + 2, methodObj);
	if (!((((storeValueDesc->generator)) == genStoreAndPopRemoteTempLongBytecode)
		 && (tempIndex == remoteTempIndex))) {
		return 0;
	}
	genNewArrayOfSizeinitialized(1, 0);
	evaluateat(pushValueDesc, (bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes)));
	reg = ssStorePoptoPreferredReg(1, TempReg);
	genStoreSourceRegslotIndexintoNewObjectInDestReg(reg, 0, ReceiverResultReg);
	ssPushRegister(ReceiverResultReg);
	evaluateat(storeArrayDesc, bytecodePC + ((pushArrayDesc->numBytes)));

	/* + pushArrayDesc numBytes this gets added by nextBytecodePCFor:at:exts:in: */

bytecodePC = ((bytecodePC + ((storeArrayDesc->numBytes))) + ((pushValueDesc->numBytes))) + ((storeValueDesc->numBytes));
	return 1;
}

static sqInt
twoByteInstructionSizeAt(AbstractInstruction * self_in_twoByteInstructionSizeAt, sqInt pc)
{
	// CogIA32Compiler>>#twoByteInstructionSizeAt:
    sqInt op;

	op = byteAt(pc + 1);
	
	switch (op & 240) {
	case 128:
		
		/* long conditional jumps */

return 6;

	default:
		error("Case not found and no otherwise clause");
		return -1;
	}
}

static sqInt
unimplementedPrimitive(void)
{
	// Cogit>>#unimplementedPrimitive
	return UnimplementedPrimitive;
}

static sqInt
unknownBytecode(void)
{
	// Cogit>>#unknownBytecode
	return EncounteredUnknownBytecode;
}


/*	Unlink all sends in cog methods. */

void
unlinkAllSends(void)
{
	// Cogit>>#unlinkAllSends
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	if (methodZoneBase == null) {
		return;
	}
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
					result = unlinkIfLinkedSendpcignored((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), 0);
					if (result != 0) {
result;
						goto l1;
					}
				}
				else {
mcpc += (mapByte >= DisplacementX2N
						? (mapByte - DisplacementX2N) << AnnotationShift
						: mapByte);
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
if (((cogMethod->cmType)) != CMFree) {
				freeMethod(cogMethod);
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	flushICacheFromto(processor, methodZoneBase, ((sqInt)(limitZony())));
}

static sqInt
unlinkIfFreeOrLinkedSendpcof(sqInt annotation, char *mcpc, sqInt theSelector)
{
	// Cogit>>#unlinkIfFreeOrLinkedSend:pc:of:
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation == IsSendCall) {
entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

/* begin targetMethodAndSendTableFor:into: */
			if ((entryPoint & entryPointMask) == checkedEntryAlignment) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = sendTrampolines;
			}
			else {
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;
			}

			
			/* It's a linked send. */

if ((((targetMethod1->cmType)) == CMFree)
			 || (((targetMethod1->selector)) == theSelector)) {
				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
				codeModified = 1;
			}

		}
		else {

		}
	}
	return 0;
}

static sqInt
unlinkIfLinkedSendToFreepcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
	// Cogit>>#unlinkIfLinkedSendToFree:pc:ignored:
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation == IsSendCall) {
entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

/* begin targetMethodAndSendTableFor:into: */
			if ((entryPoint & entryPointMask) == checkedEntryAlignment) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = sendTrampolines;
			}
			else {
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;
			}

			
			/* It's a linked send. */

if (((targetMethod1->cmType)) == CMFree) {

				/* It's a linked send. */


				/* It's a linked send. */

unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
				codeModified = 1;
			}

		}
	}
	return 0;
}

static sqInt
unlinkIfLinkedSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
	// Cogit>>#unlinkIfLinkedSend:pc:ignored:
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation == IsSendCall) {
entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

/* begin targetMethodAndSendTableFor:into: */
			if ((entryPoint & entryPointMask) == checkedEntryAlignment) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = sendTrampolines;
			}
			else {
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;
			}

			
			/* It's a linked send. */


			/* It's a linked send. */

unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
			rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);

		}
		else {

		}
	}
	return 0;
}

static sqInt
unlinkIfLinkedSendpcto(sqInt annotation, char *mcpc, sqInt theCogMethod)
{
	// Cogit>>#unlinkIfLinkedSend:pc:to:
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation == IsSendCall) {
entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

/* begin targetMethodAndSendTableFor:into: */
			if ((entryPoint & entryPointMask) == checkedEntryAlignment) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = sendTrampolines;
			}
			else {
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;
			}

			
			/* It's a linked send. */

if ((((sqInt)targetMethod1)) == theCogMethod) {

				/* It's a linked send. */


				/* It's a linked send. */

unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
				codeModified = 1;
			}

		}
		else {

			/* Can't tell the target with PushReciver/SendImplicit so flush anyway. */


		}
	}
	return 0;
}


/*	Unlink all sends in cog methods. Free all Closed PICs with the selector,
	or with an MNU case if isMNUSelector. First check if any method actually
	has the selector; if not there can't be any linked send to it. This
	routine (including descendents) is performance critical. It contributes
	perhaps 30% of entire execution time in Compiler recompileAll. */

void
unlinkSendsOfisMNUSelector(sqInt selector, sqInt isMNUSelector)
{
	// Cogit>>#unlinkSendsOf:isMNUSelector:
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt mustScanAndUnlink;
    sqInt result;

	if (methodZoneBase == null) {
		return;
	}
	cogMethod = ((CogMethod *) methodZoneBase);
	mustScanAndUnlink = 0;
	if (isMNUSelector) {
while (cogMethod < (limitZony())) {
			if (((cogMethod->cmType)) != CMFree) {
				if ((cogMethod->cpicHasMNUCase)) {
					assert(((cogMethod->cmType)) == CMClosedPIC);
					freeMethod(cogMethod);
					mustScanAndUnlink = 1;
				}
				else {
if (((cogMethod->selector)) == selector) {
						mustScanAndUnlink = 1;
						if (((cogMethod->cmType)) == CMClosedPIC) {
							freeMethod(cogMethod);
						}
					}
				}
			}
			cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		}
	}
	else {
while (cogMethod < (limitZony())) {
			if ((((cogMethod->cmType)) != CMFree)
			 && (((cogMethod->selector)) == selector)) {
				mustScanAndUnlink = 1;
				if (((cogMethod->cmType)) == CMClosedPIC) {
					freeMethod(cogMethod);
				}
			}
			cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		}
	}
	if (!mustScanAndUnlink) {
return;
	}
	codeModified = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
					result = unlinkIfFreeOrLinkedSendpcof((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), selector);
					if (result != 0) {
result;
						goto l1;
					}
				}
				else {
mcpc += (mapByte >= DisplacementX2N
						? (mapByte - DisplacementX2N) << AnnotationShift
						: mapByte);
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (codeModified) {

		/* After possibly updating inline caches we need to flush the icache. */

flushICacheFromto(processor, methodZoneBase, ((sqInt)(limitZony())));
	}
}


/*	Unlink all sends in cog methods to free methods and/or pics. */

void
unlinkSendsToFree(void)
{
	// Cogit>>#unlinkSendsToFree
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	if (methodZoneBase == null) {
		return;
	}
	codeModified = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
					result = unlinkIfLinkedSendToFreepcignored((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), 0);
					if (result != 0) {
result;
						goto l1;
					}
				}
				else {
mcpc += (mapByte >= DisplacementX2N
						? (mapByte - DisplacementX2N) << AnnotationShift
						: mapByte);
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
if (((cogMethod->cmType)) == CMClosedPIC) {
				assert(noTargetsFreeInClosedPIC(cogMethod));
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (codeModified) {

		/* After possibly updating inline caches we need to flush the icache. */

flushICacheFromto(processor, methodZoneBase, ((sqInt)(limitZony())));
	}
}


/*	Unlink all sends in cog methods to a particular target method.
	If targetMethodObject isn't actually a method (perhaps being
	used via invokeAsMethod) then there's nothing to do. */

void
unlinkSendsToandFreeIf(sqInt targetMethodObject, sqInt freeIfTrue)
{
	// Cogit>>#unlinkSendsTo:andFreeIf:
    CogMethod *cogMethod;
    sqInt freedPIC;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;
    CogMethod *targetMethod;

	if (!((isOopCompiledMethod(targetMethodObject))
		 && (methodHasCogMethod(targetMethodObject)))) {
		return;
	}
	targetMethod = cogMethodOf(targetMethodObject);
	if (methodZoneBase == null) {
		return;
	}
	codeModified = (freedPIC = 0);
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {
mcpc += mapByte & DisplacementMask;
					result = unlinkIfLinkedSendpcto((((usqInt) mapByte) >> AnnotationShift), (((char *) mcpc)), (((sqInt)targetMethod)));
					if (result != 0) {
result;
						goto l1;
					}
				}
				else {
mcpc += (mapByte >= DisplacementX2N
						? (mapByte - DisplacementX2N) << AnnotationShift
						: mapByte);
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
if ((((cogMethod->cmType)) == CMClosedPIC)
			 && (cPICHasTarget(cogMethod, targetMethod))) {
				freeMethod(cogMethod);
				freedPIC = 1;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freeIfTrue) {
freeMethod(targetMethod);
	}
	if (freedPIC) {
unlinkSendsToFree();
	}
	else {
if (codeModified) {

			/* After possibly updating inline caches we need to flush the icache. */

flushICacheFromto(processor, methodZoneBase, ((sqInt)(limitZony())));
		}
	}
}

static sqInt
unsignedShortAt(AbstractInstruction * self_in_unsignedShortAt, sqInt byteAddress)
{
	// CogIA32Compiler>>#unsignedShortAt:
	return (byteAt(byteAddress)) + (((usqInt) (byteAt(byteAddress + 1)) << 8));
}


/*	Update an instruction that depends on a label outside of
	generated code (e.g. a method or block header). */

static AbstractInstruction *
updateLabel(AbstractInstruction * self_in_updateLabel, AbstractInstruction *labelInstruction)
{
	// CogAbstractInstruction>>#updateLabel:
    sqInt offsetAddress;

	offsetAddress = ((labelInstruction->address)) + (labelOffset(labelInstruction));
	
	switch ((self_in_updateLabel->opcode)) {
	case MoveCwR:
	case PushCw:
	case FillFromWord:
		((self_in_updateLabel->operands))[0] = offsetAddress;
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	return self_in_updateLabel;
}


/*	Update a potential object reference from a closed PIC.
	This may be an object reference, an inline cache tag or null.
	Answer if the updated literal is young. */

static sqInt
updateMaybeObjRefAt(sqInt mcpc)
{
	// Cogit>>#updateMaybeObjRefAt:
    sqInt object;
    sqInt subject;

	object = literalBeforeFollowingAddress(backEnd, mcpc);
	if (!(couldBeObject(object))) {
		return 0;
	}
	subject = remapOop(object);
	if (object != subject) {
storeLiteralbeforeFollowingAddress(backEnd, subject, mcpc);
		codeModified = 1;
	}
	return isYoungObject(subject);
}

static sqInt
v3PushNilSize(sqInt aMethodObj)
{
	// StackToRegisterMappingCogit>>#v3PushNilSize:
	return 1;
}

static sqInt
v3BlockCodeSize(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	// SimpleStackBasedCogit>>#v3:Block:Code:Size:
	assert(nExts <= 0);
	return ((fetchByteofObject(pc + 2, aMethodObj)) << 8) + (fetchByteofObject(pc + 3, aMethodObj));
}

static sqInt
v3IsPushNil(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	// StackToRegisterMappingCogit>>#v3:Is:Push:Nil:
	return ((descriptor->generator)) == genPushConstantNilBytecode;
}


/*	Answer the distance of a two byte forward long jump. */

static sqInt
v3LongForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	// SimpleStackBasedCogit>>#v3:LongForward:Branch:Distance:
	assert(nExts == 0);
	return (((fetchByteofObject(pc, aMethodObj)) & 3) << 8) + (fetchByteofObject(pc + 1, aMethodObj));
}


/*	Answer the distance of a two byte forward long jump. */

static sqInt
v3LongBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	// SimpleStackBasedCogit>>#v3:Long:Branch:Distance:
	assert(nExts == 0);
	return ((((fetchByteofObject(pc, aMethodObj)) & 7) - 4) << 8) + (fetchByteofObject(pc + 1, aMethodObj));
}


/*	N.B. This serves for both BlueBook/V3 and V4 short jumps. */

static sqInt
v3ShortForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	// SimpleStackBasedCogit>>#v3:ShortForward:Branch:Distance:
	assert(nExts == 0);
	return ((fetchByteofObject(pc, aMethodObj)) & 7) + 1;
}

void
voidCogCompiledCode(void)
{
	// SimpleStackBasedCogit>>#voidCogCompiledCode
    sqInt i;

	clearCogCompiledCode();
	for (i = 0; i <= MaxNumArgs; i += 1) {
externalPrimJumpOffsets[i] = null;
		externalPrimCallOffsets[i] = null;
	}
}

static void
voidYoungReferrersPostTenureAll(void)
{
	// CogMethodZone>>#voidYoungReferrersPostTenureAll
    CogMethod *cogMethod;
    usqInt pointer;

	assert(youngReferrers <= limitAddress);
	pointer = youngReferrers;
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (((cogMethod->cmType)) != CMFree) {
			(cogMethod->cmRefersToYoung = 0);
		}
		pointer += BytesPerWord;
	}
	youngReferrers = limitAddress;
}

char *
whereIsMaybeCodeThing(sqInt anOop)
{
	// CogMethodZone>>#whereIsMaybeCodeThing:
	if (((((usqInt) anOop)) >= (((usqInt) baseAddress)))
	 && ((((usqInt) anOop)) < (((usqInt) limitAddress)))) {
		if (oopisLessThan(anOop, minCogMethodAddress())) {
			return " is in generated runtime";
		}
		if ((((usqInt) anOop)) < (((usqInt) mzFreeStart))) {
			return " is in generated methods";
		}
		if ((((usqInt) anOop)) < (((usqInt) youngReferrers))) {
			return " is in code zone";
		}
		return " is in young referrers";
	}
	return null;
}

static AbstractInstruction *
gXorCwR(sqInt wordConstant, sqInt reg)
{
	// Cogit>>#XorCw:R:
	return genoperandoperand(XorCwR, wordConstant, reg);
}


/*	Access for the object representations when they need to prepend code to
	trampolines. 
 */

static void
zeroOpcodeIndex(void)
{
	// Cogit>>#zeroOpcodeIndex
	opcodeIndex = 0;
}
